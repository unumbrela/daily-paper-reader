{
  "top_k": 200,
  "generated_at": "2026-02-27T20:22:00.321473+00:00",
  "papers": [
    {
      "id": "2601.14693v1",
      "title": "Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning",
      "abstract": "Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.",
      "authors": [
        "Jianwen Sun",
        "Xinrui Li",
        "Fuqing Li",
        "Xiaoxuan Shen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21T06:08:37+00:00",
      "link": "https://arxiv.org/pdf/2601.14693v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.08270v1",
      "title": "A few-shot and physically restorable symbolic regression turbulence model based on normalized general effective-viscosity hypothesis",
      "abstract": "Turbulence is a complex, irregular flow phenomenon ubiquitous in natural processes and engineering applications. The Reynolds-averaged Navier-Stokes (RANS) method, owing to its low computational cost, has become the primary approach for rapid simulation of engineering turbulence problems. However, the inaccuracy of classical turbulence models constitutes the main drawback of the RANS framework. With the rapid development of data-driven approaches, many data-driven turbulence models have been proposed, yet they still suffer from issues of generalizability and accuracy. In this work, we propose a few-shot, physically restorable, symbolic regression turbulence model based on the normalized general effective-viscosity hypothesis. Few-shot indicates that our model is trained on limited flow configurations spanning only a narrow subset of turbulent flow physics, yet can still outperform the baseline model in substantially different turbulent flows. Physically restorable means our model can nearly revert to the baseline model in regimes satisfying specific physical conditions, using only the symbolic regression training results. The normalized general effective-viscosity hypothesis was proposed in our previous study. Specifically, we first formalize the concept of few-shot data-driven turbulence models. Second, we train our symbolic regression turbulence models using only direct numerical simulation (DNS) data for three-dimensional periodic hill flow slices. Third, we evaluate our models on periodic hill flows, zero pressure gradient flat plate flow, NACA0012 airfoil flows, and NASA Rotor 37 transonic axial compressor flows. One of our symbolic regression turbulence models consistently outperforms the baseline model, and we further demonstrate that this model can nearly revert to baseline behavior in certain flow regimes.",
      "authors": [
        "Ziqi Ji",
        "Penghao Duan",
        "Gang Du"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-02-09T05:08:04+00:00",
      "link": "https://arxiv.org/pdf/2602.08270v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR"
      ]
    },
    {
      "id": "2602.08885v3",
      "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
      "abstract": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget.",
      "authors": [
        "Paul Saegert",
        "Ullrich Köthe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "published": "2026-02-09T16:47:00+00:00",
      "link": "https://arxiv.org/pdf/2602.08885v3",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.15169v1",
      "title": "Learning the S-matrix from data: Rediscovering gravity from gauge theory via symbolic regression",
      "abstract": "We demonstrate that modern machine-learning methods can autonomously reconstruct several flagship analytic structures in scattering amplitudes directly from numerical on-shell data. In particular, we show that the Kawai--Lewellen--Tye (KLT) relations can be rediscovered using symbolic regression applied to colour-ordered Yang--Mills amplitudes with Mandelstam invariants as input features. Using standard feature-selection techniques, specifically column-pivoted QR factorisation, we simultaneously recover the Kleiss--Kuijf and Bern--Carrasco--Johansson (BCJ) relations, identifying a minimal basis of partial amplitudes without any group-theoretic input. We obtain the tree-level KLT relations with high numerical accuracy up to five external legs, using only minimal theoretical priors, and we comment on the obstacles to generalising the method to higher multiplicity. Our results establish symbolic regression as a practical tool for exploring the analytic structure of the scattering-amplitude landscape, and suggests a general data-driven strategy for uncovering hidden relations in general theories. For comparison, we benchmark this general approach with a recently introduced neural-network based method.",
      "authors": [
        "Nathan Moynihan"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "cs.LG",
        "hep-ph"
      ],
      "published": "2026-02-16T20:15:50+00:00",
      "link": "https://arxiv.org/pdf/2602.15169v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20637v1",
      "title": "An Empirical Investigation of Neural ODEs and Symbolic Regression for Dynamical Systems",
      "abstract": "Accurately modelling the dynamics of complex systems and discovering their governing differential equations are critical tasks for accelerating scientific discovery. Using noisy, synthetic data from two damped oscillatory systems, we explore the extrapolation capabilities of Neural Ordinary Differential Equations (NODEs) and the ability of Symbolic Regression (SR) to recover the underlying equations. Our study yields three key insights. First, we demonstrate that NODEs can extrapolate effectively to new boundary conditions, provided the resulting trajectories share dynamic similarity with the training data. Second, SR successfully recovers the equations from noisy ground-truth data, though its performance is contingent on the correct selection of input variables. Finally, we find that SR recovers two out of the three governing equations, along with a good approximation for the third, when using data generated by a NODE trained on just 10% of the full simulation. While this last finding highlights an area for future work, our results suggest that using NODEs to enrich limited data and enable symbolic regression to infer physical laws represents a promising new approach for scientific discovery.",
      "authors": [
        "Panayiotis Ioannou",
        "Pietro Liò",
        "Pietro Cicuta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-01-28T14:23:59+00:00",
      "link": "https://arxiv.org/pdf/2601.20637v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.13021v2",
      "title": "Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery",
      "abstract": "Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.",
      "authors": [
        "Jing Xiao",
        "Xinhai Chen",
        "Jiaming Peng",
        "Qinglin Wang",
        "Menghan Jia",
        "Zhiquan Lai",
        "Guangping Yu",
        "Dongsheng Li",
        "Tiejun Li",
        "Jie Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-13T15:26:21+00:00",
      "link": "https://arxiv.org/pdf/2602.13021v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03506v1",
      "title": "Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models",
      "abstract": "Following their success across many domains, transformers have also proven effective for symbolic regression (SR); however, the internal mechanisms underlying their generation of mathematical operators remain largely unexplored. Although mechanistic interpretability has successfully identified circuits in language and vision models, it has not yet been applied to SR. In this article, we introduce PATCHES, an evolutionary circuit discovery algorithm that identifies compact and correct circuits for SR. Using PATCHES, we isolate 28 circuits, providing the first circuit-level characterisation of an SR transformer. We validate these findings through a robust causal evaluation framework based on key notions such as faithfulness, completeness, and minimality. Our analysis shows that mean patching with performance-based evaluation most reliably isolates functionally correct circuits. In contrast, we demonstrate that direct logit attribution and probing classifiers primarily capture correlational features rather than causal ones, limiting their utility for circuit discovery. Overall, these results establish SR as a high-potential application domain for mechanistic interpretability and propose a principled methodology for circuit discovery.",
      "authors": [
        "Arco van Breda",
        "Erman Acar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T13:27:10+00:00",
      "link": "https://arxiv.org/pdf/2602.03506v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.00031v1",
      "title": "Optimal Control-Based Falsification of Learnt Dynamics via Neural ODEs and Symbolic Regression",
      "abstract": "We present a falsification framework that integrates learned surrogate dynamics with optimal control to efficiently generate counterexamples for cyber-physical systems specified in signal temporal logic (STL). The unknown system dynamics are identified using neural ODEs, while known a-priori structure is embedded directly into the model, reducing data requirements. The learned neural ODE is converted into an analytical form via symbolic regression, enabling fast and interpretable trajectory optimization. Falsification is cast as minimizing STL robustness over input trajectories; negative robustness yields candidate counterexamples, which are validated on the original system. Spurious traces are iteratively used to refine the surrogate, while true counterexamples are returned as final results. Experiments on ARCH-COMP 2024 benchmarks show that this method requires orders of magnitude fewer experiments of the system under test than optimization-based approaches that do not model system dynamics.",
      "authors": [
        "Lasse Kötz",
        "Jonas Sjöberg",
        "Knut Åkesson"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-18T13:23:35+00:00",
      "link": "https://arxiv.org/pdf/2602.00031v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07727v1",
      "title": "Learning the relations between neutron star and nuclear matter properties with symbolic regression",
      "abstract": "The equation of state (EOS) of dense matter in neutron stars (NSs) remains uncertain, particularly at supra-nuclear densities where complex nuclear interactions and the potential presence of exotic matter, like hyperons, come into play. The complex relationships existing between nuclear matter and neutron star properties are investigated. The focus is on their nonlinearities and interdependencies. In our analysis, we apply a machine learning algorithm known as symbolic regression, paired with principal component analysis, to datasets generated from Bayesian inference over relativistic mean-field models. A systematic Principal Component Analysis has allowed to break down the percentage contribution of each element or feature in the relationships obtained. This study examines two main models (datasets): the NL model, which includes nucleonic degrees of freedom; and the NL-hyp model, which includes hyperons in addition to nucleons. Our analysis confirms a robust correlation between the tidal deformability of a 1.4 \\(M_\\odot\\) neutron star and $β$-equilibrium pressure at twice the nuclear saturation density. This correlation remains once hyperons are included. The contribution of the different nuclear matter properties at saturation to the radius and tidal deformability was calculated. It was shown that the isovector properties have the largest impact, with a contribution of about 90\\%. We also studied the relationship between the proton fraction at different densities and various symmetry energy parameters defined at saturation density. For the hyperon data set, we took into account the effects of the negatively charged hyperon $Ξ$ in order to recover the relationships. Our study reveals the individual impact of various symmetry energy parameters on proton fractions at different densities.",
      "authors": [
        "N. K. Patra",
        "Tuhin Malik",
        "Kai Zhou",
        "Constança Providência"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "astro-ph.SR",
        "gr-qc",
        "hep-ph",
        "nucl-ex"
      ],
      "published": "2026-01-12T16:58:40+00:00",
      "link": "https://arxiv.org/pdf/2601.07727v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.17082v1",
      "title": "Order of Magnitude Analysis and Data-Based Physics-Informed Symbolic Regression for Turbulent Pipe Flow",
      "abstract": "Friction losses in rough pipes are often predicted using semi-empirical correlations, such as the Colebrook-White equation (Colebrook,1939), which do not fully replicate Nikuradse's rough-pipe experiments (1950). This study derives scaling relations for the viscous and turbulent contributions to the streamwise pressure drop through an order-of-magnitude analysis of the Reynolds-averaged Navier-Stokes equations and the kinetic-energy transport equations. These relations impose constraints on the local sensitivity of the pressure drop to factors such as mean velocity, roughness, viscosity, and density through exponent envelopes and serve as a physical prior for symbolic regression. By combining Nikuradse's rough-pipe and smooth-pipe data of Zagarola and Smits (1998), we aim to derive compact correlations for the friction factor that fit experimental data while adhering to the derived constraints. A modified genetic programming engine (GPTIPS2) optimizes model structure and evaluates it based on fitness, complexity, and constraint violation. This method yields interpretable expressions that accurately reproduce friction factors across various roughness levels and Reynolds numbers, validated up to $Re \\sim 10^7$.",
      "authors": [
        "Yunus Emre Ünal",
        "Özgür Ertunç",
        "Ismail Ari",
        "Ivan Otić"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn",
        "physics.comp-ph"
      ],
      "published": "2026-02-19T05:02:58+00:00",
      "link": "https://arxiv.org/pdf/2602.17082v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01510v1",
      "title": "Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization",
      "abstract": "Genetic programming-based feature construction has achieved significant success in recent years as an automated machine learning technique to enhance learning performance. However, overfitting remains a challenge that limits its broader applicability. To improve generalization, we prove that vicinal risk, estimated through noise perturbation or mixup-based data augmentation, is bounded by the sum of empirical risk and a regularization term-either finite difference or the vicinal Jensen gap. Leveraging this decomposition, we propose an evolutionary feature construction framework that jointly optimizes empirical risk and the vicinal Jensen gap to control overfitting. Since datasets may vary in noise levels, we develop a noise estimation strategy to dynamically adjust regularization strength. Furthermore, to mitigate manifold intrusion-where data augmentation may generate unrealistic samples that fall outside the data manifold-we propose a manifold intrusion detection mechanism. Experimental results on 58 datasets demonstrate the effectiveness of Jensen gap minimization compared to other complexity measures. Comparisons with 15 machine learning algorithms further indicate that genetic programming with the proposed overfitting control strategy achieves superior performance.",
      "authors": [
        "Hengzhe Zhang",
        "Qi Chen",
        "Bing Xue",
        "Wolfgang Banzhaf",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-02-02T00:46:16+00:00",
      "link": "https://arxiv.org/pdf/2602.01510v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22328v1",
      "title": "Knowledge-Informed Kernel State Reconstruction for Interpretable Dynamical System Discovery",
      "abstract": "Recovering governing equations from data is central to scientific discovery, yet existing methods often break down under noisy, partial observations, or rely on black-box latent dynamics that obscure mechanism. We introduce MAAT (Model Aware Approximation of Trajectories), a framework for symbolic discovery built on knowledge-informed Kernel State Reconstruction. MAAT formulates state reconstruction in a reproducing kernel Hilbert space and directly incorporates structural and semantic priors such as non-negativity, conservation laws, and domain-specific observation models into the reconstruction objective, while accommodating heterogeneous sampling and measurement granularity. This yields smooth, physically consistent state estimates with analytic time derivatives, providing a principled interface between fragmented sensor data and symbolic regression. Across twelve diverse scientific benchmarks and multiple noise regimes, MAAT substantially reduces state-estimation MSE for trajectories and derivatives used by downstream symbolic regression relative to strong baselines.",
      "authors": [
        "Luca Muscarnera",
        "Silas Ruhrberg Estévez",
        "Samuel Holt",
        "Evgeny Saveliev",
        "Mihaela van der Schaar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T21:15:52+00:00",
      "link": "https://arxiv.org/pdf/2601.22328v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21789v1",
      "title": "ECSEL: Explainable Classification via Signomial Equation Learning",
      "abstract": "We introduce ECSEL, an explainable classification method that learns formal expressions in the form of signomial equations, motivated by the observation that many symbolic regression benchmarks admit compact signomial structure. ECSEL directly constructs a structural, closed-form expression that serves as both a classifier and an explanation. On standard symbolic regression benchmarks, our method recovers a larger fraction of target equations than competing state-of-the-art approaches while requiring substantially less computation. Leveraging this efficiency, ECSEL achieves classification accuracy competitive with established machine learning models without sacrificing interpretability. Further, we show that ECSEL satisfies some desirable properties regarding global feature behavior, decision-boundary analysis, and local feature attributions. Experiments on benchmark datasets and two real-world case studies i.e., e-commerce and fraud detection, demonstrate that the learned equations expose dataset biases, support counterfactual reasoning, and yield actionable insights.",
      "authors": [
        "Adia Lumadjeng",
        "Ilker Birbil",
        "Erman Acar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-29T14:35:43+00:00",
      "link": "https://arxiv.org/pdf/2601.21789v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02311v1",
      "title": "Introns and Templates Matter: Rethinking Linkage in GP-GOMEA",
      "abstract": "GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.",
      "authors": [
        "Johannes Koch",
        "Tanja Alderliesten",
        "Peter A. N. Bosman"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-02T16:42:30+00:00",
      "link": "https://arxiv.org/pdf/2602.02311v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.19477v1",
      "title": "ROIDS: Robust Outlier-Aware Informed Down-Sampling",
      "abstract": "Informed down-sampling (IDS) is known to improve performance in symbolic regression when combined with various selection strategies, especially tournament selection. However, recent work found that IDS's gains are not consistent across all problems. Our analysis reveals that IDS performance is worse for problems containing outliers. IDS systematically favors including outliers in subsets which pushes GP towards finding solutions that overfit to outliers. To address this, we introduce ROIDS (Robust Outlier-Aware Informed Down-Sampling), which excludes potential outliers from the sampling process of IDS. With ROIDS it is possible to keep the advantages of IDS without overfitting to outliers and to compete on a wide range of benchmark problems. This is also reflected in our experiments in which ROIDS shows the desired behavior on all studied benchmark problems. ROIDS consistently outperforms IDS on synthetic problems with added outliers as well as on a wide range of complex real-world problems, surpassing IDS on over 80% of the real-world benchmark problems. Moreover, compared to all studied baseline approaches, ROIDS achieves the best average rank across all tested benchmark problems. This robust behavior makes ROIDS a reliable down-sampling method for selection in symbolic regression, especially when outliers may be included in the data set.",
      "authors": [
        "Alina Geiger",
        "Martin Briesch",
        "Dominik Sobania",
        "Franz Rothlauf"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-27T11:07:47+00:00",
      "link": "https://arxiv.org/pdf/2601.19477v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.16852v1",
      "title": "Charting the Landscape of Oxygen Ion Conductors: A 60-Year Dataset with Interpretable Regression Models",
      "abstract": "Oxygen ion conductors are indispensable materials for such as solid oxide fuel cells, sensors, and membranes. Despite extensive research across diverse structural families, systematic data enabling comparative analysis remain scarce. Here, we present a curated dataset of oxygen ion conductors compiled from $84$ experimental reports spanning $60$ years, covering $483$ materials. Each record includes activation energy ($E_a$) and prefactor ($A$) derived from Arrhenius plots, alongside detailed metadata on structure, composition, measurement method, and data source. When the original papers derive these using an erroneous Arrhenius equation $σ_T=A\\exp{\\left(-\\frac{E_a}{RT}\\right)}$, where ($σ_T$ is the oxygen ion conductivity at temperature $T$ and $R$ is the gas constant), we replotted these using the correct one, $σ_{T}T=A\\exp{\\left(-\\frac{E_a}{RT}\\right)}$. To illustrate how the database can be used, we constructed interpretable regression models for predicting oxygen ionic conductivity. Two symbolic regression models for E_a and A suggest that oxygen ion transport is primarily governed by local coordination environment and the electrostatic interactions, respectively. This dataset establishes a reliable foundation for data-driven discovery and predictive modeling of next-generation oxygen ion conductors.",
      "authors": [
        "Seong-Hoon Jang",
        "Shin Kiyohara",
        "Hitoshi Takamura",
        "Yu Kumagai"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-23T16:00:58+00:00",
      "link": "https://arxiv.org/pdf/2601.16852v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-12T18:49:27+00:00",
      "link": "https://arxiv.org/pdf/2602.12259v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.08733v1",
      "title": "Foundation Inference Models for Ordinary Differential Equations",
      "abstract": "Ordinary differential equations (ODEs) are central to scientific modelling, but inferring their vector fields from noisy trajectories remains challenging. Current approaches such as symbolic regression, Gaussian process (GP) regression, and Neural ODEs often require complex training pipelines and substantial machine learning expertise, or they depend strongly on system-specific prior knowledge. We propose FIM-ODE, a pretrained Foundation Inference Model that amortises low-dimensional ODE inference by predicting the vector field directly from noisy trajectory data in a single forward pass. We pretrain FIM-ODE on a prior distribution over ODEs with low-degree polynomial vector fields and represent the target field with neural operators. FIM-ODE achieves strong zero-shot performance, matching and often improving upon ODEFormer, a recent pretrained symbolic baseline, across a range of regimes despite using a simpler pretraining prior distribution. Pretraining also provides a strong initialisation for finetuning, enabling fast and stable adaptation that outperforms modern neural and GP baselines without requiring machine learning expertise.",
      "authors": [
        "Maximilian Mauel",
        "Johannes R. Hübers",
        "David Berghaus",
        "Patrick Seifner",
        "Ramses J. Sanchez"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09T14:39:11+00:00",
      "link": "https://arxiv.org/pdf/2602.08733v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07834v1",
      "title": "Interpretable Analytic Calabi-Yau Metrics via Symbolic Distillation",
      "abstract": "Calabi--Yau manifolds are essential for string theory but require computing intractable metrics. Here we show that symbolic regression can distill neural approximations into simple, interpretable formulas. Our five-term expression matches neural accuracy ($R^2 = 0.9994$) with 3,000-fold fewer parameters. Multi-seed validation confirms that geometric constraints select essential features, specifically power sums and symmetric polynomials, while permitting structural diversity. The functional form can be maintained across the studied moduli range ($ψ\\in [0, 0.8]$) with coefficients varying smoothly; we interpret these trends as empirical hypotheses within the accuracy regime of the locally-trained teachers ($σ\\approx 8-9\\%$ at $ψ\\neq 0$). The formula reproduces physical observables -- volume integrals and Yukawa couplings -- validating that symbolic distillation recovers compact, interpretable models for quantities previously accessible only to black-box networks.",
      "authors": [
        "D Yang Eng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DG"
      ],
      "published": "2026-02-08T05:51:35+00:00",
      "link": "https://arxiv.org/pdf/2602.07834v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12870v1",
      "title": "GAME: Genetic Algorithms with Marginalised Ensembles for model-independent reconstruction of cosmological quantities",
      "abstract": "Genetic Algorithms (GA) are a powerful tool for stochastic optimisation and non-parametric symbolic regression, already widely used in cosmology. They are capable of reconstructing analytical functions directly from data points without introducing new physical models. A limitation of this approach is that while the reconstructed function is very efficient at reproducing the behaviour of the data points, non-observable quantities involving derivatives are particularly sensitive to stochasticity, hyperparameters, and to the choice of the best-fit function obtained by the GA, which implies the risk of the algorithm getting stuck in a local minimum. In this work we propose an update to the GA methodology for the reconstruction of analytical functions that involves computing a weighted average of an ensemble of GA configurations (\\texttt{GAME}). We define the weights via a quantity that accounts for both the goodness-of-fit of the points and the smoothness of the resulting function. We also present a practical method to analytically estimate and correct the errors on the averaged function by combining a path-integral approach with an ensemble variance. We demonstrate the improvement offered by \\texttt{GAME} methodology on a generic test function. We then apply the new methodology to a non-parametric reconstruction of the Hubble rate $H(z)$ using Cosmic Chronometers data and, assuming a flat Friedmann-Lemaître-Robertson-Walker background and General Relativity, we infer the corresponding dark energy equation of state $w(z)$. Through consistency tests, we show that current data produces results compatible with $Λ$CDM, and that Stage IV cosmology surveys will allow GA reinforced with \\texttt{GAME} methodology to become an even more competitive tool for discriminating between different models.",
      "authors": [
        "Matteo Peronaci",
        "Matteo Martinelli",
        "Savvas Nesseris"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-13T12:20:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12870v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14288v1",
      "title": "DeepInflation: an AI agent for research and model discovery of inflation",
      "abstract": "We present \\textbf{DeepInflation}, an AI agent designed for research and model discovery in inflationary cosmology. Built upon a multi-agent architecture, \\textbf{DeepInflation} integrates Large Language Models (LLMs) with a symbolic regression (SR) engine and a retrieval-augmented generation (RAG) knowledge base. This framework enables the agent to automatically explore and verify the vast landscape of inflationary potentials while grounding its outputs in established theoretical literature. We demonstrate that \\textbf{DeepInflation} can successfully discover simple and viable single-field slow-roll inflationary potentials consistent with the latest observations (here ACT DR6 results as example) or any given $n_s$ and $r$, and provide accurate theoretical context for obscure inflationary scenarios. \\textbf{DeepInflation} serves as a prototype for a new generation of autonomous scientific discovery engines in cosmology, which enables researchers and non-experts alike to explore the inflationary landscape using natural language. This agent is available at https://github.com/pengzy-cosmo/DeepInflation.",
      "authors": [
        "Ze-Yu Peng",
        "Hao-Shi Yuan",
        "Qi Lai",
        "Jun-Qian Jiang",
        "Gen Ye",
        "Jun Zhang",
        "Yun-Song Piao"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "cs.AI",
        "cs.CE",
        "gr-qc",
        "hep-th"
      ],
      "published": "2026-01-14T09:41:01+00:00",
      "link": "https://arxiv.org/pdf/2601.14288v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.16166v1",
      "title": "Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning",
      "abstract": "Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.",
      "authors": [
        "Jialin Zheng",
        "Ruhaan Batta",
        "Zhong Liu",
        "Xiaonan Lu"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-18T03:46:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16166v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01149v1",
      "title": "Robust Machine Learning Framework for Reliable Discovery of High-Performance Half-Heusler Thermoelectrics",
      "abstract": "Machine learning (ML) can facilitate efficient thermoelectric (TE) material discovery essential to address the environmental crisis. However, ML models often suffer from poor experimental generalizability despite high metrics. This study presents a robust workflow, applied to the half-Heusler (hH) structural prototype, for figure of merit (zT) prediction, to improve the generalizability of ML models. To resolve challenges in dataset handling and feature filtering, we first introduce a rigorous PCA-based splitting method that ensures training and test sets are unbiased and representative of the full chemical space. We then integrate Bayesian hyperparameter optimization with k-best feature filtering across three architectures-Random Forest, XGBoost, and Neural Networks - while employing SISSO symbolic regression for physical insight and comparison. Using SHAP and SISSO analysis, we identify A-site dopant concentration (xA'), and A-site Heat of Vaporization (HVA) as the primary drivers of zT besides Temperature (T). Finally, a high-throughput screening of approximately 6.6x10^8 potential compositions, filtered by stability constraints, yielded several novel high-zT candidates. Breaking from the traditional focus of improving test RMSE/R^2 values of the models, this work shifts the attention on establishing the test set a true proxy for model generalizability and strengthening the often neglected modules of the existing ML workflows for the data-driven design of next-generation thermoelectric materials.",
      "authors": [
        "Shoeb Athar",
        "Adrien Mecibah",
        "Philippe Jund"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ],
      "published": "2026-02-01T10:50:42+00:00",
      "link": "https://arxiv.org/pdf/2602.01149v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02886v1",
      "title": "Mixture of Concept Bottleneck Experts",
      "abstract": "Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.",
      "authors": [
        "Francesco De Santis",
        "Gabriele Ciravegna",
        "Giovanni De Felice",
        "Arianna Casanova",
        "Francesco Giannini",
        "Michelangelo Diligenti",
        "Mateo Espinosa Zarlenga",
        "Pietro Barbiero",
        "Johannes Schneider",
        "Danilo Giordano"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T22:44:42+00:00",
      "link": "https://arxiv.org/pdf/2602.02886v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.10576v1",
      "title": "LLM-Based Scientific Equation Discovery via Physics-Informed Token-Regularized Policy Optimization",
      "abstract": "Symbolic regression aims to distill mathematical equations from observational data. Recent approaches have successfully leveraged Large Language Models (LLMs) to generate equation hypotheses, capitalizing on their vast pre-trained scientific priors. However, existing frameworks predominantly treat the LLM as a static generator, relying on prompt-level guidance to steer exploration. This paradigm fails to update the model's internal representations based on search feedback, often yielding physically inconsistent or mathematically redundant expressions. In this work, we propose PiT-PO (Physics-informed Token-regularized Policy Optimization), a unified framework that evolves the LLM into an adaptive generator via reinforcement learning. Central to PiT-PO is a dual-constraint mechanism that rigorously enforces hierarchical physical validity while simultaneously applying fine-grained, token-level penalties to suppress redundant structures. Consequently, PiT-PO aligns LLM to produce equations that are both scientifically consistent and structurally parsimonious. Empirically, PiT-PO achieves state-of-the-art performance on standard benchmarks and successfully discovers novel turbulence models for challenging fluid dynamics problems. We also demonstrate that PiT-PO empowers small-scale models to outperform closed-source giants, democratizing access to high-performance scientific discovery.",
      "authors": [
        "Boxiao Wang",
        "Kai Li",
        "Tianyi Liu",
        "Chen Li",
        "Junzhe Wang",
        "Yifan Zhang",
        "Jian Cheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11T07:02:23+00:00",
      "link": "https://arxiv.org/pdf/2602.10576v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12109v1",
      "title": "A critical assessment of bonding descriptors for predicting materials properties",
      "abstract": "Most machine learning models for materials science rely on descriptors based on materials compositions and structures, even though the chemical bond has been proven to be a valuable concept for predicting materials properties. Over the years, various theoretical frameworks have been developed to characterize bonding in solid-state materials. However, integrating bonding information from these frameworks into machine learning pipelines at scale has been limited by the lack of a systematically generated and validated database. Recent advances in high-throughput bonding analysis workflows have addressed this issue, and our previously computed Quantum-Chemical Bonding Database for Solid-State Materials was extended to include approximately 13,000 materials. This database is then used to derive a new set of quantum-chemical bonding descriptors. A systematic assessment is performed using statistical significance tests to evaluate how the inclusion of these descriptors influences the performance of machine-learning models that otherwise rely solely on structure- and composition-derived features. Models are built to predict elastic, vibrational, and thermodynamic properties typically associated with chemical bonding in materials. The results demonstrate that incorporating quantum-chemical bonding descriptors not only improves predictive performance but also helps identify intuitive expressions for properties such as the projected force constant and lattice thermal conductivity via symbolic regression.",
      "authors": [
        "Aakash Ashok Naik",
        "Nidal Dhamrait",
        "Katharina Ueltzen",
        "Christina Ertural",
        "Philipp Benner",
        "Gian-Marco Rignanese",
        "Janine George"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.chem-ph",
        "physics.comp-ph"
      ],
      "published": "2026-02-12T16:00:12+00:00",
      "link": "https://arxiv.org/pdf/2602.12109v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07651v1",
      "title": "Cosmology with one galaxy: An analytic formula relating $Ω_{\\rm m}$ with galaxy properties",
      "abstract": "Standard cosmological analyses typically treat galaxy formation and cosmological parameter inference as decoupled problems, relying on population-level statistics such as clustering, lensing, or halo abundances. However, classical studies of baryon fractions in massive galaxy clusters have long suggested that gravitationally bound systems may retain cosmological information through their baryonic content. Building on this insight, we present the first analytic and physically interpretable cosmological tracer that links the matter density parameter, $Ω_m$, directly to intrinsic galaxy-scale observables, demonstrating that cosmological information can be extracted from individual galaxies. Using symbolic regression applied to state-of-the-art hydrodynamical simulations from the CAMELS project, we identify a compact functional form that robustly recovers $Ω_m$ across multiple simulation suites (IllustrisTNG, ASTRID, SIMBA, and Swift-EAGLE), requiring only modest recalibration of a small number of coefficients. The resulting expression admits a transparent physical interpretation in terms of baryonic retention and enrichment efficiency regulated by gravitational potential depth, providing a clear explanation for why $Ω_m$ is locally encoded in galaxy properties. Our work establishes a direct, interpretable bridge between small-scale galaxy physics and large-scale cosmology, opening a complementary pathway to cosmological inference that bypasses traditional clustering-based statistics and enables new synergies between galaxy formation theory and precision cosmology.",
      "authors": [
        "Kito Liao",
        "Francisco Villaescusa-Navarro",
        "Romain Teysser",
        "Natalí S. M. de Santi"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-02-07T18:23:07+00:00",
      "link": "https://arxiv.org/pdf/2602.07651v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05894v1",
      "title": "Learning microstructure in active matter",
      "abstract": "Understanding microstructure in terms of closed-form expressions is an open challenge in nonequilibrium statistical physics. We propose a simple and generic method that combines particle-resolved simulations, deep neural networks and symbolic regression to predict the pair-correlation function of passive and active particles. Our analytical closed-form results closely agree with Brownian dynamics simulations, even at relatively large packing fractions and for strong activity. The proposed method is broadly applicable, computationally efficient, and can be used to enhance the predictive power of nonequilibrium continuum theories and for designing pattern formation.",
      "authors": [
        "Writu Dasgupta",
        "Suvendu Mandal",
        "Aritra K. Mukhopadhyay",
        "Benno Liebchen"
      ],
      "primary_category": "cond-mat.soft",
      "categories": [
        "cond-mat.soft",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech"
      ],
      "published": "2026-01-09T16:11:38+00:00",
      "link": "https://arxiv.org/pdf/2601.05894v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR"
      ]
    },
    {
      "id": "2601.10379v1",
      "title": "Online identification of nonlinear time-varying systems with uncertain information",
      "abstract": "Digital twins (DTs), serving as the core enablers for real-time monitoring and predictive maintenance of complex cyber-physical systems, impose critical requirements on their virtual models: high predictive accuracy, strong interpretability, and online adaptive capability. However, existing techniques struggle to meet these demands simultaneously: Bayesian methods excel in uncertainty quantification but lack model interpretability, while interpretable symbolic identification methods (e.g., SINDy) are constrained by their offline, batch-processing nature, which make real-time updates challenging. To bridge this semantic and computational gap, this paper proposes a novel Bayesian Regression-based Symbolic Learning (BRSL) framework. The framework formulates online symbolic discovery as a unified probabilistic state-space model. By incorporating sparse horseshoe priors, model selection is transformed into a Bayesian inference task, enabling simultaneous system identification and uncertainty quantification. Furthermore, we derive an online recursive algorithm with a forgetting factor and establish precise recursive conditions that guarantee the well-posedness of the posterior distribution. These conditions also function as real-time monitors for data utility, enhancing algorithmic robustness. Additionally, a rigorous convergence analysis is provided, demonstrating the convergence of parameter estimates under persistent excitation conditions. Case studies validate the effectiveness of the proposed framework in achieving interpretable, probabilistic prediction and online learning.",
      "authors": [
        "He Ren",
        "Gaowei Yan",
        "Hang Liu",
        "Lifeng Cao",
        "Zhijun Zhao",
        "Gang Dang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-01-15T13:33:48+00:00",
      "link": "https://arxiv.org/pdf/2601.10379v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12979v2",
      "title": "The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check",
      "abstract": "The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a \"bitter lesson\": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.",
      "authors": [
        "Qingyu Lu",
        "Liang Ding",
        "Kanjian Zhang",
        "Jinxia Zhang",
        "Dacheng Tao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-19T11:45:39+00:00",
      "link": "https://arxiv.org/pdf/2601.12979v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07310v1",
      "title": "Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing",
      "abstract": "Current analysis of additive manufactured niobium-based copper alloys relies on hand annotation due to varying contrast, noise, and image artifacts present in micrographs, slowing iteration speed in alloy development. We present a filtering and segmentation algorithm for detecting precipitates in FIB cross-section micrographs, optimized using linear genetic programming (LGP), which accounts for the various artifacts. To this end, the optimization environment uses a domain-specific language for image processing to iterate on solutions. Programs in this language are a list of image-filtering blocks with tunable parameters that sequentially process an input image, allowing for reliable generation and mutation by a genetic algorithm. Our environment produces optimized human-interpretable MATLAB code representing an image filtering pipeline. Under ideal conditions--a population size of 60 and a maximum program length of 5 blocks--our system was able to find a near-human accuracy solution with an average evaluation error of 1.8% when comparing segmentations pixel-by-pixel to a human baseline using an XOR error evaluation. Our automation work enabled faster iteration cycles and furthered exploration of the material composition and processing space: our optimized pipeline algorithm processes a 3.6 megapixel image in about 2 seconds on average. This ultimately enables convergence on strong, low-activation, precipitation hardened copper alloys for additive manufactured fusion reactor parts.",
      "authors": [
        "Kyle Williams",
        "Andrew Seltzman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-07T01:59:10+00:00",
      "link": "https://arxiv.org/pdf/2602.07310v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.14485v1",
      "title": "Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling",
      "abstract": "The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.",
      "authors": [
        "Yuan Tian",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-20T21:13:11+00:00",
      "link": "https://arxiv.org/pdf/2601.14485v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15070v1",
      "title": "An effective Genetic Programming Hyper-Heuristic for Uncertain Agile Satellite Scheduling",
      "abstract": "This paper investigates a novel problem, namely the Uncertain Agile Earth Observation Satellite Scheduling Problem (UAEOSSP). Unlike the static AEOSSP, it takes into account a range of uncertain factors (e.g., task profit, resource consumption, and task visibility) in order to reflect the reality that the actual information is inherently unknown beforehand. An effective Genetic Programming Hyper-Heuristic (GPHH) is designed to automate the generation of scheduling policies. The evolved scheduling policies can be utilized to adjust plans in real time and perform exceptionally well. Experimental results demonstrate that evolved scheduling policies significantly outperform both well-designed Look-Ahead Heuristics (LAHs) and Manually Designed Heuristics (MDHs). Specifically, the policies generated by GPHH achieve an average improvement of 5.03% compared to LAHs and 8.14% compared to MDHs.",
      "authors": [
        "Yuning Chen",
        "Junhua Xue",
        "Wangqi Gu",
        "Mingyan Shao"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-02-15T02:09:57+00:00",
      "link": "https://arxiv.org/pdf/2602.15070v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.15717v1",
      "title": "Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling",
      "abstract": "Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.",
      "authors": [
        "Luyao Zhu",
        "Fangfang Zhang",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22T07:38:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15717v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.07659v1",
      "title": "Continuous Program Search",
      "abstract": "Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.   We make locality measurable by tracking action-level divergence under controlled latent perturbations, identifying an empirical trust region for behavior-local continuous variation. Using a compact trading-strategy DSL with four semantic components (long/short entry and exit), we learn a matching block-factorized embedding and compare isotropic Gaussian mutation over the full latent space to geometry-compiled mutation that restricts updates to semantically paired entry--exit subspaces and proposes directions using a learned flow-based model trained on logged mutation outcomes.   Under identical $(μ+λ)$ evolution strategies and fixed evaluation budgets across five assets, the learned mutation operator discovers strong strategies using an order of magnitude fewer evaluations and achieves the highest median out-of-sample Sharpe ratio. Although isotropic mutation occasionally attains higher peak performance, geometry-compiled mutation yields faster, more reliable progress, demonstrating that semantically aligned mutation can substantially improve search efficiency without modifying the underlying evolutionary algorithm.",
      "authors": [
        "Matthew Siper",
        "Muhammad Umair Nasir",
        "Ahmed Khalifa",
        "Lisa Soros",
        "Jay Azhang",
        "Julian Togelius"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST"
      ],
      "published": "2026-02-07T18:41:14+00:00",
      "link": "https://arxiv.org/pdf/2602.07659v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09772v1",
      "title": "Design and Evaluation of an Assisted Programming Interface for Behavior Trees in Robotics",
      "abstract": "The possibility to create reactive robot programs faster without the need for extensively trained programmers is becoming increasingly important. So far, it has not been explored how various techniques for creating Behavior Tree (BT) program representations could be combined with complete graphical user interfaces (GUIs) to allow a human user to validate and edit trees suggested by automated methods. In this paper, we introduce BEhavior TRee GUI (BETR-GUI) for creating BTs with the help of an AI assistant that combines methods using large language models, planning, genetic programming, and Bayesian optimization with a drag-and-drop editor. A user study with 60 participants shows that by combining different assistive methods, BETR-GUI enables users to perform better at solving the robot programming tasks. The results also show that humans using the full variant of BETR-GUI perform better than the AI assistant running on its own.",
      "authors": [
        "Jonathan Styrud",
        "Matteo Iovino",
        "Rebecca Stower",
        "Mart Kartašev",
        "Mikael Norrlöf",
        "Mårten Björkman",
        "Christian Smith"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-10T13:34:00+00:00",
      "link": "https://arxiv.org/pdf/2602.09772v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.15738v1",
      "title": "LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling",
      "abstract": "Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.",
      "authors": [
        "Junhao Qiu",
        "Haoyang Zhuang",
        "Fei Liu",
        "Jianjun Liu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-22T08:06:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15738v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10891v1",
      "title": "Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search",
      "abstract": "Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires extensive domain expertise. LLM-based curriculum generation has only recently emerged as a potential solution, but was limited to operate in static, offline modes without leveraging real-time feedback from the optimizer. Here we propose an interactive LLM-assisted framework for online curriculum generation, where the LLM adaptively designs training cases based on real-time feedback from the evolutionary optimization process. We investigate how different feedback modalities, ranging from numeric metrics alone to combinations with plots and behavior visualizations, influence the LLM ability to generate meaningful curricula. Through a 2D robot navigation case study, tackled with genetic programming as optimizer, we evaluate our approach against static LLM-generated curricula and expert-designed baselines. We show that interactive curriculum generation outperforms static approaches, with multimodal feedback incorporating both progression plots and behavior visualizations yielding performance competitive with expert-designed curricula. This work contributes to understanding how LLMs can serve as interactive curriculum designers for embodied AI systems, with potential extensions to broader evolutionary robotics applications.",
      "authors": [
        "Berfin Sakallioglu",
        "Giorgia Nadizar",
        "Eric Medvet"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-02-11T14:21:52+00:00",
      "link": "https://arxiv.org/pdf/2602.10891v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03840v1",
      "title": "Investigating Quantum Circuit Designs Using Neuro-Evolution",
      "abstract": "Designing effective quantum circuits remains a central challenge in quantum computing, as circuit structure strongly influences expressivity, trainability, and hardware feasibility. Current approaches, whether using manually designed circuit templates, fixed heuristics, or automated rules, face limitations in scalability, flexibility, and adaptability, often producing circuits that are poorly matched to the specific problem or quantum hardware. In this work, we propose the Evolutionary eXploration of Augmenting Quantum Circuits (EXAQC), an evolutionary approach to the automated design and training of parameterized quantum circuits (PQCs) which leverages and extends on strategies from neuroevolution and genetic programming. The proposed method jointly searches over gate types, qubit connectivity, parameterization, and circuit depth while respecting hardware and noise constraints. The method supports both Qiskit and Pennylane libraries, allowing the user to configure every aspect. This work highlights evolutionary search as a critical tool for advancing quantum machine learning and variational quantum algorithms, providing a principled pathway toward scalable, problem-aware, and hardware-efficient quantum circuit design. Preliminary results demonstrate that circuits evolved on classification tasks are able to achieve over 90% accuracy on most of the benchmark datasets with a limited computational budget, and are able to emulate target circuit quantum states with high fidelity scores.",
      "authors": [
        "Devroop Kar",
        "Daniel Krutz",
        "Travis Desell"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-03T18:57:39+00:00",
      "link": "https://arxiv.org/pdf/2602.03840v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.04529v1",
      "title": "Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization",
      "abstract": "The advent of Large Language Models (LLMs) has opened new frontiers in automated algorithm design, giving rise to numerous powerful methods. However, these approaches retain critical limitations: they require extensive evaluation of the target problem to guide the search process, making them impractical for real-world optimization tasks, where each evaluation consumes substantial computational resources. This research proposes an innovative and efficient framework that decouples algorithm discovery from high-cost evaluation. Our core innovation lies in combining a Genetic Programming (GP) function generator with an LLM-driven evolutionary algorithm designer. The evolutionary direction of the GP-based function generator is guided by the similarity between the landscape characteristics of generated proxy functions and those of real-world problems, ensuring that algorithms discovered via proxy functions exhibit comparable performance on real-world problems. Our method enables deep exploration of the algorithmic space before final validation while avoiding costly real-world evaluations. We validated the framework's efficacy across multiple real-world problems, demonstrating its ability to discover high-performance algorithms while substantially reducing expensive evaluations. This approach shows a path to apply LLM-based automated algorithm design to computationally intensive real-world optimization challenges.",
      "authors": [
        "Haoran Yin",
        "Shuaiqun Pan",
        "Zhao Wei",
        "Jian Cheng Wong",
        "Yew-Soon Ong",
        "Anna V. Kononova",
        "Thomas Bäck",
        "Niki van Stein"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-04T13:18:45+00:00",
      "link": "https://arxiv.org/pdf/2602.04529v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00843v1",
      "title": "NegaBent, No Regrets: Evolving Spectrally Flat Boolean Functions",
      "abstract": "Negabent Boolean functions are defined by having a flat magnitude spectrum under the nega-Hadamard transform. They exist in both even and odd dimensions, and the subclass of functions that are simultaneously bent and negabent (bent-negabent) has attracted interest due to the combined optimal periodic and negaperiodic spectral properties. In this work, we investigate how evolutionary algorithms can be used to evolve (bent-)negabent Boolean functions. Our experimental results indicate that evolutionary algorithms, especially genetic programming, are a suitable approach for evolving negabent Boolean functions, and we successfully evolve such functions in all dimensions we consider.",
      "authors": [
        "Claude Carlet",
        "Marko Ðurasevic",
        "Ermes Franch",
        "Domagoj Jakobovic",
        "Luca Mariot",
        "Stjepan Picek"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.CR"
      ],
      "published": "2026-01-31T18:13:03+00:00",
      "link": "https://arxiv.org/pdf/2602.00843v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00755v1",
      "title": "Evolving Interpretable Constitutions for Multi-Agent Coordination",
      "abstract": "Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (\"be helpful, harmless, honest\") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed.",
      "authors": [
        "Ujwal Kumar",
        "Alice Saito",
        "Hershraj Niranjani",
        "Rayan Yessou",
        "Phan Xuan Tan"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-31T14:41:43+00:00",
      "link": "https://arxiv.org/pdf/2602.00755v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.08657v1",
      "title": "NEVO-GSPT: Population-Based Neural Network Evolution Using Inflate and Deflate Operators",
      "abstract": "Evolving neural network architectures is a computationally demanding process. Traditional methods often require an extensive search through large architectural spaces and offer limited understanding of how structural modifications influence model behavior. This paper introduces \\gls{ngspt}, a novel Neuroevolution algorithm based on two key innovations. First, we adapt geometric semantic operators~(GSOs) from genetic programming to neural network evolution, ensuring that architectural changes produce predictable effects on network semantics within a unimodal error surface. Second, we introduce a novel operator (DGSM) that enables controlled reduction of network size, while maintaining the semantic properties of~GSOs. Unlike traditional approaches, \\gls{ngspt}'s efficient evaluation mechanism, which only requires computing the semantics of newly added components, allows for efficient population-based training, resulting in a comprehensive exploration of the search space at a fraction of the computational cost. Experimental results on four regression benchmarks show that \\gls{ngspt} consistently evolves compact neural networks that achieve performance comparable to or better than established methods in the literature, such as standard neural networks, SLIM-GSGP, TensorNEAT, and SLM.",
      "authors": [
        "Davide Farinati",
        "Frederico J. J. B. Santos",
        "Leonardo Vanneschi",
        "Mauro Castelli"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-13T15:35:16+00:00",
      "link": "https://arxiv.org/pdf/2601.08657v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13864v1",
      "title": "Evolving Multi-Channel Confidence-Aware Activation Functions for Missing Data with Channel Propagation",
      "abstract": "Learning in the presence of missing data can result in biased predictions and poor generalizability, among other difficulties, which data imputation methods only partially address. In neural networks, activation functions significantly affect performance yet typical options (e.g., ReLU, Swish) operate only on feature values and do not account for missingness indicators or confidence scores. We propose Three-Channel Evolved Activations (3C-EA), which we evolve using Genetic Programming to produce multivariate activation functions f(x, m, c) in the form of trees that take (i) the feature value x, (ii) a missingness indicator m, and (iii) an imputation confidence score c. To make these activations useful beyond the input layer, we introduce ChannelProp, an algorithm that deterministically propagates missingness and confidence values via linear layers based on weight magnitudes, retaining reliability signals throughout the network. We evaluate 3C-EA and ChannelProp on datasets with natural and injected (MCAR/MAR/MNAR) missingness at multiple rates under identical preprocessing and splits. Results indicate that integrating missingness and confidence inputs into the activation search improves classification performance under missingness.",
      "authors": [
        "Naeem Shahabi Sani",
        "Ferial Najiantabriz",
        "Shayan Shafaei",
        "Dean F. Hougen"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-14T19:52:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13864v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.10740v1",
      "title": "Neuro-Symbolic Activation Discovery: Transferring Mathematical Structures from Physics to Ecology for Parameter-Efficient Neural Networks",
      "abstract": "Modern neural networks rely on generic activation functions (ReLU, GELU, SiLU) that ignore the mathematical structure inherent in scientific data. We propose Neuro-Symbolic Activation Discovery, a framework that uses Genetic Programming to extract interpretable mathematical formulas from data and inject them as custom activation functions. Our key contribution is the discovery of a Geometric Transfer phenomenon: activation functions learned from particle physics data successfully generalize to ecological classification, outperforming standard activations (ReLU, GELU, SiLU) in both accuracy and parameter efficiency. On the Forest Cover dataset, our Hybrid Transfer model achieves 82.4% accuracy with only 5,825 parameters, compared to 83.4% accuracy requiring 31,801 parameters for a conventional heavy network -- a 5.5x parameter reduction with only 1% accuracy loss. We introduce a Parameter Efficiency Score ($E_{param} = AUC / \\log_{10}(Params)$) and demonstrate that lightweight hybrid architectures consistently achieve 18-21% higher efficiency than over-parameterized baselines. Crucially, we establish boundary conditions: while Physics to Ecology transfer succeeds (both involve continuous Euclidean measurements), Physics to Text transfer fails (discrete word frequencies require different mathematical structures). Our work opens pathways toward domain-specific activation libraries for efficient scientific machine learning.",
      "authors": [
        "Anas Hajbi"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-10T02:49:32+00:00",
      "link": "https://arxiv.org/pdf/2601.10740v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13410v1",
      "title": "Evolutionary design of thermodynamic logic gates and their heat emission",
      "abstract": "Landauer's principle bounds the heat generated by logical operations, but in practice the thermodynamic cost of computation is dominated by the control systems that implement logic. CMOS gates dissipate energy far above the Landauer bound, while laboratory demonstrations of near-Landauer erasure rely on external measurement or feedback systems whose energy costs exceed that of the logic operation by many orders of magnitude. Here we use simulations to show that a genetic algorithm can program a thermodynamic computer to implement logic operations in which the total heat emitted by the control system is of a similar order of magnitude to that of the information-bearing degrees of freedom. Moreover, the computer can be programmed so that heat is drawn away from the information-bearing degrees of freedom and dissipated within the control unit, suggesting the possibility of computing architectures in which heat management is an integral part of the program design.",
      "authors": [
        "Stephen Whitelam"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cs.NE"
      ],
      "published": "2026-02-13T19:17:56+00:00",
      "link": "https://arxiv.org/pdf/2602.13410v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.14480v1",
      "title": "A benchmarking framework for PON-based fronthaul network design",
      "abstract": "As mobile networks transition toward 5G and 6G RAN architectures, Passive Optical Networks (PONs) offer a critical solution for cost-effective fronthaul transport. However, the lack of standardized evaluation models in current literature makes an objective comparison of diverse optimization strategies difficult. This paper addresses this gap by proposing a unified benchmarking framework that standardizes cost catalogs and deployment scenarios. We formulate the network design problem using Integer Linear Programming (ILP) to establish optimality bounds and evaluate three scalable heuristic strategies: a Genetic Algorithm, K-Means Clustering (KMC+), and a graph-based Randomized Successive Splitter Assignment (RSSA+) algorithm. Simulation results show that a time-limited ILP remains a strong reference point, even when optimality is not reached. Despite being rarely used in prior fronthaul planning studies, it consistently yields solutions superior to those produced by standard heuristic methods. Among scalable approaches, RSSA+ reliably attains near-ILP performance while ensuring feasibility across all evaluated scenarios, which underscores the importance of advanced, constraint-aware algorithmic designs over simpler heuristics. The complete benchmarking framework and datasets are publicly shared in [1].",
      "authors": [
        "Egemen Erbayat",
        "Gustavo B. Figueiredo",
        "Shih-Chun Lin",
        "Motoharu Matsuura",
        "Hiroshi Hasegawa",
        "Suresh Subramaniam"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-20T21:03:15+00:00",
      "link": "https://arxiv.org/pdf/2601.14480v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.04901v1",
      "title": "Beyond Independent Genes: Learning Module-Inductive Representations for Gene Perturbation Prediction",
      "abstract": "Predicting transcriptional responses to genetic perturbations is a central problem in functional genomics. In practice, perturbation responses are rarely gene-independent but instead manifest as coordinated, program-level transcriptional changes among functionally related genes. However, most existing methods do not explicitly model such coordination, due to gene-wise modeling paradigms and reliance on static biological priors that cannot capture dynamic program reorganization. To address these limitations, we propose scBIG, a module-inductive perturbation prediction framework that explicitly models coordinated gene programs. scBIG induces coherent gene programs from data via Gene-Relation Clustering, captures inter-program interactions through a Gene-Cluster-Aware Encoder, and preserves modular coordination using structure-aware alignment objectives. These structured representations are then modeled using conditional flow matching to enable flexible and generalizable perturbation prediction. Extensive experiments on multiple single-cell perturbation benchmarks show that scBIG consistently outperforms state-of-the-art methods, particularly on unseen and combinatorial perturbation settings, achieving an average improvement of 6.7% over the strongest baselines.",
      "authors": [
        "Jiafa Ruan",
        "Ruijie Quan",
        "Zongxin Yang",
        "Liyang Xu",
        "Yi Yang"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN",
        "cs.LG"
      ],
      "published": "2026-02-03T16:43:40+00:00",
      "link": "https://arxiv.org/pdf/2602.04901v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.12274v1",
      "title": "Hybrid Concolic Testing with Large Language Models for Guided Path Exploration",
      "abstract": "Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.",
      "authors": [
        "Mahdi Eslamimehr"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-18T06:09:18+00:00",
      "link": "https://arxiv.org/pdf/2601.12274v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11487v1",
      "title": "Search-Based Quantum Program Testing via Commuting Pauli String",
      "abstract": "Quantum software testing is important for reliable quantum software engineering. Despite recent advances, existing quantum software testing approaches rely on simple test inputs and statistical oracles, costly program specifications, and limited validation on real quantum computers. To address these challenges, we propose SB-QOPS, a search-based quantum program testing approach via commuting Pauli strings. SB-QOPS, as a direct extension to a previously proposed QOPS approach, redefines test cases in terms of Pauli strings and introduces a measurement-centric oracle that exploits their commutation properties, enabling effective testing of quantum programs while reducing the need for full program specifications. By systematically exploring the search space through an expectation-value-based fitness function, SB-QOPS improves test budget utilization and increases the likelihood of uncovering subtle faults. We conduct a large-scale empirical evaluation on quantum circuits of up to 29 qubits on real quantum computers and emulators. We assess three search strategies: Genetic Algorithm, Hill Climbing, and the (1+1) Evolutionary Algorithm, and evaluate SB-QOPS under both simulated and real noisy conditions. Experiments span three quantum computing platforms: IBM, IQM, and Quantinuum. Results show that SB-QOPS significantly outperforms QOPS, achieving a fault-detection score of 100% for circuits up to 29 qubits, and demonstrating portability across quantum platforms.",
      "authors": [
        "Asmar Muqeet",
        "Shaukat Ali",
        "Paolo Arcaini"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-12T02:13:12+00:00",
      "link": "https://arxiv.org/pdf/2602.11487v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.08884v1",
      "title": "Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting",
      "abstract": "OpenACC lowers the barrier to GPU offloading, but writing high-performing pragma remains complex, requiring deep domain expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. We present a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with model post-training. Leveraging the GEPA (GEnetic-PAreto) framework, we iteratively evolve prompts through a reflective feedback loop. This process utilizes crossover and mutation of instructions, guided by expert-curated gold examples and structured feedback based on clause- and clause parameter-level mismatches between the gold and predicted pragma. In our evaluation on the PolyBench suite, we observe an increase in compilation success rates for programs annotated with OpenACC pragma generated using the optimized prompts compared to those annotated using the simpler initial prompt, particularly for the \"nano\"-scale models. Specifically, with optimized prompts, the compilation success rate for GPT-4.1 Nano surged from 66.7% to 93.3%, and for GPT-5 Nano improved from 86.7% to 100%, matching or surpassing the capabilities of their significantly larger, more expensive versions. Beyond compilation, the optimized prompts resulted in a 21% increase in the number of programs that achieve functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs in writing stable and effective GPU-offloading directives, establishing a cost-effective pathway to automated directive-based parallelization in HPC workflows.",
      "authors": [
        "Samyak Jhaveri",
        "Cristina V. Lopes"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "published": "2026-01-12T23:54:08+00:00",
      "link": "https://arxiv.org/pdf/2601.08884v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.06820v1",
      "title": "Bgolearn: a Unified Bayesian Optimization Framework for Accelerating Materials Discovery",
      "abstract": "Efficient exploration of vast compositional and processing spaces is essential for accelerated materials discovery. Bayesian optimization (BO) provides a principled strategy for identifying optimal materials with minimal experiments, yet its adoption in materials science is hindered by implementation complexity and limited domain-specific tools. Here, we present Bgolearn, a comprehensive Python framework that makes BO accessible and practical for materials research through an intuitive interface, robust algorithms, and materials-oriented workflows. Bgolearn supports both single-objective and multi-objective Bayesian optimization with multiple acquisition functions (e.g., expected improvement, upper confidence bound, probability of improvement, and expected hypervolume improvement etc.), diverse surrogate models (including Gaussian processes, random forests, and gradient boosting etc.), and bootstrap-based uncertainty quantification. Benchmark studies show that Bgolearn reduces the number of required experiments by 40-60% compared with random search, grid search, and genetic algorithms, while maintaining comparable or superior solution quality. Its effectiveness is demonstrated not only through the studies presented in this paper, such as the identification of maximum-elastic-modulus triply periodic minimal surface structures, ultra-high-hardness high-entropy alloys, and high-strength, high-ductility medium-Mn steels, but also by numerous publications that have proven its impact in material discovery. With a modular architecture that integrates seamlessly into existing materials workflows and a graphical user interface (BgoFace) that removes programming barriers, Bgolearn establishes a practical and reliable platform for Bayesian optimization in materials science, and is openly available at https://github.com/Bin-Cao/Bgolearn.",
      "authors": [
        "Bin Cao",
        "Jie Xiong",
        "Jiaxuan Ma",
        "Yuan Tian",
        "Yirui Hu",
        "Mengwei He",
        "Longhan Zhang",
        "Jiayu Wang",
        "Jian Hui",
        "Li Liu",
        "Dezhen Xue",
        "Turab Lookman",
        "Tong-Yi Zhang"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-11T09:09:21+00:00",
      "link": "https://arxiv.org/pdf/2601.06820v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01209v1",
      "title": "Heuristics for the Worst Optimal Value of Interval Transportation Problems",
      "abstract": "An interval transportation problem represents a model for a transportation problem in which the values of supply, demand, and transportation costs are affected by uncertainty and can vary independently within given interval ranges. One of the main tasks of solving interval programming models is computing the best and worst optimal value over all possible choices of the interval data. Although the best optimal value of an interval transportation problem can be computed in polynomial time, computing the worst (finite) optimal value was proved to be NP-hard. In this paper, we strengthen a previous result showing a quasi-extreme decomposition for finding the worst optimal value, and building on the result, we design heuristics for efficiently approximating the value. Using a simplified encoding of the scenarios, we first derive a local search method and a genetic algorithm for approximating the worst optimal value. Then, we integrate the two methods into a memetic algorithm, which combines the evolutionary improvement of a genetic algorithm with individual learning implemented via local search. Moreover, we include numerical experiments for a practical comparison of the three different approaches. We also show that the proposed memetic algorithm is competitive with the available state-of-the-art methods for approximating the worst optimal value of interval transportation problems, this is demonstrated by finding the new best solutions for several instances, among others.",
      "authors": [
        "Elif Radová Garajová",
        "Miroslav Rada"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-01T13:01:38+00:00",
      "link": "https://arxiv.org/pdf/2602.01209v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20693v1",
      "title": "Drone-Aided Blood Collection Routing Problem: A Column Generation Approach",
      "abstract": "Platelet extraction requires whole blood to be processed within six hours of donation. To meet this deadline, blood collection organizations must optimally route a fleet of vehicles to pick up blood units from donation sites and deliver them to a processing center. This paper introduces a drone-aided blood collection routing problem in which a fleet of trucks, each equipped with a drone, operates in a synchronized manner to collect blood units before their processing time limit expires. Each truck-drone tandem can perform multiple trips throughout the planning horizon, allowing donation sites to be visited repeatedly as new blood units become available over time. We formulate this problem as a mixed-integer linear program that jointly optimizes the routing of trucks and drones, pickup schedules, and timing decisions to maximize the total number of viable blood units collected. We also develop a column generation approach that decomposes the problem into a master problem to select the optimal set of truck-drone tours and a pricing subproblem, which is solved using a tailored memetic algorithm to generate promising new columns. Through a comprehensive computational study, we show the operational benefits of integrating drones into the blood collection system. In addition, we demonstrate the superior performance of the proposed algorithm over Gurobi and two metaheuristics from the literature, namely the hybrid genetic algorithm and the invasive weed optimization, in both the drone-aided and truck-only settings.",
      "authors": [
        "Amirhossein Abbaszadeh",
        "Hossein Hashemi Doulabi"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-28T15:23:05+00:00",
      "link": "https://arxiv.org/pdf/2601.20693v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00429v1",
      "title": "A Hybrid Relaxation-Heuristic Framework for Solving MIP with Binary Variables",
      "abstract": "Mixed-Integer Programming (MIP), particularly Mixed-Integer Linear Programming (MILP) and Mixed-Integer Quadratic Programming (MIQP), has found extensive applications in domains such as portfolio optimization and network flow control, which inclusion of integer variables or cardinality constraints renders these problems NP-hard, posing significant computational challenges. While traditional approaches have explored approximation methods like heuristics and relaxation techniques (e.g. Lagrangian dual relaxation), the integration of these strategies within a unified hybrid framework remains underexplored. In this paper, we propose a generalized hybrid framework to address MIQP problems with binary variables, which consists of two phases: (1) a Mixed Relaxation Phase, which employs Linear Relaxation, Duality Relaxation, and Augmented Relaxation with randomized sampling to generate a diverse pre-solution pool, and (2) a Heuristic Optimization Phase, which refines the pool using Genetic Algorithms and Variable Neighborhood Search (VNS) to approximate binary solutions effectively. Becuase of the page limit, we will only detailedly evaluate the proposed framework on portfolio optimization problems using benchmark datasets from the OR Library, where the experimental results demonstrate state-of-the-art performance, highlighting the framework's ability to solve larger and more complex MIP problems efficiently. This study offers a robust and flexible methodology that bridges relaxation techniques and heuristic optimization, advancing the practical solvability of challenging MIP problems.",
      "authors": [
        "Zayn Wang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-31T00:50:30+00:00",
      "link": "https://arxiv.org/pdf/2602.00429v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.13407v2",
      "title": "A Joint Survival Modeling and Therapy Knowledge Graph Framework to Characterize Opioid Use Disorder Trajectories",
      "abstract": "Motivation: Opioid use disorder (OUD) often arises after prescription opioid exposure and follows transitions among onset, remission, and relapse. Linked EHR-survey resources such as the All of Us Research Program enable stage-specific risk modeling and connection to intervention options. Results: We built a multi-stage framework to model time-to-onset, time-to-remission, and time-to-relapse after remission using All of Us EHR and survey data. For each participant we derived longitudinal predictors from clinical conditions and survey concepts, including recent (1/3/12-month) event counts, cumulative exposures, and time since last event. We fit regularized Cox models for each transition and aggregated selection frequencies and hazard ratios to identify a compact set of high-confidence predictors. Pain, mental health, and polysubstance use contributed across stages: chronic pain syndromes, tobacco/nicotine dependence, anxiety and depressive disorders, and cannabis dependence prominently predicted onset and relapse, whereas tobacco dependence during remission and other remission-coded conditions were strongly associated with transition to remission. To support therapeutic prioritization, we constructed a therapy knowledge graph integrating genetic targets, biological pathways, and published evidence to map identified risk factors to candidate treatments in recent OUD studies and clinical guidelines.",
      "authors": [
        "Mengman Wei",
        "Stanislav Listopad",
        "Qian Peng"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2026-01-19T21:34:10+00:00",
      "link": "https://arxiv.org/pdf/2601.13407v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02710v1",
      "title": "Maximum Likelihood Reinforcement Learning",
      "abstract": "Reinforcement learning is the method of choice to train models in sampling-based setups with binary outcome feedback, such as navigation, code generation, and mathematical problem solving. In such settings, models implicitly induce a likelihood over correct rollouts. However, we observe that reinforcement learning does not maximize this likelihood, and instead optimizes only a lower-order approximation. Inspired by this observation, we introduce Maximum Likelihood Reinforcement Learning (MaxRL), a sampling-based framework to approximate maximum likelihood using reinforcement learning techniques. MaxRL addresses the challenges of non-differentiable sampling by defining a compute-indexed family of sample-based objectives that interpolate between standard reinforcement learning and exact maximum likelihood as additional sampling compute is allocated. The resulting objectives admit a simple, unbiased policy-gradient estimator and converge to maximum likelihood optimization in the infinite-compute limit. Empirically, we show that MaxRL Pareto-dominates existing methods in all models and tasks we tested, achieving up to 20x test-time scaling efficiency gains compared to its GRPO-trained counterpart. We also observe MaxRL to scale better with additional data and compute. Our results suggest MaxRL is a promising framework for scaling RL training in correctness based settings.",
      "authors": [
        "Fahim Tajwar",
        "Guanning Zeng",
        "Yueer Zhou",
        "Yuda Song",
        "Daman Arora",
        "Yiding Jiang",
        "Jeff Schneider",
        "Ruslan Salakhutdinov",
        "Haiwen Feng",
        "Andrea Zanette"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T19:23:42+00:00",
      "link": "https://arxiv.org/pdf/2602.02710v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13949v1",
      "title": "Experiential Reinforcement Learning",
      "abstract": "Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.",
      "authors": [
        "Taiwei Shi",
        "Sihao Chen",
        "Bowen Jiang",
        "Linxin Song",
        "Longqi Yang",
        "Jieyu Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15T01:23:48+00:00",
      "link": "https://arxiv.org/pdf/2602.13949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07948v1",
      "title": "Reinforcement Learning Methods for Neighborhood Selection in Local Search",
      "abstract": "Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics specifically remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies -- multi-armed bandits (upper confidence bound, $ε$-greedy) and deep reinforcement learning methods (proximal policy optimization, double deep $Q$-network) -- and compare them against multiple baselines across three different problems: the traveling salesman problem, the pickup and delivery problem with time windows, and the car sequencing problem. We show how search-specific characteristics, particularly large variations in cost due to constraint violation penalties, necessitate carefully designed reward functions to provide stable and informative learning signals. Our extensive experiments reveal that algorithm performance varies substantially across problems, although that $ε$-greedy consistently ranks among the best performers. In contrast, the computational overhead of deep reinforcement learning approaches only makes them competitive with a substantially longer runtime. These findings highlight both the promise and the practical limitations of deep reinforcement learning in local search.",
      "authors": [
        "Yannick Molinghen",
        "Augustin Delecluse",
        "Renaud De Landtsheer",
        "Stefano Michelini"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-12T19:25:29+00:00",
      "link": "https://arxiv.org/pdf/2601.07948v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.16543v1",
      "title": "Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning",
      "abstract": "Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.",
      "authors": [
        "Jialiang Fan",
        "Shixiong Jiang",
        "Mengyu Liu",
        "Fanxin Kong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-18T15:43:36+00:00",
      "link": "https://arxiv.org/pdf/2602.16543v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.07719v1",
      "title": "Efficient Planning in Reinforcement Learning via Model Introspection",
      "abstract": "Reinforcement learning and classical planning are typically seen as two distinct problems, with differing formulations necessitating different solutions. Yet, when humans are given a task, regardless of the way it is specified, they can often derive the additional information needed to solve the problem efficiently. The key to this ability is introspection: by reasoning about their internal models of the problem, humans directly synthesize additional task-relevant information. In this paper, we propose that this introspection can be thought of as program analysis. We discuss examples of how this approach can be applied to various kinds of models used in reinforcement learning. We then describe an algorithm that enables efficient goal-oriented planning over the class of models used in relational reinforcement learning, demonstrating a novel link between reinforcement learning and classical planning.",
      "authors": [
        "Gabriel Stella"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-07T21:49:21+00:00",
      "link": "https://arxiv.org/pdf/2602.07719v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18419v1",
      "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication",
      "abstract": "Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.",
      "authors": [
        "Michael Kölle",
        "Christian Reff",
        "Leo Sünkel",
        "Julian Hager",
        "Gerhard Stenzel",
        "Claudia Linnhoff-Popien"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-26T12:21:05+00:00",
      "link": "https://arxiv.org/pdf/2601.18419v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18953v1",
      "title": "Reinforcement Learning for Quantum Technology",
      "abstract": "Many challenges arising in Quantum Technology can be successfully addressed using a set of machine learning algorithms collectively known as reinforcement learning (RL), based on adaptive decision-making through interaction with the quantum device. After a concise and intuitive introduction to RL aimed at a broad physics readership, we discuss the key ideas and core concepts in reinforcement learning with a particular focus on quantum systems. We then survey recent progress in RL in all relevant areas. We discuss state preparation in few- and many-body quantum systems, the design and optimization of high-fidelity quantum gates, and the automated construction of quantum circuits, including applications to variational quantum eigensolvers and architecture search. We further highlight the interactive capabilities of RL agents, emphasizing recent progress in quantum feedback control and quantum error correction, and briefly discuss quantum reinforcement learning as well as applications to quantum metrology. The review concludes with a discussion of open challenges -- such as scalability, interpretability, and integration with experimental platforms -- and outlines promising directions for future research. Throughout, we highlight experimental implementations that exemplify the increasing role of reinforcement learning in shaping the development of quantum technologies.",
      "authors": [
        "Marin Bukov",
        "Florian Marquardt"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.quant-gas",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-26T20:47:48+00:00",
      "link": "https://arxiv.org/pdf/2601.18953v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.16475v1",
      "title": "Certifying Hamilton-Jacobi Reachability Learned via Reinforcement Learning",
      "abstract": "We present a framework to \\emph{certify} Hamilton--Jacobi (HJ) reachability learned by reinforcement learning (RL). Building on a discounted initial time \\emph{travel-cost} formulation that makes small-step RL value iteration provably equivalent to a forward Hamilton--Jacobi (HJ) equation with damping, we convert certified learning errors into calibrated inner/outer enclosures of strict backward reachable tube. The core device is an additive-offset identity: if $W_λ$ solves the discounted travel-cost Hamilton--Jacobi--Bellman (HJB) equation, then $W_\\varepsilon:=W_λ+ \\varepsilon$ solves the same PDE with a constant offset $λ\\varepsilon$. This means that a uniform value error is \\emph{exactly} equal to a constant HJB offset. We establish this uniform value error via two routes: (A) a Bellman operator-residual bound, and (B) a HJB PDE-slack bound. Our framework preserves HJ-level safety semantics and is compatible with deep RL. We demonstrate the approach on a double-integrator system by formally certifying, via satisfiability modulo theories (SMT), a value function learned through reinforcement learning to induce provably correct inner and outer backward-reachable set enclosures over a compact region of interest.",
      "authors": [
        "Prashant Solanki",
        "Isabelle El-Hajj",
        "Jasper J. van Beers",
        "Erik-Jan van Kampen",
        "Coen C. de Visser"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-02-18T14:05:17+00:00",
      "link": "https://arxiv.org/pdf/2602.16475v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07821v1",
      "title": "Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation",
      "abstract": "Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.",
      "authors": [
        "Huanyu Li",
        "Kun Lei",
        "Sheng Zang",
        "Kaizhe Hu",
        "Yongyuan Liang",
        "Bo An",
        "Xiaoli Li",
        "Huazhe Xu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-12T18:53:11+00:00",
      "link": "https://arxiv.org/pdf/2601.07821v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.06960v2",
      "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
      "abstract": "Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.",
      "authors": [
        "Yuchen Yan",
        "Liang Jiang",
        "Jin Jiang",
        "Shuaicheng Li",
        "Zujie Wen",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Jian Shao",
        "Yueting Zhuang",
        "Yongliang Shen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-06T18:59:27+00:00",
      "link": "https://arxiv.org/pdf/2602.06960v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01260v1",
      "title": "Sample Efficient Active Algorithms for Offline Reinforcement Learning",
      "abstract": "Offline reinforcement learning (RL) enables policy learning from static data but often suffers from poor coverage of the state-action space and distributional shift problems. This problem can be addressed by allowing limited online interactions to selectively refine uncertain regions of the learned value function, which is referred to as Active Reinforcement Learning (ActiveRL). While there has been good empirical success, no theoretical analysis is available in the literature. We fill this gap by developing a rigorous sample-complexity analysis of ActiveRL through the lens of Gaussian Process (GP) uncertainty modeling. In this respect, we propose an algorithm and using GP concentration inequalities and information-gain bounds, we derive high-probability guarantees showing that an $ε$-optimal policy can be learned with ${\\mathcal{O}}(1/ε^2)$ active transitions, improving upon the $Ω(1/ε^2(1-γ)^4)$ rate of purely offline methods. Our results reveal that ActiveRL achieves near-optimal information efficiency, that is, guided uncertainty reduction leads to accelerated value-function convergence with minimal online data. Our analysis builds on GP concentration inequalities and information-gain bounds, bridging Bayesian nonparametric regression and reinforcement learning theories. We conduct several experiments to validate the algorithm and theoretical findings.",
      "authors": [
        "Soumyadeep Roy",
        "Shashwat Kushwaha",
        "Ambedkar Dukkipati"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-01T14:38:07+00:00",
      "link": "https://arxiv.org/pdf/2602.01260v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
      "authors": [
        "GigaBrain Team",
        "Boyuan Wang",
        "Chaojun Ni",
        "Guan Huang",
        "Guosheng Zhao",
        "Hao Li",
        "Jie Li",
        "Jindi Lv",
        "Jingyu Liu",
        "Lv Feng",
        "Mingming Yu",
        "Peng Li",
        "Qiuping Deng",
        "Tianze Liu",
        "Xinyu Zhou",
        "Xinze Chen",
        "Xiaofeng Wang",
        "Yang Wang",
        "Yifan Li",
        "Yifei Nie",
        "Yilong Li",
        "Yukun Zhou",
        "Yun Ye",
        "Zhichao Liu",
        "Zheng Zhu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-12T15:55:19+00:00",
      "link": "https://arxiv.org/pdf/2602.12099v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.08244v1",
      "title": "Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers",
      "abstract": "In-context reinforcement learning (ICRL) leverages the in-context learning capabilities of transformer models (TMs) to efficiently generalize to unseen sequential decision-making tasks without parameter updates. However, existing ICRL methods rely on explicit reward signals during pretraining, which limits their applicability when rewards are ambiguous, hard to specify, or costly to obtain. To overcome this limitation, we propose a new learning paradigm, In-Context Preference-based Reinforcement Learning (ICPRL), in which both pretraining and deployment rely solely on preference feedback, eliminating the need for reward supervision. We study two variants that differ in the granularity of feedback: Immediate Preference-based RL (I-PRL) with per-step preferences, and Trajectory Preference-based RL (T-PRL) with trajectory-level comparisons. We first show that supervised pretraining, a standard approach in ICRL, remains effective under preference-only context datasets, demonstrating the feasibility of in-context reinforcement learning using only preference signals. To further improve data efficiency, we introduce alternative preference-native frameworks for I-PRL and T-PRL that directly optimize TM policies from preference data without requiring reward signals nor optimal action labels.Experiments on dueling bandits, navigation, and continuous control tasks demonstrate that ICPRL enables strong in-context generalization to unseen tasks, achieving performance comparable to ICRL methods trained with full reward supervision.",
      "authors": [
        "Juncheng Dong",
        "Bowen He",
        "Moyang Guo",
        "Ethan X. Fang",
        "Zhuoran Yang",
        "Vahid Tarokh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09T03:42:16+00:00",
      "link": "https://arxiv.org/pdf/2602.08244v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.12886v1",
      "title": "Communication Methods in Multi-Agent Reinforcement Learning",
      "abstract": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.",
      "authors": [
        "Christoph Wittner"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-19T09:39:00+00:00",
      "link": "https://arxiv.org/pdf/2601.12886v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.23058v1",
      "title": "From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning",
      "abstract": "Reinforcement learning has become a cornerstone for enhancing the reasoning capabilities of Large Language Models, where group-based approaches such as GRPO have emerged as efficient paradigms that optimize policies by leveraging intra-group performance differences. However, these methods typically rely on absolute numerical rewards, introducing intrinsic limitations. In verifiable tasks, identical group evaluations often result in sparse supervision, while in open-ended scenarios, the score range instability of reward models undermines advantage estimation based on group means. To address these limitations, we propose Reinforcement Learning with Relative Rewards (RLRR), a framework that shifts reward shaping from absolute scoring to relative ranking. Complementing this framework, we introduce the Ranking Reward Model, a listwise preference model tailored for group-based optimization to directly generate relative rankings. By transforming raw evaluations into robust relative signals, RLRR effectively mitigates signal sparsity and reward instability. Experimental results demonstrate that RLRR yields consistent performance improvements over standard group-based baselines across reasoning benchmarks and open-ended generation tasks.",
      "authors": [
        "Wenzhe Niu",
        "Wei He",
        "Zongxia Xie",
        "Jinpeng Ou",
        "Huichuan Fan",
        "Yuchen Ge",
        "Yanru Sun",
        "Ziyin Wang",
        "Yizhao Sun",
        "Chengshun Shi",
        "Jiuchong Gao",
        "Jinghua Hao",
        "Renqing He"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T15:07:06+00:00",
      "link": "https://arxiv.org/pdf/2601.23058v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21912v1",
      "title": "ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation",
      "abstract": "Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to \"process hallucinations\", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.",
      "authors": [
        "Zhao Wang",
        "Ziliang Zhao",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-29T16:04:59+00:00",
      "link": "https://arxiv.org/pdf/2601.21912v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18533v1",
      "title": "From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.",
      "authors": [
        "Yuxin Jiang",
        "Yufei Wang",
        "Qiyuan Zhang",
        "Xingshan Zeng",
        "Liangyou Li",
        "Jierun Chen",
        "Chaofan Tao",
        "Haoli Bai",
        "Lifeng Shang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-26T14:39:58+00:00",
      "link": "https://arxiv.org/pdf/2601.18533v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21312v1",
      "title": "Few-Shot Learning for Dynamic Operations of Automated Electric Taxi Fleets under Evolving Charging Infrastructure: A Meta-Deep Reinforcement Learning Approach",
      "abstract": "With the rapid expansion of electric vehicles (EVs) and charging infrastructure, the effective management of Autonomous Electric Taxi (AET) fleets faces a critical challenge in environments with dynamic and uncertain charging availability. While most existing research assumes a static charging network, this simplification creates a significant gap between theoretical models and real-world operations. To bridge this gap, we propose GAT-PEARL, a novel meta-reinforcement learning framework that learns an adaptive operational policy. Our approach integrates a graph attention network (GAT) to effectively extract robust spatial representations under infrastructure layouts and model the complex spatiotemporal relationships of the urban environment, and employs probabilistic embeddings for actor-critic reinforcement learning (PEARL) to enable rapid, inference-based adaptation to changes in charging network layouts without retraining. Through extensive simulations on real-world data in Chengdu, China, we demonstrate that GAT-PEARL significantly outperforms conventional reinforcement learning baselines, showing superior generalization to unseen infrastructure layouts and achieving higher overall operational efficiency in dynamic settings.",
      "authors": [
        "Xiaozhuang Li",
        "Xindi Tang",
        "Fang He"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T06:16:34+00:00",
      "link": "https://arxiv.org/pdf/2601.21312v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.20802v1",
      "title": "Reinforcement Learning via Self-Distillation",
      "abstract": "Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model's ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.",
      "authors": [
        "Jonas Hübotter",
        "Frederike Lübeck",
        "Lejs Behric",
        "Anton Baumann",
        "Marco Bagatella",
        "Daniel Marta",
        "Ido Hakimi",
        "Idan Shenfeld",
        "Thomas Kleine Buening",
        "Carlos Guestrin",
        "Andreas Krause"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T17:45:12+00:00",
      "link": "https://arxiv.org/pdf/2601.20802v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22149v1",
      "title": "DynaWeb: Model-Based Reinforcement Learning of Web Agents",
      "abstract": "The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.",
      "authors": [
        "Hang Ding",
        "Peidong Liu",
        "Junqiao Wang",
        "Ziwei Ji",
        "Meng Cao",
        "Rongzhao Zhang",
        "Lynn Ai",
        "Eric Yang",
        "Tianyu Shi",
        "Lei Yu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-29T18:59:07+00:00",
      "link": "https://arxiv.org/pdf/2601.22149v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10894v1",
      "title": "Resource-Efficient Model-Free Reinforcement Learning for Board Games",
      "abstract": "Board games have long served as complex decision-making benchmarks in artificial intelligence. In this field, search-based reinforcement learning methods such as AlphaZero have achieved remarkable success. However, their significant computational demands have been pointed out as barriers to their reproducibility. In this study, we propose a model-free reinforcement learning algorithm designed for board games to achieve more efficient learning. To validate the efficiency of the proposed method, we conducted comprehensive experiments on five board games: Animal Shogi, Gardner Chess, Go, Hex, and Othello. The results demonstrate that the proposed method achieves more efficient learning than existing methods across these environments. In addition, our extensive ablation study shows the importance of core techniques used in the proposed method. We believe that our efficient algorithm shows the potential of model-free reinforcement learning in domains traditionally dominated by search-based methods.",
      "authors": [
        "Kazuki Ota",
        "Takayuki Osa",
        "Motoki Omura",
        "Tatsuya Harada"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11T14:25:38+00:00",
      "link": "https://arxiv.org/pdf/2602.10894v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.20688v1",
      "title": "Grover's Search-Inspired Quantum Reinforcement Learning for Massive MIMO User Scheduling",
      "abstract": "The efficient user scheduling policy in the massive Multiple Input Multiple Output (mMIMO) system remains a significant challenge in the field of 5G and Beyond 5G (B5G) due to its high computational complexity, scalability, and Channel State Information (CSI) overhead. This paper proposes a novel Grover's search-inspired Quantum Reinforcement Learning (QRL) framework for mMIMO user scheduling. The QRL agent can explore the exponentially large scheduling space effectively by applying Grover's search to the reinforcement learning process. The model is implemented using our designed quantum-gate-based circuit, which imitates the layered architecture of reinforcement learning, where quantum operations act as policy updates and decision-making units. Moreover, the simulation results demonstrate that the proposed method achieves proper convergence and significantly outperforms classical Convolutional Neural Networks (CNN) and Quantum Deep Learning (QDL) benchmarks.",
      "authors": [
        "Ruining Fan",
        "Xingyu Huang",
        "Mouli Chakraborty",
        "Avishek Nag",
        "Anshu Mukherjee"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-28T15:14:51+00:00",
      "link": "https://arxiv.org/pdf/2601.20688v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.13284v1",
      "title": "Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning",
      "abstract": "Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.",
      "authors": [
        "Duygu Nur Yaldiz",
        "Evangelia Spiliopoulou",
        "Zheng Qi",
        "Siddharth Varia",
        "Srikanth Doss",
        "Nikolaos Pappas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-19T18:31:31+00:00",
      "link": "https://arxiv.org/pdf/2601.13284v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.05578v1",
      "title": "Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection",
      "abstract": "E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.",
      "authors": [
        "Cooper Lin",
        "Yanting Zhang",
        "Maohao Ran",
        "Wei Xue",
        "Hongwei Fan",
        "Yibo Xu",
        "Zhenglin Wan",
        "Sirui Han",
        "Yike Guo",
        "Jun Song"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-01-09T06:56:27+00:00",
      "link": "https://arxiv.org/pdf/2601.05578v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.12146v1",
      "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
      "abstract": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.",
      "authors": [
        "Mahdi Khodabandeh",
        "Ghazal Shabani",
        "Arash Yousefi Jordehi",
        "Seyed Abolghasem Mirroshandel"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "published": "2026-02-12T16:30:55+00:00",
      "link": "https://arxiv.org/pdf/2602.12146v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.17275v1",
      "title": "Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning",
      "abstract": "While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \\textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \\textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.",
      "authors": [
        "Lianlei Shan",
        "Han Chen",
        "Yixuan Wang",
        "Zhenjie Liu",
        "Wei Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-24T03:18:22+00:00",
      "link": "https://arxiv.org/pdf/2601.17275v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14697v1",
      "title": "Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs",
      "abstract": "Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL selects multiple system prompts and runs rollouts with each in parallel. It applies RL updates to model weights conditioned on each system prompt, and evolutionary updates to the system prompt population via LLM-driven mutation and crossover. Each system prompt has a TrueSkill rating for evolutionary selection, updated from relative performance within each RL iteration batch. E-SPL encourages a natural division between declarative knowledge encoded in prompts and procedural knowledge encoded in weights, resulting in improved performance across reasoning and agentic tasks. For instance, in an easy-to-hard (AIME $\\rightarrow$ BeyondAIME) generalization setting, E-SPL improves RL success rate from 38.8% $\\rightarrow$ 45.1% while also outperforming reflective prompt evolution (40.0%). Overall, our results show that coupling reinforcement learning with system prompt evolution yields consistent gains in sample efficiency and generalization. Code: https://github.com/LunjunZhang/E-SPL",
      "authors": [
        "Lunjun Zhang",
        "Ryan Chen",
        "Bradly C. Stadie"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-16T12:34:27+00:00",
      "link": "https://arxiv.org/pdf/2602.14697v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.06603v2",
      "title": "The hidden risks of temporal resampling in clinical reinforcement learning",
      "abstract": "Offline reinforcement learning (ORL) has shown potential for improving decision-making in healthcare. However, contemporary research typically aggregates patient data into fixed time intervals, simplifying their mapping to standard ORL frameworks. The impact of these temporal manipulations on model safety and efficacy remains poorly understood. In this work, using both a gridworld navigation task and the UVA/Padova clinical diabetes simulator, we demonstrate that temporal resampling significantly degrades the performance of offline reinforcement learning algorithms during live deployment. We propose three mechanisms that drive this failure: (i) the generation of counterfactual trajectories, (ii) the distortion of temporal expectations, and (iii) the compounding of generalisation errors. Crucially, we find that standard off-policy evaluation metrics can fail to detect these drops in performance. Our findings reveal a fundamental risk in current healthcare ORL pipelines and emphasise the need for methods that explicitly handle the irregular timing of clinical decision-making.",
      "authors": [
        "Thomas Frost",
        "Hrisheekesh Vaidya",
        "Steve Harris"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-06T11:02:06+00:00",
      "link": "https://arxiv.org/pdf/2602.06603v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14338v1",
      "title": "Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) plays a central role in large language model (LLM) post-training. Among existing approaches, Group Relative Policy Optimization (GRPO) is widely used, especially for RL with verifiable rewards (RLVR) fine-tuning. In GRPO, each query prompts the LLM to generate a group of rollouts with a fixed group size $N$. When all rollouts in a group share the same outcome, either all correct or all incorrect, the group-normalized advantages become zero, yielding no gradient signal and wasting fine-tuning compute. We introduce Adaptive Efficient Rollout Optimization (AERO), an enhancement of GRPO. AERO uses an adaptive rollout strategy, applies selective rejection to strategically prune rollouts, and maintains a Bayesian posterior to prevent zero-advantage dead zones. Across three model configurations (Qwen2.5-Math-1.5B, Qwen2.5-7B, and Qwen2.5-7B-Instruct), AERO improves compute efficiency without sacrificing performance. Under the same total rollout budget, AERO reduces total training compute by about 48% while shortening wall-clock time per step by about 45% on average. Despite the substantial reduction in compute, AERO matches or improves Pass@8 and Avg@8 over GRPO, demonstrating a practical, scalable, and compute-efficient strategy for RL-based LLM alignment.",
      "authors": [
        "Zhi Zhang",
        "Zhen Han",
        "Costas Mavromatis",
        "Qi Zhu",
        "Yunyi Zhang",
        "Sheng Guan",
        "Dingmin Wang",
        "Xiong Zhou",
        "Shuai Wang",
        "Soji Adeshina",
        "Vassilis Ioannidis",
        "Huzefa Rangwala"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-15T23:14:05+00:00",
      "link": "https://arxiv.org/pdf/2602.14338v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.06440v1",
      "title": "TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking",
      "abstract": "Large Language Models (LLMs) have become integral to many domains, making their safety a critical priority. Prior jailbreaking research has explored diverse approaches, including prompt optimization, automated red teaming, obfuscation, and reinforcement learning (RL) based methods. However, most existing techniques fail to effectively leverage vulnerabilities revealed in earlier interaction turns, resulting in inefficient and unstable attacks. Since jailbreaking involves sequential interactions in which each response influences future actions, reinforcement learning provides a natural framework for this problem. Motivated by this, we propose a history-aware RL-based jailbreak framework that analyzes and reweights vulnerability signals from prior steps to guide future decisions. We show that incorporating historical information alone improves jailbreak success rates. Building on this insight, we introduce an attention-based reweighting mechanism that highlights critical vulnerabilities within the interaction history, enabling more efficient exploration with fewer queries. Extensive experiments on AdvBench and HarmBench demonstrate that our method achieves state-of-the-art jailbreak performance while significantly improving query efficiency. These results underscore the importance of historical vulnerability signals in reinforcement learning-driven jailbreak strategies and offer a principled pathway for advancing adversarial research on LLM safeguards.",
      "authors": [
        "Sung-Hoon Yoon",
        "Ruizhi Qian",
        "Minda Zhao",
        "Weiyue Li",
        "Mengyu Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "published": "2026-02-06T07:11:10+00:00",
      "link": "https://arxiv.org/pdf/2602.06440v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03048v2",
      "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning. However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.",
      "authors": [
        "Zhiyuan Yao",
        "Yi-Kai Zhang",
        "Yuxin Chen",
        "Yueqing Sun",
        "Zishan Xu",
        "Yu Yang",
        "Tianhao Hu",
        "Qi Gu",
        "Hui Su",
        "Xunliang Cai"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T03:14:36+00:00",
      "link": "https://arxiv.org/pdf/2602.03048v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03048v3",
      "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning. However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods often rely on instance-level metrics, such as task pass rates, failing to capture the model's dynamic learning state. To address these limitations, we propose CoBA-RL, a reinforcement learning algorithm designed to adaptively allocate rollout budgets based on the model's evolving capability. Specifically, CoBA-RL utilizes a Capability-Oriented Value function to map tasks to their potential training gains and employs a heap-based greedy strategy to efficiently self-calibrate the distribution of computational resources to samples with high training value. Extensive experiments demonstrate that our approach effectively orchestrates the trade-off between exploration and exploitation, delivering consistent generalization improvements across multiple challenging benchmarks. These findings underscore that quantifying sample training value and optimizing budget allocation are pivotal for advancing LLM post-training efficiency.",
      "authors": [
        "Zhiyuan Yao",
        "Yi-Kai Zhang",
        "Yuxin Chen",
        "Yueqing Sun",
        "Zishan Xu",
        "Yu Yang",
        "Tianhao Hu",
        "Qi Gu",
        "Hui Su",
        "Xunliang Cai"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T03:14:36+00:00",
      "link": "https://arxiv.org/pdf/2602.03048v3",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00400v1",
      "title": "KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning",
      "abstract": "Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.",
      "authors": [
        "Fan Yang",
        "Rui Meng",
        "Trudi Di Qi",
        "Ali Ezzati",
        "Yuxin Wen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T23:28:37+00:00",
      "link": "https://arxiv.org/pdf/2602.00400v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.14468v1",
      "title": "LACONIC: Length-Aware Constrained Reinforcement Learning for LLM",
      "abstract": "Reinforcement learning (RL) has enhanced the capabilities of large language models (LLMs) through reward-driven training. Nevertheless, this process can introduce excessively long responses, inflating inference latency and computational overhead. Prior length-control approaches typically rely on fixed heuristic reward shaping, which can misalign with the task objective and require brittle tuning. In this work, we propose LACONIC, a reinforcement learning method that enforces a target token budget during training. Specifically, we update policy models using an augmented objective that combines the task reward with a length-based cost. To balance brevity and task performance, the cost scale is adaptively adjusted throughout training. This yields robust length control while preserving task reward. We provide a theoretical guarantee that support the method. Across mathematical reasoning models and datasets, LACONIC preserves or improves pass@1 while reducing output length by over 50%. It maintains out-of-domain performance on general knowledge and multilingual benchmarks with 44% fewer tokens. Moreover, LACONIC integrates into standard RL-tuning with no inference changes and minimal deployment overhead.",
      "authors": [
        "Chang Liu",
        "Yiran Zhao",
        "Lawrence Liu",
        "Yaoqi Ye",
        "Csaba Szepesvári",
        "Lin F. Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-16T05:09:40+00:00",
      "link": "https://arxiv.org/pdf/2602.14468v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.11455v1",
      "title": "Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attention connectivity and find that only a small fraction of tokens (approximately 15%) exhibit strong visual-textual coupling. These high-connectivity tokens act as anchors that ground reasoning in the image, while the majority follow linguistic patterns. During RLVR training, credit assignment naturally concentrates on these anchors, sharpening their visual grounding over time. Building on this insight, we propose Anchor-Token Reinforcement Learning (AT-RL), a lightweight framework that selectively reinforces high-connectivity tokens via graph-based clustering of attention topology. Evaluated across the series (3B-32B), AT-RL introduces only 1.2% overhead yet enables the 32B model to surpass the 72B-Instruct baseline on MathVista (80.2), with consistent gains observed across STEM, video and general tasks. Conversely, training solely on low-connectivity tokens causes severe degradation, confirming that effective multimodal RL hinges on precise credit assignment to visual anchors. Our work reveals that reasoning quality is governed not by token quantity but by the fidelity of cross-modal anchoring.",
      "authors": [
        "Zhengbo Jiao",
        "Shaobo Wang",
        "Zifan Zhang",
        "Wei Wang",
        "Bing Zhao",
        "Hu Wei",
        "Linfeng Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-12T00:20:54+00:00",
      "link": "https://arxiv.org/pdf/2602.11455v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.04879v1",
      "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.",
      "authors": [
        "Penghui Qi",
        "Xiangxin Zhou",
        "Zichen Liu",
        "Tianyu Pang",
        "Chao Du",
        "Min Lin",
        "Wee Sun Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-04T18:59:04+00:00",
      "link": "https://arxiv.org/pdf/2602.04879v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.17038v1",
      "title": "Phase-Aware Mixture of Experts for Agentic Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \\emph{single} policy network, causing \\emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leaving insufficient capacity for complex tasks. A plausible remedy could be employing the Mixture-of-Experts (MoE) architecture in the policy network, as MoE allows different parameters (experts) to specialize in different tasks, preventing simple tasks from dominating all parameters. However, a key limitation of traditional MoE is its token-level routing, where the router assigns each token to specialized experts, which fragments phase-consistent patterns into scattered expert assignments and thus undermines expert specialization. In this paper, we propose \\textbf{Phase-Aware Mixture of Experts (PA-MoE)}. It first features a lightweight \\emph{phase router} that learns latent phase boundaries directly from the RL objective without pre-defining phase categories. Then, the phase router allocates temporally consistent assignments to the same expert, allowing experts to preserve phase-specific expertise. Experimental results demonstrate the effectiveness of our proposed PA-MoE.",
      "authors": [
        "Shengtian Yang",
        "Yu Li",
        "Shuo He",
        "Yewen Li",
        "Qingpeng Cai",
        "Peng Jiang",
        "Lei Feng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-19T03:18:30+00:00",
      "link": "https://arxiv.org/pdf/2602.17038v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02192v3",
      "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.",
      "authors": [
        "Jie Xiao",
        "Meng Chen",
        "Qingnan Ren",
        "Jingwei Song",
        "Jiaqi Huang",
        "Yangshen Deng",
        "Chris Tong",
        "Wanyi Chen",
        "Suli Wang",
        "Ziqian Bi",
        "Shuo Lu",
        "Yiqun Duan",
        "Xu Wang",
        "Rymon Yu",
        "Ween Yang",
        "Lynn Ai",
        "Eric Yang",
        "Bill Shi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-02-02T14:57:53+00:00",
      "link": "https://arxiv.org/pdf/2602.02192v3",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02192v2",
      "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.",
      "authors": [
        "Jie Xiao",
        "Meng Chen",
        "Qingnan Ren",
        "Song Jingwei",
        "Jiaqi Huang",
        "Yangshen Deng",
        "Chris Tong",
        "Wanyi Chen",
        "Suli Wang",
        "Ziqian Bi",
        "Shuo Lu",
        "Yiqun Duan",
        "Xu Wang",
        "Rymon Yu",
        "Ween Yang",
        "Lynn Ai",
        "Eric Yang",
        "Bill Shi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-02-02T14:57:53+00:00",
      "link": "https://arxiv.org/pdf/2602.02192v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18150v1",
      "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.",
      "authors": [
        "Zhaopeng Qiu",
        "Shuang Yu",
        "Jingqi Zhang",
        "Shuai Zhang",
        "Xue Huang",
        "Jingyi Yang",
        "Junjie Lai"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-26T05:12:05+00:00",
      "link": "https://arxiv.org/pdf/2601.18150v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03352v1",
      "title": "PEGRL: Improving Machine Translation by Post-Editing Guided Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has shown strong promise for LLM-based machine translation, with recent methods such as GRPO demonstrating notable gains; nevertheless, translation-oriented RL remains challenged by noisy learning signals arising from Monte Carlo return estimation, as well as a large trajectory space that favors global exploration over fine-grained local optimization. We introduce \\textbf{PEGRL}, a \\textit{two-stage} RL framework that uses post-editing as an auxiliary task to stabilize training and guide overall optimization. At each iteration, translation outputs are sampled to construct post-editing inputs, allowing return estimation in the post-editing stage to benefit from conditioning on the current translation behavior, while jointly supporting both global exploration and fine-grained local optimization. A task-specific weighting scheme further balances the contributions of translation and post-editing objectives, yielding a biased yet more sample-efficient estimator. Experiments on English$\\to$Finnish, English$\\to$Turkish, and English$\\leftrightarrow$Chinese show consistent gains over RL baselines, and for English$\\to$Turkish, performance on COMET-KIWI is comparable to advanced LLM-based systems (DeepSeek-V3.2).",
      "authors": [
        "Yunzhi Shen",
        "Hao Zhou",
        "Xin Huang",
        "Xue Han",
        "Junlan Feng",
        "Shujian Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-03T10:22:55+00:00",
      "link": "https://arxiv.org/pdf/2602.03352v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00759v1",
      "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.",
      "authors": [
        "Zhipeng Chen",
        "Xiaobo Qin",
        "Wayne Xin Zhao",
        "Youbin Wu",
        "Ji-Rong Wen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-31T14:48:23+00:00",
      "link": "https://arxiv.org/pdf/2602.00759v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.06107v1",
      "title": "Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \\sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.",
      "authors": [
        "Zhuoming Chen",
        "Hongyi Liu",
        "Yang Zhou",
        "Haizhong Zheng",
        "Beidi Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-05T18:57:01+00:00",
      "link": "https://arxiv.org/pdf/2602.06107v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.15245v1",
      "title": "MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning",
      "abstract": "Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.",
      "authors": [
        "Ankit Bhattarai",
        "Hannah Selder",
        "Florian Fischer",
        "Arthur Fleig",
        "Per Ola Kristensson"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "published": "2026-02-16T22:51:57+00:00",
      "link": "https://arxiv.org/pdf/2602.15245v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10019v1",
      "title": "ADORA: Training Reasoning Models with Dynamic Advantage Estimation on Reinforcement Learning",
      "abstract": "Reinforcement learning has become a cornerstone technique for developing reasoning models in complex tasks, ranging from mathematical problem-solving to imaginary reasoning. The optimization of these models typically relies on policy gradient methods, whose efficacy hinges on the accurate estimation of an advantage function. However, prevailing methods typically employ static advantage estimation, a practice that leads to inefficient credit assignment by neglecting the dynamic utility of training samples over time. This limitation results in suboptimal policy updates, which in turn manifest as slower convergence rates and increased learning instability, as models fail to adapt to evolving sample utilities effectively. To address this problem, we introduce \\textbf{ADORA} (\\textbf{A}dvantage \\textbf{D}ynamics via \\textbf{O}nline \\textbf{R}ollout \\textbf{A}daptation), a novel framework for policy optimization. ADORA dynamically adjusts the advantage function's weighting by adaptively categorizing training data into temporarily advantageous and disadvantageous samples, based on their evolving utility during online model rollouts. This tailored data differentiation strategy allows ADORA to be seamlessly integrated into existing policy optimization algorithms without significant architectural modifications, enabling the policy to prioritize learning from more informative experiences and thereby achieve more efficient policy updates. Extensive evaluations across diverse model families and varying data scales demonstrate that ADORA is a robust and efficient framework. It significantly enhances long reasoning in both geometric and mathematical tasks, consistently achieving notable performance gains without requiring sensitive hyperparameter tuning.",
      "authors": [
        "Qingnan Ren",
        "Shiting Huang",
        "Zhen Fang",
        "Zehui Chen",
        "Lin Chen",
        "Lijun Li",
        "Feng Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-10T17:40:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10019v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.09207v1",
      "title": "CausalGDP: Causality-Guided Diffusion Policies for Reinforcement Learning",
      "abstract": "Reinforcement learning (RL) has achieved remarkable success in a wide range of sequential decision-making problems. Recent diffusion-based policies further improve RL by modeling complex, high-dimensional action distributions. However, existing diffusion policies primarily rely on statistical associations and fail to explicitly account for causal relationships among states, actions, and rewards, limiting their ability to identify which action components truly cause high returns. In this paper, we propose Causality-guided Diffusion Policy (CausalGDP), a unified framework that integrates causal reasoning into diffusion-based RL. CausalGDP first learns a base diffusion policy and an initial causal dynamical model from offline data, capturing causal dependencies among states, actions, and rewards. During real-time interaction, the causal information is continuously updated and incorporated as a guidance signal to steer the diffusion process toward actions that causally influence future states and rewards. By explicitly considering causality beyond association, CausalGDP focuses policy optimization on action components that genuinely drive performance improvements. Experimental results demonstrate that CausalGDP consistently achieves competitive or superior performance over state-of-the-art diffusion-based and offline RL methods, especially in complex, high-dimensional control tasks.",
      "authors": [
        "Xiaofeng Xiao",
        "Xiao Hu",
        "Yang Ye",
        "Xubo Yue"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09T21:18:32+00:00",
      "link": "https://arxiv.org/pdf/2602.09207v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01388v2",
      "title": "The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton's Laws in Financial Deep Reinforcement Learning (RL) Algorithms",
      "abstract": "Deep Reinforcement Learning (DRL), a subset of machine learning focused on sequential decision-making, has emerged as a powerful approach for tackling financial trading problems. In finance, DRL is commonly used either to generate discrete trade signals or to determine continuous portfolio allocations. In this work, we propose a novel reinforcement learning framework for portfolio optimization that incorporates Physics-Informed Kolmogorov-Arnold Networks (PIKANs) into several DRL algorithms. The approach replaces conventional multilayer perceptrons with Kolmogorov-Arnold Networks (KANs) in both actor and critic components-utilizing learnable B-spline univariate functions to achieve parameter-efficient and more interpretable function approximation. During actor updates, we introduce a physics-informed regularization loss that promotes second-order temporal consistency between observed return dynamics and the action-induced portfolio adjustments. The proposed framework is evaluated across three equity markets-China, Vietnam, and the United States, covering both emerging and developed economies. Across all three markets, PIKAN-based agents consistently deliver higher cumulative and annualized returns, superior Sharpe and Calmar ratios, and more favorable drawdown characteristics compared to both standard DRL baselines and classical online portfolio-selection methods. This yields more stable training, higher Sharpe ratios, and superior performance compared to traditional DRL counterparts. The approach is particularly valuable in highly dynamic and noisy financial markets, where conventional DRL often suffers from instability and poor generalization.",
      "authors": [
        "Trang Thoi",
        "Hung Tran",
        "Tram Thoi",
        "Huaiyang Zhong"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.LG"
      ],
      "published": "2026-02-01T18:48:33+00:00",
      "link": "https://arxiv.org/pdf/2602.01388v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.13953v1",
      "title": "QuRL: Efficient Reinforcement Learning with Quantized Rollout",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a trending paradigm for training reasoning large language models (LLMs). However, due to the autoregressive decoding nature of LLMs, the rollout process becomes the efficiency bottleneck of RL training, consisting of up to 70\\% of the total training time. In this work, we propose Quantized Reinforcement Learning (QuRL) that uses a quantized actor for accelerating the rollout. We address two challenges in QuRL. First, we propose Adaptive Clipping Range (ACR) that dynamically adjusts the clipping ratio based on the policy ratio between the full-precision actor and the quantized actor, which is essential for mitigating long-term training collapse. Second, we identify the weight update problem, where weight changes between RL steps are extremely small, making it difficult for the quantization operation to capture them effectively. We mitigate this problem through the invariant scaling technique that reduces quantization noise and increases weight update. We evaluate our method with INT8 and FP8 quantization experiments on DeepScaleR and DAPO, and achieve 20% to 80% faster rollout during training.",
      "authors": [
        "Yuhang Li",
        "Reena Elangovan",
        "Xin Dong",
        "Priyadarshini Panda",
        "Brucek Khailany"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15T01:48:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13953v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.10539v1",
      "title": "What Makes Value Learning Efficient in Residual Reinforcement Learning?",
      "abstract": "Residual reinforcement learning (RL) enables stable online refinement of expressive pretrained policies by freezing the base and learning only bounded corrections. However, value learning in residual RL poses unique challenges that remain poorly understood. In this work, we identify two key bottlenecks: cold start pathology, where the critic lacks knowledge of the value landscape around the base policy, and structural scale mismatch, where the residual contribution is dwarfed by the base action. Through systematic investigation, we uncover the mechanisms underlying these bottlenecks, revealing that simple yet principled solutions suffice: base-policy transitions serve as an essential value anchor for implicit warmup, and critic normalization effectively restores representation sensitivity for discerning value differences. Based on these insights, we propose DAWN (Data-Anchored Warmup and Normalization), a minimal approach targeting efficient value learning in residual RL. By addressing these bottlenecks, DAWN demonstrates substantial efficiency gains across diverse benchmarks, policy architectures, and observation modalities.",
      "authors": [
        "Guozheng Ma",
        "Lu Li",
        "Haoyu Wang",
        "Zixuan Liu",
        "Pierre-Luc Bacon",
        "Dacheng Tao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11T05:25:39+00:00",
      "link": "https://arxiv.org/pdf/2602.10539v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01156v1",
      "title": "PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning",
      "abstract": "Among on-policy reinforcement learning algorithms, Proximal Policy Optimization (PPO) demonstrates is widely favored for its simplicity, numerical stability, and strong empirical performance. Standard PPO relies on surrogate objectives defined via importance ratios, which require evaluating policy likelihood that is typically straightforward when the policy is modeled as a Gaussian distribution. However, extending PPO to more expressive, high-capacity policy models such as continuous normalizing flows (CNFs), also known as flow-matching models, is challenging because likelihood evaluation along the full flow trajectory is computationally expensive and often numerically unstable. To resolve this issue, we propose PolicyFlow, a novel on-policy CNF-based reinforcement learning algorithm that integrates expressive CNF policies with PPO-style objectives without requiring likelihood evaluation along the full flow path. PolicyFlow approximates importance ratios using velocity field variations along a simple interpolation path, reducing computational overhead without compromising training stability. To further prevent mode collapse and further encourage diverse behaviors, we propose the Brownian Regularizer, an implicit policy entropy regularizer inspired by Brownian motion, which is conceptually elegant and computationally lightweight. Experiments on diverse tasks across various environments including MultiGoal, PointMaze, IsaacLab and MuJoCo Playground show that PolicyFlow achieves competitive or superior performance compared to PPO using Gaussian policies and flow-based baselines including FPO and DPPO. Notably, results on MultiGoal highlight PolicyFlow's ability to capture richer multimodal action distributions.",
      "authors": [
        "Shunpeng Yang",
        "Ben Liu",
        "Hua Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-02-01T11:08:09+00:00",
      "link": "https://arxiv.org/pdf/2602.01156v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.08267v1",
      "title": "Inverting Data Transformations via Diffusion Sampling",
      "abstract": "We study the problem of transformation inversion on general Lie groups: a datum is transformed by an unknown group element, and the goal is to recover an inverse transformation that maps it back to the original data distribution. Such unknown transformations arise widely in machine learning and scientific modeling, where they can significantly distort observations. We take a probabilistic view and model the posterior over transformations as a Boltzmann distribution defined by an energy function on data space. To sample from this posterior, we introduce a diffusion process on Lie groups that keeps all updates on-manifold and only requires computations in the associated Lie algebra. Our method, Transformation-Inverting Energy Diffusion (TIED), relies on a new trivialized target-score identity that enables efficient score-based sampling of the transformation posterior. As a key application, we focus on test-time equivariance, where the objective is to improve the robustness of pretrained neural networks to input transformations. Experiments on image homographies and PDE symmetries demonstrate that TIED can restore transformed inputs to the training distribution at test time, showing improved performance over strong canonicalization and sampling baselines. Code is available at https://github.com/jw9730/tied.",
      "authors": [
        "Jinwoo Kim",
        "Sékou-Oumar Kaba",
        "Jiyun Park",
        "Seunghoon Hong",
        "Siamak Ravanbakhsh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09T04:58:34+00:00",
      "link": "https://arxiv.org/pdf/2602.08267v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.08857v1",
      "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
      "abstract": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.",
      "authors": [
        "Xinting Huang",
        "Aleksandra Bakalova",
        "Satwik Bhattamishra",
        "William Merrill",
        "Michael Hahn"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-09T16:22:29+00:00",
      "link": "https://arxiv.org/pdf/2602.08857v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.06300v1",
      "title": "Accelerating Vision Transformers on Brain Processing Unit",
      "abstract": "With the advancement of deep learning technologies, specialized neural processing hardware such as Brain Processing Units (BPUs) have emerged as dedicated platforms for CNN acceleration, offering optimized INT8 computation capabilities for convolutional operations. Meanwhile, Vision Transformer (ViT) models, such as the Data-efficient Image Transformer (DeiT), have demonstrated superior performance and play increasingly crucial roles in computer vision tasks. However, due to the architectural mismatch between CNN-optimized hardware and Vision Transformer computation characteristics--namely, that linear layers in Transformers operate on three-dimensional data while BPU acceleration is designed for four-dimensional convolution operations-it is difficult or even impossible to leverage BPU's advantages when deploying Vision Transformers. To address this challenge, we propose a novel approach that restructures the Vision Transformer by replacing linear layers and layer normalization operations with carefully designed convolutional operators. This enables DeiT to fully utilize the acceleration capabilities of BPUs, while allowing the original weight parameters to be inherited by the restructured models without retraining or fine-tuning. To the best of our knowledge, this is the first successful deployment of Vision Transformers that fully leverages BPU classification datasets demonstrate the effectiveness of our approach. Specifically, the quantized DeiT-Base model achieves 80.4% accuracy on ImageNet, compared to the original 81.8%, while obtaining up to a 3.8* inference speedup. Our finetuned DeiT model on the flower classification dataset also achieves excellent performance, with only a 0.5% accuracy drop for the DeiT-Base model, further demonstrating the effectiveness of our method.",
      "authors": [
        "Jinchi Tang",
        "Yan Guo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-06T01:48:54+00:00",
      "link": "https://arxiv.org/pdf/2602.06300v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.08695v1",
      "title": "Trapped by simplicity: When Transformers fail to learn from noisy features",
      "abstract": "Noise is ubiquitous in data used to train large language models, but it is not well understood whether these models are able to correctly generalize to inputs generated without noise. Here, we study noise-robust learning: are transformers trained on data with noisy features able to find a target function that correctly predicts labels for noiseless features? We show that transformers succeed at noise-robust learning for a selection of $k$-sparse parity and majority functions, compared to LSTMs which fail at this task for even modest feature noise. However, we find that transformers typically fail at noise-robust learning of random $k$-juntas, especially when the boolean sensitivity of the optimal solution is smaller than that of the target function. We argue that this failure is due to a combination of two factors: transformers' bias toward simpler functions, combined with an observation that the optimal function for noise-robust learning typically has lower sensitivity than the target function for random boolean functions. We test this hypothesis by exploiting transformers' simplicity bias to trap them in an incorrect solution, but show that transformers can escape this trap by training with an additional loss term penalizing high-sensitivity solutions. Overall, we find that transformers are particularly ineffective for learning boolean functions in the presence of feature noise.",
      "authors": [
        "Evan Peters",
        "Ando Deng",
        "Matheus H. Zambianco",
        "Devin Blankespoor",
        "Achim Kempf"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09T14:14:39+00:00",
      "link": "https://arxiv.org/pdf/2602.08695v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12681v1",
      "title": "Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations",
      "abstract": "Binary code analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations at the binary level remains underexplored. We evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. We introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness relies on the processing pipeline, including code pre-processing, architecture, and feature selection; ii) adversarial transformation effectiveness is bounded by a budget shaped by model-specific constraints like input size and instruction expressive capacity; iii) well-crafted transformations can be highly effective with minimal perturbations; and iv) such transformations efficiently disrupt model decisions (e.g., misleading to false positives or false negatives) by focusing on semantically significant instructions.",
      "authors": [
        "Jiyong Uhm",
        "Minseok Kim",
        "Michalis Polychronakis",
        "Hyungjoon Koo"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-13T07:23:15+00:00",
      "link": "https://arxiv.org/pdf/2602.12681v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16450v1",
      "title": "On the Expressive Power of Floating-Point Transformers",
      "abstract": "The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.",
      "authors": [
        "Sejun Park",
        "Yeachan Park",
        "Geonho Hwang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-23T05:03:00+00:00",
      "link": "https://arxiv.org/pdf/2601.16450v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10519v1",
      "title": "Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models",
      "abstract": "Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems.",
      "authors": [
        "Andrea Melis",
        "Andrea Piroddi",
        "Roberto Girau"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-15T15:46:22+00:00",
      "link": "https://arxiv.org/pdf/2601.10519v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07070v1",
      "title": "Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures",
      "abstract": "Standard Transformer architectures rely heavily on dense linear transformations, treating feature projection as a monolithic, full-rank operation. We argue that this formulation is inefficient and lacks the structural inductive bias necessary for distinguishing between local feature preservation and global context integration. To address this, we introduce the Hybrid Dual-Path Linear (HDPL) operator, which decomposes the affine transformation into two topologically distinct pathways: a sparse block-diagonal component for high-rank local processing, and a low-rank Variational Autoencoder (VAE) bottleneck for global context regularization. By \"surgically\" replacing specific projections (Query, Key, Value, Gate, Up) with HDPL operators while retaining standard dense layers for aggregation (Output, Down), we achieve a superior balance of efficiency and representational power. Experiments on the FineWeb-Edu dataset demonstrate that the HDPL architecture outperforms a standard Llama-style baseline, reducing validation loss while simultaneously reducing parameter count by 6.8%. Beyond immediate performance gains, we discuss how the explicit materialization of a probabilistic latent space within the Transformer backbone serves as a vital architectural affordance, offering new pathways for inference-time or hypernetwork induced control, continual adaptation, interpretability, and cross-model or cross-modal synchronization. The code is available at https://github.com/VladimerKhasia/HDPL",
      "authors": [
        "Vladimer Khasia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T20:16:10+00:00",
      "link": "https://arxiv.org/pdf/2602.07070v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.14318v1",
      "title": "In Transformer We Trust? A Perspective on Transformer Architecture Failure Modes",
      "abstract": "Transformer architectures have revolutionized machine learning across a wide range of domains, from natural language processing to scientific computing. However, their growing deployment in high-stakes applications, such as computer vision, natural language processing, healthcare, autonomous systems, and critical areas of scientific computing including climate modeling, materials discovery, drug discovery, nuclear science, and robotics, necessitates a deeper and more rigorous understanding of their trustworthiness. In this work, we critically examine the foundational question: \\textitHow trustworthy are transformer models?} We evaluate their reliability through a comprehensive review of interpretability, explainability, robustness against adversarial attacks, fairness, and privacy. We systematically examine the trustworthiness of transformer-based models in safety-critical applications spanning natural language processing, computer vision, and science and engineering domains, including robotics, medicine, earth sciences, materials science, fluid dynamics, nuclear science, and automated theorem proving; highlighting high-impact areas where these architectures are central and analyzing the risks associated with their deployment. By synthesizing insights across these diverse areas, we identify recurring structural vulnerabilities, domain-specific risks, and open research challenges that limit the reliable deployment of transformers.",
      "authors": [
        "Trishit Mondal",
        "Ameya D. Jagtap"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-15T21:57:14+00:00",
      "link": "https://arxiv.org/pdf/2602.14318v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13224v1",
      "title": "Functional Logic Program Transformations",
      "abstract": "Many tools used to process programs, like compilers, analyzers, or verifiers, perform transformations on their intermediate program representation, like abstract syntax trees. Implementing such program transformations is a non-trivial task, since it is necessary to iterate over the complete syntax tree and apply various transformations at nodes in a tree. In this paper we show how the features of functional logic programming are useful to implement program transformations in a compact and comprehensible manner. For this purpose, we propose to write program transformations as partially defined and non-deterministic operations. Since the implementation of non-determinism usually causes some overhead compared to deterministically defined operations, we compare our approach to a deterministic transformation method. We evaluate these alternatives for the functional logic language Curry and its intermediate representation FlatCurry which is used in various analysis and verification tools and compilers.",
      "authors": [
        "Michael Hanus",
        "Steven Libby"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-01-19T16:59:12+00:00",
      "link": "https://arxiv.org/pdf/2601.13224v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.14803v3",
      "title": "A physics inspired and efficient transform for optoacoustic systems",
      "abstract": "Optoacoustic imaging technologies require fast and accurate signal pre-processing algorithms to enable widespread deployment in clinical and home-care settings. However, they still rely on the Discrete Fourier Transform (DFT) as the default tool for essential signal-conditioning operations, which imposes hard limits on both execution speed and signal-retrieval accuracy. Here, we present a new transform whose building blocks are directly inspired by the physics of optoacoustic signal generation. We compared its performance with the DFT and other classical transforms on common signal-processing tasks using both simulations and experimental datasets. Our results indicate that the proposed transform not only sets a new lower bound on computational complexity relative to the DFT, but also substantially outperforms classical transforms on basic signal-processing operations in terms of accuracy. We expect this transform to catalyze broader adoption of optoacoustic methods.",
      "authors": [
        "Maria Rodriguez Saenz de Tejada",
        "Alvaro Jimenez",
        "Rodrigo Rojo",
        "Sergio Contador",
        "Juan Aguirre"
      ],
      "primary_category": "physics.med-ph",
      "categories": [
        "physics.med-ph"
      ],
      "published": "2026-02-16T14:54:00+00:00",
      "link": "https://arxiv.org/pdf/2602.14803v3",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10876v1",
      "title": "Efficient Quantum Circuits for the Hilbert Transform",
      "abstract": "The quantum Fourier transform and quantum wavelet transform have been cornerstones of quantum information processing. However, for non-stationary signals and anomaly detection, the Hilbert transform can be a more powerful tool, yet no prior work has provided efficient quantum implementations for the discrete Hilbert transform. This letter presents a novel construction for a quantum Hilbert transform in polylogarithmic size and logarithmic depth for a signal of length $N$, exponentially fewer operations than classical algorithms for the same mapping. We generalize this algorithm to create any $d$-dimensional Hilbert transform in depth $O(d\\log N)$. Simulations demonstrate effectiveness for tasks such as power systems control and image processing, with exact agreement with classical results.",
      "authors": [
        "Henry Zhang",
        "Joseph Li"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "eess.SP"
      ],
      "published": "2026-01-15T22:02:32+00:00",
      "link": "https://arxiv.org/pdf/2601.10876v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05618v1",
      "title": "Boundedness of the discrete Hilbert transform on discrete weighted Morrey spaces",
      "abstract": "The Hilbert transform is a multiplier operator and is widely used in the theory of Fourier transforms. The Hilbert transform was the motivation for the development of modern harmonic analysis. Its discrete version is also widely used in many areas of science and technology and plays an important role in digital signal processing. The essential motivation behind thinking about discrete transforms is that experimental data are most often not taken in a continuous manner but sampled at discrete time values. Since much of the data collected in both the physical sciences and engineering are discrete, the discrete Hilbert transform is a rather useful tool in these areas for the general analysis of this type of data. In this paper, we discuss the discrete Hilbert transform on discrete Weighted Morrey spaces and obtain its boundedness in these spaces.",
      "authors": [
        "Rashid Aliev",
        "Amil Jabiyev"
      ],
      "primary_category": "math.FA",
      "categories": [
        "math.FA"
      ],
      "published": "2026-01-09T08:21:47+00:00",
      "link": "https://arxiv.org/pdf/2601.05618v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18274v1",
      "title": "TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers",
      "abstract": "In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.",
      "authors": [
        "Sicheng Shen",
        "Mingyang Lv",
        "Bing Han",
        "Dongcheng Zhao",
        "Guobin Shen",
        "Feifei Zhao",
        "Yi Zeng"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-26T08:58:36+00:00",
      "link": "https://arxiv.org/pdf/2601.18274v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.16608v1",
      "title": "Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models",
      "abstract": "Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \\textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.",
      "authors": [
        "Melkamu Abay Mersha",
        "Jugal Kalita"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-18T17:03:10+00:00",
      "link": "https://arxiv.org/pdf/2602.16608v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.16914v1",
      "title": "A statistical perspective on transformers for small longitudinal cohort data",
      "abstract": "Modeling of longitudinal cohort data typically involves complex temporal dependencies between multiple variables. There, the transformer architecture, which has been highly successful in language and vision applications, allows us to account for the fact that the most recently observed time points in an individual's history may not always be the most important for the immediate future. This is achieved by assigning attention weights to observations of an individual based on a transformation of their values. One reason why these ideas have not yet been fully leveraged for longitudinal cohort data is that typically, large datasets are required. Therefore, we present a simplified transformer architecture that retains the core attention mechanism while reducing the number of parameters to be estimated, to be more suitable for small datasets with few time points. Guided by a statistical perspective on transformers, we use an autoregressive model as a starting point and incorporate attention as a kernel-based operation with temporal decay, where aggregation of multiple transformer heads, i.e. different candidate weighting schemes, is expressed as accumulating evidence on different types of underlying characteristics of individuals. This also enables a permutation-based statistical testing procedure for identifying contextual patterns. In a simulation study, the approach is shown to recover contextual dependencies even with a small number of individuals and time points. In an application to data from a resilience study, we identify temporal patterns in the dynamics of stress and mental health. This indicates that properly adapted transformers can not only achieve competitive predictive performance, but also uncover complex context dependencies in small data settings.",
      "authors": [
        "Kiana Farhadyar",
        "Maren Hackenberg",
        "Kira Ahrens",
        "Charlotte Schenk",
        "Bianca Kollmann",
        "Oliver Tüscher",
        "Klaus Lieb",
        "Michael M. Plichta",
        "Andreas Reif",
        "Raffael Kalisch",
        "Martin Wolkewitz",
        "Moritz Hess",
        "Harald Binder"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-18T22:03:59+00:00",
      "link": "https://arxiv.org/pdf/2602.16914v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07930v1",
      "title": "Transformer-Based Approach for Automated Functional Group Replacement in Chemical Compounds",
      "abstract": "Functional group replacement is a pivotal approach in cheminformatics to enable the design of novel chemical compounds with tailored properties. Traditional methods for functional group removal and replacement often rely on rule-based heuristics, which can be limited in their ability to generate diverse and novel chemical structures. Recently, transformer-based models have shown promise in improving the accuracy and efficiency of molecular transformations, but existing approaches typically focus on single-step modeling, lacking the guarantee of structural similarity. In this work, we seek to advance the state of the art by developing a novel two-stage transformer model for functional group removal and replacement. Unlike one-shot approaches that generate entire molecules in a single pass, our method generates the functional group to be removed and appended sequentially, ensuring strict substructure-level modifications. Using a matched molecular pairs (MMPs) dataset derived from ChEMBL, we trained an encoder-decoder transformer model with SMIRKS-based representations to capture transformation rules effectively. Extensive evaluations demonstrate our method's ability to generate chemically valid transformations, explore diverse chemical spaces, and maintain scalability across varying search sizes.",
      "authors": [
        "Bo Pan",
        "Zhiping Zhang",
        "Kevin Spiekermann",
        "Tianchi Chen",
        "Xiang Yu",
        "Liying Zhang",
        "Liang Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-12T19:01:11+00:00",
      "link": "https://arxiv.org/pdf/2601.07930v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12571v1",
      "title": "Self-avoiding walk, connective constant, cubic graph, Fisher transformation, quasi-transitive graph",
      "abstract": "We study self-avoiding walks (SAWs) on infinite quasi-transitive cubic graphs under \\emph{local transformations} that replace each degree-$3$ vertex by a finite, symmetric three-port gadget. To each gadget we associate a two-port SAW generating function $g(x)$, defined by counting SAWs that enter and exit the gadget through prescribed ports. Our first main result shows that, if $G$ is cubic and $G_1=φ(G)$ is obtained by applying the local transformation at every vertex, then the connective constants $μ(G)$ and $μ(G_1)$ satisfy the functional relation \\[ μ(G)^{-1}=g\\bigl(μ(G_1)^{-1}\\bigr). \\] We next consider critical exponents defined via susceptibility-type series that do not rely on an ambient Euclidean dimension, and prove that the exponents $γ$ and $η$ are invariant under local transformations; moreover $ν$ is invariant under a standard regularity hypothesis on SAW counts (a common slowly varying function).   Our second set of results concerns bipartite graphs, where the local transformation is applied to one colour class (or to both classes, possibly with different gadgets). In this setting we obtain an analogous relation \\[ μ(G)^{-2}=h\\bigl(μ(G_{\\mathrm e})^{-1}\\bigr), \\] with $h(x)=xg(x)$ when only one class is transformed and $h(x)=g_{φ_1}(x)\\,g_{φ_2}(x)$ when both are transformed. We further present explicit families of examples, including replacing each degree-3 vertex by a complete-graph gadget $K_N$.",
      "authors": [
        "Benjamin Grant",
        "Zhongyang Li"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math-ph",
        "math.PR"
      ],
      "published": "2026-01-18T20:25:37+00:00",
      "link": "https://arxiv.org/pdf/2601.12571v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.08920v1",
      "title": "Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration",
      "abstract": "Uncertainty calibration in pre-trained transformers is critical for their reliable deployment in risk-sensitive applications. Yet, most existing pre-trained transformers do not have a principled mechanism for uncertainty propagation through their feature transformation stack. In this work, we propose a diffusion-inspired reconfiguration of transformers in which each feature transformation block is modeled as a probabilistic mapping. Composing these probabilistic mappings reveals a probability path that mimics the structure of a diffusion process, transporting data mass from the input distribution to the pre-trained feature distribution. This probability path can then be recompiled on a diffusion process with a unified transition model to enable principled propagation of representation uncertainty throughout the pre-trained model's architecture while maintaining its original predictive performance. Empirical results across a variety of vision and language benchmarks demonstrate that our method achieves superior calibration and predictive accuracy compared to existing uncertainty-aware transformers.",
      "authors": [
        "Manh Cuong Dao",
        "Quang Hung Pham",
        "Phi Le Nguyen",
        "Thao Nguyen Truong",
        "Bryan Kian Hsiang Low",
        "Trong Nghia Hoang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-09T17:24:47+00:00",
      "link": "https://arxiv.org/pdf/2602.08920v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10434v1",
      "title": "The transformation mechanisms among cuboctahedra, Ino's decahedra and icosahedra structures of magic-size gold nanoclusters",
      "abstract": "Gold nanoclusters possess multiple competing structural motifs with small energy differences, enabling structural coexistence and interconversion. Using a high-accuracy machine learned potential trained on some 20'000 density functional theory reference data points, we investigate transformation pathways connecting both high-symmetry and amorphous cuboctahedra, Ino's decahedra and icosahedra for Au55, Au147, Au309 and Au561 nanoclusters. Our saddle point searches reveal that high-symmetry transformations from cuboctahedra and Ino's decahedra to icosahedra proceed through a single barrier and represent soft-mode-driven jitterbug-type and slip-dislocation motions. In addition, we identify lower-barrier asymmetric transformation pathways that drive the system into disordered, Jahn-Teller-stabilized amorphous icosahedra. Minima Hopping sampling further uncovers, in this context, many such low-symmetry minima. Some of the newly identified global minima for Au309 and Au561 have energies that are up to 2.8 eV lower than the previously reported global minima. Hence, both the shapes and the transformation pathways studied in previous investigations are not the physically relevant ones. In contrast to the previously studied pathways, our transformation pathways give reasonable transformation times that are in rough agreement with experiments.",
      "authors": [
        "Ehsan Rahmatizad Khajehpasha",
        "Mohammad Ismaeil Safa",
        "Nasrin Eyvazi",
        "Marco Krummenacher",
        "Stefan Goedecker"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ],
      "published": "2026-01-15T14:29:17+00:00",
      "link": "https://arxiv.org/pdf/2601.10434v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.16264v1",
      "title": "Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge",
      "abstract": "In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.",
      "authors": [
        "Zixian Wu",
        "Xuebao Li",
        "Yanfang Zheng",
        "Rui Wang",
        "Shunhuang Zhang",
        "Jinfang Wei",
        "Yongshang Lv",
        "Liang Dong",
        "Zamri Zainal Abidin",
        "Noraisyah Mohamed Shah",
        "Hongwei Ye",
        "Pengchao Yan",
        "Xuefeng Li",
        "Xiaojia Ji",
        "Xusheng Huang",
        "Xiaotian Wang",
        "Honglei Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "astro-ph.SR"
      ],
      "published": "2026-02-18T08:30:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16264v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15509v1",
      "title": "The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers",
      "abstract": "The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.",
      "authors": [
        "Prasanna Kumar"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-21T22:40:47+00:00",
      "link": "https://arxiv.org/pdf/2601.15509v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09467v1",
      "title": "Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting",
      "abstract": "Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture that incorporates zonal periodicity and meridional boundaries into window-based self-attention for physically consistent global information exchange. We further introduce a Relay Autoregressive (RAR) fine-tuning strategy that enables learning long-range atmospheric evolution under constrained memory and computational budgets. Based on these methods, we develop YanTian, a global medium-range weather forecasting model. YanTian achieves higher accuracy than the high-resolution forecast of the European Centre for Medium-Range Weather Forecasts and performs competitively with state-of-the-art AI models at one-degree resolution, while requiring roughly 200 times lower computational cost than standard autoregressive fine-tuning. Furthermore, YanTian attains a longer skillful forecast lead time for Z500 (10.3 days) than HRES (9 days). Beyond weather forecasting, this work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science.",
      "authors": [
        "Tianye Li",
        "Qi Liu",
        "Hao Li",
        "Lei Chen",
        "Wencong Cheng",
        "Fei Zheng",
        "Xiangao Xia",
        "Ya Wang",
        "Gang Huang",
        "Weiwei Wang",
        "Xuan Tong",
        "Ziqing Zu",
        "Yi Fang",
        "Shenming Fu",
        "Jiang Jiang",
        "Haochen Li",
        "Mingxing Li",
        "Jiangjiang Xia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "published": "2026-01-14T13:20:17+00:00",
      "link": "https://arxiv.org/pdf/2601.09467v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07677v1",
      "title": "Affine Transformable Unmanned Ground Vehicle",
      "abstract": "This paper develops the proof of concept for a novel affine transformable unmanned ground vehicle (ATUGV) with the capability of safe and aggressive deformation while carrying multiple payloads. The ATUGV is a multi-body system with mobile robots that can be used to power the ATUGV morphable motion, powered cells to enclose the mobile robots, unpowered cells to contain payloads, and a deformable structure to integrate cells through bars and joints. The objective is that all powered and unpowered cells motion can safely track a desired affine transformation, where an affine transformation can be decomposed into translation, rigid body rotation, and deformation. To this end, the paper first uses a deep neural network to structure cell interconnection in such a way that every cell can freely move over the deformation plane, and the entire structure can reconfigurably deform to track a desired affine transformation. Then, the mobile robots, contained by the powered cells and stepper motors, regulating the connections of the powered and unpowered cells, design the proper controls so that all cells safely track the desired affine transformation. The functionality of the proposed ATUGV is validated through hardware experimentation and simulation.",
      "authors": [
        "Aron Mathias",
        "Mohammad Ghufran",
        "Jack Hughes",
        "Hossein Rastgoftar"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-02-07T19:56:27+00:00",
      "link": "https://arxiv.org/pdf/2602.07677v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21069v2",
      "title": "CompSRT: Quantization and Pruning for Image Super Resolution Transformers",
      "abstract": "Model compression has become an important tool for making image super resolution models more efficient. However, the gap between the best compressed models and the full precision model still remains large and a need for deeper understanding of compression theory on more performant models remains. Prior research on quantization of LLMs has shown that Hadamard transformations lead to weights and activations with reduced outliers, which leads to improved performance. We argue that while the Hadamard transform does reduce the effect of outliers, an empirical analysis on how the transform functions remains needed. By studying the distributions of weights and activations of SwinIR-light, we show with statistical analysis that lower errors is caused by the Hadamard transforms ability to reduce the ranges, and increase the proportion of values around $0$. Based on these findings, we introduce CompSRT, a more performant way to compress the image super resolution transformer network SwinIR-light. We perform Hadamard-based quantization, and we also perform scalar decomposition to introduce two additional trainable parameters. Our quantization performance statistically significantly surpasses the SOTA in metrics with gains as large as 1.53 dB, and visibly improves visual quality by reducing blurriness at all bitwidths. At $3$-$4$ bits, to show our method is compatible with pruning for increased compression, we also prune $40\\%$ of weights and show that we can achieve $6.67$-$15\\%$ reduction in bits per parameter with comparable performance to SOTA.",
      "authors": [
        "Dorsa Zeinali",
        "Hailing Wang",
        "Yitian Zhang",
        "Yun Fu"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-01-28T21:52:29+00:00",
      "link": "https://arxiv.org/pdf/2601.21069v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00856v1",
      "title": "Higher-order transformations of bidirectional quantum processes",
      "abstract": "Bidirectional devices are devices for which the roles of the input and output ports can be exchanged. Mathematically, these devices are described by bistochastic quantum channels, namely completely positive linear maps that are both trace-preserving and identity-preserving. Recently, it has been shown that bidirectional quantum devices can, in principle, be used in ways that are incompatible with a definite input-output direction, giving rise to a new phenomenon called input-output indefiniteness. Here we characterize the most general forms of input-output indefiniteness, associated with a hierarchy of higher-order transformations built from transformations of bistochastic quantum channels. Some levels of the hierarchy correspond to transformations that combine bistochastic channels in a definite causal order, while generally using each channel in an indefinite input-output direction. For other levels of the hierarchy, the indefiniteness can involve both the local input-output direction of each process and the global causal order among the processes. On the foundational side, the hierarchy of higher-order transformations characterized here can be regarded as the largest set of physical processes compatible with a time-symmetric variant of quantum theory, where the possible state transformations are restricted to bistochastic channels.",
      "authors": [
        "Luca Apadula",
        "Alessandro Bisio",
        "Giulio Chiribella",
        "Paolo Perinotti",
        "Kyrylo Simonov"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph"
      ],
      "published": "2026-01-31T18:39:36+00:00",
      "link": "https://arxiv.org/pdf/2602.00856v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14875v1",
      "title": "GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars",
      "abstract": "High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.",
      "authors": [
        "Zhe Chang",
        "Haodong Jin",
        "Ying Sun",
        "Yan Song",
        "Hui Yu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-21T11:05:13+00:00",
      "link": "https://arxiv.org/pdf/2601.14875v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.06597v1",
      "title": "DiTS: Multimodal Diffusion Transformers Are Time Series Forecasters",
      "abstract": "While generative modeling on time series facilitates more capable and flexible probabilistic forecasting, existing generative time series models do not address the multi-dimensional properties of time series data well. The prevalent architecture of Diffusion Transformers (DiT), which relies on simplistic conditioning controls and a single-stream Transformer backbone, tends to underutilize cross-variate dependencies in covariate-aware forecasting. Inspired by Multimodal Diffusion Transformers that integrate textual guidance into video generation, we propose Diffusion Transformers for Time Series (DiTS), a general-purpose architecture that frames endogenous and exogenous variates as distinct modalities. To better capture both inter-variate and intra-variate dependencies, we design a dual-stream Transformer block tailored for time-series data, comprising a Time Attention module for autoregressive modeling along the temporal dimension and a Variate Attention module for cross-variate modeling. Unlike the common approach for images, which flattens 2D token grids into 1D sequences, our design leverages the low-rank property inherent in multivariate dependencies, thereby reducing computational costs. Experiments show that DiTS achieves state-of-the-art performance across benchmarks, regardless of the presence of future exogenous variate observations, demonstrating unique generative forecasting strengths over traditional deterministic deep forecasting models.",
      "authors": [
        "Haoran Zhang",
        "Haixuan Liu",
        "Yong Liu",
        "Yunzhong Qiu",
        "Yuxuan Wang",
        "Jianmin Wang",
        "Mingsheng Long"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-06T10:48:13+00:00",
      "link": "https://arxiv.org/pdf/2602.06597v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.13188v1",
      "title": "Diamond-to-graphite transformation under hypersonic impact",
      "abstract": "Diamond to graphite transformation is a complex kinetically driven process which has been studied under various conditions for its fundamental importance. We report the transformation of diamond embedded ceramic matrix composites during hypersonic impact. Diamond particles embedded in cubic boron nitride matrix provide a superhard composite that was subjected to high impact collisions of metal projectiles travelling at speeds reaching Mach 8.45. Our observations suggest that the energy absorption and fracture of the composite is primarily enabled via the phase change of diamond into graphite. Characterization of the impact-fractured composite shows transformed diamond particles and provides details of the shock-induced phase transformation and the nature of diamond-graphite interfaces formed during rapid phase change. The study provides new understanding of phase transformation of diamond under extreme conditions.",
      "authors": [
        "Abhijit Biswas",
        "Aniket Mote",
        "Rajib Sahu",
        "Marcelo Lopes Pereira Junior",
        "Shuo Yang",
        "Sudaice Kazibwe",
        "Jishnu Murukeshan",
        "Raphael Benjamin de Oliveira",
        "Guilherme da Silva Lopes Fabris",
        "Shreyasi Chattopadhyay",
        "Gelu Costin",
        "Jianhua Li",
        "Robert Vajtai",
        "Ching-Wu Chu",
        "Lizhong Lang",
        "Yu Zou",
        "Liangzi Deng",
        "Tobin Filleter",
        "Douglas Soares Galvão",
        "Christian Kübel",
        "Thomas E Lacy",
        "Pulickel M. Ajayan"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-13T18:55:16+00:00",
      "link": "https://arxiv.org/pdf/2602.13188v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.17307v1",
      "title": "Security of the Fischlin Transform in Quantum Random Oracle Model",
      "abstract": "The Fischlin transform yields non-interactive zero-knowledge proofs with straight-line extractability in the classical random oracle model. This is done by forcing a prover to generate multiple accepting transcripts through a proof-of-work mechanism. Whether the Fischlin transform is straight-line extractable against quantum adversaries has remained open due to the difficulty of reasoning about the likelihood of query transcripts in the quantum-accessible random oracle model (QROM), even when using the compressed oracle methodology. In this work, we prove that the Fischlin transform remains straight-line extractable in the QROM, via an extractor based on the compressed oracle. This establishes the post-quantum security of the Fischlin transform, providing a post-quantum straight-line extractable NIZK alternative to Pass' transform with smaller proof size. Our techniques include tail bounds for sums of independent random variables and for martingales as well as symmetrization, query amplitude and quantum union bound arguments.",
      "authors": [
        "Christian Majenz",
        "Jaya Sharma"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-02-19T12:18:28+00:00",
      "link": "https://arxiv.org/pdf/2602.17307v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05770v1",
      "title": "Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer",
      "abstract": "Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.",
      "authors": [
        "Yifan Zhang",
        "Wei Bi",
        "Kechi Zhang",
        "Dongming Jin",
        "Jie Fu",
        "Zhi Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-09T12:49:41+00:00",
      "link": "https://arxiv.org/pdf/2601.05770v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18385v1",
      "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals",
      "abstract": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.",
      "authors": [
        "Rinka Kawano",
        "Masaki Kawamura"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-26T11:33:01+00:00",
      "link": "https://arxiv.org/pdf/2601.18385v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12515v1",
      "title": "Matching of SAR and optical images based on transformation to shared modality",
      "abstract": "Significant differences in optical images and Synthetic Aperture Radar (SAR) images are caused by fundamental differences in the physical principles underlying their acquisition by Earth remote sensing platforms. These differences make precise image matching (co-registration) of these two types of images difficult. In this paper, we propose a new approach to image matching of optical and SAR images, which is based on transforming the images to a new modality. The new image modality is common to both optical and SAR images and satisfies the following conditions. First, the transformed images must have an equal pre-defined number of channels. Second, the transformed and co-registered images must be as similar as possible. Third, the transformed images must be non-degenerate, meaning they must preserve the significant features of the original images. To further match images transformed to this shared modality, we train the RoMa image matching model, which is one of the leading solutions for matching of regular digital photographs. We evaluated the proposed approach on the publicly available MultiSenGE dataset containing both optical and SAR images. We demonstrated its superiority over alternative approaches based on image translation between original modalities and various feature matching algorithms. The proposed solution not only provides better quality of matching, but is also more versatile. It enables the use of ready-made RoMa and DeDoDe models, pre-trained for regular images, without retraining for a new modality, while maintaining high-quality matching of optical and SAR images.",
      "authors": [
        "Alexey Borisov",
        "Evgeny Myasnikov",
        "Vladislav Myasnikov"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13T01:41:24+00:00",
      "link": "https://arxiv.org/pdf/2602.12515v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21942v1",
      "title": "Clustering in Deep Stochastic Transformers",
      "abstract": "Transformers have revolutionized deep learning across various domains but understanding the precise token dynamics remains a theoretical challenge. Existing theories of deep Transformers with layer normalization typically predict that tokens cluster to a single point; however, these results rely on deterministic weight assumptions, which fail to capture the standard initialization scheme in Transformers. In this work, we show that accounting for the intrinsic stochasticity of random initialization alters this picture. More precisely, we analyze deep Transformers where noise arises from the random initialization of value matrices. Under diffusion scaling and token-wise RMS normalization, we prove that, as the number of Transformer layers goes to infinity, the discrete token dynamics converge to an interacting-particle system on the sphere where tokens are driven by a \\emph{common} matrix-valued Brownian noise. In this limit, we show that initialization noise prevents the collapse to a single cluster predicted by deterministic models. For two tokens, we prove a phase transition governed by the interaction strength and the token dimension: unlike deterministic attention flows, antipodal configurations become attracting with positive probability. Numerical experiments confirm the predicted transition, reveal that antipodal formations persist for more than two tokens, and demonstrate that suppressing the intrinsic noise degrades accuracy.",
      "authors": [
        "Lev Fedorov",
        "Michaël E. Sander",
        "Romuald Elie",
        "Pierre Marion",
        "Mathieu Laurière"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-29T16:28:13+00:00",
      "link": "https://arxiv.org/pdf/2601.21942v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20854v1",
      "title": "Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation",
      "abstract": "Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.",
      "authors": [
        "Aníbal Silva",
        "Moisés Santos",
        "André Restivo",
        "Carlos Soares"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T18:54:27+00:00",
      "link": "https://arxiv.org/pdf/2601.20854v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05896v1",
      "title": "Parity, Sensitivity, and Transformers",
      "abstract": "The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY have at least 2 layers and employ impractical features: either a length-dependent positional encoding, or hardmax, or layernorm without the regularization parameter, or they are not implementable with causal masking.   We give a new construction of a transformer for PARITY with softmax, length-independent and polynomially bounded positional encoding, no layernorm, working both with and without causal masking. We also give the first lower bound for transformers solving PARITY -- by showing that it cannot be done with only one layer and one head.",
      "authors": [
        "Alexander Kozachinskiy",
        "Tomasz Steifer",
        "Przemysław Wałȩga"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-05T17:14:33+00:00",
      "link": "https://arxiv.org/pdf/2602.05896v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05523v1",
      "title": "Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations",
      "abstract": "Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities of agents across alternative versions of the source code. We introduce CTF challenge families, whereby a single CTF is used as the basis for generating a family of semantically-equivalent challenges via semantics-preserving program transformations. This enables controlled evaluation of agent robustness to source code transformations while keeping the underlying exploit strategy fixed. We introduce a new tool, Evolve-CTF, that generates CTF families from Python challenges using a range of transformations. Using Evolve-CTF to derive families from Cybench and Intercode challenges, we evaluate 13 agentic LLM configurations with tool access. We find that models are remarkably robust to intrusive renaming and code insertion-based transformations, but that composed transformations and deeper obfuscation affect performance by requiring more sophisticated use of tools. We also find that enabling explicit reasoning has little effect on solution success rates across challenge families. Our work contributes a valuable technique and tool for future LLM evaluations, and a large dataset characterising the capabilities of current state-of-the-art models in this domain.",
      "authors": [
        "Shahin Honarvar",
        "Amber Gorzynski",
        "James Lee-Jones",
        "Harry Coppock",
        "Marek Rei",
        "Joseph Ryan",
        "Alastair F. Donaldson"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-05T10:30:57+00:00",
      "link": "https://arxiv.org/pdf/2602.05523v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22081v1",
      "title": "Accessibility-Driven Information Transformations in Mixed-Visual Ability Work Teams",
      "abstract": "Blind and low-vision (BLV) employees in mixed-visual ability teams often encounter information (e.g., PDFs, diagrams) in inaccessible formats. To enable teamwork, teams must transform these representations by modifying or re-creating them into accessible forms. However, these transformations are frequently overlooked, lack infrastructural support, and cause additional labour. To design systems that move beyond one-off accommodations to effective mixed-ability collaboration, we need a deeper understanding of the representations, their transformations and how they occur. We conducted a week-long diary study with follow-up interviews with 23 BLV and sighted professionals from five legal, non-profit, and consulting teams, documenting 36 transformation cases. Our analysis characterizes how teams perform representational transformations for accessibility: how they are triggered proactively or reactively, how they simplify or enhance, and four common patterns in which workers coordinate with each other to address representational incompatibility. Our findings uncover opportunities for designing systems that can better support mixed-visual ability work.",
      "authors": [
        "Yichun Zhao",
        "Miguel A. Nacenta",
        "Mahadeo A. Sukhai",
        "Sowmya Somanath"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "published": "2026-01-29T18:20:27+00:00",
      "link": "https://arxiv.org/pdf/2601.22081v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17724v1",
      "title": "Quantum-Inspired Algorithms beyond Unitary Circuits: the Laplace Transform",
      "abstract": "Quantum-inspired algorithms can deliver substantial speedups over classical state-of-the-art methods by executing quantum algorithms with tensor networks on conventional hardware. Unlike circuit models restricted to unitary gates, tensor networks naturally accommodate non-unitary maps. This flexibility lets us design quantum-inspired methods that start from a quantum algorithmic structure, yet go beyond unitarity to achieve speedups. Here we introduce a tensor-network approach to compute the discrete Laplace transform, a non-unitary, aperiodic transform (in contrast to the Fourier transform). We encode a length-$N$ signal on two paired $n$-qubit registers and decompose the overall map into a non-unitary exponential Damping Transform followed by a Quantum Fourier Transform, both compressed in a single matrix-product operator. This decomposition admits strong MPO compression to low bond dimension resulting in significant acceleration. We demonstrate simulations up to $N=2^{30}$ input data points, with up to $2^{60}$ output data points, and quantify how bond dimension controls runtime and accuracy, including precise and efficient pole identification.",
      "authors": [
        "Noufal Jaseem",
        "Sergi Ramos-Calderer",
        "Gauthameshwar S.",
        "Dingzu Wang",
        "José Ignacio Latorre",
        "Dario Poletti"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph",
        "physics.data-an"
      ],
      "published": "2026-01-25T07:19:56+00:00",
      "link": "https://arxiv.org/pdf/2601.17724v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20796v1",
      "title": "Dissecting Multimodal In-Context Learning: Modality Asymmetries and Circuit Dynamics in modern Transformers",
      "abstract": "Transformer-based multimodal large language models often exhibit in-context learning (ICL) abilities. Motivated by this phenomenon, we ask: how do transformers learn to associate information across modalities from in-context examples? We investigate this question through controlled experiments on small transformers trained on synthetic classification tasks, enabling precise manipulation of data statistics and model architecture. We begin by revisiting core principles of unimodal ICL in modern transformers. While several prior findings replicate, we find that Rotary Position Embeddings (RoPE) increases the data complexity threshold for ICL. Extending to the multimodal setting reveals a fundamental learning asymmetry: when pretrained on high-diversity data from a primary modality, surprisingly low data complexity in the secondary modality suffices for multimodal ICL to emerge. Mechanistic analysis shows that both settings rely on an induction-style mechanism that copies labels from matching in-context exemplars; multimodal training refines and extends these circuits across modalities. Our findings provide a mechanistic foundation for understanding multimodal ICL in modern transformers and introduce a controlled testbed for future investigation.",
      "authors": [
        "Yiran Huang",
        "Karsten Roth",
        "Quentin Bouniot",
        "Wenjia Xu",
        "Zeynep Akata"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-28T17:37:28+00:00",
      "link": "https://arxiv.org/pdf/2601.20796v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.06246v1",
      "title": "Adaptive Sparse Möbius Transforms for Learning Polynomials",
      "abstract": "We consider the problem of exactly learning an $s$-sparse real-valued Boolean polynomial of degree $d$ of the form $f:\\{ 0,1\\}^n \\rightarrow \\mathbb{R}$. This problem corresponds to decomposing functions in the AND basis and is known as taking a Möbius transform. While the analogous problem for the parity basis (Fourier transform) $f: \\{-1,1 \\}^n \\rightarrow \\mathbb{R}$ is well-understood, the AND basis presents a unique challenge: the basis vectors are coherent, precluding standard compressed sensing methods. We overcome this challenge by identifying that we can exploit adaptive group testing to provide a constructive, query-efficient implementation of the Möbius transform (also known as Möbius inversion) for sparse functions. We present two algorithms based on this insight. The Fully-Adaptive Sparse Möbius Transform (FASMT) uses $O(sd \\log(n/d))$ adaptive queries in $O((sd + n) sd \\log(n/d))$ time, which we show is near-optimal in query complexity. Furthermore, we also present the Partially-Adaptive Sparse Möbius Transform (PASMT), which uses $O(sd^2\\log(n/d))$ queries, trading a factor of $d$ to reduce the number of adaptive rounds to $O(d^2\\log(n/d))$, with no dependence on $s$. When applied to hypergraph reconstruction from edge-count queries, our results improve upon baselines by avoiding the combinatorial explosion in the rank $d$. We demonstrate the practical utility of our method for hypergraph reconstruction by applying it to learning real hypergraphs in simulations.",
      "authors": [
        "Yigit Efe Erginbas",
        "Justin Singh Kang",
        "Elizabeth Polito",
        "Kannan Ramchandran"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T22:50:49+00:00",
      "link": "https://arxiv.org/pdf/2602.06246v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.11145v1",
      "title": "SCRAPL: Scattering Transform with Random Paths for Machine Learning",
      "abstract": "The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose \"Scattering transform with Random Paths for machine Learning\" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.",
      "authors": [
        "Christopher Mitcheltree",
        "Vincent Lostanlen",
        "Emmanouil Benetos",
        "Mathieu Lagrange"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS"
      ],
      "published": "2026-02-11T18:57:08+00:00",
      "link": "https://arxiv.org/pdf/2602.11145v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.13067v1",
      "title": "SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery",
      "abstract": "This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value\" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.",
      "authors": [
        "Chunming Li",
        "Shidong Wang",
        "Tong Xin",
        "Haofeng Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-13T16:22:31+00:00",
      "link": "https://arxiv.org/pdf/2602.13067v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20116v1",
      "title": "In-Context Reinforcement Learning From Suboptimal Historical Data",
      "abstract": "Transformer models have achieved remarkable empirical successes, largely due to their in-context learning capabilities. Inspired by this, we explore training an autoregressive transformer for in-context reinforcement learning (ICRL). In this setting, we initially train a transformer on an offline dataset consisting of trajectories collected from various RL tasks, and then fix and use this transformer to create an action policy for new RL tasks. Notably, we consider the setting where the offline dataset contains trajectories sampled from suboptimal behavioral policies. In this case, standard autoregressive training corresponds to imitation learning and results in suboptimal performance. To address this, we propose the Decision Importance Transformer(DIT) framework, which emulates the actor-critic algorithm in an in-context manner. In particular, we first train a transformer-based value function that estimates the advantage functions of the behavior policies that collected the suboptimal trajectories. Then we train a transformer-based policy via a weighted maximum likelihood estimation loss, where the weights are constructed based on the trained value function to steer the suboptimal policies to the optimal ones. We conduct extensive experiments to test the performance of DIT on both bandit and Markov Decision Process problems. Our results show that DIT achieves superior performance, particularly when the offline dataset contains suboptimal historical data.",
      "authors": [
        "Juncheng Dong",
        "Moyang Guo",
        "Ethan X. Fang",
        "Zhuoran Yang",
        "Vahid Tarokh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T23:13:06+00:00",
      "link": "https://arxiv.org/pdf/2601.20116v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14522v1",
      "title": "On the Runway Cascade of Transformers for Language Modeling",
      "abstract": "In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.",
      "authors": [
        "Hunjae Lee",
        "Corey Clark"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-20T22:29:34+00:00",
      "link": "https://arxiv.org/pdf/2601.14522v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06365v1",
      "title": "Dynamic nanoscale spatial heterogeneity in a perovskite to brownmillerite topotactic phase transformation",
      "abstract": "Phase transitions are omnipresent in modern condensed matter physics and its applications. In solids, phase transformations typically occur by nucleation and growth under non-equilibrium conditions. Under constant external conditions, $\\textit{e.g.}$, constant heating temperature and pressure, the nucleation and growth dynamics are often thought of as spatially and temporally independent. Here, $\\textit{in-situ}$ Bragg X-ray photon correlation spectroscopy (XPCS) reveals nanoscale spatial and dynamical heterogeneity in the perovskite to brownmillerite topotactic phase transformation in La$_{0.7}$Sr$_{0.3}$CoO$_3$ (LSCO) thin films under constant reducing conditions over a time-span of multiple hours. Specifically, a timescale associated with domain growth remains stable, with a corresponding domain wall speed of $v_d = 6 \\pm 0.5 \\times10^{-4}$ nm/s ($2 \\pm 0.2$ nm/h), while a slower timescale, associated with temperature driven de-pinning of domains, leads to accelerating dynamics with timescales following an aging power law with exponent $-2.2 \\pm 0.5$. The experiment demonstrates that Bragg XPCS is a powerful tool to study nanoscale dynamics in phase transformations. The results are relevant for phase engineering of phase-change devices, as they show that nanoscale dynamics, linked to domain and domain-wall motion, can continuously evolve and speed up with time, even hours after the initiation of the phase transformation, with potential repercussions on electrical performance.",
      "authors": [
        "Nicolò D'Anna",
        "Erik S. Lamb",
        "Robin Glefke",
        "Daseul Ham",
        "Ishmam Nihal",
        "Su Yong Lee",
        "Yayoi Takamura",
        "Oleg Shpyrko"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall"
      ],
      "published": "2026-01-10T00:33:05+00:00",
      "link": "https://arxiv.org/pdf/2601.06365v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.12480v1",
      "title": "MXFormer: A Microscaling Floating-Point Charge-Trap Transistor Compute-in-Memory Transformer Accelerator",
      "abstract": "The proliferation of Transformer models is often constrained by the significant computational and memory bandwidth demands of deployment. To address this, we present MXFormer, a novel, hybrid, weight-stationary Compute-in-Memory (CIM) accelerator that provides high throughput and efficiency for fixed-model inference on large short-sequence Transformers. Our architecture's foundation is the use of ultra-dense Charge-Trap Transistors (CTTs) in Microscaling MXFP4 CIM arrays, uniquely enabling the on-chip storage of up to hundreds of millions of parameters in Fully Weight Stationary (FWS) fashion.   We introduce a statically partitioned design with 12 Transformer blocks connected by a deeply pipelined dataflow. Static-weight layers (MLPs and linear projections) execute on highly parallel analog CTT arrays using an MXFP4-native flow with per-block exponent alignment and a 10-bit SAR ADC. Dynamic computations are handled in fully accurate digital blocks that utilize MXFP-enabled systolic arrays for scaled dot-product attention and vector units for LayerNorm and FlashAttention-style Softmax.   By eliminating all weight movement, the deeply pipelined MXFormer architecture yields very high single-stream throughput and efficiency, processing 58275 FPS on ViT-L/32 (dual-chip) or 41269 FPS on ViT-B/16 (single chip). MXFormer outperforms comparable state-of-the-art non-FWS digital, hybrid and photonic Transformer accelerators ~3.3x-60.5x in compute density and ~1.7x-2.5x in energy efficiency. Against FWS accelerators, MXFormer improves compute density by ~20.9x and resident weight storage density by ~2x, while preserving near-digital accuracy (drop of <1%) without any model retraining.",
      "authors": [
        "George Karfakis",
        "Samyak Chakrabarty",
        "Vinod Kurian Jacob",
        "Siyun Qiao",
        "Subramanian S. Iyer",
        "Sudhakar Pamarti",
        "Puneet Gupta"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-02-12T23:38:08+00:00",
      "link": "https://arxiv.org/pdf/2602.12480v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15348v1",
      "title": "Abusive music and song transformation using GenAI and LLMs",
      "abstract": "Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\\% across artists, with major improvements in chorus sections (up to 88.6\\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the \"forbidden fruit\" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.",
      "authors": [
        "Jiyang Choi",
        "Rohitash Chandra"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-21T02:56:45+00:00",
      "link": "https://arxiv.org/pdf/2601.15348v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11237v1",
      "title": "Likelihood-Based Ergodicity Transformations in Time Series Analysis",
      "abstract": "Time series often exhibit non-ergodic behaviour that complicates forecasting and inference. This article proposes a likelihood-based approach for estimating ergodicity transformations that addresses such challenges. The method is broadly compatible with standard models, including Gaussian processes, ARMA, and GARCH. A detailed simulation study using geometric and arithmetic Brownian motion demonstrates the ability of the approach to recover known ergodicity transformations. A further case study on the large macroeconomic database FRED-QD shows that incorporating ergodicity transformations can provide meaningful improvements over conventional transformations or naive specifications in applied work.",
      "authors": [
        "Anthony Britto"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "stat.ME"
      ],
      "published": "2026-01-16T12:30:51+00:00",
      "link": "https://arxiv.org/pdf/2601.11237v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15158v3",
      "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",
      "abstract": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive policy gradient to discover such systematic reasoning remains poorly understood. We address this by analyzing the policy gradient dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, policy gradient drives the Transformer to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler examples, the Transformer learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, policy gradient learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.",
      "authors": [
        "Yuval Ran-Milo",
        "Yotam Alexander",
        "Shahar Mendel",
        "Nadav Cohen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21T16:36:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15158v3",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.13513v2",
      "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization",
      "abstract": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.",
      "authors": [
        "Grant Norman",
        "Conor Rowan",
        "Kurt Maute",
        "Alireza Doostan"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.CE",
        "cs.LG",
        "math.DS",
        "math.NA"
      ],
      "published": "2026-02-13T22:44:33+00:00",
      "link": "https://arxiv.org/pdf/2602.13513v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07970v1",
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "abstract": "Partial Differential Equations are precise in modelling the physical, biological and graphical phenomena. However, the numerical methods suffer from the curse of dimensionality, high computation costs and domain-specific discretization. We aim to explore pros and cons of different PDE solvers, and apply them to specific scientific simulation problems, including forwarding solution, inverse problems and equations discovery. In particular, we extend the recent CNF (NeurIPS 2023) framework solver to multi-dependent-variable and non-linear settings, together with down-stream applications. The outcomes include implementation of selected methods, self-tuning techniques, evaluation on benchmark problems and a comprehensive survey of neural PDE solvers and scientific simulation applications.",
      "authors": [
        "Zheyuan Hu",
        "Weitao Chen",
        "Cengiz Öztireli",
        "Chenliang Zhou",
        "Fangcheng Zhong"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-02-08T13:44:36+00:00",
      "link": "https://arxiv.org/pdf/2602.07970v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04114v1",
      "title": "Turning mechanistic models into forecasters by using machine learning",
      "abstract": "The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\\% for learning a time series and below 6\\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.",
      "authors": [
        "Amit K. Chakraborty",
        "Hao Wang",
        "Pouria Ramazi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DS"
      ],
      "published": "2026-02-04T01:00:08+00:00",
      "link": "https://arxiv.org/pdf/2602.04114v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14779v2",
      "title": "Integrating the probe and singular sources methods: IV. IPS function for the Schrödinger equation",
      "abstract": "The integrated theory of the probe and singular sources methods (IPS) is developed for an inverse obstacle problem governed by the stationary Schrödinger equation in a bounded domain. The unknown obstacles are penetrable, and their surface is modeled by a part of the support of the potential in the governing equation. The main results concern an analytical detection method for these obstacles from the Dirichlet-to-Neumann map. They consist of three parts: a singular sources method via the probe method using a solution with higher-order singularity for the governing equation of the background medium; the discovery of an IPS function whose two ways of decomposition give us the indicator functions for both the probe and singular sources methods; a completely integrated version of both methods, which means their indicator functions coincide. Furthermore, a result on Side B of IPS is also given, concerning the blowing-up property of a sequence calculated from the Dirichlet-to-Neumann map.",
      "authors": [
        "Masaru Ikehata"
      ],
      "primary_category": "math.AP",
      "categories": [
        "math.AP"
      ],
      "published": "2026-01-21T08:59:16+00:00",
      "link": "https://arxiv.org/pdf/2601.14779v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04907v1",
      "title": "Physics as the Inductive Bias for Causal Discovery",
      "abstract": "Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these paradigms potentially allows physical knowledge to act as an inductive bias, improving identifiability, stability, and robustness of causal discovery in dynamical systems. However, such integration remains challenging: real dynamical systems often exhibit feedback, cyclic interactions, and non-stationary data trend, while many widely used causal discovery methods are formulated under acyclicity or equilibrium-based assumptions. In this work, we propose an integrative causal discovery framework for dynamical systems that leverages partial physical knowledge as an inductive bias. Specifically, we model system evolution as a stochastic differential equation (SDE), where the drift term encodes known ODE dynamics and the diffusion term corresponds to unknown causal couplings beyond the prescribed physics. We develop a scalable sparsity-inducing MLE algorithm that exploits causal graph structure for efficient parameter estimation. Under mild conditions, we establish guarantees to recover the causal graph. Experiments on dynamical systems with diverse causal structures show that our approach improves causal graph recovery and produces more stable, physically consistent estimates than purely data-driven state-of-the-art baselines.",
      "authors": [
        "Jianhong Chen",
        "Naichen Shi",
        "Xubo Yue"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "published": "2026-02-03T23:42:01+00:00",
      "link": "https://arxiv.org/pdf/2602.04907v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05632v1",
      "title": "LLM-DMD: Large Language Model-based Power System Dynamic Model Discovery",
      "abstract": "Current model structural discovery methods for power system dynamics impose rigid priors on the basis functions and variable sets of dynamic models while often neglecting algebraic constraints, thereby limiting the formulation of high-fidelity models required for precise simulation and analysis. This letter presents a novel large language model (LLM)-based framework for dynamic model discovery (LLM-DMD) which integrates the reasoning and code synthesis capabilities of LLMs to discover dynamic equations and enforce algebraic constraints through two sequential loops: the differential-equation loop that identifies state dynamics and associated variables, and the algebraic-equation loop that formulates algebraic constraints on the identified algebraic variables. In each loop, executable skeletons of power system dynamic equations are generated by the LLM-based agent and evaluated via gradient-based optimizer. Candidate models are stored in an island-based archive to guide future iterations, and evaluation stagnation activates a variable extension mechanism that augments the model with missing algebraic or input variables, such as stator currents to refine the model. Validation on synchronous generator benchmarks of the IEEE 39-bus system demonstrates the superiority of LLM-DMD in complete dynamic model discovery.",
      "authors": [
        "Chao Shen",
        "Zihan Guo",
        "Ke Zuo",
        "Wenqi Huang",
        "Mingyang Sun"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-09T08:40:45+00:00",
      "link": "https://arxiv.org/pdf/2601.05632v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04498v1",
      "title": "Painleve solitons of AKNS system and irrational algebraic solitons of NLS equations",
      "abstract": "A novel symmetry decomposition approach is introduced to derive the so-called ``Painleve solitons'' of the Ablowitz-Kaup-Newell-Segur (AKNS) system. These Painleve solitons propagate against a background governed by a Painleve transcendent, establishing a fundamental generalization of the well-known elliptic solitons concept. We demonstrate that while elliptic solitons arise from the combination of translation invariance and square eigenfunction symmetry, a different symmetry combination-scaling invariance, Galilean invariance, and square eigenfunction symmetry-generates ``Painleve IV solitons'' for the AKNS system. This discovery represents a significant theoretical advance in integrable systems theory. By selecting special solutions of the Painleve IV equation, we obtain explicit forms of several previously unknown classes of solutions for the AKNS system and the nonlinear Schrodinger (NLS) equation: irrational algebraic solitons, rational algebraic solitons, and parabolic cylindrical function solitons. These results dramatically expand the known solution landscape of one of the most important integrable models in mathematical physics, with broad implications for nonlinear wave phenomena across multiple physical disciplines including optics, Bose-Einstein condensates, and fluid dynamics.",
      "authors": [
        "Man Jia",
        "Xia-Zhi Hao",
        "Ruo-Xia Yao",
        "Fa-Ren Wang",
        "S. Y. Lou"
      ],
      "primary_category": "nlin.SI",
      "categories": [
        "nlin.SI",
        "math-ph",
        "nlin.PS",
        "physics.class-ph"
      ],
      "published": "2026-02-04T12:44:18+00:00",
      "link": "https://arxiv.org/pdf/2602.04498v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04498v2",
      "title": "Painleve solitons of AKNS system and irrational algebraic solitons of NLS equations",
      "abstract": "A novel symmetry decomposition approach is introduced to derive the so-called ``Painlevé solitons'' of the Ablowitz-Kaup-Newell-Segur (AKNS) system. These Painlevé solitons propagate against a background governed by a Painlevé transcendent, establishing a fundamental generalization of the well-known elliptic solitons concept. We demonstrate that while elliptic solitons arise from the combination of translation invariance and square eigenfunction symmetry, a \\textit{different} symmetry combination-scaling invariance, Galilean invariance, and square eigenfunction symmetry-generates ``Painlevé IV solitons'' for the AKNS system. This discovery represents a significant theoretical advance in integrable systems theory. By selecting special solutions of the Painlevé IV equation, we obtain explicit forms of several previously unknown classes of solutions for the AKNS system and the nonlinear Schrödinger (NLS) equation: irrational algebraic solitons, rational algebraic solitons, and parabolic cylindrical function solitons. These results dramatically expand the known solution landscape of one of the most important integrable models in mathematical physics, with broad implications for nonlinear wave phenomena across multiple physical disciplines including optics, Bose-Einstein condensates, and fluid dynamics.",
      "authors": [
        "Man Jia",
        "Xia-Zhi Hao",
        "Ruo-Xia Yao",
        "Fa-Ren Wang",
        "S. Y. Lou"
      ],
      "primary_category": "nlin.SI",
      "categories": [
        "nlin.SI",
        "math-ph",
        "nlin.PS",
        "physics.class-ph"
      ],
      "published": "2026-02-04T12:44:18+00:00",
      "link": "https://arxiv.org/pdf/2602.04498v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07733v1",
      "title": "Data-Driven Discovery of Sign-Indefinite Artificial Viscosity for Linear Convection -- A Space-Time Reconvolution Perspective",
      "abstract": "Artificial viscosity is traditionally interpreted as a positive, spatially acting regularization introduced to stabilize numerical discretizations of hyperbolic conservation laws. In this work, we report a data-driven discovery that motivates a reinterpretation of this classical view. We consider the linear convection equation discretized using an unstable FTCS scheme augmented with a learnable artificial viscosity. Using automatic differentiation and gradient-based optimization, the viscosity field is inferred by minimizing the error with respect to the exact solution, without imposing any sign constraints. The optimized viscosity consistently becomes locally negative near extrema, while the numerical solution remains stable and nearly exact. This behavior is not readily explained within classical modified equation analysis and Lax-Wendroff-type arguments, which predict a strictly positive effective viscosity. To resolve this apparent contradiction, we reinterpret artificial viscosity as a space-time closure that compensates unresolved truncation errors while enforcing entropy stability through global dissipation balance rather than pointwise positivity. Within this framework, the Lax-Wendroff scheme corresponds to a degenerate projection in which temporal truncation errors are eliminated and reintroduced as spatial diffusion. We show that entropy stability constrains the integrated dissipation budget rather than the pointwise sign of spatial viscosity. As a result, locally negative viscosity naturally emerges as a numerical reconvolution operator that compensates for dispersive truncation errors. Negative viscosity is therefore not an unphysical diffusion process, but a scheme- and grid-dependent correction mechanism.",
      "authors": [
        "Arun Govind Neelan"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-08T00:00:05+00:00",
      "link": "https://arxiv.org/pdf/2602.07733v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19223v1",
      "title": "Nonlocal Kramers-Moyal formulas and data-driven discovery of stochastic dynamical systems with multiplicative Lévy noise",
      "abstract": "Traditional data-driven methods, effective for deterministic systems or stochastic differential equations (SDEs) with Gaussian noise, fail to handle the discontinuous sample paths and heavy-tailed fluctuations characteristic of Lévy processes, particularly when the noise is state-dependent. To bridge this gap, we establish nonlocal Kramers-Moyal formulas, rigorously generalizing the classical Kramers-Moyal relations to SDEs with multiplicative Lévy noise. These formulas provide a direct link between short-time transition probability densities (or sample path statistics) and the underlying SDE coefficients: the drift vector, diffusion matrix, Lévy jump measure kernel, and Lévy noise intensity functions. Leveraging these theoretical foundations, we develop novel data-driven algorithms capable of simultaneously identifying all governing components from data and establish convergence results and error analysis for the algorithms. We validate the framework through extensive numerical experiments on prototypical systems. This work provides a principled and practical toolbox for discovering interpretable SDE models governing complex systems influenced by discontinuous, heavy-tailed, state-dependent fluctuations, with broad applicability in climate science, neuroscience, epidemiology, finance, and biological physics.",
      "authors": [
        "Yang Li",
        "Jinqiao Duan"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS",
        "stat.ML"
      ],
      "published": "2026-01-27T05:44:50+00:00",
      "link": "https://arxiv.org/pdf/2601.19223v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.11849v1",
      "title": "Data-driven discovery of chemical reaction networks",
      "abstract": "We propose a unified framework that allows for the full mechanistic reconstruction of chemical reaction networks (CRNs) from concentration data. The framework utilizes an integral formulation of the differential equations governing the chemical reactions, followed by an automatic procedure to recover admissible mass-action mechanisms from the equations. We provide theoretical justification for the use of integral formulations using analytical and numerical error bounds. The integral formulation is demonstrated to offer superior robustness to noise and improved accuracy in both rate-law and graph recovery when compared to other commonly used formulations. Together, our developments advance the goal of fully automated, data-driven chemical mechanism discovery.",
      "authors": [
        "Abraham Reyes-Velazquez",
        "Stefan Güttel",
        "Igor Larrosa",
        "Jonas Latz"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-12T11:41:42+00:00",
      "link": "https://arxiv.org/pdf/2602.11849v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.10632v1",
      "title": "The Neurosymbolic Frontier of Nonuniform Ellipticity: Formalizing Sharp Schauder Theory via Topos-Theoretic Reasoning Models",
      "abstract": "This white paper presents a critical synthesis of the recent breakthrough in nonuniformly elliptic regularity theory and the burgeoning field of neurosymbolic large reasoning models (LRMs). We explore the resolution of the long-standing sharp growth rate conjecture in Schauder theory, achieved by Cristiana De Filippis and Giuseppe Mingione, which identifies the exact threshold $q/p < 1 + α/n$ for gradient Hölder continuity. Central to this mathematical achievement is the ``ghost equation'' methodology, a sophisticated auxiliary derivation that bypasses the non-differentiability of classical Euler-Lagrange systems. We propose that the next era of mathematical discovery lies in the integration of these pure analytical constructs with LRMs grounded in topos theory and formal verification frameworks such as Safe and Typed Chain-of-Thought (PC-CoT). By modeling the reasoning process as a categorical colimit in a slice topos, we demonstrate how LRMs can autonomously navigate the ``Dark Side'' of the calculus of variations, providing machine-checkable proofs for regularity bounds in complex, multi-phase physical systems.",
      "authors": [
        "Suyash Mishra"
      ],
      "primary_category": "cs.SC",
      "categories": [
        "cs.SC",
        "cs.AI"
      ],
      "published": "2026-02-11T08:24:57+00:00",
      "link": "https://arxiv.org/pdf/2602.10632v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19838v1",
      "title": "Modified splitting methods for Gross-Pitaevskii systems modelling Bose-Einstein condensates: Time evolution and ground state computation",
      "abstract": "The year 2025 marks the 100 and 30 years anniversaries of the discovery of Bose--Einstein condensation and its successful experimental realisation. Inspired by these important research achievements, a conceptually simple approach is proposed to facilitate reliable and efficient numerical simulations. The structure of the underlying systems of coupled Gross--Pitaevskii equations suggests the use of optimised high-order operator splitting methods for dynamical evolution and ground state computation. A second-order barrier, however, prevents the applicability of standard operator splitting methods for both, time evolution as well as imaginary time propagation. An innovative alternative approach accomplishes the design of novel modified operator splitting methods that remain stable under moderate smallness assumptions on the time increments. The core idea is to incorporate commutators of the defining differential and nonlinear multiplication operators, since this permits to fulfill the basic stability requirement of positive method coefficients. Further improvements with respect to convergence at the targeted precision arise from automatic adjustments of the time stepsizes by an inexpensive local error control. The presented numerical experiments confirm the favourable performance of a specific fourth-order modified operator splitting method. Amongst others, it is demonstrated that the excellent mass and energy conservation in long-term evolutions, intrinsic attributes of geometric numerical integrators for Hamiltonian systems, is maintained for a sensible variation of the time stepsizes. Moreover, the benefits of adaptive higher-order approximations in ground state computations are illustrated.",
      "authors": [
        "Mechthild Thalhammer",
        "Gregor Thalhammer-Thurner"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-27T17:44:03+00:00",
      "link": "https://arxiv.org/pdf/2601.19838v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14961v1",
      "title": "Power-Law Scaling in the Classification Performance of Small-Scale Spiking Neural Networks",
      "abstract": "This paper investigates the classification capability of small-scale spiking neural networks based on the Leaky Integrate-and-Fire (LIF) neuron model. We analyze the relationship between classification accuracy and three factors: the number of neurons, the number of stimulus nodes, and the number of classification categories. Notably, we employ a large language model (LLM) to assist in discovering the underlying functional relationships among these variables, and compare its performance against traditional methods such as linear and polynomial fitting. Experimental results show that classification accuracy follows a power-law scaling primarily with the number of categories, while the effects of neuron count and stimulus nodes are relatively minor. A key advantage of the LLM-based approach is its ability to propose plausible functional forms beyond pre-defined equation templates, often leading to more concise or accurate mathematical descriptions of the observed scaling laws. This finding has important implications for understanding efficient computation in biological neural systems and for pioneering new paradigms in AI-aided scientific discovery.",
      "authors": [
        "Zhengdi Zhang",
        "Cong Han",
        "Wenjun Xia"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC"
      ],
      "published": "2026-01-21T13:05:34+00:00",
      "link": "https://arxiv.org/pdf/2601.14961v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19091v1",
      "title": "Out-of-Distribution Generalization for Neural Physics Solvers",
      "abstract": "Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery",
      "authors": [
        "Zhao Wei",
        "Chin Chun Ooi",
        "Jian Cheng Wong",
        "Abhishek Gupta",
        "Pao-Hsiung Chiu",
        "Yew-Soon Ong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27T01:57:14+00:00",
      "link": "https://arxiv.org/pdf/2601.19091v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10038v1",
      "title": "What Understanding Means in AI-Laden Astronomy",
      "abstract": "Artificial intelligence is rapidly transforming astronomical research, yet the scientific community has largely treated this transformation as an engineering challenge rather than an epistemological one. This perspective article argues that philosophy of science offers essential tools for navigating AI's integration into astronomy--conceptual clarity about what \"understanding\" means, critical examination of assumptions about data and discovery, and frameworks for evaluating AI's roles across different research contexts. Drawing on an interdisciplinary workshop convening astronomers, philosophers, and computer scientists, we identify several tensions. First, the narrative that AI will \"derive fundamental physics\" from data misconstrues contemporary astronomy as equation-derivation rather than the observation-driven enterprise it is. Second, scientific understanding involves more than prediction--it requires narrative construction, contextual judgment, and communicative achievement that current AI architectures struggle to provide. Third, because narrative and judgment matter, human peer review remains essential--yet AI-generated content flooding the literature threatens our capacity to identify genuine insight. Fourth, while AI excels at well-defined problem-solving, the ill-defined problem-finding that drives breakthroughs appears to require capacities beyond pattern recognition. Fifth, as AI accelerates what is feasible, pursuitworthiness criteria risk shifting toward what AI makes easy rather than what is genuinely important. We propose \"pragmatic understanding\" as a framework for integration--recognizing AI as a tool that extends human cognition while requiring new norms for validation and epistemic evaluation. Engaging with these questions now may help the community shape the transformation rather than merely react to it.",
      "authors": [
        "Yuan-Sen Ting",
        "André Curtis-Trudel",
        "Siyu Yao"
      ],
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-15T03:28:38+00:00",
      "link": "https://arxiv.org/pdf/2601.10038v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.09093v1",
      "title": "Predicting magnetism with first-principles AI",
      "abstract": "Computational discovery of magnetic materials remains challenging because magnetism arises from the competition between kinetic energy and Coulomb interaction that is often beyond the reach of standard electronic-structure methods. Here we tackle this challenge by directly solving the many-electron Schrödinger equation with neural-network variational Monte Carlo, which provides a highly expressive variational wavefunction for strongly correlated systems. Applying this technique to transition metal dichalcogenide moiré semicondutors, we predict itinerant ferromagnetism in WSe$_2$/WS$_2$ and an antiferromagnetic insulator in twisted $Γ$-valley homobilayer, using the same neural network without any physics input beyond the microscopic Hamiltonian. Crucially, both types of magnetic states are obtained from a single calculation within the $S_z=0$ sector, removing the need to compute and compare multiple $S_z$ sectors. This significantly reduces computational cost and paves the way for faster and more reliable magnetic material design.",
      "authors": [
        "Max Geier",
        "Liang Fu"
      ],
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cs.LG"
      ],
      "published": "2026-02-09T19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.09093v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12320v1",
      "title": "Molecular pentaquarks composed of a ground octet baryon and a $P-$wave anti-charmed meson",
      "abstract": "In this work, we investigate the interactions between an excited anti-charm meson doublet $(\\bar{D}_1, \\bar{D}_2^*)$ and ground-state octet baryons $(N, Λ, Σ, Ξ)$ with the aim of identifying possible molecular pentaquark states. A systematic analysis is performed within the one-boson-exchange model, which incorporates both $S$-wave and $P$-wave interactions, $S$-$D$ wave mixing, and coupled-channel effects. By solving the Schrödinger equations, we can predict a rich spectrum of loosely bound anti-charm molecular pentaquarks with strangeness $|S| = 0, 1, 2$. Our results provide specific quantum number assignments and mass range predictions to guide future experimental searches at facilities such as LHCb and Belle II. The discovery of such states would significantly enrich the hadron spectrum and serve as a critical test of theoretical models for hadronic interactions.",
      "authors": [
        "Yu-Yue Cui",
        "Rui Chen",
        "Qi Huang"
      ],
      "primary_category": "hep-ph",
      "categories": [
        "hep-ph"
      ],
      "published": "2026-01-18T09:05:04+00:00",
      "link": "https://arxiv.org/pdf/2601.12320v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.07939v1",
      "title": "New solution to the hyperon puzzle of neutron stars: Quantum many-body effects",
      "abstract": "The hyperon puzzle refers to the challenge of reconciling the existence of hyperons in neutron star cores and the observed high masses of neutron stars. The recent discovery of PSR J0952-0607 ($2.35\\pm0.17 M_{\\odot}$) has intensified this challenge. Existing solutions fail to achieve such a high mass, and often predict unrealistically fast cooling that is at odds with observations. Here, we propose a novel solution to the hyperon puzzle. Using the Dyson-Schwinger equation approach, we incorporate the quantum many-body effects caused by strong baryon-meson interactions into the equation of state for cold baryonic matter and find it stiff enough to support a maximum hyperon-star mass of $M_{\\mathrm{max}} \\approx 2.59 M_{\\odot}$, which can explain all the observed high neutron-star masses. The resulting proton and hyperon fractions are remarkably low, thus the nucleonic and hyperonic direct Urca processes are significantly suppressed. As a result, fast cooling typically does not occur in ordinary neutron stars.",
      "authors": [
        "Hao-Fu Zhu",
        "Guo-Zhu Liu",
        "Xufen Wu",
        "Ye-Fei Yuan"
      ],
      "primary_category": "nucl-th",
      "categories": [
        "nucl-th",
        "astro-ph.HE",
        "cond-mat.str-el"
      ],
      "published": "2026-02-08T12:13:06+00:00",
      "link": "https://arxiv.org/pdf/2602.07939v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.08269v1",
      "title": "Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation",
      "abstract": "Modern problems in high-performance computing, ranging from training and inferencing deep learning models in computer vision and language models to simulating complex physical systems with nonlinearly-coupled equations, require exponential growth of computational resources. Photonic analog systems are emerging with solutions of intrinsic parallelism, high bandwidth, and low propagation loss. However, their application has been hindered by the low analog accuracy due to the electro-optic distortion, material nonlinearities, and signal-to-noise ratios. Here we overcome this barrier with a quantization-aware digital-photonic mixed-precision framework across chiplets for accelerated AI processing and physical simulation. Using Lithium Niobate photonics with channel equalization techniques, we demonstrate linear multiplication (9-bit amplitude-phase decoupling) in homodyne optical logics with 6-bit precision at the clock rate of 128 giga-symbol-per-second (128 GS/s), enabling AI processing with 6 ns latency. Codesign hardware-algorithms, including iterative solvers, sparse-dense quantization, and bit-sliced matrix multiplication, explore photonic amplitude and phase coherence for complex-valued, physics-inspired computation. In electromagnetic problems, our approach yields 12-bit solutions for partial differential equations (PDEs) in scattering problems that would conventionally require up to 32-bit and often even 64-bit precision. These results preserve digital-level fidelity while leveraging the high-speed low-energy photonic hardware, establishing a pathway toward general-purpose optical acceleration for generative artificial intelligence, real-time robotics, and accurate simulation for climate challenges and biological discoveries.",
      "authors": [
        "Lian Zhou",
        "Kaiwen Xue",
        "Amirhossein Fallah",
        "Lijin Liu",
        "Chun-Ho Lee",
        "Kiwon Kwon",
        "Clayton Cheung",
        "Yuan Li",
        "Yue Yu",
        "Yun-Jhu Lee",
        "Songlin Zhao",
        "Ryan Hamerly",
        "Edo Waks",
        "Dirk Englund",
        "Constantine Sideris",
        "Mengjie Yu",
        "Zaijun Chen"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET"
      ],
      "published": "2026-02-09T05:08:03+00:00",
      "link": "https://arxiv.org/pdf/2602.08269v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.17493v1",
      "title": "Learning with Boolean threshold functions",
      "abstract": "We develop a method for training neural networks on Boolean data in which the values at all nodes are strictly $\\pm 1$, and the resulting models are typically equivalent to networks whose nonzero weights are also $\\pm 1$. The method replaces loss minimization with a nonconvex constraint formulation. Each node implements a Boolean threshold function (BTF), and training is expressed through a divide-and-concur decomposition into two complementary constraints: one enforces local BTF consistency between inputs, weights, and output; the other imposes architectural concurrence, equating neuron outputs with downstream inputs and enforcing weight equality across training-data instantiations of the network. The reflect-reflect-relax (RRR) projection algorithm is used to reconcile these constraints.   Each BTF constraint includes a lower bound on the margin. When this bound is sufficiently large, the learned representations are provably sparse and equivalent to networks composed of simple logical gates with $\\pm 1$ weights. Across a range of tasks -- including multiplier-circuit discovery, binary autoencoding, logic-network inference, and cellular automata learning -- the method achieves exact solutions or strong generalization in regimes where standard gradient-based methods struggle. These results demonstrate that projection-based constraint satisfaction provides a viable and conceptually distinct foundation for learning in discrete neural systems, with implications for interpretability and efficient inference.",
      "authors": [
        "Veit Elser",
        "Manish Krishan Lal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-19T16:07:25+00:00",
      "link": "https://arxiv.org/pdf/2602.17493v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04806v2",
      "title": "A Two-Dimensional Analytic Solution for the Generation of Hyperbolic Trajectories Via A Single Close Encounter with Applications To Interstellar Objects",
      "abstract": "The discovery of interstellar interlopers such as 1I/`Oumuamua, 2I/Borisov, and 3I/ATLAS have highlighted the necessity of understanding the dynamical pathways that eject small bodies from planetary systems into hyperbolic trajectories. In this paper we examine the orbital elements of particles in the restricted three-body problem prior to and post scattering onto hyperbolic trajectories by massive perturbers. Building on previous work, we calculate closed-form -- but approximate -- analytic criteria that map pre- to post-encounter orbital elements. An application of these equations demonstrates that ejection occurs most efficiently when the orbital eccentricity of the massless test particle exceeds a minimum threshold, $e\\gtrsim0.4$. The primary driver of the final eccentricity is the component of the perturber-centric velocity projected along the direction of motion of the perturber. These analytic criteria are then benchmarked and validated against numerical simulations which demonstrate that they provide a reasonably good zeroth-order approximation for ejection behavior. However, system-specific cases will generally require numerical simulations in addition to this analytic construction. The methodology is applied to (i) the solar system and exoplanetary systems (ii) $β$ Pictoris and (iii) HR 8799 to evaluate the pre-scattering orbits of ejected particles. This method provides a transparent and computationally efficient tool for identifying orbits within a given system from which interstellar objects are efficiently ejected via a single scattering event from a massive perturber.",
      "authors": [
        "Hayden Monk",
        "Darryl Z. Seligman"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA"
      ],
      "published": "2026-02-04T17:53:23+00:00",
      "link": "https://arxiv.org/pdf/2602.04806v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04806v1",
      "title": "A Two-Dimensional Analytic Solution for the Generation of Hyperbolic Trajectories Via A Single Close Encounter with Applications To Interstellar Objects",
      "abstract": "The discovery of interstellar interlopers such as 1I/`Oumuamua, 2I/Borisov, and 3I/ATLAS have highlighted the necessity of understanding the dynamical pathways that eject small bodies from planetary systems into hyperbolic trajectories. In this paper we examine the orbital elements of particles in the restricted three-body problem prior to and post scattering onto hyperbolic trajectories by massive perturbers. Building on previous work, we calculate closed-form -- but approximate -- analytic criteria that map pre- to post-encounter orbital elements. An application of these equations demonstrates that ejection occurs most efficiently when the orbital eccentricity of the massless test particle exceeds a minimum threshold, $e\\gtrsim0.4$. The primary driver of the final eccentricity is the component of the perturber-centric velocity projected along the direction of motion of the perturber. These analytic criteria are then benchmarked and validated against numerical simulations which demonstrate that they provide a reasonably good zeroth-order approximation for ejection behavior. However, system-specific cases will generally require numerical simulations in addition to this analytic construction. The methodology is applied to (i) the solar system and exoplanetary systems (ii) $β$ Pictoris and (iii) HR 8799 to evaluate the pre-scattering orbits of ejected particles. This method provides a transparent and computationally efficient tool for identifying orbits within a given system from which interstellar objects are efficiently ejected via a single scattering event from a massive perturber.",
      "authors": [
        "Hayden Monk",
        "Darryl Z. Seligman"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP",
        "astro-ph.GA"
      ],
      "published": "2026-02-04T17:53:23+00:00",
      "link": "https://arxiv.org/pdf/2602.04806v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.14105v1",
      "title": "Non-Hermitian Quantum Mechanics of Open Quantum Systems: Revisiting The One-Body Problem",
      "abstract": "We review analyses of open quantum systems. We show how non-Hermiticity arises in an open quantum system with an infinite environment, focusing on the one-body problem. One of the reasons for taking the present approach is that we can solve the problem completely, making it easier to see the structures of problems involving open quantum systems. We show that this results in the discovery of a new complete set, which is one of the main topics of the present article. Another reason for focusing on the one-body problem is that the theory permits the strong coupling between the system and the environment. In the current research landscape, it is valuable to revisit the one-body problem for open quantum systems, which can be solved accurately for arbitrary strengths of the system-environment couplings. A rigorous understanding of the problem structures in the present approach will be helpful when we tackle problems with many-body interactions. First, we consider potential scattering and directly define the resonant state as an eigenstate of the Schrödinger equation under the Siegert outgoing boundary condition. We show that the resonant eigenstate can have a complex energy eigenvalue, even though the Hamiltonian is seemingly Hermitian. Second, we introduce the Feshbach formalism, which eliminates the infinite degrees of freedom of the environment and represents its effect as a complex potential. The resulting effective Hamiltonian is explicitly non-Hermitian. By unifying these two ways of defining resonant states, we obtain a new complete set of bases for the scattering problem that contains all discrete eigenstates, including resonant states. We finally mention the non-Markovian dynamics of open quantum systems. We emphasize the time-reversal symmetry of the dynamics that continuously connects the past and the future. We can capture it using the new complete set that we develop here.",
      "authors": [
        "Naomichi Hatano",
        "Gonzalo Ordonez"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "math-ph",
        "nucl-th"
      ],
      "published": "2026-02-15T11:42:18+00:00",
      "link": "https://arxiv.org/pdf/2602.14105v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.16551v1",
      "title": "Automated Extraction of Mechanical Constitutive Models from Scientific Literature using Large Language Models: Applications in Cultural Heritage Conservation",
      "abstract": "The preservation of cultural heritage is increasingly transitioning towards data-driven predictive maintenance and \"Digital Twin\" construction. However, the mechanical constitutive models required for high-fidelity simulations remain fragmented across decades of unstructured scientific literature, creating a \"Data Silo\" that hinders conservation engineering. To address this, we present an automated, two-stage agentic framework leveraging Large Language Models (LLMs) to extract mechanical constitutive equations, calibrated parameters, and metadata from PDF documents. The workflow employs a resource-efficient \"Gatekeeper\" agent for relevance filtering and a high-capability \"Analyst\" agent for fine-grained extraction, featuring a novel Context-Aware Symbolic Grounding mechanism to resolve mathematical ambiguities. Applied to a corpus of over 2,000 research papers, the system successfully isolated 113 core documents and constructed a structured database containing 185 constitutive model instances and over 450 calibrated parameters. The extraction precision reached 80.4\\%, establishing a highly efficient \"Human-in-the-loop\" workflow that reduces manual data curation time by approximately 90\\%. We demonstrate the system's utility through a web-based Knowledge Retrieval Platform, which enables rapid parameter discovery for computational modeling. This work transforms scattered literature into a queryable digital asset, laying the data foundation for the \"Digital Material Twin\" of built heritage.",
      "authors": [
        "Rui Hu",
        "Yue Wu",
        "Tianhao Su",
        "Yin Wang",
        "Shunbo Hu",
        "Jizhong Huang"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-18T15:53:15+00:00",
      "link": "https://arxiv.org/pdf/2602.16551v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11414v1",
      "title": "New Adaptive Mechanism for Large Neighborhood Search using Dual Actor-Critic",
      "abstract": "Adaptive Large Neighborhood Search (ALNS) is a widely used heuristic method for solving combinatorial optimization problems. ALNS explores the solution space by iteratively using destroy and repair operators with probabilities, which are adjusted by an adaptive mechanism to find optimal solutions. However, the classic ALNS adaptive mechanism does not consider the interaction between destroy and repair operators when selecting them. To overcome this limitation, this study proposes a novel adaptive mechanism. This mechanism enhances the adaptability of the algorithm through a Dual Actor-Critic (DAC) model, which fully considers the fact that the quality of new solutions is jointly determined by the destroy and repair operators. It effectively utilizes the interaction between these operators during the weight adjustment process, greatly improving the adaptability of the ALNS algorithm. In this mechanism, the destroy and repair processes are modeled as independent Markov Decision Processes to guide the selection of operators more accurately. Furthermore, we use Graph Neural Networks to extract key features from problem instances and perform effective aggregation and normalization to enhance the algorithm's transferability to different sizes and characteristics of problems. Through a series of experiments, we demonstrate that the proposed DAC-ALNS algorithm significantly improves solution efficiency and exhibits excellent transferability.",
      "authors": [
        "Shaohua Yu",
        "Wenhao Mao",
        "Zigao Wu",
        "Jakob Puchinger"
      ],
      "primary_category": "cs.GT",
      "categories": [
        "cs.GT",
        "cs.LG"
      ],
      "published": "2026-01-16T16:33:52+00:00",
      "link": "https://arxiv.org/pdf/2601.11414v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08253v1",
      "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
      "abstract": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.",
      "authors": [
        "Baoyun Zhao",
        "He Wang",
        "Liang Zeng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-09T04:13:35+00:00",
      "link": "https://arxiv.org/pdf/2602.08253v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11010v1",
      "title": "The Dynamic Team Orienteering Problem in Spatial Crowdsourcing: A Scenario Sampling Approach",
      "abstract": "In services such as retail audits and urban infrastructure monitoring, a platform dispatches rewarded, location-based micro-tasks to mobile workers traveling along personal origin-destination (OD) trips under hard time budgets. As requests with time constraints arrive online over a finite horizon, the platform must decide which requests to accept and how to route workers to maximize collected profit. We model this setting as the Dynamic Team Orienteering Problem in Spatial Crowdsourcing (DTOP-SC). To solve this problem, we propose a scenario-sampling rolling-horizon framework that mitigates myopic bias by augmenting each planning epoch with sampled virtual tasks. At each epoch, the augmented task set defines a deterministic static subproblem solved via an adaptive large neighborhood search (ALNS). We also formulate a mixed-integer programming model to provide offline reference solutions. Computational experiments are conducted on synthetic DTOP-SC instances generated from real-world road-map coordinates and on a dynamic team orienteering (DTOP) benchmark. On the map-based instances, the proposed policy exhibits stable gaps with respect to time-limited MIP solutions across the tested scales, while maintaining smooth computational scalability as the problem size increases. On the DTOP benchmark, the policy achieves an average decision time of 0.14s per instance, with 192-198s reported for multiple plan approach as an indicative reference, while maintaining competitive profit.",
      "authors": [
        "Zhibin Wu",
        "Songhao Shen",
        "Yufeng Zhou",
        "Qin Lei"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-16T05:47:04+00:00",
      "link": "https://arxiv.org/pdf/2601.11010v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22052v2",
      "title": "Learning to Dial-a-Ride: A Deep Graph Reinforcement Learning Approach to the Electric Dial-a-Ride Problem",
      "abstract": "Urban mobility systems are transitioning toward electric, on-demand services, creating operational challenges for fleet management under energy and service-quality constraints. The Electric Dial-a-Ride Problem (E-DARP) extends the classical dial-a-ride problem by incorporating limited battery capacity and nonlinear charging dynamics, increasing computational complexity and limiting the scalability of exact methods for real-time use. This paper proposes a deep reinforcement learning approach based on an edge-centric graph neural network encoder and an attention-driven route construction policy. By operating directly on edge attributes such as travel time and energy consumption, the method captures non-Euclidean, asymmetric, and energy-dependent routing costs in real road networks. The learned policy jointly optimizes routing, charging, and service quality without relying on Euclidean assumptions or handcrafted heuristics. The approach is evaluated on two case studies using ride-sharing data from San Francisco. On benchmark instances, the method achieves solutions within 0.4% of best-known results while reducing computation times by orders of magnitude. A second case study considers large-scale instances with up to 250 request pairs, realistic energy models, and nonlinear charging. On these instances, the learned policy outperforms Adaptive Large Neighborhood Search (ALNS) by 9.5% in solution quality while achieving 100% service completion, with inference times under 10 seconds compared to hours for the metaheuristic. Finally, sensitivity analyses quantify the impact of battery capacity, fleet size, ride-sharing capacity, and reward weights, while robustness experiments show that deterministically trained policies generalize effectively under stochastic conditions.",
      "authors": [
        "Sten Elling Tingstad Jacobsen",
        "Attila Lischka",
        "Balázs Kulcsár",
        "Anders Lindman"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-29T17:51:04+00:00",
      "link": "https://arxiv.org/pdf/2601.22052v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.12055v1",
      "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
      "abstract": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
      "authors": [
        "Amath Sow",
        "Mauricio Rodriguez Cesen",
        "Fabiola Martins Campos de Oliveira",
        "Mariusz Wzorek",
        "Daniel de Leng",
        "Mattias Tiger",
        "Fredrik Heintz",
        "Christian Esteve Rothenberg"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "published": "2026-02-12T15:18:46+00:00",
      "link": "https://arxiv.org/pdf/2602.12055v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.17899v2",
      "title": "Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization",
      "abstract": "Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.",
      "authors": [
        "Junhao Qiu",
        "Xin Chen",
        "Liang Ge",
        "Liyong Lin",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-25T16:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.17899v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05358v1",
      "title": "Bayesian Neighborhood Adaptation for Graph Neural Networks",
      "abstract": "The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for message aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis shows that the scope inference improves the expressivity of a GNN. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, achieving competitive or superior performance on the node classification task, and providing well-calibrated predictions.",
      "authors": [
        "Paribesh Regmi",
        "Rui Li",
        "Kishan K C"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T06:29:38+00:00",
      "link": "https://arxiv.org/pdf/2602.05358v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05358v2",
      "title": "Bayesian Neighborhood Adaptation for Graph Neural Networks",
      "abstract": "The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for message aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis shows that the scope inference improves the expressivity of a GNN. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, achieving competitive or superior performance on the node classification task, and providing well-calibrated predictions. Implementation is available at : https://github.com/paribeshregmi/BNA-GNN",
      "authors": [
        "Paribesh Regmi",
        "Rui Li",
        "Kishan KC"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T06:29:38+00:00",
      "link": "https://arxiv.org/pdf/2602.05358v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08616v1",
      "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces",
      "abstract": "Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforcement Learning (DGRL), combining Sampled Dynamic Neighborhoods (SDN) and Distance-Based Updates (DBU) to enable efficient RL in spaces with up to 10$^\\text{20}$ actions. Unlike prior methods, SDN leverages a semantic embedding space to perform stochastic volumetric exploration, provably providing full support over a local trust region. Complementing this, DBU transforms policy optimization into a stable regression task, decoupling gradient variance from action space cardinality and guaranteeing monotonic policy improvement. DGRL naturally generalizes to hybrid continuous-discrete action spaces without requiring hierarchical dependencies. We demonstrate performance improvements of up to 66% against state-of-the-art benchmarks across regularly and irregularly structured environments, while simultaneously improving convergence speed and computational complexity.",
      "authors": [
        "Heiko Hoppe",
        "Fabian Akkerman",
        "Wouter van Heeswijk",
        "Maximilian Schiffer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-09T13:05:07+00:00",
      "link": "https://arxiv.org/pdf/2602.08616v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11047v1",
      "title": "CoG: Controllable Graph Reasoning via Relational Blueprints and Failure-Aware Refinement over Knowledge Graphs",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities but often grapple with reliability challenges like hallucinations. While Knowledge Graphs (KGs) offer explicit grounding, existing paradigms of KG-augmented LLMs typically exhibit cognitive rigidity--applying homogeneous search strategies that render them vulnerable to instability under neighborhood noise and structural misalignment leading to reasoning stagnation. To address these challenges, we propose CoG, a training-free framework inspired by Dual-Process Theory that mimics the interplay between intuition and deliberation. First, functioning as the fast, intuitive process, the Relational Blueprint Guidance module leverages relational blueprints as interpretable soft structural constraints to rapidly stabilize the search direction against noise. Second, functioning as the prudent, analytical process, the Failure-Aware Refinement module intervenes upon encountering reasoning impasses. It triggers evidence-conditioned reflection and executes controlled backtracking to overcome reasoning stagnation. Experimental results on three benchmarks demonstrate that CoG significantly outperforms state-of-the-art approaches in both accuracy and efficiency.",
      "authors": [
        "Yuanxiang Liu",
        "Songze Li",
        "Xiaoke Guo",
        "Zhaoyan Gong",
        "Qifei Zhang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-16T07:27:40+00:00",
      "link": "https://arxiv.org/pdf/2601.11047v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.17495v1",
      "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems",
      "abstract": "In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.",
      "authors": [
        "Ruiyu Zhang",
        "Lin Nie",
        "Wai-Fung Lam",
        "Qihao Wang",
        "Xin Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-24T15:46:02+00:00",
      "link": "https://arxiv.org/pdf/2601.17495v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.13969v1",
      "title": "Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval",
      "abstract": "Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.",
      "authors": [
        "Joaquín Polonuer",
        "Lucas Vittor",
        "Iñaki Arango",
        "Ayush Noori",
        "David A. Clifton",
        "Luciano Del Corro",
        "Marinka Zitnik"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-20T13:46:37+00:00",
      "link": "https://arxiv.org/pdf/2601.13969v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.08621v1",
      "title": "GraphSearch: Agentic Search-Augmented Reasoning for Zero-Shot Graph Learning",
      "abstract": "Recent advances in search-augmented large reasoning models (LRMs) enable the retrieval of external knowledge to reduce hallucinations in multistep reasoning. However, their ability to operate on graph-structured data, prevalent in domains such as e-commerce, social networks, and scientific citations, remains underexplored. Unlike plain text corpora, graphs encode rich topological signals that connect related entities and can serve as valuable priors for retrieval, enabling more targeted search and improved reasoning efficiency. Yet, effectively leveraging such structure poses unique challenges, including the difficulty of generating graph-expressive queries and ensuring reliable retrieval that balances structural and semantic relevance. To address this gap, we introduce GraphSearch, the first framework that extends search-augmented reasoning to graph learning, enabling zero-shot graph learning without task-specific fine-tuning. GraphSearch combines a Graph-aware Query Planner, which disentangles search space (e.g., 1-hop, multi-hop, or global neighbors) from semantic queries, with a Graph-aware Retriever, which constructs candidate sets based on topology and ranks them using a hybrid scoring function. We further instantiate two traversal modes: GraphSearch-R, which recursively expands neighborhoods hop by hop, and GraphSearch-F, which flexibly retrieves across local and global neighborhoods without hop constraints. Extensive experiments across diverse benchmarks show that GraphSearch achieves competitive or even superior performance compared to supervised graph learning methods, setting state-of-the-art results in zero-shot node classification and link prediction. These findings position GraphSearch as a flexible and generalizable paradigm for agentic reasoning over graphs.",
      "authors": [
        "Jiajin Liu",
        "Yuanfu Sun",
        "Dongzhe Fan",
        "Qiaoyu Tan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-13T15:00:57+00:00",
      "link": "https://arxiv.org/pdf/2601.08621v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.12151v1",
      "title": "Significant impact of Al1-xGaxN interlayer on GaN/AlN thermal boundary conductance",
      "abstract": "AlN-GaN heterostructures are central to high-power and high-frequency electronics, including RF devices, power converters, and AI accelerators. An intermediate Al1-xGaxN (AlGaN) layer is often present, either unintentionally during growth or intentionally to induce a 2D electron gas, yet its impact on the interfacial thermal boundary conductance (TBC) remains unknown due to the lack of reliable measurement or modeling methods. Here, we report a first principles-based evaluation of the TBCs of AlN-AlGaN, AlGaN-GaN, and AlN-AlGaN-GaN interfaces over the full alloy range. This is realized by the development of accurate deep learning interatomic potentials based on first-principles simulations. Contrary to other material systems where mixed interlayers enhance thermal coupling, we find that an AlGaN interlayer markedly degrades TBC between GaN and AlN, explaining the observation in experiments. Finally, we show that if the Al composition is sigmoidally transitioned from 0 to 1 across the AlN-GaN interface, it can remarkably increase the TBC, compared to an abrupt or a linear transition. This work is expected to shed light on an accurate thermal analysis and electro-thermal co-design of future AlGaN-based devices.",
      "authors": [
        "Khalid Zobaid Adnan",
        "Hao Zhou",
        "Tianli Feng"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-17T19:51:35+00:00",
      "link": "https://arxiv.org/pdf/2601.12151v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.17214v1",
      "title": "Polarization Switching of Piezoelectric Films due to Proximity of Ferroelectric Nanoclusters",
      "abstract": "Using Landau-Ginzburg-Devonshire thermodynamical approach and finite element modelling, we studied the influence of nanoclusters shape on the polarization switching and domain nucleation emerging in otherwise non-switchable piezoelectric films due to the proximity of ferroelectric nanoclusters. The boundary of the ferroelectric nanocluster embedded in the piezoelectric film is a compositionally graded layer. We analyzed the conditions, which allow switching the electric polarization of the piezoelectric AlN film at coercive field significantly lower than the electric breakdown field due to the proximity of ferroelectric Al1-xScxN clusters. Due to proximity effect, the spontaneous polarization switches in all elements of the nanopatterned film, and corresponding coercive fields can be reduced significantly in the presence of spike-like Al1-xScxN clusters. We also explored the underlaying physical mechanisms of the proximity effects in the piezoelectric films with ferroelectric nanoclusters. The internal field, which is depolarizing inside the piezoelectric film (due to the larger spontaneous polarization of AlN) and polarizing in the ferroelectric cluster (due to the smaller spontaneous polarization of Al1-xScxN), lowers the potential barrier in the clusters and facilitates the instant growth of nanodomains (emerging in the clusters) through the piezoelectric film. Since considered nanostructured materials can be created by implantation of Sc ions into AlN films, obtained theoretical results can be useful for creation of nanopatterned ferroelectrics by chemical engineering, with exciting prospects for previously unrealizable ferroelectric memory technologies.",
      "authors": [
        "Anna N. Morozovska",
        "Eugene A. Eliseev",
        "Sergei V. Kalin",
        "Long-Qing Chen",
        "Dean R. Evans",
        "Venkatraman Gopalan"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ],
      "published": "2026-01-23T22:53:10+00:00",
      "link": "https://arxiv.org/pdf/2601.17214v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.10495v1",
      "title": "Growth and Morphology of InN Nanowires on Si<111> and Si<100> at Back-End-Of-Line Compatible Temperatures",
      "abstract": "InN nanowires were grown on Si<111> and Si<100> substrates by plasma-assisted molecular beam epitaxy using a thin AlN buffer layer at temperatures compatible with the thermal budget limitation imposed by Back-End-Of-Line processing. Reflection high-energy electron diffraction reveals different nucleation behaviors on the two substrate orientations, with higher structural disorder in the case of Si<100>. However, vertically aligned nanowires with hexagonal cross section and N polarity are obtained on both substrates. A statistical analysis of nanowire morphology as a function of growth temperature indicates similar trends in diameter, density, and length on Si<111> and Si<100>, which are explained by adatom kinetics during growth. Nanowires on Si<100> exhibit improved uniformity and reduced tapering, attributed to the different nanowire nucleation due to microstructural properties of the AlN buffer layer. The results demonstrate the feasibility of growing high-quality InN nanowires on Si<100>, supporting their potential for monolithic integration of nanowire-based photodetectors on silicon.",
      "authors": [
        "Andrea Orlando-cunnac",
        "Arthur Arnaud",
        "Martien Den Hertog",
        "Ettore Coccato",
        "Vincent Calvo",
        "Jonathan Steckel",
        "Eva Monroy"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-15T15:13:56+00:00",
      "link": "https://arxiv.org/pdf/2601.10495v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.12956v1",
      "title": "Molecular Beam Epitaxy of Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N Nanowires: Towards Group-III Nitride Piezoelectric Nanogenerators with Enhanced Response",
      "abstract": "We study the molecular beam epitaxy of self-assembled Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N nanowires on conductive TiN layers and demonstrate their application in piezoelectric nanogenerators. Wurtzite Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N nanowires with uniform Sc incorporation are grown across a wide composition range (0<x<0.35). At substrate temperatures below 700 $^\\circ{}$C, these nanowires exhibit an inversely tapered morphology, whereas higher temperatures favor the nucleation of additional branches due to a phase separation of Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N into wurtzite AlN and rock-salt ScN. Phase-pure Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N nanowires are integrated into vertical nanogenerators, where the metallic TiN substrate serves as bottom electrode. The fabricated polymer-nanowire composite devices achieve effective piezoelectric charge coefficients of up to 8.5 pC N$^{-1}$ at x=0.32, thus exceeding the piezoelectric response of bulk AlN by nearly a factor of two. Although the charge response remains lower compared to Al$\\mathrm{_{1-x}}$Sc$\\mathrm{_{x}}$N thin films, the reduced effective dielectric permittivity of the nanowire-polymer composites compensates the reduction in piezoelectric charge coefficient, eventually yielding a higher voltage response and comparable energy harvesting efficiency. Finally, effective medium modeling reveals that the device architecture is the primary factor limiting performance, providing general design principles for highly efficient nanowire-based piezoelectric energy harvesters.",
      "authors": [
        "Adriano Notarangelo",
        "Rudeesun Songmuang",
        "Mostafa Saleh",
        "Nattawadi Buatip",
        "Ileana Florea",
        "Philippe Vennéguès",
        "Aidan F. Campbell",
        "Hans Tornatzky",
        "Jonas Lähnemann",
        "Thomas Auzelle",
        "Lutz Geelhaar",
        "Oliver Brandt",
        "Philipp M. John"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "physics.app-ph"
      ],
      "published": "2026-02-13T14:21:36+00:00",
      "link": "https://arxiv.org/pdf/2602.12956v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.13827v1",
      "title": "Ion Implantation Enhanced Nucleation Facilitates Heat Transport across Atomically-Sharp Semiconductor Interfaces",
      "abstract": "Overheating is a critical bottleneck limiting the performance and reliability of next-generation high-power and high-frequency electronics. Interfacial thermal resistance constitutes a significant portion of the total thermal resistance. In this study, we report an ultrahigh thermal boundary conductance (TBC) of approximately 800 MW/m2-K at the atomically-sharp AlN-SiC interface, achieved through an ion implantation-enhanced nucleation epitaxy technique. This value is among the highest TBC values reported for semiconductor interfaces, confirmed by structural characterizations which show an ultrahigh-quality interface. Atomistic Green Function calculations reveal that elastic phonon transmission dominates the interface, with nearly half of the acoustic modes (0-15 THz) exhibiting near-unity transmission due to the atomically sharp structure. Furthermore, using high-energy-resolution electron energy loss spectroscopy, we probe vibrational properties with nanometer spatial resolution and identify unique interfacial phonon modes connecting the mismatched phonon spectra, confirmed by molecular dynamics simulations. The ultrahigh TBC is attributed to both the high elastic phonon transmission due to the high quality interfaces and the inelastic phonon scattering channel due to interfacial phonon modes. These findings not only advance the fundamental understanding of interfacial thermal transport but also provide a pathway for effective thermal management in emerging electronic devices.",
      "authors": [
        "Jinwen Liu",
        "Zifeng Huang",
        "Lina Yang",
        "Yachao Zhang",
        "Xingqiang Zhang",
        "Kun Zhang",
        "Xufei Guo",
        "Yuxiang Wang",
        "Hong Zhou",
        "Jincheng Zhang",
        "Wei Wang",
        "Yue Hao",
        "Zhe Cheng"
      ],
      "primary_category": "cond-mat.mes-hall",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-14T15:41:43+00:00",
      "link": "https://arxiv.org/pdf/2602.13827v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.19201v1",
      "title": "Electrically pumped AlGaN edge-emitting UV-B laser diodes grown by molecular beam epitaxy",
      "abstract": "Mid and deep ultraviolet (UV) laser diodes remain among the least explored devices in semiconductor optoelectronics, despite their importance for spectroscopy, biochemical sensing, disinfection, and emerging quantum photonics. Here, we demonstrate an electrically pumped AlGaN-based laser diode operating in the UV-B band (280-315 nm). The device is grown by molecular beam epitaxy (MBE) on single-crystal AlN substrate and fabricated in a ridge-waveguide geometry. The laser diode operates at 298.5 nm and exhibits a relatively low threshold current density of 3.4 kA/cm$^2$. Clear nonlinear light-current characteristics and pronounced spectral narrowing with a full-width-at-half-maximum (FWHM) of 0.2 nm are measured above threshold.",
      "authors": [
        "Huabin Yu",
        "Shubham Mondal",
        "Rui Shen",
        "Md Tanvir Hasan",
        "David He",
        "Jiangnan Liu",
        "Samuel Yang",
        "Minming He",
        "Omar Alkhazragi",
        "Danhao Wang",
        "Mackillo Kira",
        "Parag Deotare",
        "Di Liang",
        "Zetian Mi"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "physics.app-ph"
      ],
      "published": "2026-01-27T05:04:08+00:00",
      "link": "https://arxiv.org/pdf/2601.19201v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20691v1",
      "title": "Impact of O concentration on the thermal stability and decomposition mechanism of (Cr,Al)N compared to (Ti,Al)N thin films",
      "abstract": "The composition-dependent thermal stability of (Cr$_{0.47 \\mp 0.03}$Al$_{0.53 \\mp 0.03}$)$_{z}$(O$_{y}$N$_{1-y}$)$_{1-z}$ thin films with O concentrations of y = 0, 0.15, and 0.40 is investigated up to 1200 °C and then compared to (Ti$_{0.56}$Al$_{0.44}$)$_{z}$(O$_{y}$N$_{1-y}$)$_{1-z}$. X-ray diffraction reveals a thermal stability limit of 1150 °C independent of the O concentration, as witnessed by the formation of decomposition products, namely h-Cr$_{2}$N for (Cr$_{0.50}$Al$_{0.50}$)$_{0.49}$N$_{0.51}$ and c-Cr for both (Cr$_{0.48}$Al$_{0.52}$)$_{0.48}$(O$_{0.15}$N$_{0.85}$)$_{0.52}$ and (Cr$_{0.44}$Al$_{0.56}$)$_{0.46}$(O$_{0.40}$N$_{0.60}$)$_{0.54}$. Based on TEM and ERDA data, the thermal stability limit is extended to 1100 - 1150 °C. DFT calculations indicate that bond breaking limits the thermal stability. In (Cr,Al)N, N has the lowest activation energy for migration. Furthermore, the O vacancy formation energy is highest in (Cr,Al)(O,N). It has to be overcome to enable diffusion on the non-metal sublattice, which is necessary for forming decomposition products like w-AlN or c-Cr. However, once Cr-N bonds break, decomposition into h-Cr$_{2}$N and subsequent c-Cr together with N$_{2}$ is triggered. This results in N evaporation, generating sufficient non-metal vacancies that greatly enhance diffusion and render the extensive vacancy formation energies for non-metals irrelevant. This reduction of the activation energy for mass transport on the non-metal sublattice to the migration barrier causes the similar thermal stability in (Cr$_{0.47 \\mp 0.03}$Al$_{0.53 \\mp 0.03}$)$_{z}$(O$_{y}$N$_{1-y}$)$_{1-z}$. In contrast, Al bonds break first without creating non-metal vacancies in (Ti,Al)(O,N). Thus, the high O vacancy formation energy in (Ti,Al)(O,N) significantly increases the thermal stability compared to (Ti,Al)N as well as the here investigated films.",
      "authors": [
        "Pauline Kümmerl",
        "Ganesh Kumar Nayak",
        "Felix Leinenbach",
        "Zsolt Czigány",
        "Daniel Primetzhofer",
        "Szilárd Kolozsvári",
        "Peter Polcik",
        "Marcus Hans",
        "Jochen M. Schneider"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-28T15:21:05+00:00",
      "link": "https://arxiv.org/pdf/2601.20691v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05675v1",
      "title": "Variable Search Stepsize for Randomized Local Search in Multi-Objective Combinatorial Optimization",
      "abstract": "Over the past two decades, research in evolutionary multi-objective optimization has predominantly focused on continuous domains, with comparatively limited attention given to multi-objective combinatorial optimization problems (MOCOPs). Combinatorial problems differ significantly from continuous ones in terms of problem structure and landscape. Recent studies have shown that on MOCOPs multi-objective evolutionary algorithms (MOEAs) can even be outperformed by simple randomised local search. Starting with a randomly sampled solution in search space, randomised local search iteratively draws a random solution (from an archive) to perform local variation within its neighbourhood. However, in most existing methods, the local variation relies on a fixed neighbourhood, which limits exploration and makes the search easy to get trapped in local optima. In this paper, we present a simple yet effective local search method, called variable stepsize randomized local search (VS-RLS), which adjusts the stepsize during the search. VS-RLS transitions gradually from a broad, exploratory search in the early phases to a more focused, fine-grained search as the search progresses. We demonstrate the effectiveness and generalizability of VS-RLS through extensive evaluations against local search and MOEAs methods on diverse MOCOPs.",
      "authors": [
        "Xuepeng Ren",
        "Maocai Wang",
        "Guangming Dai",
        "Zimin Liang",
        "Qianrong Liu",
        "Shengxiang Yang",
        "Miqing Li"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-05T13:59:05+00:00",
      "link": "https://arxiv.org/pdf/2602.05675v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.01475v1",
      "title": "Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models",
      "abstract": "Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs) is a fundamental yet computationally challenging problem arising in domains such as diagnosis, planning, and structured prediction. In many practical settings, the graphical model remains fixed while inference must be performed repeatedly for varying evidence patterns. Stochastic Local Search (SLS) algorithms scale to large models but rely on myopic best-improvement rule that prioritizes immediate likelihood gains and often stagnate in poor local optima. Heuristics such as Guided Local Search (GLS+) partially alleviate this limitation by modifying the search landscape, but their guidance cannot be reused effectively across multiple inference queries on the same model. We propose a neural amortization framework for improving local search in this repeated-query regime. Exploiting the fixed graph structure, we train an attention-based network to score local moves by predicting their ability to reduce Hamming distance to a near-optimal solution. Our approach integrates seamlessly with existing local search procedures, using this signal to balance short-term likelihood gains with long-term promise during neighbor selection. We provide theoretical intuition linking distance-reducing move selection to improved convergence behavior, and empirically demonstrate consistent improvements over SLS and GLS+ on challenging high-treewidth benchmarks in the amortized inference setting.",
      "authors": [
        "Brij Malhotra",
        "Shivvrat Arya",
        "Tahrima Rahman",
        "Vibhav Giridhar Gogate"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-01T22:43:28+00:00",
      "link": "https://arxiv.org/pdf/2602.01475v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.06318v1",
      "title": "Random is Faster than Systematic in Multi-Objective Local Search",
      "abstract": "Local search is a fundamental method in operations research and combinatorial optimisation. It has been widely applied to a variety of challenging problems, including multi-objective optimisation where multiple, often conflicting, objectives need to be simultaneously considered. In multi-objective local search algorithms, a common practice is to maintain an archive of all non-dominated solutions found so far, from which the algorithm iteratively samples a solution to explore its neighbourhood. A central issue in this process is how to explore the neighbourhood of a selected solution. In general, there are two main approaches: 1) systematic exploration and 2) random sampling. The former systematically explores the solution's neighbours until a stopping condition is met -- for example, when the neighbourhood is exhausted (i.e., the best improvement strategy) or once a better solution is found (i.e., first improvement). In contrast, the latter randomly selects and evaluates only one neighbour of the solution. One may think systematic exploration may be more efficient, as it prevents from revisiting the same neighbours multiple times. In this paper, however, we show that this may not be the case. We first empirically demonstrate that the random sampling method is consistently faster than the systematic exploration method across a range of multi-objective problems. We then give an intuitive explanation for this phenomenon using toy examples, showing that the superior performance of the random sampling method relies on the distribution of ``good neighbours''. Next, we show that the number of such neighbours follows a certain probability distribution during the search. Lastly, building on this distribution, we provide a theoretical insight for why random sampling is more efficient than systematic exploration, regardless of whether the best improvement or first improvement strategy is used.",
      "authors": [
        "Zimin Liang",
        "Miqing Li"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-09T21:27:30+00:00",
      "link": "https://arxiv.org/pdf/2601.06318v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11883v1",
      "title": "Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach",
      "abstract": "Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.",
      "authors": [
        "Chaoqi Jia",
        "Longkun Guo",
        "Kewen Liao",
        "Zhigang Lu",
        "Chao Chen",
        "Jason Xue"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-17T02:39:41+00:00",
      "link": "https://arxiv.org/pdf/2601.11883v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.16156v1",
      "title": "All ascents exponential from valued constraint graphs of pathwidth three",
      "abstract": "Many combinatorial optimization problems can be formulated as finding as assignment that maximized some pseudo-Boolean function (that we call the fitness function). Strict local search starts with some assignment and follows some update rule to proceed to an adjacent assignment of strictly higher fitness. This means that strict local search algorithms follow ascents in the fitness landscape of the pseudo-Boolean function. The complexity of the pseudo-Boolean function (and the fitness landscapes that it represents) can be parameterized by properties of the valued constraint satisfaction problem (VCSP) that encodes the pseudo-Boolean function. We focus on properties of the constraint graphs of the VCSP, with the intuition that spare graphs are less complex than dense ones. Specifically, we argue that pathwidth is the natural sparsity parameter for understanding limits on the power of strict local search. We show that prior constructions of sparse VCSPs where all ascents are exponentially long had pathwidth greater than or equal to four. We improve this this with our controlled doubling construction: a valued constraint satisfaction problem of pathwidth three where all ascents are exponentially long from a designated initial assignment. From this, we conclude that all strict local search algorithms can be forced to take an exponential number of steps even on simple valued constraint graphs of pathwidth three.",
      "authors": [
        "Artem Kaznatcheev",
        "Willemijn Volgering"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM",
        "cs.DS"
      ],
      "published": "2026-01-22T17:57:54+00:00",
      "link": "https://arxiv.org/pdf/2601.16156v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.14212v1",
      "title": "Generalization and Completeness of Stochastic Local Search Algorithms",
      "abstract": "We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.",
      "authors": [
        "Daniel Loscos",
        "Narciso Marti-Oliet",
        "Ismael Rodriguez"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.CL"
      ],
      "published": "2026-01-20T18:17:45+00:00",
      "link": "https://arxiv.org/pdf/2601.14212v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11841v1",
      "title": "Analysis of a Random Local Search Algorithm for Dominating Set",
      "abstract": "Dominating Set is a well-known combinatorial optimization problem which finds application in computational biology or mobile communication. Because of its $\\mathrm{NP}$-hardness, one often turns to heuristics for good solutions. Many such heuristics have been empirically tested and perform rather well. However, it is not well understood why their results are so good or even what guarantees they can offer regarding their runtime or the quality of their results. For this, a strong theoretical foundation has to be established. We contribute to this by rigorously analyzing a Random Local Search (RLS) algorithm that aims to find a minimum dominating set on a graph. We consider its performance on cycle graphs with $n$ vertices. We prove an upper bound for the expected runtime until an optimum is found of $\\mathcal{O}\\left(n^4\\log^2(n)\\right)$. In doing so, we introduce several models to represent dominating sets on cycles that help us understand how RLS explores the search space to find an optimum. For our proof we use techniques which are already quite popular for the analysis of randomized algorithms. We further apply a special method to analyze a reversible Markov Chain, which arises as a result of our modeling. This method has not yet found wide application in this kind of runtime analysis.",
      "authors": [
        "Hendrik Higl"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "math.CO",
        "math.PR"
      ],
      "published": "2026-01-17T00:17:14+00:00",
      "link": "https://arxiv.org/pdf/2601.11841v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.04745v1",
      "title": "Impact of diversity on bounded archives for multi-objective local search",
      "abstract": "This work tackles two critical challenges related to the development of metaheuristics for Multi-Objective Optimization Problems (MOOPs): the exponential growth of non-dominated solutions and the tendency of metaheuristics to disproportionately concentrate their search on a subset of the Pareto Front. To counteract the first, bounded archives are employed as a strategic mechanism for effectively managing the increasing number of non-dominated solutions. Addressing the second challenge involves an in-depth exploration of solution diversity algorithms found in existing literature. Upon recognizing that current approaches predominantly center on diversity within the objective space, this research introduces innovative methods specifically designed to enhance diversity in the solution space. Results demonstrate the efficacy of the Hamming Distance Archiving Algorithm, one of the newly proposed algorithms for multi-objective local search, surpassing the performance of the Adaptive Grid Archiving and the Hypervolume Archiving, both drawn from the literature. This outcome suggests a promising avenue for enhancing the overall efficiency of metaheuristics employed for solving MOOPs.",
      "authors": [
        "Amadeu A. Coco",
        "Cyprien Borée",
        "Julien Baste",
        "Laetitia Jourdan",
        "Lucien Mousin"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-04T16:47:14+00:00",
      "link": "https://arxiv.org/pdf/2602.04745v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12005v1",
      "title": "The challenge of scale in molecular adaptation: Local searches in astronomical genotype networks",
      "abstract": "The exploration of vast genotype spaces poses fundamental challenges for evolving populations. As the number of genotypes encoding viable phenotypes grows exponentially with genome length, populations can only explore a tiny fraction of these immense spaces, a fact consistently supported by empirical and theoretical evidence. Paradoxically, local, mutation-driven searches near abundant sequences allow populations to generate phenotypic improvements and functional innovations despite this immense search space. In this contribution, we integrate insights from viral evolution with theoretical expectations derived from genotype-phenotype maps to re-examine how high-dimensional sequence spaces shape evolutionary dynamics. In resolving the paradox, abundant phenotypes play a crucial role because their combinatorial weight biases evolutionary trajectories. We discuss how this bias, together with limited accessibility of fitness peaks, modifies traditional metaphors -- such as fitness landscapes -- and challenges standard notions of evolutionary optimality. Our results underscore that adaptation is predominantly local yet remarkably efficient, providing a unifying perspective on the coexistence of robustness, innovation, and constrained exploration in molecular evolution.",
      "authors": [
        "Susanna Manrubia",
        "Luis F. Seoane",
        "José A. Cuesta"
      ],
      "primary_category": "q-bio.PE",
      "categories": [
        "q-bio.PE"
      ],
      "published": "2026-01-17T10:54:20+00:00",
      "link": "https://arxiv.org/pdf/2601.12005v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.13266v2",
      "title": "The Query Complexity of Local Search in Rounds on General Graphs",
      "abstract": "We analyze the query complexity of finding a local minimum in $t$ rounds on general graphs. More precisely, given a graph $G = (V,E)$ and oracle access to an unknown function $f : V \\to \\mathbb{R}$, the goal is to find a local minimum--a vertex $v$ such that $f(v) \\leq f(u)$ for all $(u,v) \\in E$--using at most $t$ rounds of interaction with the oracle. The query complexity is well understood on grids, but much less is known beyond. This abstract problem captures many optimization tasks, such as finding a local minimum of a loss function during neural network training.   For each graph with $n$ vertices, we prove a deterministic upper bound of $O(t n^{1/t} (sΔ)^{1-1/t})$, where $s$ is the separation number and $Δ$ is the maximum degree of the graph. We complement this result with a randomized lower bound of $Ω(t n^{1/t}-t)$ that holds for any connected graph. We also find that parallel steepest descent with a warm start provides improved bounds for graphs with high separation number and bounded degree.   To obtain our results, we utilized an advanced version of Gemini at various stages of our research. We discuss our experience in a methodology section.",
      "authors": [
        "Simina Brânzei",
        "Ioannis Panageas",
        "Dimitris Paparas"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "cs.DS"
      ],
      "published": "2026-01-19T18:06:35+00:00",
      "link": "https://arxiv.org/pdf/2601.13266v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.12465v1",
      "title": "Probabilistic Design of Parametrized Quantum Circuits through Local Gate Modifications",
      "abstract": "Within quantum machine learning, parametrized quantum circuits provide flexible quantum models, but their performance is often highly task-dependent, making manual circuit design challenging. Alternatively, quantum architecture search algorithms have been proposed to automate the discovery of task-specific parametrized quantum circuits using systematic frameworks. In this work, we propose an evolution-inspired heuristic quantum architecture search algorithm, which we refer to as the local quantum architecture search. The goal of the local quantum architecture search algorithm is to optimize parametrized quantum circuit architectures through a local, probabilistic search over a fixed set of gate-level actions applied to existing circuits. We evaluate the local quantum architecture search algorithm on two synthetic function-fitting regression tasks and two quantum chemistry regression datasets, including the BSE49 dataset of bond separation energies for first- and second-row elements and a dataset of water conformers generated using the data-driven coupled-cluster approach. Using state-vector simulation, our results highlight the applicability of local quantum architecture search algorithm for identifying competitive circuit architectures with desirable performance metrics. Lastly, we analyze the properties of the discovered circuits and demonstrate the deployment of the best-performing model on state-of-the-art quantum hardware.",
      "authors": [
        "Grier M. Jones",
        "Aviraj Newatia",
        "Alexander Lao",
        "Aditya K. Rao",
        "Viki Kumar Prasad",
        "Hans-Arno Jacobsen"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "published": "2026-02-12T22:47:03+00:00",
      "link": "https://arxiv.org/pdf/2602.12465v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.13046v1",
      "title": "Classification of Local Optimization Problems in Directed Cycles",
      "abstract": "We present a complete classification of the distributed computational complexity of local optimization problems in directed cycles for both the deterministic and the randomized LOCAL model. We show that for any local optimization problem $Π$ (that can be of the form min-sum, max-sum, min-max, or max-min, for any local cost or utility function over some finite alphabet), and for any \\emph{constant} approximation ratio $α$, the task of finding an $α$-approximation of $Π$ in directed cycles has one of the following complexities:   1. $O(1)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,   2. $Θ(\\log^* n)$ rounds in deterministic LOCAL, $O(1)$ rounds in randomized LOCAL,   3. $Θ(\\log^* n)$ rounds in deterministic LOCAL, $Θ(\\log^* n)$ rounds in randomized LOCAL,   4. $Θ(n)$ rounds in deterministic LOCAL, $Θ(n)$ rounds in randomized LOCAL.   Moreover, for any given $Π$ and $α$, we can determine the complexity class automatically, with an efficient (centralized, sequential) meta-algorithm, and we can also efficiently synthesize an asymptotically optimal distributed algorithm.   Before this work, similar results were only known for local search problems (e.g., locally checkable labeling problems). The family of local optimization problems is a strict generalization of local search problems, and it contains numerous commonly studied distributed tasks, such as the problems of finding approximations of the maximum independent set, minimum vertex cover, minimum dominating set, and minimum vertex coloring.",
      "authors": [
        "Thomas Boudier",
        "Fabian Kuhn",
        "Augusto Modanese",
        "Ronja Stimpert",
        "Jukka Suomela"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.CC",
        "cs.FL"
      ],
      "published": "2026-02-13T16:03:14+00:00",
      "link": "https://arxiv.org/pdf/2602.13046v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11144v3",
      "title": "Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration",
      "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.",
      "authors": [
        "Yuejie Li",
        "Ke Yang",
        "Tao Wang",
        "Bolin Chen",
        "Bowen Li",
        "Chengjun Mao"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-16T10:02:31+00:00",
      "link": "https://arxiv.org/pdf/2601.11144v3",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08952v1",
      "title": "Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search",
      "abstract": "We study the construction of $d$-deletion-correcting binary codes by formulating the problem as a Maximum Clique Problem (MCP). In this formulation, vertices represent candidate codewords and edges connect pairs whose longest common subsequence (LCS) distance guarantees correction of up to $d$ deletions. A valid codebook corresponds to a clique in the resulting graph, and finding the largest codebook is equivalent to identifying a maximum clique. While MCP-based formulations for deletion-correcting codes have previously been explored, we demonstrate that applying Penalty-Guided Clique Search (PGCS), a lightweight stochastic clique-search heuristic inspired by Dynamic Local Search (DLS), consistently yields larger codebooks than existing graph-based heuristics, including minimum-degree and coloring methods, for block lengths $n = 8,9,\\dots,14$ and deletion parameters $d = 1,2,3$. In several finite-length regimes, the resulting codebooks match known optimal sizes and outperform classical constructions such as Helberg codes. For decoding under segmented reception, where codeword boundaries are known, we propose an optimized LCS-based decoder that exploits symbol-count filtering and early termination to substantially reduce the number of LCS evaluations while preserving exact decoding guarantees. These optimizations lead to significantly lower average-case decoding complexity than the baseline $O(|C| n^2)$ approach.",
      "authors": [
        "Aniruddh Pandav",
        "Rajshekhar V Bhat"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-09T17:47:11+00:00",
      "link": "https://arxiv.org/pdf/2602.08952v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22075v1",
      "title": "Lens-descriptor guided evolutionary algorithm for optimization of complex optical systems with glass choice",
      "abstract": "Designing high-performance optical lenses entails exploring a high-dimensional, tightly constrained space of surface curvatures, glass choices, element thicknesses, and spacings. In practice, standard optimizers (e.g., gradient-based local search and evolutionary strategies) often converge to a single local optimum, overlooking many comparably good alternatives that matter for downstream engineering decisions. We propose the Lens Descriptor-Guided Evolutionary Algorithm (LDG-EA), a two-stage framework for multimodal lens optimization. LDG-EA first partitions the design space into behavior descriptors defined by curvature-sign patterns and material indices, then learns a probabilistic model over descriptors to allocate evaluations toward promising regions. Within each descriptor, LDG-EA applies the Hill-Valley Evolutionary Algorithm with covariance-matrix self-adaptation to recover multiple distinct local minima, optionally followed by gradient-based refinement. On a 24-variable (18 continuous and 6 integer), six-element Double-Gauss topology, LDG-EA generates on average around 14500 candidate minima spanning 636 unique descriptors, an order of magnitude more than a CMA-ES baseline, while keeping wall-clock time at one hour scale. Although the best LDG-EA design is slightly worse than a fine-tuned reference lens, it remains in the same performance range. Overall, the proposed LDG-EA produces a diverse set of solutions while maintaining competitive quality within practical computational budgets and wall-clock time.",
      "authors": [
        "Kirill Antonov",
        "Teus Tukker",
        "Tiago Botari",
        "Thomas H. W. Bäck",
        "Anna V. Kononova",
        "Niki van Stein"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-29T18:13:24+00:00",
      "link": "https://arxiv.org/pdf/2601.22075v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.04248v1",
      "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search",
      "abstract": "Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.",
      "authors": [
        "Hao Lu",
        "Haoyuan Huang",
        "Yulin Zhou",
        "Chen Li",
        "Ningxin Zhu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-04T06:14:55+00:00",
      "link": "https://arxiv.org/pdf/2602.04248v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11389v1",
      "title": "Hyperparameter Optimization of Constraint Programming Solvers",
      "abstract": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.   We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.   Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.",
      "authors": [
        "Hedieh Haddad",
        "Thibault Falque",
        "Pierre Talbot",
        "Pascal Bouvry"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-16T16:02:36+00:00",
      "link": "https://arxiv.org/pdf/2601.11389v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.19041v1",
      "title": "HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems",
      "abstract": "Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.",
      "authors": [
        "Bo-Cheng Lin",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-01-26T23:51:19+00:00",
      "link": "https://arxiv.org/pdf/2601.19041v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.13532v1",
      "title": "Fast Swap-Based Element Selection for Multiplication-Free Dimension Reduction",
      "abstract": "In this paper, we propose a fast algorithm for element selection, a multiplication-free form of dimension reduction that produces a dimension-reduced vector by simply selecting a subset of elements from the input. Dimension reduction is a fundamental technique for reducing unnecessary model parameters, mitigating overfitting, and accelerating training and inference. A standard approach is principal component analysis (PCA), but PCA relies on matrix multiplications; on resource-constrained systems, the multiplication count itself can become a bottleneck. Element selection eliminates this cost because the reduction consists only of selecting elements, and thus the key challenge is to determine which elements should be retained. We evaluate a candidate subset through the minimum mean-squared error of linear regression that predicts a target vector from the selected elements, where the target may be, for example, a one-hot label vector in classification. When an explicit target is unavailable, the input itself can be used as the target, yielding a reconstruction-based criterion. The resulting optimization is combinatorial, and exhaustive search is impractical. To address this, we derive an efficient formula for the objective change caused by swapping a selected and an unselected element, using the matrix inversion lemma, and we perform a swap-based local search that repeatedly applies objective-decreasing swaps until no further improvement is possible. Experiments on MNIST handwritten-digit images demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Nobutaka Ono"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.AS",
        "eess.IV",
        "eess.SP"
      ],
      "published": "2026-02-14T00:11:43+00:00",
      "link": "https://arxiv.org/pdf/2602.13532v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12040v1",
      "title": "Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty",
      "abstract": "The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.",
      "authors": [
        "Murilo da Luz",
        "Bruno Brandão",
        "Luana Martins",
        "Gustavo Oliveira",
        "Bryan de Oliveira",
        "Luckeciano Melo",
        "Telma Soares"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-17T13:00:17+00:00",
      "link": "https://arxiv.org/pdf/2601.12040v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.18005v1",
      "title": "Flow-based Extremal Mathematical Structure Discovery",
      "abstract": "The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources.",
      "authors": [
        "Gergely Bérczi",
        "Baran Hashemi",
        "Jonas Klüver"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.LG"
      ],
      "published": "2026-01-25T21:41:47+00:00",
      "link": "https://arxiv.org/pdf/2601.18005v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.09424v1",
      "title": "Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design",
      "abstract": "Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards.",
      "authors": [
        "Prin Phunyaphibarn",
        "Minhyuk Sung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-02-10T05:39:48+00:00",
      "link": "https://arxiv.org/pdf/2602.09424v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08473v1",
      "title": "Submodular Maximization over a Matroid $k$-Intersection: Multiplicative Improvement over Greedy",
      "abstract": "We study the problem of maximizing a non-negative monotone submodular objective $f$ subject to the intersection of $k$ arbitrary matroid constraints. The natural greedy algorithm guarantees $(k+1)$-approximation for this problem, and the state-of-the-art algorithm only improves this approximation ratio to $k$. We give a $\\frac{2k\\ln2}{1+\\ln2}+O(\\sqrt{k})<0.819k+O(\\sqrt{k})$ approximation for this problem. Our result is the first multiplicative improvement over the approximation ratio of the greedy algorithm for general $k$. We further show that our algorithm can be used to obtain roughly the same approximation ratio also for the more general problem in which the objective is not guaranteed to be monotone (the sublinear term in the approximation ratio becomes $O(k^{2/3})$ rather than $O(\\sqrt{k})$ in this case).   All of our results hold also when the $k$-matroid intersection constraint is replaced with a more general matroid $k$-parity constraint. Furthermore, unlike the case in many of the previous works, our algorithms run in time that is independent of $k$ and polynomial in the size of the ground set. Our algorithms are based on a hybrid greedy local search approach recently introduced by Singer and Thiery (STOC 2025) for the weighted matroid $k$-intersection problem, which is a special case of the problem we consider. Leveraging their approach in the submodular setting requires several non-trivial insights and algorithmic modifications since the marginals of a submodular function $f$, which correspond to the weights in the weighted case, are not independent of the algorithm's internal randomness. In the special weighted case studied by Singer and Thiery, our algorithms reduce to a variant of their algorithm with an improved approximation ratio of $k\\ln2+1-\\ln2<0.694k+0.307$, compared to an approximation ratio of $\\frac{k+1}{2\\ln2}\\approx0.722k+0.722$ guaranteed by Singer and Thiery.",
      "authors": [
        "Moran Feldman",
        "Justin Ward"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.DM"
      ],
      "published": "2026-02-09T10:19:45+00:00",
      "link": "https://arxiv.org/pdf/2602.08473v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.13494v1",
      "title": "Quantum Speedups for Group Relaxations of Integer Linear Programs",
      "abstract": "Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \\textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest.",
      "authors": [
        "Brandon Augustino",
        "Dylan Herman",
        "Guneykan Ozgul",
        "Jacob Watkins",
        "Atithi Acharya",
        "Enrico Fontana",
        "Junhyung Lyle Kim",
        "Shouvanik Chakrabarti"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.DS",
        "math.OC"
      ],
      "published": "2026-02-13T21:58:59+00:00",
      "link": "https://arxiv.org/pdf/2602.13494v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.16473v1",
      "title": "Synthesis and Verification of Transformer Programs",
      "abstract": "C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).",
      "authors": [
        "Hongjian Jiang",
        "Matthew Hague",
        "Philipp Rümmer",
        "Anthony Widjaja Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.FL",
        "cs.LO"
      ],
      "published": "2026-02-18T14:04:02+00:00",
      "link": "https://arxiv.org/pdf/2602.16473v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.10159v1",
      "title": "Beyond Closed-Pool Video Retrieval: A Benchmark and Agent Framework for Real-World Video Search and Moment Localization",
      "abstract": "Traditional video retrieval benchmarks focus on matching precise descriptions to closed video pools, failing to reflect real-world searches characterized by fuzzy, multi-dimensional memories on the open web. We present \\textbf{RVMS-Bench}, a comprehensive system for evaluating real-world video memory search. It consists of \\textbf{1,440 samples} spanning \\textbf{20 diverse categories} and \\textbf{four duration groups}, sourced from \\textbf{real-world open-web videos}. RVMS-Bench utilizes a hierarchical description framework encompassing \\textbf{Global Impression, Key Moment, Temporal Context, and Auditory Memory} to mimic realistic multi-dimensional search cues, with all samples strictly verified via a human-in-the-loop protocol. We further propose \\textbf{RACLO}, an agentic framework that employs abductive reasoning to simulate the human ``Recall-Search-Verify'' cognitive process, effectively addressing the challenge of searching for videos via fuzzy memories in the real world. Experiments reveal that existing MLLMs still demonstrate insufficient capabilities in real-world Video Retrieval and Moment Localization based on fuzzy memories. We believe this work will facilitate the advancement of video retrieval robustness in real-world unstructured scenarios.",
      "authors": [
        "Tao Yu",
        "Yujia Yang",
        "Haopeng Jin",
        "Junhao Gong",
        "Xinlong Chen",
        "Yuxuan Zhou",
        "Shanbin Zhang",
        "Jiabing Yang",
        "Xinming Wang",
        "Hongzhu Yi",
        "Ping Nie",
        "Kai Zou",
        "Zhang Zhang",
        "Yan Huang",
        "Liang Wang",
        "Yeshani",
        "Ruiwen Tao",
        "Jin Ma",
        "Haijin Liang",
        "Jinwen Luo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-02-10T03:50:59+00:00",
      "link": "https://arxiv.org/pdf/2602.10159v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.14162v1",
      "title": "Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering",
      "abstract": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this \"pre-ingestion\" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is \"Index for locating, not understanding\"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the \"QA accuracy\" problem into a \"page localization\" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.",
      "authors": [
        "Tao Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ],
      "published": "2026-02-15T14:23:50+00:00",
      "link": "https://arxiv.org/pdf/2602.14162v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.14985v1",
      "title": "Real-time Range-Angle Estimation and Tag Localization for Multi-static Backscatter Systems",
      "abstract": "Multi-static backscatter networks (BNs) are strong candidates for joint communication and localization in the ambient IoT paradigm for 6G. Enabling real-time localization in large-scale multi-static deployments with thousands of devices require highly efficient algorithms for estimating key parameters such as range and angle of arrival (AoA), and for fusing these parameters into location estimates. We propose two low-complexity algorithms, Joint Range-Angle Clustering (JRAC) and Stage-wise Range-Angle Estimation (SRAE). Both deliver range and angle estimation accuracy comparable to FFT- and subspace-based baselines while significantly reducing the computation. We then introduce two real-time localization algorithms that fuse the estimated ranges and AoAs: a maximum-likelihood (ML) method solved via gradient search and an iterative re-weighted least squares (IRLS) method. Both achieve localization accuracy comparable to ML-based brute force search albeit with far lower complexity. Experiments on a real-world large-scale multi-static testbed with 4 illuminators, 1 multi-antenna receiver, and 100 tags show that JRAC and SRAE reduce runtime by up to 40X and IRLS achieves up to 500X reduction over ML-based brute force search without degrading localization accuracy. The proposed methods achieve 3 m median localization error across all 100 tags in a sub-6GHz band with 40 MHz bandwidth. These results demonstrate that multi-static range-angle estimation and localization algorithms can make real-time, scalable backscatter localization practical for next-generation ambient IoT networks.",
      "authors": [
        "Tara Esmaeilbeig",
        "Kartik Patel",
        "Traian E. Abrudan",
        "John Kimionis",
        "Eleftherios Kampianakis",
        "Michael S. Eggleston"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-16T18:09:47+00:00",
      "link": "https://arxiv.org/pdf/2602.14985v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08501v1",
      "title": "Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes",
      "abstract": "Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency.",
      "authors": [
        "Yubeen Jo",
        "Geon Choi",
        "Yongjune Kim",
        "Namyoon Lee"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-02-09T10:53:48+00:00",
      "link": "https://arxiv.org/pdf/2602.08501v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.06566v2",
      "title": "SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs",
      "abstract": "Despite recent successes, test-time scaling - i.e., dynamically expanding the token budget during inference as needed - remains brittle for vision-language models (VLMs): unstructured chains-of-thought about images entangle perception and reasoning, leading to long, disorganized contexts where small perceptual mistakes may cascade into completely wrong answers. Moreover, expensive reinforcement learning with hand-crafted rewards is required to achieve good performance. Here, we introduce SPARC (Separating Perception And Reasoning Circuits), a modular framework that explicitly decouples visual perception from reasoning. Inspired by sequential sensory-to-cognitive processing in the brain, SPARC implements a two-stage pipeline where the model first performs explicit visual search to localize question-relevant regions, then conditions its reasoning on those regions to produce the final answer. This separation enables independent test-time scaling with asymmetric compute allocation (e.g., prioritizing perceptual processing under distribution shift), supports selective optimization (e.g., improving the perceptual stage alone when it is the bottleneck for end-to-end performance), and accommodates compressed contexts by running global search at lower image resolutions and allocating high-resolution processing only to selected regions, thereby reducing total visual tokens count and compute. Across challenging visual reasoning benchmarks, SPARC outperforms monolithic baselines and strong visual-grounding approaches. For instance, SPARC improves the accuracy of Qwen3VL-4B on the $V^*$ VQA benchmark by 6.7 percentage points, and it surpasses \"thinking with images\" by 4.6 points on a challenging OOD task despite requiring a 200$\\times$ lower token budget.",
      "authors": [
        "Niccolo Avogaro",
        "Nayanika Debnath",
        "Li Mi",
        "Thomas Frick",
        "Junling Wang",
        "Zexue He",
        "Hang Hua",
        "Konrad Schindler",
        "Mattia Rigotti"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-06T10:05:25+00:00",
      "link": "https://arxiv.org/pdf/2602.06566v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.07621v1",
      "title": "Searching point patterns in point clouds describing local topography",
      "abstract": "We address the problem of comparing and aligning spatial point configurations in $\\mathbb{R}^3$ arising from structured geometric patterns. Each pattern is decomposed into arms along which we define a normalized finite-difference operator measuring local variations of the height component with respect to the planar geometry of the pattern. This quantity provides a parametrization-independent local descriptor that complements global similarity measures. In particular, it integrates naturally with Wasserstein-type distances for comparing point distributions and with Procrustes analysis for rigid alignment of geometric structures.",
      "authors": [
        "Ewa Bednarczuk",
        "Rafał Bieńkowski",
        "Robert Kłopotek",
        "Jan Kryński",
        "Krzysztof Leśsniewski",
        "Krzysztof Rutkowski",
        "Małgorzata Szelachowska"
      ],
      "primary_category": "cs.CG",
      "categories": [
        "cs.CG",
        "math.OC"
      ],
      "published": "2026-01-12T15:05:47+00:00",
      "link": "https://arxiv.org/pdf/2601.07621v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.23023v1",
      "title": "The Where and How of Touch: A Review of Tactile Localization Research",
      "abstract": "Tactile localization is the seemingly simple ability to 'tell' where a touch has occurred. However, how this ability is assessed, and what conclusions are drawn from experiments, depends on the theoretical ideas that inspire the research. Here, we review both theoretical frameworks and methodological approaches based on a systematic web-based literature search on tactile localization. After presenting current theories of tactile localization, we discuss task characteristics that differentiate current methodology for tactile localization into at least 8 distinct types of experimental tasks. We describe these tasks, discuss their, often implicit, underlying assumptions and cognitive requirements, and relate them to the theoretical approaches. We then compare, in an exemplary manner, the tactile localization results reported by a subset of studies and demonstrate how some methods are associated with specific biases, illustrating that the choice of experimental method significantly affects the conclusions drawn from the results. Our review suggests that the field currently lacks a clear concept of the specific processes induced by the various experimental tasks and, thus, calls for concerted efforts to clarify and unify currently diverse, fragmented, and partly inconsistent theoretical underpinnings of tactile spatial processing, flanked by dedicated data sharing to allow across-study analysis.",
      "authors": [
        "Xaver Fuchs",
        "Jason A. M. Khoury",
        "Sergiu Tcaci Popescu",
        "Tobias Heed",
        "Matej Hoffmann"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC"
      ],
      "published": "2026-01-30T14:32:03+00:00",
      "link": "https://arxiv.org/pdf/2601.23023v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02623v1",
      "title": "Learning Consistent Causal Abstraction Networks",
      "abstract": "Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves and cosheaves of causal knowledge. Pushing in the same direction, we tackle the learning of consistent causal abstraction network (CAN), a sheaf-theoretic framework where (i) SCMs are Gaussian, (ii) restriction maps are transposes of constructive linear causal abstractions (CAs) adhering to the semantic embedding principle, and (iii) edge stalks correspond--up to permutation--to the node stalks of more detailed SCMs. Our problem formulation separates into edge-specific local Riemannian problems and avoids nonconvex objectives. We propose an efficient search procedure, solving the local problems with SPECTRAL, our iterative method with closed-form updates and suitable for positive definite and semidefinite covariance matrices. Experiments on synthetic data show competitive performance in the CA learning task, and successful recovery of diverse CAN structures.",
      "authors": [
        "Gabriele D'Acunto",
        "Paolo Di Lorenzo",
        "Sergio Barbarossa"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "published": "2026-02-02T16:16:29+00:00",
      "link": "https://arxiv.org/pdf/2602.02623v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.15921v1",
      "title": "Latent Objective Induction and Diversity-Constrained Selection: Algorithms for Multi-Locale Retrieval Pipelines",
      "abstract": "We present three algorithms with formal correctness guarantees and complexity bounds for the problem of selecting a diverse, multi-locale set of sources from ranked search results. First, we formulate weighted locale allocation as a constrained integer partition problem and give an $O(n \\log n)$ algorithm that simultaneously satisfies minimum-representation, budget-exhaustion, and proportionality-bound constraints; we prove all three hold with a tight deviation bound of $< 1$. Second, we define a cascaded country-code inference function as a deterministic priority chain over heterogeneous signals (TLD structure, model-inferred metadata, language fallback) and prove it satisfies both determinism and graceful degradation. Third, we introduce a $κ$-domain diversity constraint for source selection and give an $O(|K| \\cdot R)$ algorithm that maintains the invariant via hash-map lookup, eliminating the aggregator monopolization pathology present in URL-level deduplication. We further formalize Latent Objective Induction (LOI), an environment-shaping operator over prompt spaces that steers downstream model behavior without restricting the feasible output set, and prove its convergence under mild assumptions. Applied to a multi-locale retrieval pipeline, these algorithms yield 62% improvement in first-party source ratio and 89% reduction in same-domain duplication across 120 multilingual queries.",
      "authors": [
        "Faruk Alpay",
        "Levent Sarioglu"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.IR"
      ],
      "published": "2026-02-17T12:25:22+00:00",
      "link": "https://arxiv.org/pdf/2602.15921v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.06269v1",
      "title": "PurSAMERE: Reliable Adversarial Purification via Sharpness-Aware Minimization of Expected Reconstruction Error",
      "abstract": "We propose a novel deterministic purification method to improve adversarial robustness by mapping a potentially adversarial sample toward a nearby sample that lies close to a mode of the data distribution, where classifiers are more reliable. We design the method to be deterministic to ensure reliable test accuracy and to prevent the degradation of effective robustness observed in stochastic purification approaches when the adversary has full knowledge of the system and its randomness. We employ a score model trained by minimizing the expected reconstruction error of noise-corrupted data, thereby learning the structural characteristics of the input data distribution. Given a potentially adversarial input, the method searches within its local neighborhood for a purified sample that minimizes the expected reconstruction error under noise corruption and then feeds this purified sample to the classifier. During purification, sharpness-aware minimization is used to guide the purified samples toward flat regions of the expected reconstruction error landscape, thereby enhancing robustness. We further show that, as the noise level decreases, minimizing the expected reconstruction error biases the purified sample toward local maximizers of the Gaussian-smoothed density; under additional local assumptions on the score model, we prove recovery of a local maximizer in the small-noise limit. Experimental results demonstrate significant gains in adversarial robustness over state-of-the-art methods under strong deterministic white-box attacks.",
      "authors": [
        "Vinh Hoang",
        "Sebastian Krumscheid",
        "Holger Rauhut",
        "Raúl Tempone"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "math.PR"
      ],
      "published": "2026-02-06T00:06:30+00:00",
      "link": "https://arxiv.org/pdf/2602.06269v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.16819v1",
      "title": "Hybrid-Gym: Training Coding Agents to Generalize Across Tasks",
      "abstract": "When assessing the quality of coding agents, predominant benchmarks focus on solving single issues on GitHub, such as SWE-Bench. In contrast, in real use, these agents solve more various and complex tasks that involve other skills such as exploring codebases, testing software, and designing architecture. In this paper, we first characterize some transferable skills that are shared across diverse tasks by decomposing trajectories into fine-grained components, and derive a set of principles for designing auxiliary training tasks to teach language models these skills. Guided by these principles, we propose a training environment, Hybrid-Gym, consisting of a set of scalable synthetic tasks, such as function localization and dependency search. Experiments show that agents trained on our synthetic tasks effectively generalize to diverse real-world tasks that are not present in training, improving a base model by 25.4% absolute gain on SWE-Bench Verified, 7.9% on SWT-Bench Verified, and 5.1% on Commit-0 Lite. Hybrid-Gym also complements datasets built for the downstream tasks (e.g., improving SWE-Play by 4.9% on SWT-Bench Verified). Code available at: https://github.com/yiqingxyq/Hybrid-Gym.",
      "authors": [
        "Yiqing Xie",
        "Emmy Liu",
        "Gaokai Zhang",
        "Nachiket Kotalwar",
        "Shubham Gandhi",
        "Sathwik Acharya",
        "Xingyao Wang",
        "Carolyn Rose",
        "Graham Neubig",
        "Daniel Fried"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-18T19:30:55+00:00",
      "link": "https://arxiv.org/pdf/2602.16819v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.08084v1",
      "title": "REAMP: A Stochastic Resonance Approach for Multi-Change Point Detection in High-Dimensional Data",
      "abstract": "Detecting multiple structural breaks in high-dimensional data remains a challenge, particularly when changes occur in higher-order moments or within complex manifold structures. In this paper, we propose REAMP (Resonance-Enhanced Analysis of Multi-change Points), a novel framework that integrates optimal transport theory with the physical principles of stochastic resonance. By utilizing a two-stage dimension reduction via the Earth Movers Distance (EMD) and Shortest Hamiltonian Paths (SHP), we map high-dimensional observations onto a graph-based count statistic. To overcome the locality constraints of traditional search algorithms, we implement a stochastic resonance system that utilizes randomized Beta-density priors to vibrate the objective function. This process allows multiple change points to resonate as global minima across iterative simulations, generating a candidate point cloud. A double-sharpening procedure is then applied to these candidates to pinpoint precise change point locations. We establish the asymptotic consistency of the resonance estimator and demonstrate through simulations that REAMP outperforms state-of-the-art methods, especially in scenarios involving simultaneous mean and variance shifts. The practical utility of the method is further validated through an application to time-lapse embryo monitoring, where REAMP provides both accurate detection and intuitive visualization of cell division stages.",
      "authors": [
        "Xiaoping Shi",
        "Baisuo Jin",
        "Xianhui Liu",
        "Qiong Li"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-12T23:57:21+00:00",
      "link": "https://arxiv.org/pdf/2601.08084v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02486v1",
      "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
      "abstract": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.",
      "authors": [
        "Jialiang Zhu",
        "Gongrui Zhang",
        "Xiaolong Ma",
        "Lin Xu",
        "Miaosen Zhang",
        "Ruiqi Yang",
        "Song Wang",
        "Kai Qiu",
        "Zhirong Wu",
        "Qi Dai",
        "Ruichun Ma",
        "Bei Liu",
        "Yifan Yang",
        "Chong Luo",
        "Zhengyuan Yang",
        "Linjie Li",
        "Lijuan Wang",
        "Weizhu Chen",
        "Xin Geng",
        "Baining Guo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-02T18:58:07+00:00",
      "link": "https://arxiv.org/pdf/2602.02486v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12667v1",
      "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration",
      "abstract": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",
      "authors": [
        "Yi Di",
        "Zhibin Zhao",
        "Fujin Wang",
        "Xue Liu",
        "Jiafeng Tang",
        "Jiaxin Ren",
        "Zhi Zhai",
        "Xuefeng Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-19T02:28:27+00:00",
      "link": "https://arxiv.org/pdf/2601.12667v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.21481v1",
      "title": "Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays",
      "abstract": "Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.",
      "authors": [
        "Sai Pavan Deram",
        "Jacopo Pegoraro",
        "Javier Lorca Hernando",
        "Jesus O. Lacruz",
        "Joerg Widmer"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.ET"
      ],
      "published": "2026-01-29T10:00:27+00:00",
      "link": "https://arxiv.org/pdf/2601.21481v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22369v1",
      "title": "Learning Provably Correct Distributed Protocols Without Human Knowledge",
      "abstract": "Provably correct distributed protocols, which are a critical component of modern distributed systems, are highly challenging to design and have often required decades of human effort. These protocols allow multiple agents to coordinate to come to a common agreement in an environment with uncertainty and failures. We formulate protocol design as a search problem over strategies in a game with imperfect information, and the desired correctness conditions are specified in Satisfiability Modulo Theories (SMT). However, standard methods for solving multi-agent games fail to learn correct protocols in this setting, even when the number of agents is small. We propose a learning framework, GGMS, which integrates a specialized variant of Monte Carlo Tree Search with a transformer-based action encoder, a global depth-first search to break out of local minima, and repeated feedback from a model checker. Protocols output by GGMS are verified correct via exhaustive model checking for all executions within the bounded setting. We further prove that, under mild assumptions, the search process is complete: if a correct protocol exists, GGMS will eventually find it. In experiments, we show that GGMS can learn correct protocols for larger settings than existing methods.",
      "authors": [
        "Yujie Hui",
        "Xiaoyi Lu",
        "Andrew Perrault",
        "Yang Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "published": "2026-01-29T22:24:07+00:00",
      "link": "https://arxiv.org/pdf/2601.22369v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.00667v1",
      "title": "zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing",
      "abstract": "Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development.",
      "authors": [
        "Rong Fu",
        "Jia Yee Tan",
        "Wenxin Zhang",
        "Youjin Wang",
        "Ziyu Kong",
        "Zeli Su",
        "Zhaolu Kang",
        "Shuning Zhang",
        "Xianda Li",
        "Kun Liu",
        "Simon Fong"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "published": "2026-01-31T11:31:00+00:00",
      "link": "https://arxiv.org/pdf/2602.00667v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.23232v2",
      "title": "ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search",
      "abstract": "In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes editing requirements as keyframe-oriented shot descriptions and introduces five types of controllable single-factor constraints: Temporal order, Color, Visual style, Audio, and Resolution. We curate 1,210 high-quality samples from YouTube across 20 thematic categories, using large models for generation with human verification. Based on the benchmark, we propose ShotFinder, a text-driven three-stage retrieval and localization pipeline: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization. Experiments on multiple closed-source and open-source models reveal a significant gap to human performance, with clear imbalance across constraints: temporal localization is relatively tractable, while color and visual style remain major challenges. These results reveal that open-domain video shot retrieval is still a critical capability that multimodal large models have yet to overcome.",
      "authors": [
        "Tao Yu",
        "Haopeng Jin",
        "Hao Wang",
        "Shenghua Chai",
        "Yujia Yang",
        "Junhao Gong",
        "Jiaming Guo",
        "Minghui Zhang",
        "Xinlong Chen",
        "Zhenghao Zhang",
        "Yuxuan Zhou",
        "Yufei Xiong",
        "Shanbin Zhang",
        "Jiabing Yang",
        "Hongzhu Yi",
        "Xinming Wang",
        "Cheng Zhong",
        "Xiao Ma",
        "Zhang Zhang",
        "Yan Huang",
        "Liang Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-30T18:01:17+00:00",
      "link": "https://arxiv.org/pdf/2601.23232v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.08495v1",
      "title": "Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments",
      "abstract": "Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations.",
      "authors": [
        "Akanksha Sneh",
        "Shobha Sundar Ram"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-02-09T10:46:45+00:00",
      "link": "https://arxiv.org/pdf/2602.08495v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05371v1",
      "title": "Hinge Regression Tree: A Newton Method for Oblique Regression Tree Splitting",
      "abstract": "Oblique decision trees combine the transparency of trees with the power of multivariate decision boundaries, but learning high-quality oblique splits is NP-hard, and practical methods still rely on slow search or theory-free heuristics. We present the Hinge Regression Tree (HRT), which reframes each split as a non-linear least-squares problem over two linear predictors whose max/min envelope induces ReLU-like expressive power. The resulting alternating fitting procedure is exactly equivalent to a damped Newton (Gauss-Newton) method within fixed partitions. We analyze this node-level optimization and, for a backtracking line-search variant, prove that the local objective decreases monotonically and converges; in practice, both fixed and adaptive damping yield fast, stable convergence and can be combined with optional ridge regularization. We further prove that HRT's model class is a universal approximator with an explicit $O(δ^2)$ approximation rate, and show on synthetic and real-world benchmarks that it matches or outperforms single-tree baselines with more compact structures.",
      "authors": [
        "Hongyi Li",
        "Han Lin",
        "Jun Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T06:49:01+00:00",
      "link": "https://arxiv.org/pdf/2602.05371v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02999v1",
      "title": "ResQ: Realistic Performance-Aware Query Generation",
      "abstract": "Database research and development rely heavily on realistic user workloads for benchmarking, instance optimization, migration testing, and database tuning. However, acquiring real-world SQL queries is notoriously challenging due to strict privacy regulations. While cloud database vendors have begun releasing anonymized performance traces to the research community, these traces typi- cally provide only high-level execution statistics without the origi- nal query text or data, which is insufficient for scenarios that require actual execution. Existing tools fail to capture fine-grained perfor- mance patterns or generate runnable workloads that reproduce these public traces with both high fidelity and efficiency. To bridge this gap, we propose ResQ, a fine-grained workload synthesis sys- tem designed to generate executable SQL workloads that faithfully match the per-query execution targets and operator distributions of production traces. ResQ constructs execution-aware query graphs, instantiates them into SQL via Bayesian Optimization-driven pred- icate search, and explicitly models workload repetition through reuse at both exact-query and parameterized-template levels. To ensure practical scalability, ResQ combines search-space bounding with lightweight local cost models to accelerate optimization. Ex- periments on public cloud traces (Snowset, Redset) and a newly released industrial trace (Bendset) demonstrate that ResQ signif- icantly outperforms state-of-the-art baselines, achieving 96.71% token savings and a 86.97% reduction in runtime, while lowering maximum Q-error by 14.8x on CPU time and 997.7x on scanned bytes, and closely matching operator composition.",
      "authors": [
        "Zhengle Wang",
        "Yanfei Zhang",
        "Chunwei Liu"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-03T02:15:40+00:00",
      "link": "https://arxiv.org/pdf/2602.02999v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.07465v1",
      "title": "Exoplanet transit search at the detection limit: detection and false alarm vetting pipeline",
      "abstract": "One of the primary mission goals of the Kepler space telescope was to detect Earth-like terrestrial planets in the habitable zone around Sun-like stars. These planets are at the detection limit, where the Kepler detection and vetting pipeline produced unreliable planet candidates. We present a novel pipeline that improves the removal of localized defects prior to the planet search, improves vetting at the level of individual transits and introduces a Bayes factor test statistic and an algorithm for extracting multiple candidates from a single detection run. We show with injections in the Kepler data that the introduced novelties improve pipeline's completeness at a fixed false alarm rate. We apply the pipeline to the stars with previously identified planet candidates and show that our pipeline successfully recovers the previously confirmed candidates, but flags a considerable portion of unconfirmed candidates as likely false alarms, especially in the long period, low signal-to-noise ratio regime. In particular, several known Earth-like candidates in the habitable zone, such as KOI 8063.01, 8107.01 and 8242.01, are identified as false alarms, which could have a significant impact on the estimates of $η_{\\oplus}$, i.e., the occurrence of Earth-like planets in the habitable zone.",
      "authors": [
        "Jakob Robnik",
        "Uroš Seljak",
        "Jon M. Jenkins",
        "Steve Bryson"
      ],
      "primary_category": "astro-ph.EP",
      "categories": [
        "astro-ph.EP"
      ],
      "published": "2026-01-12T12:21:18+00:00",
      "link": "https://arxiv.org/pdf/2601.07465v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05704v1",
      "title": "Limitations of SGD for Multi-Index Models Beyond Statistical Queries",
      "abstract": "Understanding the limitations of gradient methods, and stochastic gradient descent (SGD) in particular, is a central challenge in learning theory. To that end, a commonly used tool is the Statistical Queries (SQ) framework, which studies performance limits of algorithms based on noisy interaction with the data. However, it is known that the formal connection between the SQ framework and SGD is tenuous: Existing results typically rely on adversarial or specially-structured gradient noise that does not reflect the noise in standard SGD, and (as we point out here) can sometimes lead to incorrect predictions. Moreover, many analyses of SGD for challenging problems rely on non-trivial algorithmic modifications, such as restricting the SGD trajectory to the sphere or using very small learning rates. To address these shortcomings, we develop a new, non-SQ framework to study the limitations of standard vanilla SGD, for single-index and multi-index models (namely, when the target function depends on a low-dimensional projection of the inputs). Our results apply to a broad class of settings and architectures, including (potentially deep) neural networks.",
      "authors": [
        "Daniel Barzilai",
        "Ohad Shamir"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-05T14:29:10+00:00",
      "link": "https://arxiv.org/pdf/2602.05704v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16139v1",
      "title": "On the Intrinsic Dimensions of Data in Kernel Learning",
      "abstract": "The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\\to \\int_ΩK(\\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\\left(ε^{-d_ρ}\\log\\frac{1}ε\\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.",
      "authors": [
        "Rustem Takhanov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-22T17:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16139v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05119v1",
      "title": "Unbiased Single-Queried Gradient for Combinatorial Objective",
      "abstract": "In a probabilistic reformulation of a combinatorial problem, we often face an optimization over a hypercube, which corresponds to the Bernoulli probability parameter for each binary variable in the primal problem. The combinatorial nature suggests that an exact gradient computation requires multiple queries. We propose a stochastic gradient that is unbiased and requires only a single query of the combinatorial function. This method encompasses a well-established REINFORCE (through an importance sampling), as well as including a class of new stochastic gradients.",
      "authors": [
        "Thanawat Sornwanee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-04T23:08:07+00:00",
      "link": "https://arxiv.org/pdf/2602.05119v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.20152v1",
      "title": "Concentration Inequalities for Exchangeable Tensors and Matrix-valued Data",
      "abstract": "We study concentration inequalities for structured weighted sums of random data, including (i) tensor inner products and (ii) sequential matrix sums. We are interested in tail bounds and concentration inequalities for those structured weighted sums under exchangeability, extending beyond the classical framework of independent terms.   We develop Hoeffding and Bernstein bounds provided with structure-dependent exchangeability. Along the way, we recover known results in weighted sum of exchangeable random variables and i.i.d. sums of random matrices to the optimal constants. Notably, we develop a sharper concentration bound for combinatorial sum of matrix arrays than the results previously derived from Chatterjee's method of exchangeable pairs.   For applications, the richer structures provide us with novel analytical tools for estimating the average effect of multi-factor response models and studying fixed-design sketching methods in federated averaging. We apply our results to these problems, and find that our theoretical predictions are corroborated by numerical evidence.",
      "authors": [
        "Chen Cheng",
        "Rina Foygel Barber"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.PR",
        "stat.ML"
      ],
      "published": "2026-01-28T00:55:33+00:00",
      "link": "https://arxiv.org/pdf/2601.20152v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08184v2",
      "title": "Wasserstein-p Central Limit Theorem Rates: From Local Dependence to Markov Chains",
      "abstract": "Finite-time central limit theorem (CLT) rates play a central role in modern machine learning. In this paper, we study CLT rates for multivariate dependent data in Wasserstein-$p$ ($W_p$) distance, for general $p \\geq 1$. We focus on two fundamental dependence structures that commonly arise in machine learning: locally dependent sequences and geometrically ergodic Markov chains. In both settings, we establish the first optimal $O(n^{-1/2})$ rate in $W_1$, as well as the first $W_p$ ($p\\ge 2$) CLT rates under mild moment assumptions, substantially improving the best previously known bounds in these dependent-data regimes. As an application of our optimal $W_1$ rate for locally dependent sequences, we further obtain the first optimal $W_1$-CLT rate for multivariate $U$-statistics.   On the technical side, we derive a tractable auxiliary bound for $W_1$ Gaussian approximation errors that is well suited for studying dependent data. For Markov chains, we further prove that the regeneration time of the split chain associated with a geometrically ergodic chain has a geometric tail without assuming strong aperiodicity or other restrictive conditions. These tools may be of independent interests and enable our optimal $W_1$ rates and underpin our $W_p$ ($p\\ge 2$) results.",
      "authors": [
        "Yixuan Zhang",
        "Qiaomin Xie"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-13T03:25:24+00:00",
      "link": "https://arxiv.org/pdf/2601.08184v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.10028v2",
      "title": "Fundamental Limits of Coded Polynomial Aggregation",
      "abstract": "Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.",
      "authors": [
        "Xi Zhong",
        "Jörg Kliewer",
        "Mingyue Ji"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.DC"
      ],
      "published": "2026-01-15T03:19:48+00:00",
      "link": "https://arxiv.org/pdf/2601.10028v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00754v1",
      "title": "Hardness Condensation for Decision Tree Measures by Restrictions",
      "abstract": "For any Boolean function $f:\\{0,1\\}^n \\to \\{0,1\\}$ with a complexity measure having value $k \\ll n$, is it possible to restrict the function $f$ to $Θ(k)$ variables while keeping the complexity preserved at $Θ(k)$? This question, in the context of query complexity, was recently studied by G{ö}{ö}s, Newman, Riazanov and Sokolov (STOC 2024). They showed, among other results, that query complexity can not be condensed losslessly. They asked if complexity measures like block sensitivity or unambiguous certificate complexity can be condensed losslessly?   In this work, we show that decision tree measures like block sensitivity and certificate complexity, cannot be condensed losslessly. That is, there exists a Boolean function $f$ such that any restriction of $f$ to $O(\\mathcal{M}(f))$ variables has $\\mathcal{M}(\\cdot)$-complexity at most $\\tilde{O}(\\mathcal{M}(f)^{2/3})$, where $\\mathcal{M} \\in \\{\\mathsf{bs},\\mathsf{fbs},\\mathsf{C},\\mathsf{D}\\}$. This also improves upon a result of G{ö}{ö}s, Newman, Riazanov and Sokolov (STOC 2024).   We also complement the negative results on lossless condensation with positive results about lossy condensation. In particular, we show that for every Boolean function $f$ there exists a restriction of $f$ to $O(\\mathcal{M}(f))$ variables such that its $\\mathcal{M}(\\cdot)$-complexity is at least $Ω(\\mathcal{M}(f)^{1/2})$, where $\\mathcal{M} \\in \\{\\mathsf{bs},\\mathsf{fbs},\\mathsf{C},\\mathsf{UC}_{min},\\mathsf{UC}_1,\\mathsf{UC},\\mathsf{D},\\widetilde{\\mathsf{deg}},λ\\}$. We also show a slightly weaker positive result for randomized and quantum query complexity.",
      "authors": [
        "Chandrima Kayal",
        "Rajat Mittal",
        "Manaswi Paraashar",
        "Nitin Saurabh"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC"
      ],
      "published": "2026-01-31T14:39:24+00:00",
      "link": "https://arxiv.org/pdf/2602.00754v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08614v1",
      "title": "Accelerated Methods with Complexity Separation Under Data Similarity for Federated Learning Problems",
      "abstract": "Heterogeneity within data distribution poses a challenge in many modern federated learning tasks. We formalize it as an optimization problem involving a computationally heavy composite under data similarity. By employing different sets of assumptions, we present several approaches to develop communication-efficient methods. An optimal algorithm is proposed for the convex case. The constructed theory is validated through a series of experiments across various problems.",
      "authors": [
        "Dmitry Bylinkin",
        "Sergey Skorik",
        "Dmitriy Bystrov",
        "Leonid Berezin",
        "Aram Avetisyan",
        "Aleksandr Beznosikov"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-13T14:59:22+00:00",
      "link": "https://arxiv.org/pdf/2601.08614v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05684v1",
      "title": "Characterizations of the Aubin property of the KKT-mapping in composite optimization by SC derivatives and quadratic bundles",
      "abstract": "For general set-valued mappings, the Aubin property is ultimately tied to limiting coderivatives by the Mordukhovich criterion. Likewise, the existence of single-valued Lipschitzian localizations is related to strict graphical derivatives. In this paper we will show that for the special case of the KKT-mapping from composite optimization, the Aubin property and the existence of single-valued Lipschitzian localizations can be characterized by SC derivatives and quadratic bundles, respectively, which are easier accessible than limiting coderivatives and strict graphical derivatives.",
      "authors": [
        "Helmut Gfrerer",
        "Jiri V. Outrata"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-05T14:09:32+00:00",
      "link": "https://arxiv.org/pdf/2602.05684v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21539v1",
      "title": "Wide neural networks with general weights: convergence rate and explicit dependence on the hyper-parameters",
      "abstract": "Using Stein's method techniques introduced by Chatterjee (2008) and further extended by Kasprzak and Peccati (2022) and by Lachièze-Rey and Peccati (2017), we derive novel quantitative bounds on the convergence in distribution of feed-forward fully connected neural networks (with Lipschitz activation functions) towards Gaussian processes, as the hidden layer width $n$ tends to infinity. We consider networks initialized with independent and identically distributed (i.i.d.) weights possessing sufficiently many finite moments, and i.i.d. Gaussian biases independent of the weights. Specifically, when the network is evaluated at a single input, we obtain convergence rates of order $O(n^{-1/2})$ in both total variation and Wasserstein distances. When evaluated at a general finite collection of inputs, we establish bounds of the same order in terms of the convex distance. All bounds are given in explicit and computable form. As a consequence of our estimates, we also deduce a novel convergence result in the regime where the depth of the neural network increases simultaneously with the width $n$, up to order $O\\big((\\log_2 n)^{1/3}\\big)$. To the best of our knowledge, this is the first CLT in the infinite width/depth limit holding for general (nonlinear) Lipschitz activation functions and non-Gaussian weight distributions. Our analysis yields several results of independent interest, including: (i) an explicit lower bound on the determinant of the limiting covariance matrix and (ii) new advances in Stein's method, both for the one-dimensional Stein's equation associated with the square of a Lipschitz function and for the multivariate Stein's equation associated with the tensor product of a Lipschitz function with itself.",
      "authors": [
        "Lucia Celli"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-29T10:54:16+00:00",
      "link": "https://arxiv.org/pdf/2601.21539v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01104v1",
      "title": "Fast $k$-means Seeding Under The Manifold Hypothesis",
      "abstract": "We study beyond worst case analysis for the $k$-means problem where the goal is to model typical instances of $k$-means arising in practice. Existing theoretical approaches provide guarantees under certain assumptions on the optimal solutions to $k$-means, making them difficult to validate in practice. We propose the manifold hypothesis, where data obtained in ambient dimension $D$ concentrates around a low dimensional manifold of intrinsic dimension $d$, as a reasonable assumption to model real world clustering instances. We identify key geometric properties of datasets which have theoretically predictable scaling laws depending on the quantization exponent $\\varepsilon = 2/d$ using techniques from optimum quantization theory. We show how to exploit these regularities to design a fast seeding method called $\\operatorname{Qkmeans}$ which provides $O(ρ^{-2} \\log k)$ approximate solutions to the $k$-means problem in time $O(nD) + \\widetilde{O}(\\varepsilon^{1+ρ}ρ^{-1}k^{1+γ})$; where the exponent $γ= \\varepsilon + ρ$ for an input parameter $ρ< 1$. This allows us to obtain new runtime - quality tradeoffs. We perform a large scale empirical study across various domains to validate our theoretical predictions and algorithm performance to bridge theory and practice for beyond worst case data clustering.",
      "authors": [
        "Poojan Shah",
        "Shashwat Agrawal",
        "Ragesh Jaiswal"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-01T08:58:15+00:00",
      "link": "https://arxiv.org/pdf/2602.01104v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15092v1",
      "title": "Federated Incremental Subgradient Method for Convex Bilevel Optimization Problems",
      "abstract": "In this letter, we consider a bilevel optimization problem in which the outer-level objective function is strongly convex, whereas the inner-level problem consists of a finite sum of convex functions. Bilevel optimization problems arise in situations where the inner-level problem does not have a unique solution. This has led to the idea of introducing an outer-level objective function to select a solution with the specific desired properties. We propose an iterative method that combines an incremental algorithm with a broadcast algorithm, both based on the principles of federated learning. Under appropriate assumptions, we establish the convergence results of the proposed algorithm. To demonstrate its performance, we present two numerical examples related to binary classification and a location problem.",
      "authors": [
        "Sudkobfa Boontawee",
        "Mootta Prangprakhon",
        "Nimit Nimana"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21T15:32:18+00:00",
      "link": "https://arxiv.org/pdf/2601.15092v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00266v1",
      "title": "Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic",
      "abstract": "Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through algebraic rewrites governed by the logic axioms. A compositional norm form is proposed to facilitate the mapping from Lukasiewicz logic formulae back to ReLU networks. Using Chang's completeness theorem, we show that for every functional equivalence class, all ReLU networks in that class are connected by a finite set of symmetries corresponding to the finite set of axioms of Lukasiewicz logic. This idea is reminiscent of Shannon's seminal work on switching circuit design, where the circuits are translated into Boolean formulae, and synthesis is effected by algebraic rewriting governed by Boolean logic axioms.",
      "authors": [
        "Yani Zhang",
        "Helmut Bölcskei"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T19:39:55+00:00",
      "link": "https://arxiv.org/pdf/2602.00266v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16581v1",
      "title": "Necessary Optimality Conditions for Integrated Learning and Optimization Problem in Contextual Optimization",
      "abstract": "Integrated learning and optimization (ILO) is a framework in contextual optimization which aims to train a predictive model for the probability distribution of the underlying problem data uncertainty, with the goal of enhancing the quality of downstream decisions. This framework represents a new class of stochastic bilevel programs, which are extensively utilized in the literature of operations research and management science, yet remain underexplored from the perspective of optimization theory. In this paper, we fill the gap. Specifically, we derive the first-order necessary optimality conditions in terms of Mordukhovich limiting subdifferentials. To this end, we formulate the bilevel program as a two-stage stochastic program with variational inequality constraints when the lower-level decision-making problem is convex, and establish an optimality condition via sensitivity analysis of the second-stage value function. In the case where the lower level optimization problem is nonconvex, we adopt the value function approach in the literature of bilevel programs and derive the first-order necessary conditions under stochastic partial calmness conditions. The derived optimality conditions are applied to several existing ILO problems in the literature. These conditions may be used for the design of gradient-based algorithms for solving ILO problems.",
      "authors": [
        "Yuan Tao",
        "Huifu Xu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-23T09:31:39+00:00",
      "link": "https://arxiv.org/pdf/2601.16581v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08111v1",
      "title": "Derandomizing Matrix Concentration Inequalities from Free Probability",
      "abstract": "Recently, sharp matrix concentration inequalities~\\cite{BBvH23,BvH24} were developed using the theory of free probability. In this work, we design polynomial time deterministic algorithms to construct outcomes that satisfy the guarantees of these inequalities. As direct consequences, we obtain polynomial time deterministic algorithms for the matrix Spencer problem~\\cite{BJM23} and for constructing near-Ramanujan graphs. Our proofs show that the concepts and techniques in free probability are useful not only for mathematical analyses but also for efficient computations.",
      "authors": [
        "Robert Wang",
        "Lap Chi Lau",
        "Hong Zhou"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.DM",
        "math.CO",
        "math.PR"
      ],
      "published": "2026-01-13T01:05:48+00:00",
      "link": "https://arxiv.org/pdf/2601.08111v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16071v1",
      "title": "On the Stable Euclidean Distance Degree of Algebraic Layers",
      "abstract": "We study the projective geometry of algebraic neural layers, namely families of maps induced by a polynomial activation function, with particular emphasis on the generic Euclidean Distance degree ($\\mathrm{gED}$). This invariant is projective in nature and measures the number of optimal approximations of a general point in the ambient space with respect to a general metric. For a fixed architecture (i.e. fixed width and activation polynomial), we prove that the $\\mathrm{gED}$ is stably polynomial in the dimensions of the input and output spaces. Moreover, we show that this stable polynomial depends only on the degree of the activation function.   Our approach relies on standard intersection theory on the Nash blow-up, which allows us to express the $\\gED$ as an intersection number over products of Grassmannians. Stable polynomiality is deduced via equivariant localization, while the reduction to the monomial case follows from an explicit Schubert calculus computation on Grassmannians.",
      "authors": [
        "Giacomo Graziani"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-22T16:13:26+00:00",
      "link": "https://arxiv.org/pdf/2601.16071v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00116v1",
      "title": "THDC: Training Hyperdimensional Computing Models with Backpropagation",
      "abstract": "Hyperdimensional computing (HDC) offers lightweight learning for energy-constrained devices by encoding data into high-dimensional vectors. However, its reliance on ultra-high dimensionality and static, randomly initialized hypervectors limits memory efficiency and learning capacity. Therefore, we propose Trainable Hyperdimensional Computing (THDC), which enables end-to-end HDC via backpropagation. THDC replaces randomly initialized vectors with trainable embeddings and introduces a one-layer binary neural network to optimize class representations. Evaluated on MNIST, Fashion-MNIST and CIFAR-10, THDC achieves equal or better accuracy than state-of-the-art HDC, with dimensionality reduced from 10.000 to 64.",
      "authors": [
        "Hanne Dejonghe",
        "Sam Leroux"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T10:33:36+00:00",
      "link": "https://arxiv.org/pdf/2602.00116v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17969v1",
      "title": "Quadratic Programming over Linearly Ordered Fields: Decidability and Attainment of Optimal Solutions",
      "abstract": "Classical existence theorems and solution methods for quadratic programming traditionally rely on the analytical properties of real numbers, specifically compactness and completeness. These tools are unavailable in general linearly ordered fields, such as the field of rational numbers or non-Archimedean structures, rendering standard analytical proofs insufficient in these general algebraic settings. In this paper, we establish a unified algebraic framework for the decidability of indefinite quadratic programming subject to linear constraints over general linearly ordered fields. We prove a generalized Eaves' theorem, demonstrating that if a quadratic function -- encompassing convex, non-convex, or degenerate (linear) cases -- is bounded from below on a polyhedron, the minimum is attained within the field itself, regardless of topological completeness. Our approach replaces classical analytical arguments with algebraic induction on dimension and polyhedral decomposition. Based on this foundation, we propose an exact, deterministic algorithm within the Blum--Shub--Smale model of computation that decides boundedness and computes a global minimizer using only field operations. We show that the problem is solvable in finite time via a recursive search over orthant-restricted facets. Finally, we note that linearly constrained quadratic programming represents the maximal class of polynomial optimization problems where exact solutions are structurally guaranteed within the original field, thereby demarcating the algebraic boundary of exact optimization over ordered structures.",
      "authors": [
        "Dmytro O. Plutenko"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "math.LO"
      ],
      "published": "2026-01-25T19:53:13+00:00",
      "link": "https://arxiv.org/pdf/2601.17969v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.11782v1",
      "title": "Mixed-Integer Reaggregated Hull Reformulation of Special Structured Generalized Linear Disjunctive Programs",
      "abstract": "Generalized Disjunctive Programming (GDP) provides a powerful framework for combining algebraic constraints with logical disjunctions. To solve these problems, mixed-integer reformulations are required, but traditional reformulation schemes, such as Big-M and Hull, either yield a weak continuous relaxation or result in a bloated model size. Castro and Grossmann showed that scheduling problems can be formulated as GDP by modeling task orderings as disjunctions with algebraic timing constraints. Moreover, in their work, a particular representation of the single-unit scheduling problem, namely using a time-slot concept, can be reformulated as a tight yet compact mixed-integer linear program with notable computational performance. Based on that observation, and focusing on the case where the constraints in disjunctions are linear and share the same coefficients, we connect the characterization of the convex hull of these disjunctive sets by Jeroslow and Blair with Castro and Grossmann's time-slot reaggregation strategy to derive a unified reformulation methodology. We test this reformulation in two problems, single-unit scheduling and two-dimensional strip-packing. We derive new formulations of the general precedence concept of single-unit scheduling and symmetry-breaking formulations of the strip-packing problem, yielding mixed-integer programs with strong theoretical guarantees, particularly compact formulations in terms of continuous variables, and efficient computational performance when solving them with commercial mixed-integer solvers for these problems.",
      "authors": [
        "Albert Joon Lee",
        "David E. Bernal Neira"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-16T21:13:35+00:00",
      "link": "https://arxiv.org/pdf/2601.11782v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15252v1",
      "title": "Automating Idealness Proofs for Binary Programs with Application to Rectangle Packing",
      "abstract": "An integer program is called ideal if its continuous relaxation coincides with its convex hull allowing the problem to be solved as a continuous program and offering substantial computational advantages. Proving idealness analytically can be extraordinarily tedious -- even for small formulations -- such proofs often span many pages of intricate case analysis which motivates the development of automated verification methods. We develop a general-purpose framework for certifying idealness in Mixed Binary Linear Programs (MBLPs), formulating the verification problem as a linear program when the data is fixed and as a nonconvex quadratic program when the data is parametric. We apply this framework to study several formulations of the rectangle packing problem that are conjectured to be pairwise-ideal, obtaining computational proofs where analytic proofs were previously unknown or impractical. As our second contribution, we introduce and model a novel generalization of the rectangle packing problem that enforces edge clearances between selected rectangles. We present both existing and novel MBLP formulations which arise from different encodings of the underlying disjunctive constraints. We perform some computational experiments on these formulations under a strip-packing objective to determine the importance of pairwise-idealness in practice.",
      "authors": [
        "Jamie Fravel",
        "Robert Hildebrand"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21T18:35:20+00:00",
      "link": "https://arxiv.org/pdf/2601.15252v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.05557v1",
      "title": "Difference of Convex (DC) approach for neural network approximation with uniform loss function",
      "abstract": "Neural networks (NNs) can be viewed as approximation tools. Traditionally, NNs are relying on gradient and stochastic gradient (SG) methods. There are a number of available computational packages for constructing least squares approximations, while uniform (minimax) approximations are hard due to their nonsmooth nature. It was recently demonstrated that a difference convex (DC) programming approach is an efficient alternative optimiser for NNs. In this paper, we demonstrate that a DC programming approach is also efficient for minimax approximation. In our numerical experiments, we compare a DC-programming approach and ADAMAX, a commonly used method for minimax NN approximations.",
      "authors": [
        "Vinesha Peiris",
        "Nadezda Sukhorukova"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-09T06:15:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05557v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04378v1",
      "title": "Lower Bounds for Frank-Wolfe on Strongly Convex Sets",
      "abstract": "We present a constructive lower bound of $Ω(1/\\sqrt{\\varepsilon})$ for Frank-Wolfe (FW) when both the objective and the constraint set are smooth and strongly convex, showing that the known uniform $\\mathcal{O}(1/\\sqrt{\\varepsilon})$ guarantees in this regime are tight. It is known that under additional assumptions on the position of the optimizer, FW can converge linearly. However, it remained unclear whether strong convexity of the set can yield rates uniformly faster than $\\mathcal{O}(1/\\sqrt{\\varepsilon})$, i.e., irrespective of the position of the optimizer. To investigate this question, we focus on a simple yet representative problem class: minimizing a strongly convex quadratic over the Euclidean unit ball, with the optimizer on the boundary. We analyze the dynamics of FW for this problem in detail and develop a novel computational approach to construct worst-case FW trajectories, which is of independent interest. Guided by these constructions, we develop an analytical proof establishing the lower bound.",
      "authors": [
        "Jannis Halbey",
        "Daniel Deza",
        "Max Zimmer",
        "Christophe Roux",
        "Bartolomeo Stellato",
        "Sebastian Pokutta"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-02-04T09:55:44+00:00",
      "link": "https://arxiv.org/pdf/2602.04378v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01499v2",
      "title": "Totally $Δ$-Modular Tree Decompositions of Graphic Matrices for Integer Programming",
      "abstract": "We introduce the tree-decomposition-based parameter totally $Δ$-modular treewidth (TDM-treewidth) for matrices with two nonzero entries per row. We show how to solve integer programs whose matrices have bounded TDM-treewidth when variables are bounded. This extends previous graph-based decomposition parameters for matrices with at most two nonzero entries per row to include matrices with entries outside of $\\{-1,0,1\\}$. We also give an analogue of the Grid Theorem of Robertson and Seymour for matrices of bounded TDM-treewidth in the language of rooted signed graphs.",
      "authors": [
        "Caleb McFarland"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM",
        "cs.DS",
        "math.OC"
      ],
      "published": "2026-02-02T00:30:08+00:00",
      "link": "https://arxiv.org/pdf/2602.01499v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09548v1",
      "title": "Further results on Minimal and Minimum Cylindrical Algebraic Decompositions",
      "abstract": "We consider cylindrical algebraic decompositions (CADs) as a tool for representing semi-algebraic subsets of $\\mathbb{R}^n$. In this framework, a CAD $\\mathscr{C}$ is adapted to a given set $S$ if $S$ is a union of cells of $\\mathscr{C}$. Different algorithms computing an adapted CAD may produce different outputs, usually with redundant cell divisions. In this paper we analyse the possibility to remove the superfluous data. We thus consider the set $\\text{CAD}^r(\\mathcal{F})$ of CADs of class $C^r$ ($r \\in \\mathbb{N} \\cup \\{\\infty, ω\\}$) that are adapted to a finite family $\\mathcal{F}$ of semi-algebraic sets of $\\mathbb{R}^n$, endowed with the refinement partial order and we study the existence of minimal and minimum element in $\\text{CAD}^r(\\mathcal{F})$. We show that for every such $\\mathcal{F}$ and every $\\mathscr{C} \\in \\text{CAD}^r(\\mathcal{F})$, there is a minimal CAD of class $C^r$ adapted to $\\mathcal{F}$ and smaller (i.e. coarser) than or equal to $\\mathscr{C}$. In dimension $n=1$ or $n=2$, this result is strengthened by proving the existence of a minimum element in $\\text{CAD}^r(\\mathcal{F})$. In contrast, for any $n \\geq 3$, we provide explicit examples of semi-algebraic sets whose associated poset of adapted CADs does not admit a minimum. We then introduce a reduction relation on $\\text{CAD}^r(\\mathcal{F})$ in order to define an algorithm for the computation of minimal CADs and we characterise those semi-algebraic sets $\\mathcal{F}$ for which $\\text{CAD}^r(\\mathcal{F})$ has a minimum by means of confluence of the associated reduction system. We finally provide practical criteria for deciding if a semi-algebraic set does admit a minimum CAD and apply them to describe various concrete examples of semi-algebraic sets, along with their minimum CAD of class $C^r$.",
      "authors": [
        "Lucas Michel",
        "Pierre Mathonet",
        "Naïm Zénaïdi"
      ],
      "primary_category": "cs.SC",
      "categories": [
        "cs.SC"
      ],
      "published": "2026-01-14T15:07:50+00:00",
      "link": "https://arxiv.org/pdf/2601.09548v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.13124v1",
      "title": "Full characterization of core for nonlinear optimization games",
      "abstract": "We fully characterize the core of a broad class of nonlinear games by identifying a suitable relaxation for inherent nonlinearity, directly generalizing the linear frameworks in the literature. This characterization significantly expands the scope of cooperative games that can be analyzed and contributes to the literature on games induced from optimization models. We apply these insights to not only establish connections with and provide new insights on classical models but also solve new games untamed in the existing literature, including combinatorial quadratic and ratio games such as portfolio, maximum cut, matching, and assortment games. These results are further extended to more general models and also the approximate core.",
      "authors": [
        "Donglei Du",
        "Qizhi Fang",
        "Bin Liu",
        "Tianhang Lu",
        "Chenchen Wu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-19T15:12:16+00:00",
      "link": "https://arxiv.org/pdf/2601.13124v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14917v1",
      "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models",
      "abstract": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.",
      "authors": [
        "Giorgia Rigamonti",
        "Mirko Paolo Barbato",
        "Davide Marelli",
        "Paolo Napoletano"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21T11:57:51+00:00",
      "link": "https://arxiv.org/pdf/2601.14917v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.11615v1",
      "title": "A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia",
      "abstract": "Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.",
      "authors": [
        "Beyza Cinar",
        "Louisa van den Boom",
        "Maria Maleshkova"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-09T23:06:36+00:00",
      "link": "https://arxiv.org/pdf/2601.11615v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08474v1",
      "title": "Degree-preserving Godel logics with an involution: intermediate logics and (ideal) paraconsistency",
      "abstract": "In this paper we study intermediate logics between the degree preserving companion of Godel fuzzy logic with an involution and classical propositional logic CPL, as well as the intermediate logics of their finite-valued counterparts. Although these degree-preserving Godel logics are explosive with respect to Godel negation, they are paraconsistent with respect to the involutive negation. We introduce the notion of saturated paraconsistency, a weaker notion than ideal paraconsistency, and we fully characterize the ideal and the saturated paraconsistent logics between the degree-preserving n-valued Godel fuzzy logic with an involution and CPL. We also identify a large family of saturated paraconsistent logics in the family of intermediate logics for degree-preserving finite-valued Lukasiewicz logics.",
      "authors": [
        "M. E. Coniglio",
        "F. Esteva",
        "J. Gispert",
        "L. Godo"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "math.LO"
      ],
      "published": "2026-01-13T12:07:16+00:00",
      "link": "https://arxiv.org/pdf/2601.08474v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.10262v1",
      "title": "Algebraic Properties of PAC Codes",
      "abstract": "We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.",
      "authors": [
        "Vlad-Florin Dragoi",
        "Mohammad Rowshan"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-15T10:35:00+00:00",
      "link": "https://arxiv.org/pdf/2601.10262v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14355v2",
      "title": "Mathematical Foundations of Quantum Pricing Theory",
      "abstract": "Let $M$ be a von Neumann algebra and let $(N_t)_{t\\in[0,T]}$ be an increasing family of abelian von Neumann subalgebras encoding a (classical) information flow. Fix a faithful normal state $\\varphi_ρ$ and a filtration of normal $\\varphi_ρ$-preserving conditional expectations $E_t:M\\to N_t$ satisfying the tower property. Using bounded functional-calculus cutoffs $f_n$, we introduce a truncation-stable notion of localized $(N_t,E_t)$-martingales for affiliated self-adjoint observables, and formulate a \\emph{Local Informational Efficiency Principle} requiring symmetrically discounted traded prices to be martingales in this sense. Assuming a pricing state $\\varphi^\\star$ and a compatible family of normal $\\varphi^\\star$-preserving conditional expectations $(E_t^\\star)$, we define for bounded terminal payoffs $X\\in M_T$ the dynamic pricing operator \\[ Π_t(X):=B_t^{1/2}\\,E_t^\\star\\!\\bigl(B_T^{-1/2}XB_T^{-1/2}\\bigr)\\,B_t^{1/2}, \\] where $(B_t)$ is a strictly positive numéraire adapted to $(N_t)$. We prove that $(Π_t)$ is normal, completely positive, $N_t$-bimodular, and time-consistent, and satisfies $Π_t(\\mathbf 1)=B_t$ (equivalently, $\\widetildeΠ_t(X):=B_t^{-1/2}Π_t(X)B_t^{-1/2}$ is unital). In the commutative reduction it agrees with risk-neutral valuation by conditional expectation. Finally, we develop an $L^2(M,\\varphi_ρ)$ prediction theory and introduce an operator-valued Fisher information relative to $(N_t)$, obtaining a noncommutative Cramér--Rao lower bound for conditional mean-square prediction error; we compute the bound for compound Poisson lattice-jump models under $\\sum_αγ_α(e^{αΔx}-1)=r$.",
      "authors": [
        "Tian Xin",
        "Liang Aoqin"
      ],
      "primary_category": "math.OA",
      "categories": [
        "math.OA",
        "math.PR"
      ],
      "published": "2026-01-20T18:16:43+00:00",
      "link": "https://arxiv.org/pdf/2601.14355v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.12351v1",
      "title": "Analyzing Collection Strategies: A Computational Perspective on the Coupon Collector Problem",
      "abstract": "The Coupon Collector Problem (CCP) is a well-known combinatorial problem that seeks to estimate the number of random draws required to complete a collection of $n$ distinct coupon types. Various generalizations of this problem have been applied in numerous engineering domains. However, practical applications are often hindered by the computational challenges associated with deriving numerical results for moments and distributions. In this work, we present three algorithms for solving the most general form of the CCP, where coupons are collected under any arbitrary drawing probability, with the objective of obtaining $t$ copies of a subset of $k$ coupons from a total of $n$. The First algorithm provides the base model to compute the expectation, variance, and the second moment of the collection process. The second algorithm utilizes the construction of the base model and computes the same values in polynomial time with respect to $n$ under the uniform drawing distribution, and the third algorithm extends to any general drawing distribution. All algorithms leverage Markov models specifically designed to address computational challenges, ensuring exact computation of the expectation and variance of the collection process. Their implementation uses a dynamic programming approach that follows from the Markov models framework, and their time complexity is analyzed accordingly.",
      "authors": [
        "Hadas Abraham",
        "Ido Feldman",
        "Eitan Yaakobi"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.IT"
      ],
      "published": "2026-01-18T11:03:05+00:00",
      "link": "https://arxiv.org/pdf/2601.12351v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17250v1",
      "title": "Conditional Reflected Backward Stochastic Differential Equations with Two Barriers",
      "abstract": "In this paper, we study the doubly conditional reflected backward stochastic differential equations (BSDEs), where constraints are made on the conditional expectation of the first component of the solution with respect to a general subfiltration. With the help of the Skorokhod problem on a time-dependent interval and the Dynkin game in a general framework, we establish the existence and uniqueness result under the Mokobodski condition for the obstacles. The relation between the conditional expectation of the solution and the value function of a certain Dynkin game with partial information is obtained. As a by-product, we obtain a weaker version of the comparison theorem. Finally, we provide an application to the starting and stopping problem in reversible investments under partial information.",
      "authors": [
        "Hanwu Li"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-24T01:12:11+00:00",
      "link": "https://arxiv.org/pdf/2601.17250v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17800v2",
      "title": "Differentiable Integer Linear Programming is not Differentiable & it's not a mere technical problem",
      "abstract": "We show how the differentiability method employed in the paper ``Differentiable Integer Linear Programming'', Geng, et al., 2025 as shown in its theorem 5 is incorrect. Moreover, there already exists some downstream work that inherits the same error. The underlying reason comes from that, though being continuous in expectation, the surrogate loss is discontinuous in almost every realization of the randomness, for the stochastic gradient descent.",
      "authors": [
        "Thanawat Sornwanee"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-25T11:28:02+00:00",
      "link": "https://arxiv.org/pdf/2601.17800v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.19331v1",
      "title": "Extreme Points and Large Contests",
      "abstract": "In this paper, we characterize the extreme points of a class of multidimensional monotone functions. This result is then applied to large contests, where it provides a useful representation of optimal allocation rules under a broad class of distributional preferences of the contest designer. In contests with complete information, the representation significantly simplifies the characterization of the equilibria.",
      "authors": [
        "Giovanni Valvassori Bolgè"
      ],
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH"
      ],
      "published": "2026-01-27T08:16:16+00:00",
      "link": "https://arxiv.org/pdf/2601.19331v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17832v1",
      "title": "Computing bounded solutions to linear Diophantine equations with the sum of divisors",
      "abstract": "We propose an efficient computational method for finding all solutions $n\\leq U$ to the Diophantine equation $aσ(n) = bn + c$, where integer coefficient $a,b,c$ and an upper bound $U$ are given. Our method is implemented in SageMath computer algebra system within the framework of recursively enumerated sets and natively benefits from MapReduce parallelization. We used it to discover new solutions to many published equations and close gaps in between the known large solutions, including but not limited to hyperperfect and $f$-perfect numbers, as well as to significantly lift the existence bounds in open questions about quasiperfect and almost-perfect numbers.",
      "authors": [
        "Max A. Alekseyev"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "cs.DM"
      ],
      "published": "2026-01-25T13:25:23+00:00",
      "link": "https://arxiv.org/pdf/2601.17832v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00233v1",
      "title": "Exact cospectrality probabilities for uniform random matrices",
      "abstract": "We study the conjugation action of orthogonal matrices on symmetric random matrices. Given a fixed orthogonal matrix over an algebraic number field and a random matrix with entries sufficiently uniform in the ring of integers, we wonder what the probability is that the conjugate is again integral. Our main result establishes an exact formula for this probability in terms of the Smith ideals associated to the orthogonal matrix.   As an illustrative application, we establish exact formulas for the expected number of rational orthogonal matrices that preserve the integrality of a random matrix for every fixed denominator in dimensions two and three. Notably, the dependence on the denominator turns out to be non-monotone due to number-theoretic fluctuations. We also prove bounds on the probability of rational cospectrality with bounded but arbitrarily large denominator.",
      "authors": [
        "Alexander Van Werde"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "math.CO",
        "math.NT",
        "math.SP"
      ],
      "published": "2026-01-30T19:00:11+00:00",
      "link": "https://arxiv.org/pdf/2602.00233v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04531v1",
      "title": "Algebraic and Arithmetic Attributes of Hypergeometric Functions in SageMath",
      "abstract": "We report on implementations for algorithms treating algebraic and arithmetic properties of hypergeometric functions in the computer algebra system SageMath. We treat hypergeometric series over the rational numbers, over finite fields, and over the p-adics. Among other things, we provide implementations deciding algebraicity, computing valuations, and computing minimal polynomials in positive characteristic.",
      "authors": [
        "Xavier Caruso",
        "Florian Fürnsinn"
      ],
      "primary_category": "cs.SC",
      "categories": [
        "cs.SC",
        "math.NT"
      ],
      "published": "2026-02-04T13:20:18+00:00",
      "link": "https://arxiv.org/pdf/2602.04531v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21156v1",
      "title": "Further results on fuzzy negations and implications induced by fuzzy conjunctions and disjunctions",
      "abstract": "In this article, we deeply investigate some properties of fuzzy negations induced from fuzzy conjunctions (resp. disjunctions), which are then applied to characterizing the fuzzy negations. We further use the obtained characterization of fuzzy negations to explore some properties of $(D,N)$-implications generated from fuzzy disjunctions and negations. We finally describe $(D,N)$-implications (resp. continuous $(D,N)$-implications) generated from fuzzy disjunctions and negations.",
      "authors": [
        "Xin-Tong Zhang",
        "Xue-ping Wang"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT"
      ],
      "published": "2026-01-29T01:32:07+00:00",
      "link": "https://arxiv.org/pdf/2601.21156v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.06785v1",
      "title": "On the conformal preimage decay exponent of the Julia sets of rational graph-directed Markov systems",
      "abstract": "We define and investigate the conformal preimage decay exponent of the Julia sets of rational graph-directed Markov systems. We show that this exponent coincides with the difference between the topological entropy and upper sequential capacity topological pressure for the rational skew product map associated with the system $S$. Here, upper sequential capacity topological pressure is a slight generalisation of upper capacity topological pressure given in \\cite{MR969568}.",
      "authors": [
        "Tadashi Arimitsu"
      ],
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "published": "2026-01-11T06:15:50+00:00",
      "link": "https://arxiv.org/pdf/2601.06785v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16626v1",
      "title": "On generalized eigenvalues of MAX matrices to MIN matrices and of LCM matrices to GCD matrices",
      "abstract": "We determine, for any n $\\ge$ 1, the generalized eigenvalues of an n x n MAX matrix to the corresponding MIN matrix. We also show that a similar result holds for the generalized eigenvalues of an nxn LCM matrix to the corresponding GCD matrix when n $\\le$ 4, but breaks down for n > 4. In addition, we prove Cauchy's interlacing theorem for generalized eigenvalues, and we conjecture an unexpected connection between the OEIS sequence A004754 and the appearance of -1 as a generalized eigenvalue in the LCM-GCD setting.",
      "authors": [
        "Jorma K. Merikoski",
        "Pentti Haukkanen",
        "Antonio Sasaki",
        "Timo Tossavainen"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "math.SP"
      ],
      "published": "2026-01-23T10:30:56+00:00",
      "link": "https://arxiv.org/pdf/2601.16626v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00578v1",
      "title": "The degrees of irreducible factors of binomials and multiplicativity of the n-Hartley condition",
      "abstract": "We prove that, over a field of characteristic $0$, the degrees of factors of a binomial $t^n-α$ are divisible by the least such degree. As a consequence, we deduce that for relatively prime natural numbers $m,n$, a polynomial has the $mn$-Hartley condition if and only if it has the $m$-Hartley and $n$-Hartley conditions.",
      "authors": [
        "Matthew Bolan",
        "Ben Williams"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-31T07:46:12+00:00",
      "link": "https://arxiv.org/pdf/2602.00578v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00280v1",
      "title": "An algorithm for annihilator and Bernstein-Sato polynomial of a rational function",
      "abstract": "The singularity theory of rational functions, i.e., the quotient of two polynomials, has been investigated in the past two decades. The Bernstein-Sato polynomial of a rational function has recently been introduced by Takeuchi. However, only trivial examples are known. We provide an algorithm for computing the Bernstein-Sato polynomial in this context. The strategy is to compute the annihilator of the rational function by using the annihilator of the pair consisting of the numerator and denominator of the quotient. In a natural way a non-vanishing condition on the Bernstein-Sato ideal of the pair appears. This method has been implemented in freely available computer algebra system SINGULAR. It relies on Gröbner bases in noncommutative PBW algebras. The algorithm allows us to exhibit some explicit non-trivial examples and to support some existing conjectures.",
      "authors": [
        "Manuel González-Villa",
        "Edwin León-Cardenal",
        "Viktor Levandovskyy",
        "Jorge Martín-Morales"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "cs.SC"
      ],
      "published": "2026-01-30T20:04:09+00:00",
      "link": "https://arxiv.org/pdf/2602.00280v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05841v1",
      "title": "Generalized Perfect Matrices",
      "abstract": "We generalize Voronoi's theory of perfect quadratic forms to generalized copositive matrices over a closed convex and full-dimensional cone K. We introduce a notion of a K-copositive minimum and of perfect K-copositive matrices. We consider a key feature of a given cone, which we call Interior Ryshkov (IR) property. Under this property the classical theory and its applications generalize nicely and we prove that rationally generated cones possess this IR property. For contrast, we give a detailed example of a simple cone without the IR property, showing various differences to the classical case. Moreover, this example yields connections to questions of number theory, in particular to Diophantine approximation and the Pell Equation. Finally, as an application, we give inner and outer polyhedral approximations for the generalized completely positive cone and a method to find rational certificates for (non-)membership in this cone.",
      "authors": [
        "Alexander Oertel",
        "Achill Schürmann"
      ],
      "primary_category": "math.MG",
      "categories": [
        "math.MG",
        "math.NT"
      ],
      "published": "2026-02-05T16:28:36+00:00",
      "link": "https://arxiv.org/pdf/2602.05841v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.11133v1",
      "title": "Concentration of the empirical measure in Wasserstein distance: bounds involving the covering dimension",
      "abstract": "We give concentration inequalities in Wasserstein distance for the empirical measure of a sequence of independent and identically distributed random variables with values in a Polish space E. These inequalities involve the covering dimension of the support of the distribution of the variables. More precisely, we obtain a complete extension of the concentration inequalities of Fournier and Guillin [2015] in the case where E = R^d , in which the covering dimension replaces the dimension of the ambient space E.",
      "authors": [
        "Jérôme Dedecker",
        "Aurélie Fischer",
        "Bertrand Michel"
      ],
      "primary_category": "math.PR",
      "categories": [
        "math.PR"
      ],
      "published": "2026-01-16T09:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.11133v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16105v2",
      "title": "Algorithms for Algebraic and Arithmetic Attributes of Hypergeometric Functions",
      "abstract": "We discuss algorithms for arithmetic properties of hypergeometric functions. Most notably, we are able to compute the p-adic valuation of a hypergeometric function on any disk of radius smaller than the p-adic radius of convergence. This we use, building on work of Christol, to determine the set of prime numbers modulo which it can be reduced. Moreover, we describe an algorithm to find an annihilating polynomial of the reduction of a hypergeometric function modulo p.",
      "authors": [
        "Xavier Caruso",
        "Florian Fürnsinn"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "cs.SC"
      ],
      "published": "2026-01-22T16:53:29+00:00",
      "link": "https://arxiv.org/pdf/2601.16105v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09102v2",
      "title": "Solution to a Problem of Erdős Concerning Distances and Points",
      "abstract": "In 1997, Erdős asked whether for arbitrarily large $n$ there exists a set of $n$ points in $\\mathbb{R}^2$ that determines $O(\\frac{n}{\\sqrt{\\log n}})$ distinct distances while satisfying the local constraint that every 4-point subset determines at least 3 distinct pairwise distances. We construct $n$-point sets from an $m\\times m$ box of the lattice $L = \\{(x,\\sqrt{2}y):x,y \\in \\mathbb{Z}\\} \\subset \\mathbb{R}^2.$ The distinct distance bound follows from applying Bernays' theorem to the number of integers represented by the binary quadratic form $u^2 + 2v^2$. The local 4-point constraint is verified through Perucca's similarity classification of the six similarity types determining exactly two distances.",
      "authors": [
        "Benjamin Grayzel"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-14T03:06:24+00:00",
      "link": "https://arxiv.org/pdf/2601.09102v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07630v1",
      "title": "Learning to Unfold Fractional Programming for Multi-Cell MU-MIMO Beamforming with Graph Neural Networks",
      "abstract": "In the multi-cell multiuser multi-input multi-output (MU-MIMO) systems, fractional programming (FP) has demonstrated considerable effectiveness in optimizing beamforming vectors, yet it suffers from high computational complexity. Recent improvements demonstrate reduced complexity by avoiding large-dimension matrix inversions (i.e., FastFP) and faster convergence by learning to unfold the FastFP algorithm (i.e., DeepFP).",
      "authors": [
        "Zihan Jiao",
        "Xinping Yi",
        "Shi Jin"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-12T15:11:25+00:00",
      "link": "https://arxiv.org/pdf/2601.07630v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01471v2",
      "title": "Erdős Matching (Conjecture) Theorem",
      "abstract": "Let $\\mathcal{F}$ be a family of $k$-sized subsets of $[n]$ that does not contain $s$ pairwise disjoint subsets.   The Erdős Matching Conjecture, a celebrated and long-standing open problem in extremal combinatorics, asserts the maximum cardinality of $\\mathcal{F}$ is upper bounded by   $\\max\\left\\{\\binom{sk-1}{k}, \\binom{n}{k}-\\allowbreak \\binom{n-s+1}{k}\\right\\}$.   These two bounds correspond to the sizes of two canonical extremal families: one in which all subsets are contained within a ground set of $sk-1$ elements, and one in which every subset intersects a fixed set of $s-1$ elements.   In this paper, we prove the conjecture.",
      "authors": [
        "Tapas Kumar Mishra"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-02-01T22:30:13+00:00",
      "link": "https://arxiv.org/pdf/2602.01471v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17169v1",
      "title": "Complexity of the Feedback Vertex Set Problem in Tournaments with Forbidden Subtournaments",
      "abstract": "In this paper, we consider the complexity of the minimum feedback vertex set problem (MFBVS) for tournaments with forbidden subtournaments. The MFBVS problem in general tournaments is known to be NP-complete. We prove that the MFBVS problem for $W_5$-free and $U_5$-free tournaments is in P, and for $T_5$-free tournaments it remains NP-complete. Moreover, we prove a necessary condition for all $H$ such that the MFBVS problem for $H$-free tournaments is in P. We also show that the necessary condition is not sufficient.",
      "authors": [
        "Sophie Spirkl",
        "Yun Xing"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-01-23T21:05:43+00:00",
      "link": "https://arxiv.org/pdf/2601.17169v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07511v2",
      "title": "Principal ideal problem and ideal shortest vector over rational primes in power-of-two cyclotomic fields",
      "abstract": "The shortest vector problem (SVP) over ideal lattices is closely related to the Ring-LWE problem, which is widely used to build post-quantum cryptosystems. Power-of-two cyclotomic fields are frequently adopted to instantiate Ring-LWE. Pan et al. (EUROCRYPT~2021) explored the SVP over ideal lattices via the decomposition fields and, in particular determined the length of the shortest vector in prime ideals lying over rational primes $p\\equiv3,5\\pmod{8}$ in power-of-two cyclotomic fields via explicit construction of reduced lattice bases.   In this work, we first provide a new method (different from analyzing lattice bases) to analyze the length of the shortest vector in prime ideals in $\\mathbb{Z}[ζ_{2^{n+1}}]$ when $p\\equiv3,5\\pmod{8}$. Then we precisely characterize the length of the shortest vector in the cases of $p\\equiv7,9\\pmod{16}$. Furthermore, we derive a new upper bound $\\sqrt[4]{2^{2n+1}p}$ for this length, which is tighter than the bound $2^n\\sqrt[4]{p}$ obtained from Minkowski's theorem. Our key technique is to investigate whether a generator of a principal ideal can achieve the shortest length after embedding as a vector. If this holds for the ideal, finding the shortest vector in this ideal can be reduced to finding its shortest generator.",
      "authors": [
        "Gaohao Cui",
        "Jianing Li",
        "Jincheng Zhuang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-12T13:09:36+00:00",
      "link": "https://arxiv.org/pdf/2601.07511v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02876v1",
      "title": "Frugal coloring of graphs revisited",
      "abstract": "Given a graph $G$ and a positive integer $t$, an independent set $S\\subseteq V(G)$ is $t$-frugal if every vertex has at most $t$ neighbors in $S$. A $t$-frugal coloring of $G$ is a partition of its vertex set into $t$-frugal independent sets. The maximum cardinality of a $t$-frugal independent set in $G$ is denoted by $α_t^f(G)$, while the minimum cardinality of a $t$-frugal coloring of $G$, $χ_t^f(G)$, is called the $t$-frugal chromatic number of $G$. Frugal colorings were introduced in 1998 and studied later in just a handful of papers. In this paper, we revisit this concept. While the NP-hardness of frugal coloring is known, we prove that the decision version of $α_t^f$ is NP-complete even for bipartite graphs, and present a linear-time algorithm to determine its value for trees. We prove a general sharp lower bound on $χ_{t}^{f}(G)$ expressed in terms of $α_{t}^{f}(G)$ and size of $G$. We also give a sharp upper bound on the $α_2^f$ of any graph $G$, which in the case of graphs with minimum degree $δ\\geq2$ simplifies to $α_2^f(G)\\le 2n/(δ+2)$. We prove that $3\\leχ_2^f(G)\\le 5$ holds for any graph $G$ with $Δ(G)=3$. For several classes of graphs such as block graphs, the Cartesian and strong products of multiple two-way infinite paths, we determine the exact values of $α_2^f$. We provide sharp bounds on the $α_2^f$ in all four standard graph products, which are expressed as different invariants of their factors. Finally, we obtain Nordhaus-Gaddum type inequalities for the sum of the $2$-frugal chromatic numbers of $G$ and its complement from below and from above by functions of the order of $G$. For the upper bound $χ_{2}^{f}(G)+χ_{2}^{f}(\\overline{G})\\leq 3n/2$, we characterize the family of extremal graphs $G$.",
      "authors": [
        "Boštjan Brešar",
        "Wenjie Hu",
        "Babak Samadi"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-02T22:33:16+00:00",
      "link": "https://arxiv.org/pdf/2602.02876v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14803v1",
      "title": "Efficient Beamforming for Discrete SIM-Aided Multiuser Systems Under Statistical CSI",
      "abstract": "Stacked Intelligent Metasurfaces (SIM) have emerged as a revolutionary architecture for next-generation wireless communications, offering wave-domain signal processing capabilities with significantly reduced hardware complexity compared to conventional systems. However, most existing SIM research assumes continuous phase shifts and perfect instantaneous channel state information (CSI), which are impractical due to hardware discrete phase shift constraints and prohibitive pilot overhead. This paper presents a joint power allocation and discrete phase shift optimization framework for SIM-aided multiuser multiple-input single-output(MISO) downlink systems under statistical CSI. We formulate the achievable sum rate maximization problem considering practical discrete phase constraints and derive a closed-form expression for the average achievable rate under statistical CSI. To tackle the resulting non-convex optimization problem, we decouple the problem by using the weighted minimum mean square error (WMMSE) algorithm and alternating optimization (AO). Subsequently, we utilize the Lagrangian multiplier method and alternating direction method of multipliers (ADMM) to obtain closed-form iterative solutions. Our simulations demonstrate that the proposed algorithm reduces computational complexity by a factor of 50 compared to semi-definite relaxation (SDR) methods, , while maintaining over 85% of the continuous phase shift performance with only 1-bit quantization, highlighting its feasibility for low-cost hardware systems.",
      "authors": [
        "Yuhui Jiao",
        "Qian Zhang",
        "Xuejun Cheng",
        "Yunxiao Li",
        "Yufei Zhao",
        "Ju Liu",
        "Yong Liang Guan"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-21T09:29:35+00:00",
      "link": "https://arxiv.org/pdf/2601.14803v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03860v1",
      "title": "Polynomial Closed-Form Model for Evaluating Nonlinear Interference in Any Island",
      "abstract": "Polynomial closed-form GN model is proposed by expressing the spatial power profile of each channel along a span as a polynomial. In this paper, we present the generic closed-form expression for all contributions of self-, cross-, and multi-channel interference. The full derivation is provided.",
      "authors": [
        "Yanchao Jiang",
        "Pierluigi Poggiolini"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "published": "2026-01-23T21:21:04+00:00",
      "link": "https://arxiv.org/pdf/2602.03860v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14920v1",
      "title": "Diagonals and algebraicity modulo $p$: a sharper degree bound",
      "abstract": "In 1984, Deligne proved that for any prime number $p$, the reduction modulo $p$ of the diagonal of a multivariate algebraic power series with integer coefficients is algebraic over the field of rational functions with coefficients in $\\mathbb F_p$. Moreover, he conjectured that the algebraic degrees $d_p$ of these functions should grow at most polynomially in $p$. In this article, we provide a new and elementary proof of Deligne's theorem, which yields the first general polynomial bound on $d_p$ with an explicit and reasonable degree.",
      "authors": [
        "Boris Adamczewski",
        "Alin Bostan",
        "Xavier Caruso"
      ],
      "primary_category": "cs.SC",
      "categories": [
        "cs.SC",
        "math.NT"
      ],
      "published": "2026-01-21T12:09:26+00:00",
      "link": "https://arxiv.org/pdf/2601.14920v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17539v1",
      "title": "Laurent type expansion of multiple polylogarithms at integer points",
      "abstract": "In this article, we study the local behaviour of the multiple polylogarithm functions at integer points, in the $s$-aspect. This is done by writing a Laurent type expansion at integer points, involving certain power series and rational functions. The coefficients of these power series are the regularised values of the multiple polylogarithm functions at certain related integer points.",
      "authors": [
        "Pawan Singh Mehta",
        "Biswajyoti Saha"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-24T17:41:12+00:00",
      "link": "https://arxiv.org/pdf/2601.17539v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08092v1",
      "title": "Quadratic codimension growth and minimal varieties of unitary algebras with superinvolution",
      "abstract": "Let $A$ be an associative algebra with a superinvolution $*$ over a field of characteristic zero, and let $c_n^*(A)$, $n = 1, 2, \\ldots$, denote its sequence of $*$-codimensions. It is well known that this sequence is either polynomially bounded or grows exponentially. In the polynomial case, a central problem in PI-theory is the classification of varieties ${V}$ for which $c_n^*({V}) \\approx αn^k$ for a given $k$. One of the main objectives of this paper is to classify minimal varieties of unitary algebras endowed with a superinvolution that exhibit quadratic codimension growth. We obtain a structural characterization, up to PI-equivalence, of all unitary algebras with quadratic codimension growth. As a consequence, we show that any unitary variety of quadratic codimension growth is generated by a direct sum of algebras generating minimal varieties.",
      "authors": [
        "Wesley Quaresma Cota",
        "Luiz Henrique de Souza Matos"
      ],
      "primary_category": "math.RA",
      "categories": [
        "math.RA"
      ],
      "published": "2026-01-13T00:25:01+00:00",
      "link": "https://arxiv.org/pdf/2601.08092v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07639v2",
      "title": "Pluripotential theory on algebraic curves",
      "abstract": "In previous works, the second author defined directional Robin constants associated to a compact, nonpolar subset $K$ of an algebraic curve $A$ in $\\mathbb{C}^N$ and related these to a natural class of Chebyshev constants for $K$. We define a second class of Chebyshev constants for $K$; relate these two classes; and utilize each of them to define two families of extremal-like functions which can be used to recover the Siciak-Zaharjuta extremal function for $K$.",
      "authors": [
        "Norm Levenberg",
        "Sione Ma'u"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV"
      ],
      "published": "2026-01-12T15:19:14+00:00",
      "link": "https://arxiv.org/pdf/2601.07639v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17742v1",
      "title": "Partitionable Diffractive Neural Networks for Multifunctional Optical Operations",
      "abstract": "Diffractive neural network (DNN), which can perform machine learning tasks based on the light propagation and diffraction, has recently emerged as a promising optical computing paradigm due to its high parallel processing speed and low power consumption nature. However, existing diffractive network architectures face challenges in implementing functional reconfiguration. Once a diffractive neural network is fabricated, its functionality is fixed. Deploying such systems for different tasks typically requires reconstructing the entire physical setup, which significantly compromises hardware efficiency in practical applications. In this work, we propose the multifunctional partitionable diffractive neural networks (PDNNs) that can generate networks with additional capabilities by stacking multiple sub-modules with independent functions in the horizontal direction. Each submodule functions as an independent diffractive network capable of performing specific imaging or classification tasks. When these submodules are combined, they can form a new network with additional functionalities. Moreover, assembling these submodules in different configurations enables structures with diverse functions. This powerful PDNN framework demonstrates remarkable advantages in flexibility and reconfigurability for multitask operations, opening a new pathway for realizing multifunctional and integrated optical artificial intelligence systems.",
      "authors": [
        "Yudong Tian",
        "Haifeng Xu",
        "Yuqing Liu",
        "Xiangyu Zhao",
        "Jierong Cheng",
        "Chongzhao Wu"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics"
      ],
      "published": "2026-01-25T08:23:35+00:00",
      "link": "https://arxiv.org/pdf/2601.17742v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.12427v1",
      "title": "Counterexamples, Constructions, and Nonexistence Results for Optimal Ternary Cyclic Codes",
      "abstract": "Cyclic codes are an important subclass of linear codes with wide applications in communication systems and data storage systems. In 2013, Ding and Helleseth presented nine open problems on optimal ternary cyclic codes $\\mathcal{C}_{(1,e)}$. While the first two and the sixth problems have been fully solved, others remain open. In this paper, we advance the study of the third and fourth open problems by providing the first counterexamples to both and constructing two families of optimal codes under certain conditions, thereby partially solving the third problem. Furthermore, we investigate the cyclic codes $\\mathcal{C}_{(1,e)}$ where $e(3^h\\pm 1)\\equiv\\frac{3^m-a}{2}\\pmod{3^m-1}$ and $a$ is odd. For $a\\equiv 3\\pmod{4}$, we present two new families of optimal codes with parameters $[3^m-1,3^m-1-2m,4]$, generalizing known constructions. For $a\\equiv 1\\pmod{4}$, we obtain several nonexistence results on optimal codes $\\mathcal{C}_{(1,e)}$ with the aforementioned parameters revealing the constraints of such codes.",
      "authors": [
        "Jingjun Bao",
        "Hanlin Zou"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "math.CO"
      ],
      "published": "2026-01-18T14:25:06+00:00",
      "link": "https://arxiv.org/pdf/2601.12427v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02997v1",
      "title": "Entire area-minimizing surfaces in R^4 are algebraic",
      "abstract": "We classify entire 2-dimensional area-minimizing or stable surfaces in R^4 with quadratic area growth as algebraic, cut out by a finite union of holomorphic polynomials whose collective degrees are controlled by the density at infinity. As a consequence, we obtain bounds on the singular set size and genus in terms of the density at infinity.",
      "authors": [
        "Nick Edelen",
        "Luis Atzin Franco Reyna",
        "Paul Minter"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "math.AP"
      ],
      "published": "2026-02-03T02:11:28+00:00",
      "link": "https://arxiv.org/pdf/2602.02997v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18138v1",
      "title": "Repellent properties of perfect powers on partition functions: a heuristic approach",
      "abstract": "In 2013, Sun conjectured that the partition function $p(n)$ is never a perfect power for $n \\geq 2$. Building on this, Merca, Ono, and Tsai recently observed that for any fixed integers $d \\geq 0$ and $k \\geq 2$, there appear to be only finitely many integers $n$ such that $p(n)$ differs from a perfect $k$th power by at most $d$. Denoting by $M_k(d)$ the largest such $n$, they conjectured that $M_k(d) = o(d^ε)$ for every $ε> 0$.   In this paper, we investigate the asymptotic growth of analogs of $M_k(d)$ for a wide class of partition functions. We establish sharp lower bounds and provide heuristics which suggest that $M_k(d)$ in fact grows polylogarithmically in $d$, i.e. of order $\\log^2(d)$. More generally, we prove that if $f(n)$ is a suitably random chosen function with asymptotic growth rate similar to that of $p(n)$, then the set of integers $n$ for which $f(n)$ is a perfect power is finite with probability 1.",
      "authors": [
        "Summer Haag",
        "Praneel Samanta",
        "Swati",
        "Holly Swisher",
        "Stephanie Treneer",
        "Robin Visser"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-26T04:43:59+00:00",
      "link": "https://arxiv.org/pdf/2601.18138v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.20122v1",
      "title": "On the Arithmetic of Bicritical Rational Functions",
      "abstract": "Bicritical rational functions -- those with precisely two critical points -- include the well-studied families of unicritical polynomials and quadratic rational functions. In this article we lay out general foundations for studying arithmetic dynamical properties of bicritical rational functions, and prove new Galois-theoretic results for a family with special properties. We study the field of definition of the critical points, and give a normal form up to Möbius conjugacy over this field. As a corollary, we show that after a finite extension of the ground field, the arboreal Galois representation attached to a bicritical rational function injects into an iterated wreath product of cyclic groups. We then examine the family of quadratic $φ\\in \\mathbb{Q}(x)$ with critical points $γ_1$ and $γ_2$ such that $φ(γ_1) = γ_2$. Adapting methods of Odoni-Stoll in the polynomial case to rational functions, we show that the arboreal representation is surjective for an infinite subfamily.",
      "authors": [
        "Vefa Goksel",
        "Rafe Jones"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-27T23:30:23+00:00",
      "link": "https://arxiv.org/pdf/2601.20122v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02131v1",
      "title": "Two-Stage Coded-Sliding Beam Training and QoS-Constrained Sum-Rate Maximization for SIM-Assisted Wireless Communications",
      "abstract": "Stacked intelligent metasurfaces (SIM) provide a cost-effective and scalable solution for large-scale antenna communications.However, efficient channel state information acquisition and phase shift optimization remain critical challenges. In this paper, we develop a unified framework of low-complexity algorithms for SIM-assisted communication systems to address these issues. Specifically, we propose a generalized two-step codebook construction (TSCC) method that leverages two-dimensional angular-domain decoupling to transform planar array beamformer design into two independent one-dimensional linear array beamformer design problems, efficiently solved via the Gerchberg-Saxton algorithm and our proposed majorization-minimization-based proximal distance (PDMM) algorithm. We further develop a two-stage coded-sliding beam training (TSCSBT) method for low-overhead and high-accuracy beam training, where error-correcting codes are embedded in the first-stage training to enhance robustness against noise, and sliding sampling is subsequently performed around the matched angular samples to improve angular resolution. The proposed framework is further extended to multi-path user channels. Finally, a variable decoupling-based block successive upper bound minimization (VD-BSUM) algorithm is proposed to directly solve the QoS-constrained sum-rate maximization problem through closed-form iterative updates with substantially reduced computational complexity. Simulation results demonstrate the effectiveness of the proposed methods in achieving precise beam pattern realization, improved beam training accuracy and angular resolution, and enhanced sum-rate performance.",
      "authors": [
        "Qian Zhang",
        "Ju Liu",
        "Yao Ge",
        "Yufei Zhao",
        "Wali Ullah Khan",
        "Zheng Dong",
        "Yong Liang Guan",
        "Chau Yuen"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-02-02T14:15:19+00:00",
      "link": "https://arxiv.org/pdf/2602.02131v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04654v1",
      "title": "On the density of rational lines on diagonal cubic hypersurfaces",
      "abstract": "In this paper, we establish the asymptotic estimates for the rational lines on diagonal cubic hypersurfaces defined by $\\sum_{i=1}^sc_ix^3_i=0$ with $c_i\\in\\mathbb{Z}\\setminus \\{0\\},$ provided that $s\\geq 19.$ This improves the previously known bound $s\\geq 21$ required to obtain such asymptotic estimates. Our approach develops a multidimensional shifting variables argument together with a pruning argument, and exploits the recent progress on the Parsell-Vinogradov system.",
      "authors": [
        "Kiseok Yeon"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-04T15:29:23+00:00",
      "link": "https://arxiv.org/pdf/2602.04654v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15138v2",
      "title": "Inequalities of Miyaoka-Yau type $\\&$ Uniformisation of varieties of intermediate Kodaira Dimension",
      "abstract": "In this paper we present, for any integers $0\\leq ν\\leq n$, a set of inequalities satisfied by the Chern classes of any minimal complex projective variety of dimension $n$ and numerical dimension $ν$. In the cases where $ν$ is either very small or very large compared with $n$, this recovers many previously known results. We demonstrate that our inequalities are sharp by providing an explicit characterisation of those varieties achieving the equality; our proof, in particular, resolves the Abundance conjecture in this situation. Additionally, we provide some new examples of varieties with extremal Chern classes that demonstrate the optimality of our results.",
      "authors": [
        "Niklas Müller"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-21T16:12:26+00:00",
      "link": "https://arxiv.org/pdf/2601.15138v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21871v1",
      "title": "Polync varieties and multiparameter Kulikov models",
      "abstract": "We study \"polync varieties\", whose singularities are locally products of normal crossing (nc) singularities. We introduce the notion of d-semistability of such varieties, and generalize work of Friedman and Kawamata-Namikawa to address the smoothability of d-semistable, K-trivial, polync varieties. These results are applications of recent breakthroughs on the logarithmic Bogomolov-Tian-Todorov theorem, due to Chan-Leung-Ma and Felten-Filip-Ruddat. We generalize the combinatorial description of Kulikov models for K3 surfaces to the setting of a multiparameter base and describe some interesting examples.",
      "authors": [
        "Philip Engel"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.SG"
      ],
      "published": "2026-01-29T15:38:30+00:00",
      "link": "https://arxiv.org/pdf/2601.21871v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01178v1",
      "title": "From subtractive ideals of semirings to deductive and inductive sets in general algebras",
      "abstract": "In this paper we extend the characterisation of kernels in semirings as subtractive ideals to general algebras. We then analyse the counterparts of ``subtractive'' and ``ideal'' in several different algebraic settings.",
      "authors": [
        "Elena Caviglia",
        "Amartya Goswami",
        "Zurab Janelidze",
        "Luca Mesiti",
        "Vaino T. Shaumbwa"
      ],
      "primary_category": "math.RA",
      "categories": [
        "math.RA"
      ],
      "published": "2026-02-01T12:06:52+00:00",
      "link": "https://arxiv.org/pdf/2602.01178v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01112v1",
      "title": "Optimal algebraic tangent cone of torsion-free sheaves via valuations",
      "abstract": "We develop a valuation-theoretic framework for studying tangent cones of torsion-free sheaves on algebraic varieties. To analyze these objects, we introduce a slope stability theory, including the Harder-Narasimhan filtrations, for finitely generated $\\mathbb{R}$-graded modules over finitely generated $\\mathbb{R}_{\\geq 0}$-graded algebras. Using it, we show that there is a canonically determined tangent cone of torsion-free sheaves, up to the expected equivalence ambiguity, for quasi-regular valuations, which generalize Chen-Sun [3].",
      "authors": [
        "Yohei Hada"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.DG"
      ],
      "published": "2026-02-01T09:17:19+00:00",
      "link": "https://arxiv.org/pdf/2602.01112v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14453v1",
      "title": "Universality of Neural Network Field Theory",
      "abstract": "We prove that any quantum field theory, or more generally any probability distribution over tempered distributions in $\\mathbb{R}^d$, admits a neural network description with a countable infinity of parameters. As an example, we realize the $2d$ Liouville theory as a neural network and numerically compute the three-point function of vertex operators, finding agreement with the DOZZ formula.",
      "authors": [
        "Christian Ferko",
        "James Halverson",
        "Aaron Mutchler"
      ],
      "primary_category": "hep-th",
      "categories": [
        "hep-th",
        "math.PR"
      ],
      "published": "2026-01-20T20:24:13+00:00",
      "link": "https://arxiv.org/pdf/2601.14453v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.06841v2",
      "title": "Efficient Subdivision of Bézier Curves/Surfaces via Blossoms",
      "abstract": "We consider the problem of Bézier curves/surfaces subdivision using blossoms. We propose closed-form formulae for blossoms evaluation, as needed for the calculation of control points. This approach leads to direct and efficient way to obtain subdivisions for Bézier curves and both tensor product and triangular Bézier surfaces. It simplifies considerably the computation of control points of subdivisions which is crucial in applications where curves/surfaces need to be refined or adapted dynamically. For instance, in CAD/CAM systems, architectural design, or animation, the ability to quickly and accurately determine new control points is essential for manipulation and rendering complex shapes. More efficient subdivision can facilitate complex operations like finding intersections between surfaces or smoothly blending multiple surfaces.",
      "authors": [
        "Krassimira Vlachkova"
      ],
      "primary_category": "cs.CG",
      "categories": [
        "cs.CG"
      ],
      "published": "2026-01-11T10:08:27+00:00",
      "link": "https://arxiv.org/pdf/2601.06841v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00278v1",
      "title": "Thresholds vs. expectation thresholds for non-spanning graphs",
      "abstract": "The threshold $p_c(H)$ for the event that the binomial random graph $G_{n,p}$ contains a copy of a graph $H$ is the unique $p$ for which $\\mathbb{P}(H \\subseteq G_{n,p}) = 1/2$, and the fractional expectation threshold $q_f(H)$ is roughly the best lower bound on $p_c(H)$ using simple expectation considerations. All previously known $H$'s with $p_c(H)$ substantially larger than $q_f(H)$ have the property that $v_H > n/2$ (where $v_H$ is the number of vertices of $H$). We construct small graphs whose threshold for containment in $G_{n,p}$ is of different order than their corresponding fractional expectation threshold: there is a constant $c > 0$ such that for any $m \\; (\\leq n)$, there is a graph $H$ with $v_H = m$ and $p_c(H) > q_f(H) c \\log^{1/2}(v_H).$",
      "authors": [
        "Quentin Dubroff"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-01-30T20:01:46+00:00",
      "link": "https://arxiv.org/pdf/2602.00278v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08704v1",
      "title": "Singular del Pezzo surfaces and isotropic flag varieties",
      "abstract": "We compute the Chow quotient of the complete flag variety of isotropic subspaces of a four dimensional complex vector space with respect to a skew/symmetric form, and show that it is a singular del Pezzo surface of degree four.",
      "authors": [
        "Michele Bianco",
        "Luis E. Solá Conde"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-13T16:34:05+00:00",
      "link": "https://arxiv.org/pdf/2601.08704v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03739v1",
      "title": "Semiseparability of induction functors in a monoidal category",
      "abstract": "For any algebra morphism in a monoidal category, we provide sufficient conditions (which are also necessary if the unit is a left tensor generator) for the attached induction functor being semiseparable. Under mild assumptions, we prove that the semiseparability of the induction functor is preserved if one applies a lax monoidal functor. Similar results are shown for the coinduction functors attached to coalgebra morphisms in a monoidal category. As an application, we study the semiseparability of combinations of (co)induction functors in the context of duoidal categories.",
      "authors": [
        "Lucrezia Bottegoni",
        "Zhenbang Zuo"
      ],
      "primary_category": "math.CT",
      "categories": [
        "math.CT",
        "math.QA",
        "math.RA",
        "math.RT"
      ],
      "published": "2026-02-03T16:58:28+00:00",
      "link": "https://arxiv.org/pdf/2602.03739v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01080v1",
      "title": "Skirting the $n$-tuples",
      "abstract": "Let $n\\ge 2$ and $q\\ge 2$ be given. The set $X = \\mathbb Z_q^n$ is a metric space of diameter $n$ under the Hamming metric $d(\\cdot,\\cdot)$. We seek a smallest set $S\\subseteq X$ that ``skirts'' every $q$-ary $n$-tuple in the sense that every $x\\in X$ is at distance $n$ from at least one element of $S$. Thus we aim to compute the total domination number $f(n,q)$ of the graph $G(n,q)$ with vertex set $X$ and edge set $\\{ xy \\, \\| \\, d(x,y)=n\\}$. We provide constructions and bounds for this number, establishing $f(n,q) = C_q^{(1+o(1))n}$ for some constants $2=C_2>C_3 \\geq \\cdots$ which we are only able to estimate at the present time.",
      "authors": [
        "Sam Adriaensen",
        "Ferdinand Ihringer",
        "William J. Martin",
        "Ralihe R. Villagrán"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-01T07:51:56+00:00",
      "link": "https://arxiv.org/pdf/2602.01080v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16765v1",
      "title": "Components of the nested Hilbert scheme of few points",
      "abstract": "We study the existence and the schematic structure of elementary components of the nested Hilbert scheme on a smooth quasi-projective variety. Precisely, we find a new lower bound for the existence of non-smoothable nestings of fat points on a smooth $n$-fold, for $n\\geqslant 4$. Moreover, we implement a systematic method to build generically non-reduced elementary components. We also investigate the problem of irreducibility of the Hilbert scheme of points on a singular hypersurface of $\\mathbb A^3$. Explicitly, we show that the Hilbert scheme of points on a hypersurface of $\\mathbb{A}^3$ having a singularity of multiplicity at least 5 admits elementary components.",
      "authors": [
        "Michele Graffeo",
        "Paolo Lella"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.AC"
      ],
      "published": "2026-01-23T14:12:31+00:00",
      "link": "https://arxiv.org/pdf/2601.16765v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17345v1",
      "title": "Algebraic models for equivariant rational homotopy theory for discrete groups",
      "abstract": "We provide a framework which generalizes algebraic models of a homotopy theory of spaces to the genuine equivariant case for a discrete group. We explain how this applies to commutative differential graded algebra (cdga) models and complete differential graded Lie algebra models for rational spaces. We compare the cdga model to other model categories in the literature.",
      "authors": [
        "José M. Moreno-Fernández",
        "Bruno Stonek"
      ],
      "primary_category": "math.AT",
      "categories": [
        "math.AT",
        "math.CT"
      ],
      "published": "2026-01-24T07:12:57+00:00",
      "link": "https://arxiv.org/pdf/2601.17345v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14095v1",
      "title": "Basis Number and Pathwidth",
      "abstract": "We prove two results relating the basis number of a graph $G$ to path decompositions of $G$. Our first result shows that the basis number of a graph is at most four times its pathwidth. Our second result shows that, if a graph $G$ has a path decomposition with adhesions of size at most $k$ in which the graph induced by each bag has basis number at most $b$, then $G$ has basis number at most $b+O(k\\log^2 k)$. The first result, combined with recent work of Geniet and Giocanti shows that the basis number of a graph is bounded by a polynomial function of its treewidth. The second result (also combined with the work of Geniet and Giocanti) shows that every $K_t$-minor-free graph has a basis number bounded by a polynomial function of $t$.",
      "authors": [
        "Babak Miraftab",
        "Pat Morin",
        "Yelena Yuditsky"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "cs.DM"
      ],
      "published": "2026-01-20T15:57:32+00:00",
      "link": "https://arxiv.org/pdf/2601.14095v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22072v1",
      "title": "On singularities of determinantal hypersurfaces",
      "abstract": "Given a closed subscheme $Z$ in a smooth variety $X$, defined by the maximal minors of an $s\\times r$ matrix of regular functions, with $s\\geq r$, we consider the corresponding incidence correspondence $W$ in $Y=X\\times {\\mathbf P}^{r-1}$, and relate the log canonical thresholds of $(X,Z)$ and $(Y,W)$. In particular, when $r=s$, we show that ${\\rm lct}(X,Z)=1$ if and only if ${\\rm lct}(Y,W)=r$. Moreover, in this case, we show that $Z$ has rational singularities if and only if $W$ has pure codimension $r$ in $Y$ and has rational singularities. As a consequence, we deduce that for a configuration hypersurface with a connected configuration matroid, the corresponding configuration incidence variety has rational singularities.",
      "authors": [
        "Daniel Bath",
        "Mircea Mustaţă"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-29T18:09:14+00:00",
      "link": "https://arxiv.org/pdf/2601.22072v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01001v1",
      "title": "Generalized fruit Diophantine equation and super elliptic curves",
      "abstract": "In this article, we are interested in finding rational points on certain superelliptic curves.",
      "authors": [
        "Kalyan Banerjee",
        "Kalyan Chakraborty",
        "Ankita Das"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-01T03:45:13+00:00",
      "link": "https://arxiv.org/pdf/2602.01001v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.13794v1",
      "title": "Asymptotic Properties of Filtrations of Ideals",
      "abstract": "We introduce a unified framework for studying persistence phenomena in commutative algebra via filtrations of ideals. For a filtration $\\mathcal{F} = \\{I_i\\}_{i \\in \\mathbb{N}}$, we define $\\mathcal{F}$-persistence and $\\mathcal{F}$-strong persistence, extending the classical notions for ordinary and symbolic powers of ideals. We show that if $\\mathcal{F}$ is strongly persistent, then $\\mathcal{F}_{\\mathrm{sym}}$ is strongly persistent, where $\\mathcal{F}_{\\mathrm{sym}}$ denotes the symbolic filtration associated with the filtration $\\mathcal{F}$. In addition, we prove that if $\\mathcal{F}$ is strongly persistent, then $\\mathcal{F}$ is persistent.",
      "authors": [
        "Mehrdad Nasernejad",
        "Jonathan Toledo"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2026-01-20T09:52:39+00:00",
      "link": "https://arxiv.org/pdf/2601.13794v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15243v1",
      "title": "Koszul Binomial Edge Ideals",
      "abstract": "As the binomial edge ideal of a graph is always generated by homogeneous quadratic polynomials corresponding to the edges of the graph, the question of when a binomial edge ideal defines a Koszul algebra has been studied by many authors ever since the class of ideals was first defined. Several partial results are known, including a characterization of those binomial edge ideals that possess a quadratic Gröbner basis. However, a complete characterization of the graphs determining Koszul binomial edge ideals has remained elusive. Inspired by our recent work characterizing when the graded Möbius algebras of graphic matroids are Koszul, we answer the question once and for all by proving that a graph defines a Koszul binomial edge ideal if and only if it is strongly chordal and claw-free.",
      "authors": [
        "Adam LaClair",
        "Matthew Mastroeni",
        "Jason McCullough",
        "Irena Peeva"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC",
        "math.CO"
      ],
      "published": "2026-01-21T18:25:51+00:00",
      "link": "https://arxiv.org/pdf/2601.15243v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01014v1",
      "title": "Inequalities Concerning Rational Functions With Prescribed Poles",
      "abstract": "Let $\\Re_n$ be the set of all rational functions of the type $r(z) = p(z)/w(z),$ where $p(z)$ is a polynomial of degree at most $n$ and $w(z) = \\prod_{j=1}^{n}(z-a_j)$, $|a_j|>1$ for $1\\leq j\\leq n$. In this paper, we set up some results for rational functions with fixed poles and restricted zeros. The obtained results bring forth generalizations and refinements of some known inequalities for rational functions and in turn produce generalizations and refinements of some polynomial inequalities as well.",
      "authors": [
        "N. A. Rather",
        "Tanveer Bhat",
        "Danish Rashid Bhat"
      ],
      "primary_category": "math.CV",
      "categories": [
        "math.CV"
      ],
      "published": "2026-02-01T04:44:05+00:00",
      "link": "https://arxiv.org/pdf/2602.01014v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16607v1",
      "title": "Card guessing after an asymmetric riffle shuffle",
      "abstract": "We consider a card guessing game with complete feedback. An ordered deck of $n$ cards labeled $1$ up to $n$ is riffle-shuffled exactly one time. Given a value $p\\in(0{,}1)\\setminus\\{\\frac12\\}$, the riffle shuffle is assumed to be unbalanced, such that the cut is expected to happen at position $p\\cdot n$. The goal of the game is to maximize the number of correct guesses of the cards: one after another a single card is drawn from the top, and shown to the guesser until no cards remain. We provide a detailed analysis of the optimal guessing strategy and study the distribution of the number of correct guesses.",
      "authors": [
        "Markus Kuba"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.PR"
      ],
      "published": "2026-01-23T10:07:02+00:00",
      "link": "https://arxiv.org/pdf/2601.16607v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22287v1",
      "title": "Smooth correspondences between quiver varieties",
      "abstract": "We introduce a new class of smooth correspondences between Nakajima quiver varieties called split parabolic quiver varieties, and study their properties. We use these correspondences to construct an explicit resolution of singularities of quiver Brill--Noether loci and prove that the latter are irreducible and Cohen-Macaulay of expected dimension (if non-empty). This generalizes the results of Nakajima--Yoshioka and Bayer--Chen--Jiang for Hilbert schemes of points on surfaces.",
      "authors": [
        "Nicolle González",
        "Eugene Gorsky",
        "José Simental"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.RT"
      ],
      "published": "2026-01-29T20:02:24+00:00",
      "link": "https://arxiv.org/pdf/2601.22287v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09517v1",
      "title": "Rational integers as sums of units -- the quadratic case",
      "abstract": "How many natural numbers below $X$ can be written as a sum of $k$ units of the ring of integers of a given number field? We give the asymptotics as $X$ gets large for quadratic number fields. This solves a problem of Jarden and Narkiewicz from 2007 for quadratic number fields.",
      "authors": [
        "Christopher Frei",
        "Martin Widmer",
        "Volker Ziegler"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-14T14:36:48+00:00",
      "link": "https://arxiv.org/pdf/2601.09517v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09472v1",
      "title": "Estimates on binomial sums of partition functions",
      "abstract": "Let $p(n)$ denote the partition function and define $p(n,k)=\\sum_{j=0}^{k}\\binom{n-j}{k-j}p(j)$ where $p(0)=1$. We prove that $p(n,k)$ is unimodal and satisfies $p(n,k) < \\frac{2.825}{\\sqrt{n}}\\, 2^n $ for fixed $n\\ge 1$ and all $1\\le k\\le n$. This result has an interesting application: the minimal dimension of a faithful module for a $k$-step nilpotent Lie algebra of dimension $n$ is bounded by $p(n,k)$ and hence by $\\frac{3}{\\sqrt{n}}\\, 2^n $, independently of $k$. So far only the bound $n^{n-1}$ was known. We will also prove that $p(n,n-1)<\\sqrt{n}\\exp(π\\sqrt{2n/3})$ for $n\\ge 1$ and $p(n-1,n-1)<\\exp (π\\sqrt{2n/3} )$.",
      "authors": [
        "Dietrich Burde"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-14T13:28:28+00:00",
      "link": "https://arxiv.org/pdf/2601.09472v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09510v1",
      "title": "Powers in prime bases and a problem on central binomial coefficients",
      "abstract": "It is an open problem whether $ \\binom{2n}{n} $ is divisible by 4 or 9 for all $n>256$. In connection with this, we prove that for a fixed uneven $m$ the asymptotic density of $k$'s such that $ m \\nmid \\binom{2^{k+1}}{2^{k}} $ is 0. To do so we examine numbers of the form $α^{k}$ in base $p$, where $p$ is a prime and $(α, p)=1$. For every $n$ and $a$ we find an upper bound on the number of $k$'s less than $a$ such that $(α^{k})_p$ contains less than $n$ digits greater than $\\frac{p}{2}$. This is done by showing that every sequence of the form $\\langle σ_t, \\dots, σ_1,σ_0 \\rangle$, where $0\\leq σ_i<p$ for $i\\geq 1$ and $σ_0$ is in the residue class generated by $α$ modulo $p$, occurs at specific places in the representation $(α^k)_p$ as $k$ varies.",
      "authors": [
        "Sebastian Tim Holdum",
        "Frederik Ravn Klausen",
        "Peter Michael Reichstein Rasmussen"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-14T14:21:26+00:00",
      "link": "https://arxiv.org/pdf/2601.09510v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15905v1",
      "title": "Pregroup representable expansions of residuated lattices",
      "abstract": "Group representable relation algebras play an important role in the study of representable relation algebras. The class of distributive involutive FL-algebras (DInFL-algebras) generalises relation algebras, as well as Sugihara monoids and MV-algebras. We construct DInFL-algebras from pregroups and show that they can be represented as algebras of binary relations. Even for finite pregroups we obtain relational representations of DInFL-algebras with non-Boolean lattice reducts. If the pregroup is enriched with a particular unary order-reversing operation, then our construction yields representation results for distributive quasi relation algebras.",
      "authors": [
        "Andrew Craig",
        "Claudette Robinson"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-22T12:32:19+00:00",
      "link": "https://arxiv.org/pdf/2601.15905v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08399v1",
      "title": "The Chow Ring of the Hilbert Cube",
      "abstract": "Given a smooth projective variety $X$ over a field $k$, we compute the Chow ring of the Hilbert scheme of three points on $X$, $\\operatorname{Hilb}^3(X)$, as an algebra with generators and relations over the Chow ring of $X\\times\\operatorname{Sym}^2(X)$. If in addition the characteristic of $k$ is zero, we extend the computation to the quasi-projective case.",
      "authors": [
        "Ian Selvaggi"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-13T10:13:48+00:00",
      "link": "https://arxiv.org/pdf/2601.08399v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07000v1",
      "title": "Product representations of perfect powers",
      "abstract": "Let $ρ_k(N)$ denote the maximum size of a set $A\\subseteq \\{1,2,\\dots,N\\}$ such that no product of $k$ distinct elements of $A$ is a perfect $d$-th power. In this short note, we prove that $ρ_d(N)=\\sum\\limits_{k=1}^{d-1}π\\left( \\frac{N}{k} \\right) +O_d(π(N^{1/2}))$, furthermore, for prime power $d$ and sufficiently large $N$ we have $ρ_d(N)=\\sum\\limits_{k=1}^{d-1}π\\left( \\frac{N}{k} \\right)$. This answers a question of Verstraëte.",
      "authors": [
        "Péter Pál Pach",
        "Csaba Sándor"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.NT"
      ],
      "published": "2026-01-11T17:29:00+00:00",
      "link": "https://arxiv.org/pdf/2601.07000v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18153v1",
      "title": "On Golod Subdeterminantal Ideals",
      "abstract": "Let $X=(x_{ij})_{m\\times n}$ be a matrix of indeterminates and let $S=\\mathbb{k}[x_{ij} \\mid 1\\leq i\\leq m,\\ 1\\leq j\\leq n]$ be a polynomial ring over an infinite field $\\mathbb{k}$. Let $I$ be an ideal generated by a subset of the set of all $2\\times2$ minors of $X$. We show that the quotient ring $S/I$ is Golod if and only if $I=I_2(Y)$ for some $2\\times \\ell$ or $\\ell\\times2$ submatrix $Y$ of $X$. In fact, we prove that Golodness of $S/I$ is equivalent to the triviality of the product on the Koszul homology of $S/I$ and to $I$ having a linear resolution. Along the way, we also prove a result on the non-Golodness of tensor products of rings under certain conditions.",
      "authors": [
        "Omkar Javadekar"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2026-01-26T05:17:01+00:00",
      "link": "https://arxiv.org/pdf/2601.18153v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.10895v1",
      "title": "On the rational points in conics of a cubic surfac",
      "abstract": "In this paper, we give a uniform upper bound on the rational points of bounded height provided by conics in a cubic surface. For this target, we give a generalized version of the global determinant method of Salberger by Arakelov geometry.",
      "authors": [
        "Chunhui Liu"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG",
        "math.NT"
      ],
      "published": "2026-01-15T22:49:53+00:00",
      "link": "https://arxiv.org/pdf/2601.10895v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09509v1",
      "title": "Categories of split filtrations and graded quiver varieties",
      "abstract": "By the work of Hernandez-Leclerc, Leclerc-Plamondon, and Keller-Scherotzke, affine graded Nakajima quiver varieties associated with a Dynkin quiver $Q$ admit an algebraic description in terms of modules over the singular Nakajima category $\\mathcal{S}$ and a stratification functor to the derived category of $Q$. In this paper, we extend this framework to Nakajima's $n$-fold affine graded tensor product varieties, which allow one to geometrically realize $n$-fold tensor products of standard modules over the quantum affine algebra. We introduce a category of filtrations with splitting of length $n$ of modules over a category and show that it is equivalent to the module category of a triangular matrix category. Applied to the singular Nakajima category, this yields a category $\\mathcal{S}^{n\\operatorname{-filt}}$ whose modules are parametrized by the points of the $n$-fold tensor product varieties. Generalizing the results of Keller-Scherotzke from $\\mathcal{S}$ to $\\mathcal{S}^{n\\operatorname{-filt}}$, we prove that the stable category of finitely generated Gorenstein projective $\\mathcal{S}^{n\\operatorname{-filt}}$-modules is triangle equivalent to the derived category of the algebra of $n \\times n$ upper triangular matrices over the path algebra of $Q$, and we obtain a corresponding stratification functor.",
      "authors": [
        "Ricardo Canesin"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT"
      ],
      "published": "2026-01-14T14:20:57+00:00",
      "link": "https://arxiv.org/pdf/2601.09509v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00963v1",
      "title": "Some sufficient conditions for a graph with minimum degree to be $k$-critical with respect to $[1,b]$-odd factors",
      "abstract": "A graph $G$ is $k$-factor-critical if $G-S$ has a perfect matching for every subset $S \\subseteq V(G)$ with $|S|=k$. A spanning subgraph $H$ of $G$ is called a $[1,b]$-odd factor if $b \\equiv 1 \\pmod{2}$ and $d_{H}(v) \\in\\left\\lbrace 1, 3, \\ldots, b\\right\\rbrace$ for every $v\\in V(G),$ where $d_{H}(v)$ denotes the degree of vertex $v$ in $H$. Moreover, $G$ is said to be $k$-critical with respect to $[1,b]$-odd factors if $G-X$ contains a $[1,b]$-odd factor for every subset $X \\subseteq V(G)$ with $|X|=k$. In this paper, we provide some sufficient conditions based on the distance spectral radius and the distance signless Laplacian spectral radius for a graph with minimum degree to be $k$-critical with respect to $[1,b]$-odd factors.",
      "authors": [
        "Jiaxu Zhong",
        "Yong Lu"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-01T01:51:01+00:00",
      "link": "https://arxiv.org/pdf/2602.00963v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04283v1",
      "title": "Distance spectral radius conditions for perfect $k$-matching, generalized factor-criticality (bicriticality) and $k$-$d$-criticality of graphs",
      "abstract": "Let $G$ be a simple connected graph with vertex set $V(G)$ and edge set $E(G)$. A $k$-matching of a graph $G$ is a function $f:E(G)\\rightarrow \\{0,1,\\ldots, k\\}$ satisfying   $\\sum_{e \\in E_G(v)} f(e) \\leq k$ for every vertex $v \\in V(G)$, where $E_G(v)$ is the set of edges incident with $v$ in $G$. A $k$-matching of a graph $G$ is perfect if   $   \\sum_{e \\in E_G(v) } f(e) = k   $   for any vertex $v \\in V(G)$. The $k$-Berge-Tutte-formula of a graph $G$ is defined as:   \\[   \\defk(G) = \\max_{S \\subseteq V(G)}   \\begin{cases}   k \\cdot i(G - S) - k|S|, & k \\text{ is even;} \\\\[6pt]   \\odd(G - S) + k \\cdot i(G - S) - k|S|, & k \\text{ is odd.}   \\end{cases}   \\]   A $k$-barrier of the graph $G$ is the subset $S \\subseteq V(G)$ that reaches the maximum value in $k$-Berge-Tutte-formula. A connected graph \\( G \\) of odd (even) order is a {generalized factor-critical (generalized bicritical) graph about integer \\( k \\)-matching}, abbreviated as a \\( \\mathrm{GFC}_k (\\mathrm{GBC}_k)\\) graph, if $\\emptyset$ is a unique $k$-barrier. When $k$ is odd, let \\( 1 \\leq d \\leq k \\) and \\( |V(G)| \\equiv d \\pmod{2} \\). If for any \\( v \\in V(G) \\), there exists a \\( k \\)-matching \\( h \\) such that   $\\sum_{e \\in E_G(v)} h(e) = k - d$ {and} $\\sum_{e \\in E_G(u)} h(e) = k$ for any \\( u \\in V(G) - \\{v\\} \\), then \\( G \\) is said to be \\( k \\)-\\( d \\)-critical.   In this paper, we provide sufficient conditions in terms of distance spectral radius to ensure that a graph has a perfect $k$-matching and a graph is \\( k \\)-\\( d \\)-critical, $\\mathrm{GFC}_k$ or $\\mathrm{GBC}_k$, respectively.",
      "authors": [
        "Yang kexin",
        "Wang ligong",
        "Zhang zhenhao"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-04T07:25:23+00:00",
      "link": "https://arxiv.org/pdf/2602.04283v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01398v1",
      "title": "Quadratic points on the Fermat quartic over number fields",
      "abstract": "Let $C$ be a curve defined over a number field $K$. A point $P\\in C(\\overline{\\mathbb{Q}})$ is called $K$-quadratic if $[K(P):K]=2$. Let $K$ be a number field such that the rank of the elliptic curves $E_1:\\,y^2= x^3 + 4x$ and $E_2:\\,y^2= x^3 - 4x$ over $K$ are $0$. Under the above condition, we prove that the set of $K$-quadratic points on the Fermat quartic $F_4\\colon X^4+Y^4=Z^4$ is finite and computable and we provide a procedure to compute this finite set. In particular, we explicitly compute all the $K$-quadratic points if $[K:\\mathbb{Q}]<8$. Moreover, if the degree of $K$ is odd, we prove that all the $K$-quadratic points corresponds just to the $\\mathbb{Q}$-quadratic points",
      "authors": [
        "Enrique González-Jiménez"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "math.AG"
      ],
      "published": "2026-02-01T19:06:34+00:00",
      "link": "https://arxiv.org/pdf/2602.01398v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.12016v2",
      "title": "Structure of ind-pro completions of Noetherian rings",
      "abstract": "We prove some results on the structure of ind-pro completions of Noetherian rings along flags of prime ideals. In particular, we compute the Krull dimension and deduce the criterion on semilocality in the case of essentially of finite type algebras over a field. We also show that ind-pro completion inherits properties of the base ring such as normality, regularity, local equidimensionality, etc.",
      "authors": [
        "Dmitry Badulin"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC",
        "math.AG"
      ],
      "published": "2026-01-17T11:47:19+00:00",
      "link": "https://arxiv.org/pdf/2601.12016v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.01782v1",
      "title": "Normality of monomial ideals in three variables",
      "abstract": "An ideal $I$ in a Noetherian ring is called \\textit{normal} if $I^n$ is integrally closed for all $n \\geq 1$. Zariski proved that in two-dimensional regular local rings, every integrally closed ideal is normal. However, in dimension three and higher, this is no longer true in general, including monomial ideals in polynomial rings.   In this paper, we study the normality of integrally closed monomial ideals in the polynomial ring $k[x,y,z]$ over a field $k$. We prove that every such ideal with at most seven minimal monomial generators is normal, thereby giving a sharp bound for normality in this setting. The proof is based on a detailed case-by-case analysis, combined with valuation-theoretic and combinatorial methods via Newton polyhedra.",
      "authors": [
        "Maki Ataka",
        "Naoyuki Matsuoka"
      ],
      "primary_category": "math.AC",
      "categories": [
        "math.AC"
      ],
      "published": "2026-02-02T08:07:02+00:00",
      "link": "https://arxiv.org/pdf/2602.01782v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04066v1",
      "title": "Exploring the Potential of Large Language Models in Simulink-Stateflow Mutant Generation",
      "abstract": "Mutation analysis is a powerful technique for assessing test-suite adequacy, yet conventional approaches suffer from generating redundant, equivalent, or non-executable mutants. These challenges are particularly amplified in Simulink-Stateflow models due to the hierarchical structure these models have, which integrate continuous dynamics with discrete-event behaviors and are widely deployed in safety-critical Cyber-Physical Systems (CPSs). While prior work has explored machine learning and manually engineered mutation operators, these approaches remain constrained by limited training data and scalability issues. Motivated by recent advances in Large Language Models (LLMs), we investigate their potential to generate high-quality, domain-specific mutants for Simulink-Stateflow models. We develop an automated pipeline that converts Simulink-Stateflow models to structured JSON representations and systematically evaluates different mutation and prompting strategies across eight state-of-the-art LLMs. Through a comprehensive empirical study involving 38,400 LLM-generated mutants across four Simulink-Stateflow models, we demonstrate that LLMs generate mutants up to 13x faster than a manually engineered mutation-based baseline while producing significantly fewer equivalent and duplicate mutants and consistently achieving superior mutant quality. Moreover, our analysis reveals that few-shot prompting combined with low-to-medium temperature values yields optimal results. We provide an open-source prototype tool and release our complete dataset to facilitate reproducibility and advance future research in this domain.",
      "authors": [
        "Pablo Valle",
        "Shaukat Ali",
        "Aitor Arrieta"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-02-03T23:01:47+00:00",
      "link": "https://arxiv.org/pdf/2602.04066v1",
      "tags": [
        "keyword:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22203v1",
      "title": "Beyond Conditional Computation: Retrieval-Augmented Genomic Foundation Models with Gengram",
      "abstract": "Current genomic foundation models (GFMs) rely on extensive neural computation to implicitly approximate conserved biological motifs from single-nucleotide inputs. We propose Gengram, a conditional memory module that introduces an explicit and highly efficient lookup primitive for multi-base motifs via a genomic-specific hashing scheme, establishing genomic \"syntax\". Integrated into the backbone of state-of-the-art GFMs, Gengram achieves substantial gains (up to 14%) across several functional genomics tasks. The module demonstrates robust architectural generalization, while further inspection of Gengram's latent space reveals the emergence of meaningful representations that align closely with fundamental biological knowledge. By establishing structured motif memory as a modeling primitive, Gengram simultaneously boosts empirical performance and mechanistic interpretability, providing a scalable and biology-aligned pathway for the next generation of GFMs. The code is available at https://github.com/zhejianglab/Genos, and the model checkpoint is available at https://huggingface.co/ZhejiangLab/Gengram.",
      "authors": [
        "Huinan Xu",
        "Xuyang Feng",
        "Junhong Chen",
        "Junchen Liu",
        "Kaiwen Deng",
        "Kai Ding",
        "Shengning Long",
        "Jiaxue Shuai",
        "Zhaorong Li",
        "Shiping Liu",
        "Guirong Xue",
        "Zhan Xiao"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "published": "2026-01-29T17:43:10+00:00",
      "link": "https://arxiv.org/pdf/2601.22203v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22688v1",
      "title": "TSLM: Tree-Structured Language Modeling for Divergent Thinking",
      "abstract": "Language models generate reasoning sequentially, preventing them from decoupling irrelevant exploration paths during search. We introduce Tree-Structured Language Modeling (TSLM), which uses special tokens to encode branching structure, enabling models to generate and selectively expand multiple search paths within a single generation process. By training on complete search trees including both successful and failed attempts, TSLM learns to internalize systematic exploration without redundant recomputation of shared prefixes. TSLM achieves robust performance and superior inference efficiency by avoiding the multiple independent forward passes required by external search methods. These results suggest a new paradigm of inference-time scaling for robust reasoning, demonstrating that supervised learning on complete tree-structured traces provides an efficient alternative for developing systematic exploration capabilities in language models.",
      "authors": [
        "Doyoung Kim",
        "Jaehyeok Doo",
        "Minjoon Seo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-30T08:04:59+00:00",
      "link": "https://arxiv.org/pdf/2601.22688v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02382v1",
      "title": "ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs",
      "abstract": "Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.",
      "authors": [
        "Ziyan Zhang",
        "Chao Wang",
        "Zhuo Chen",
        "Chiyi Li",
        "Kai Song"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-02T17:45:43+00:00",
      "link": "https://arxiv.org/pdf/2602.02382v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09381v1",
      "title": "Query Languages for Machine-Learning Models",
      "abstract": "In this paper, I discuss two logics for weighted finite structures: first-order logic with summation (FO(SUM)) and its recursive extension IFP(SUM). These logics originate from foundational work by Grädel, Gurevich, and Meer in the 1990s. In recent joint work with Standke, Steegmans, and Van den Bussche, we have investigated these logics as query languages for machine learning models, specifically neural networks, which are naturally represented as weighted graphs. I present illustrative examples of queries to neural networks that can be expressed in these logics and discuss fundamental results on their expressiveness and computational complexity.",
      "authors": [
        "Martin Grohe"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DB"
      ],
      "published": "2026-01-14T11:15:09+00:00",
      "link": "https://arxiv.org/pdf/2601.09381v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22642v1",
      "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification",
      "abstract": "Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification-guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain. We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification-guided supervised fine-tuning and policy optimization. Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.",
      "authors": [
        "Chuxue Cao",
        "Jinluan Yang",
        "Haoran Li",
        "Kunhao Pan",
        "Zijian Zhao",
        "Zhengyu Chen",
        "Yuchen Tian",
        "Lijun Wu",
        "Conghui He",
        "Sirui Han",
        "Yike Guo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T07:01:25+00:00",
      "link": "https://arxiv.org/pdf/2601.22642v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02143v1",
      "title": "Learning Generative Selection for Best-of-N",
      "abstract": "Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.",
      "authors": [
        "Shubham Toshniwal",
        "Aleksander Ficek",
        "Siddhartha Jain",
        "Wei Du",
        "Vahid Noroozi",
        "Sadegh Mahdavi",
        "Somshubra Majumdar",
        "Igor Gitman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-02T14:21:15+00:00",
      "link": "https://arxiv.org/pdf/2602.02143v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.23085v1",
      "title": "OrLog: Resolving Complex Queries with LLMs and Probabilistic Reasoning",
      "abstract": "Resolving complex information needs that come with multiple constraints should consider enforcing the logical operators encoded in the query (i.e., conjunction, disjunction, negation) on the candidate answer set. Current retrieval systems either ignore these constraints in neural embeddings or approximate them in a generative reasoning process that can be inconsistent and unreliable. Although well-suited to structured reasoning, existing neuro-symbolic approaches remain confined to formal logic or mathematics problems as they often assume unambiguous queries and access to complete evidence, conditions rarely met in information retrieval. To bridge this gap, we introduce OrLog, a neuro-symbolic retrieval framework that decouples predicate-level plausibility estimation from logical reasoning: a large language model (LLM) provides plausibility scores for atomic predicates in one decoding-free forward pass, from which a probabilistic reasoning engine derives the posterior probability of query satisfaction. We evaluate OrLog across multiple backbone LLMs, varying levels of access to external knowledge, and a range of logical constraints, and compare it against base retrievers and LLM-as-reasoner methods. Provided with entity descriptions, OrLog can significantly boost top-rank precision compared to LLM reasoning with larger gains on disjunctive queries. OrLog is also more efficient, cutting mean tokens by $\\sim$90\\% per query-entity pair. These results demonstrate that generation-free predicate plausibility estimation combined with probabilistic reasoning enables constraint-aware retrieval that outperforms monolithic reasoning while using far fewer tokens.",
      "authors": [
        "Mohanna Hoveyda",
        "Jelle Piepenbrock",
        "Arjen P de Vries",
        "Maarten de Rijke",
        "Faegheh Hasibi"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-30T15:31:58+00:00",
      "link": "https://arxiv.org/pdf/2601.23085v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10581v1",
      "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA",
      "abstract": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.",
      "authors": [
        "Kimia Abedini",
        "Farzad Shami",
        "Gianmaria Silvello"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-15T16:54:11+00:00",
      "link": "https://arxiv.org/pdf/2601.10581v1",
      "tags": [
        "keyword:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09446v1",
      "title": "Improving Symbolic Translation of Language Models for Logical Reasoning",
      "abstract": "The use of formal language for deductive logical reasoning aligns well with language models (LMs), where translating natural language (NL) into first-order logic (FOL) and employing an external solver results in a verifiable and therefore reliable reasoning system. However, smaller LMs often struggle with this translation task, frequently producing incorrect symbolic outputs due to formatting and translation errors. Existing approaches typically rely on self-iteration to correct these errors, but such methods depend heavily on the capabilities of the underlying model. To address this, we first categorize common errors and fine-tune smaller LMs using data synthesized by large language models. The evaluation is performed using the defined error categories. We introduce incremental inference, which divides inference into two stages, predicate generation and FOL translation, providing greater control over model behavior and enhancing generation quality as measured by predicate metrics. This decomposition framework also enables the use of a verification module that targets predicate-arity errors to further improve performance. Our study evaluates three families of models across four logical-reasoning datasets. The comprehensive fine-tuning, incremental inference, and verification modules reduce error rates, increase predicate coverage, and improve reasoning performance for smaller LMs, moving us closer to developing reliable and accessible symbolic-reasoning systems.",
      "authors": [
        "Ramya Keerthy Thatikonda",
        "Jiuzhou Han",
        "Wray Buntine",
        "Ehsan Shareghi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-14T12:47:14+00:00",
      "link": "https://arxiv.org/pdf/2601.09446v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.20909v1",
      "title": "Leveraging Generative AI for Enhancing Domain-Driven Software Design",
      "abstract": "Domain-Driven Design (DDD) is a key framework for developing customer-oriented software, focusing on the precise modeling of an application's domain. Traditionally, metamodels that describe these domains are created manually by system designers, forming the basis for iterative software development. This paper explores the partial automation of metamodel generation using generative AI, particularly for producing domain-specific JSON objects. By training a model on real-world DDD project data, we demonstrate that generative AI can produce syntactically correct JSON objects based on simple prompts, offering significant potential for streamlining the design process. To address resource constraints, the AI model was fine-tuned on a consumer-grade GPU using a 4-bit quantized version of Code Llama and Low-Rank Adaptation (LoRA). Despite limited hardware, the model achieved high performance, generating accurate JSON objects with minimal post-processing. This research illustrates the viability of incorporating generative AI into the DDD process, improving efficiency and reducing resource requirements, while also laying the groundwork for further advancements in AI-driven software development.",
      "authors": [
        "Götz-Henrik Wiegand",
        "Filip Stepniak",
        "Patrick Baier"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "published": "2026-01-28T16:25:53+00:00",
      "link": "https://arxiv.org/pdf/2601.20909v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18383v1",
      "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.",
      "authors": [
        "Zhenyuan Guo",
        "Tong Chen",
        "Wenlong Meng",
        "Chen Gong",
        "Xin Yu",
        "Chengkun Wei",
        "Wenzhi Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-26T11:31:40+00:00",
      "link": "https://arxiv.org/pdf/2601.18383v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11683v1",
      "title": "Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory",
      "abstract": "The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \\textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.",
      "authors": [
        "Zhuoyi Shang",
        "Jiasen Li",
        "Pengzhen Chen",
        "Yanwei Liu",
        "Xiaoyan Gu",
        "Weiping Wang"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-01-16T08:56:13+00:00",
      "link": "https://arxiv.org/pdf/2601.11683v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18846v1",
      "title": "LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties",
      "abstract": "Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.",
      "authors": [
        "Urban Skvorc",
        "Niki van Stein",
        "Moritz Seiler",
        "Britta Grimme",
        "Thomas Bäck",
        "Heike Trautmann"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-26T12:34:52+00:00",
      "link": "https://arxiv.org/pdf/2601.18846v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.01237v1",
      "title": "Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models",
      "abstract": "Large language models (LLMs) achieve state-of-the-art accuracy on complex reasoning tasks by generating multiple chain-of-thought (CoT) traces, but using a fixed token budget per query leads to over-computation on easy inputs and under-computation on hard ones. We introduce Predictive Scheduling, a plug-and-play framework that pre-runs lightweight predictors, an MLP on intermediate transformer hidden states or a LoRA-fine-tuned classifier on raw question text, to estimate each query's optimal reasoning length or difficulty before any full generation. Our greedy batch allocator dynamically distributes a fixed total token budget across queries to maximize expected accuracy. On the GSM8K arithmetic benchmark, predictive scheduling yields up to 7.9 percentage points of absolute accuracy gain over uniform budgeting at identical token cost, closing over 50\\% of the gap to an oracle with perfect foresight. A systematic layer-wise study reveals that middle layers (12 - 17) of the transformer carry the richest signals for size estimation. These results demonstrate that pre-run budget prediction enables fine-grained control of the compute-accuracy trade-off, offering a concrete path toward latency-sensitive, cost-efficient LLM deployments.",
      "authors": [
        "Katrina Brown",
        "Aneesh Muppidi",
        "Rana Shahout"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-01T13:58:23+00:00",
      "link": "https://arxiv.org/pdf/2602.01237v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05539v1",
      "title": "Steering Large Reasoning Models towards Concise Reasoning via Flow Matching",
      "abstract": "Large Reasoning Models (LRMs) excel at complex reasoning tasks, but their efficiency is often hampered by overly verbose outputs. Prior steering methods attempt to address this issue by applying a single, global vector to hidden representations -- an approach grounded in the restrictive linear representation hypothesis. In this work, we introduce FlowSteer, a nonlinear steering method that goes beyond uniform linear shifts by learning a complete transformation between the distributions associated with verbose and concise reasoning. This transformation is learned via Flow Matching as a velocity field, enabling precise, input-dependent control over the model's reasoning process. By aligning steered representations with the distribution of concise-reasoning activations, FlowSteer yields more compact reasoning than the linear shifts. Across diverse reasoning benchmarks, FlowSteer demonstrates strong task performance and token efficiency compared to leading inference-time baselines. Our work demonstrates that modeling the full distributional transport with generative techniques offers a more effective and principled foundation for controlling LRMs.",
      "authors": [
        "Yawei Li",
        "Benjamin Bergner",
        "Yinghan Zhao",
        "Vihang Prakash Patil",
        "Bei Chen",
        "Cheng Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-05T10:56:13+00:00",
      "link": "https://arxiv.org/pdf/2602.05539v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07782v1",
      "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning",
      "abstract": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",
      "authors": [
        "Wei Fang",
        "James Glass"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-12T17:58:39+00:00",
      "link": "https://arxiv.org/pdf/2601.07782v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.04892v1",
      "title": "Doc2Spec: Synthesizing Formal Programming Specifications from Natural Language via Grammar Induction",
      "abstract": "Ensuring that API implementations and usage comply with natural language programming rules is critical for software correctness, security, and reliability. Formal verification can provide strong guarantees but requires precise specifications, which are difficult and costly to write manually. To address this challenge, we present Doc2Spec, a multi-agent framework that uses LLMs to automatically induce a specification grammar from natural-language rules and then generates formal specifications guided by the induced grammar. The grammar captures essential domain knowledge, constrains the specification space, and enforces consistent representations, thereby improving the reliability and quality of generated specifications. Evaluated on seven benchmarks across three programming languages, Doc2Spec outperforms a baseline without grammar induction and achieves competitive results against a technique with a manually crafted grammar, demonstrating the effectiveness of automated grammar induction for formalizing natural-language rules.",
      "authors": [
        "Shihao Xia",
        "Mengting He",
        "Haomin Jia",
        "Linhai Song"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-01-30T02:58:27+00:00",
      "link": "https://arxiv.org/pdf/2602.04892v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22010v1",
      "title": "Exploring Diverse Generation Paths via Inference-time Stiefel Activation Steering",
      "abstract": "Language models often default to a narrow set of high-probability outputs, leaving their generation paths homogeneous and prone to mode collapse. Sampling-based strategies inject randomness but still struggle to guarantee diversity across multiple concurrent generation runs. We address this limitation by introducing STARS ($\\textbf{St}$iefel-based $\\textbf{A}$ctivation Steering for Diverse $\\textbf{R}$ea$\\textbf{S}$oning), a training-free, inference-time intervention method that transforms activation steering into an exploration engine. At each token, STARS collects the hidden activations of concurrent generation runs and optimizes multiple additive steering directions jointly on the Stiefel manifold. STARS maximizes the geometric volume of the steered activations, while the Stiefel manifold induces orthogonality of the steering interventions. This formulation explicitly promotes divergent activation vectors of concurrent generation runs, and implicitly promotes divergent generation trajectories. This manifold optimization formulation can be solved using a Riemannian gradient descent algorithm with convergence guarantees, but this algorithm is too time-consuming for real-time inference. To guarantee low latency, we further design a lightweight one-step update with an aggressive, closed-form stepsize. For test case generation and scientific discovery benchmarks, STARS consistently outperforms standard sampling methods, achieving greater diversity without sacrificing qualitative performance.",
      "authors": [
        "Dongxuan Zhu",
        "Ly Tran Ho Khanh",
        "Andy Yat-Ming Cheung",
        "Man-Chung Yue",
        "Viet Anh Nguyen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T17:17:04+00:00",
      "link": "https://arxiv.org/pdf/2601.22010v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.16199v2",
      "title": "PAL*M: Property Attestation for Large Generative Models",
      "abstract": "Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.",
      "authors": [
        "Prach Chantasantitam",
        "Adam Ilyas Caulfield",
        "Vasisht Duddu",
        "Lachlan J. Gunn",
        "N. Asokan"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-22T18:51:13+00:00",
      "link": "https://arxiv.org/pdf/2601.16199v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.15756v1",
      "title": "CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)",
      "abstract": "We study model checking algorithms for infinite families of finite-state labeled transition systems against temporal properties written in CTL*. Such families arise, for example, as models of highly configurable systems or software product lines.   We model families using context-free graph grammars. We then develop a state labeling algorithm that works compositionally on the grammar's production rules with limited information about the context in which the rule is applied. The result is a graph grammar modeling the same family but with extended labels. We leverage this grammar to decide whether all, some, or (in)finitely many members of a family satisfy a given temporal property. We have implemented our algorithms and present early experiments.",
      "authors": [
        "Roberto Pettinau",
        "Christoph Matheja"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-22T08:46:46+00:00",
      "link": "https://arxiv.org/pdf/2601.15756v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.19094v2",
      "title": "FloydNet: A Learning Paradigm for Global Relational Reasoning",
      "abstract": "Developing models capable of complex, multi-step reasoning is a central goal in artificial intelligence. While representing problems as graphs is a powerful approach, Graph Neural Networks (GNNs) are fundamentally constrained by their message-passing mechanism, which imposes a local bottleneck that limits global, holistic reasoning. We argue that dynamic programming (DP), which solves problems by iteratively refining a global state, offers a more powerful and suitable learning paradigm. We introduce FloydNet, a new architecture that embodies this principle. In contrast to local message passing, FloydNet maintains a global, all-pairs relationship tensor and learns a generalized DP operator to progressively refine it. This enables the model to develop a task-specific relational calculus, providing a principled framework for capturing long-range dependencies. Theoretically, we prove that FloydNet achieves 3-WL (2-FWL) expressive power, and its generalized form aligns with the k-FWL hierarchy. FloydNet demonstrates state-of-the-art performance across challenging domains: it achieves near-perfect scores (often >99\\%) on the CLRS-30 algorithmic benchmark, finds exact optimal solutions for the general Traveling Salesman Problem (TSP) at rates significantly exceeding strong heuristics, and empirically matches the 3-WL test on the BREC benchmark. Our results establish this learned, DP-style refinement as a powerful and practical alternative to message passing for high-level graph reasoning.",
      "authors": [
        "Jingcheng Yu",
        "Mingliang Zeng",
        "Qiwei Ye"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27T01:58:40+00:00",
      "link": "https://arxiv.org/pdf/2601.19094v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12842v1",
      "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning",
      "abstract": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",
      "authors": [
        "Qitong Fang",
        "Haotian Li",
        "Xu Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-19T08:55:46+00:00",
      "link": "https://arxiv.org/pdf/2601.12842v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.18091v1",
      "title": "From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models",
      "abstract": "Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\\textbf{LLM-instruct}$) and reasoning-augmented ($\\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.",
      "authors": [
        "Longwei Ding",
        "Anhao Zhao",
        "Fanghua Ye",
        "Ziyang Chen",
        "Xiaoyu Shen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-26T03:01:39+00:00",
      "link": "https://arxiv.org/pdf/2601.18091v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02313v2",
      "title": "Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient",
      "abstract": "Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.",
      "authors": [
        "Changming Li",
        "Kaixing Zhang",
        "Haoyun Xu",
        "Yingdong Shi",
        "Zheng Zhang",
        "Kaitao Song",
        "Kan Ren"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-02T16:43:09+00:00",
      "link": "https://arxiv.org/pdf/2602.02313v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22617v1",
      "title": "EntroCut: Entropy-Guided Adaptive Truncation for Efficient Chain-of-Thought Reasoning in Small-scale Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) excel at complex reasoning tasks through extended chain-of-thought generation, but their reliance on lengthy intermediate steps incurs substantial computational cost. We find that the entropy of the model's output distribution in early reasoning steps reliably distinguishes correct from incorrect reasoning. Motivated by this observation, we propose EntroCut, a training-free method that dynamically truncates reasoning by identifying high-confidence states where reasoning can be safely terminated. To comprehensively evaluate the trade-off between efficiency and accuracy, we introduce the Efficiency-Performance Ratio (EPR), a unified metric that quantifies relative token savings per unit accuracy loss. Experiments on four benchmarks show that EntroCut reduces token usage by up to 40\\% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared with existing training-free methods. These results demonstrate that entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of LRMs.",
      "authors": [
        "Hongxi Yan",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T06:19:16+00:00",
      "link": "https://arxiv.org/pdf/2601.22617v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.23236v1",
      "title": "YuriiFormer: A Suite of Nesterov-Accelerated Transformers",
      "abstract": "We propose a variational framework that interprets transformer layers as iterations of an optimization algorithm acting on token embeddings. In this view, self-attention implements a gradient step of an interaction energy, while MLP layers correspond to gradient updates of a potential energy. Standard GPT-style transformers emerge as vanilla gradient descent on the resulting composite objective, implemented via Lie--Trotter splitting between these two energy functionals. This perspective enables principled architectural design using classical optimization ideas. As a proof of concept, we introduce a Nesterov-style accelerated transformer that preserves the same attention and MLP oracles. The resulting architecture consistently outperforms a nanoGPT baseline on TinyStories and OpenWebText, demonstrating that optimization-theoretic insights can translate into practical gains.",
      "authors": [
        "Aleksandr Zimin",
        "Yury Polyanskiy",
        "Philippe Rigollet"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "published": "2026-01-30T18:06:21+00:00",
      "link": "https://arxiv.org/pdf/2601.23236v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09692v1",
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "abstract": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.",
      "authors": [
        "Tianyi Niu",
        "Justin Chih-Yao Chen",
        "Genta Indra Winata",
        "Shi-Xiong Zhang",
        "Supriyo Chakraborty",
        "Sambit Sahu",
        "Yue Zhang",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-14T18:43:32+00:00",
      "link": "https://arxiv.org/pdf/2601.09692v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13465v3",
      "title": "Graph Neural Networks are Heuristics",
      "abstract": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.",
      "authors": [
        "Yimeng Min",
        "Carla P. Gomes"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-19T23:40:08+00:00",
      "link": "https://arxiv.org/pdf/2601.13465v3",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07525v1",
      "title": "Thinking Before Constraining: A Unified Decoding Framework for Large Language Models",
      "abstract": "Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model's reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10-20 extra tokens.",
      "authors": [
        "Ngoc Trinh Hung Nguyen",
        "Alonso Silva",
        "Laith Zumot",
        "Liubov Tupikina",
        "Armen Aghasaryan",
        "Mehwish Alam"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-12T13:25:28+00:00",
      "link": "https://arxiv.org/pdf/2601.07525v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.00092v1",
      "title": "Interpreting and Controlling Model Behavior via Constitutions for Atomic Concept Edits",
      "abstract": "We introduce a black-box interpretability framework that learns a verifiable constitution: a natural language summary of how changes to a prompt affect a model's specific behavior, such as its alignment, correctness, or adherence to constraints. Our method leverages atomic concept edits (ACEs), which are targeted operations that add, remove, or replace an interpretable concept in the input prompt. By systematically applying ACEs and observing the resulting effects on model behavior across various tasks, our framework learns a causal mapping from edits to predictable outcomes. This learned constitution provides deep, generalizable insights into the model. Empirically, we validate our approach across diverse tasks, including mathematical reasoning and text-to-image alignment, for controlling and understanding model behavior. We found that for text-to-image generation, GPT-Image tends to focus on grammatical adherence, while Imagen 4 prioritizes atmospheric coherence. In mathematical reasoning, distractor variables confuse GPT-5 but leave Gemini 2.5 models and o4-mini largely unaffected. Moreover, our results show that the learned constitutions are highly effective for controlling model behavior, achieving an average of 1.86 times boost in success rate over methods that do not use constitutions.",
      "authors": [
        "Neha Kalibhat",
        "Zi Wang",
        "Prasoon Bajpai",
        "Drew Proud",
        "Wenjun Zeng",
        "Been Kim",
        "Mani Malek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-23T16:56:33+00:00",
      "link": "https://arxiv.org/pdf/2602.00092v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09093v1",
      "title": "Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling",
      "abstract": "Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process has relied on similarity-based or confidence-based pruning, but these signals do not reliably indicate trace quality. To address these limitations, we propose STEP: Step-level Trace Evaluation and Pruning, a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation. We train a lightweight step scorer to estimate trace quality, and design a GPU memory-aware pruning strategy that triggers pruning as the GPU memory is saturated by KV cache to reduce end-to-end latency. Experiments across challenging reasoning benchmarks demonstrate that STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy. Our code is released at: https://github.com/Supercomputing-System-AI-Lab/STEP",
      "authors": [
        "Zhixiang Liang",
        "Beichen Huang",
        "Zheng Wang",
        "Minjia Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-14T02:54:55+00:00",
      "link": "https://arxiv.org/pdf/2601.09093v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.21096v1",
      "title": "Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve",
      "abstract": "Modern compilers rely on hand-crafted heuristics to guide optimization passes. These human-designed rules often struggle to adapt to the complexity of modern software and hardware and lead to high maintenance burden. To address this challenge, we present Magellan, an agentic framework that evolves the compiler pass itself by synthesizing executable C++ decision logic. Magellan couples an LLM coding agent with evolutionary search and autotuning in a closed loop of generation, evaluation on user-provided macro-benchmarks, and refinement, producing compact heuristics that integrate directly into existing compilers. Across several production optimization tasks, Magellan discovers policies that match or surpass expert baselines. In LLVM function inlining, Magellan synthesizes new heuristics that outperform decades of manual engineering for both binary-size reduction and end-to-end performance. In register allocation, it learns a concise priority rule for live-range processing that matches intricate human-designed policies on a large-scale workload. We also report preliminary results on XLA problems, demonstrating portability beyond LLVM with reduced engineering effort.",
      "authors": [
        "Hongzheng Chen",
        "Alexander Novikov",
        "Ngân Vũ",
        "Hanna Alam",
        "Zhiru Zhang",
        "Aiden Grossman",
        "Mircea Trofin",
        "Amir Yazdanbakhsh"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "published": "2026-01-28T22:34:56+00:00",
      "link": "https://arxiv.org/pdf/2601.21096v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.13922v1",
      "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery",
      "abstract": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.",
      "authors": [
        "Adrian Cosma",
        "Oleg Szehr",
        "David Kletz",
        "Alessandro Antonucci",
        "Olivier Pelletier"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-20T12:51:03+00:00",
      "link": "https://arxiv.org/pdf/2601.13922v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07180v1",
      "title": "Structured Reasoning for Large Language Models",
      "abstract": "Large language models (LLMs) achieve strong performance by generating long chains of thought, but longer traces always introduce redundant or ineffective reasoning steps. One typical behavior is that they often perform unnecessary verification and revisions even if they have reached the correct answers. This limitation stems from the unstructured nature of reasoning trajectories and the lack of targeted supervision for critical reasoning abilities. To address this, we propose Structured Reasoning (SCR), a framework that decouples reasoning trajectories into explicit, evaluable, and trainable components. We mainly implement SCR using a Generate-Verify-Revise paradigm. Specifically, we construct structured training data and apply Dynamic Termination Supervision to guide the model in deciding when to terminate reasoning. To avoid interference between learning signals for different reasoning abilities, we adopt a progressive two-stage reinforcement learning strategy: the first stage targets initial generation and self-verification, and the second stage focuses on revision. Extensive experiments on three backbone models show that SCR substantially improves reasoning efficiency and self-verification. Besides, compared with existing reasoning paradigms, it reduces output token length by up to 50%.",
      "authors": [
        "Jinyi Han",
        "Zixiang Di",
        "Zishang Jiang",
        "Ying Liao",
        "Jiaqing Liang",
        "Yongqi Wang",
        "Yanghua Xiao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-12T04:04:01+00:00",
      "link": "https://arxiv.org/pdf/2601.07180v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01070v1",
      "title": "What If We Allocate Test-Time Compute Adaptively?",
      "abstract": "Test-time compute scaling allocates inference computation uniformly, uses fixed sampling strategies, and applies verification only for reranking. In contrast, we propose a verifier-guided adaptive framework treating reasoning as iterative trajectory generation and selection. For each problem, the agent runs multiple inference iterations. In each iteration, it optionally produces a high-level plan, selects a set of reasoning tools and a compute strategy together with an exploration parameter, and then generates a candidate reasoning trajectory. A process reward model (PRM) serves as a unified control signal: within each iteration, step-level PRM scores are aggregated to guide pruning and expansion during generation, and across iterations, aggregated trajectory rewards are used to select the final response. Across datasets, our dynamic, PRM-guided approach consistently outperforms direct test-time scaling, yielding large gains on MATH-500 and several-fold improvements on harder benchmarks such as AIME24 and AMO-Bench. We characterize efficiency using theoretical FLOPs and a compute intensity metric penalizing wasted generation and tool overhead, demonstrating that verification-guided allocation concentrates computation on high-utility reasoning paths.",
      "authors": [
        "Ahsan Bilal",
        "Ahmed Mohsin",
        "Muhammad Umer",
        "Ali Subhan",
        "Hassan Rizwan",
        "Ayesha Mohsin",
        "Dean Hougen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-01T07:30:22+00:00",
      "link": "https://arxiv.org/pdf/2602.01070v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.15127v2",
      "title": "Predictor-Free and Hardware-Aware Federated Neural Architecture Search via Pareto-Guided Supernet Training",
      "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS",
      "authors": [
        "Bostan Khan",
        "Masoud Daneshtalab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.DC"
      ],
      "published": "2026-01-21T16:03:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15127v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05048v1",
      "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation",
      "abstract": "Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.",
      "authors": [
        "Zeyu Fang",
        "Tian Lan",
        "Mahdi Imani"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-02-04T20:58:53+00:00",
      "link": "https://arxiv.org/pdf/2602.05048v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.09473v2",
      "title": "SimMerge: Learning to Select Merge Operators from Similarity Signals",
      "abstract": "Model merging combines multiple models into a single model with aggregated capabilities, making it a powerful tool for large language model (LLM) development. However, scaling model merging is challenging: performance depends on the choice of merge operator, model subset, and merge order, often requiring expensive merge-and-evaluate searches. In this work, we introduce SimMerge, a predictive merge-selection method that identifies high-performing merges using inexpensive, task-agnostic similarity signals between models. Given a small set of unlabeled probes, SimMerge extracts functional and structural features to predict the performance of candidate two-way merges, enabling merge operator, order and model subset selection without iterative evaluation. We show that SimMerge consistently outperforms the best fixed merge operator across 7B-parameter LLMs and generalizes to multi-way merges and 111B-parameter LLMs without retraining. We further introduce a bandit variant that supports adding new tasks and operators online. Our results suggest that learning how to merge enables scalable model composition when checkpoint catalogs are large and evaluation budgets are limited.",
      "authors": [
        "Oliver Bolton",
        "Aakanksha",
        "Arash Ahmadian",
        "Sara Hooker",
        "Marzieh Fadaee",
        "Beyza Ermis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-14T13:30:00+00:00",
      "link": "https://arxiv.org/pdf/2601.09473v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.14971v1",
      "title": "Fine-Grained Traceability for Transparent ML Pipelines",
      "abstract": "Modern machine learning systems are increasingly realised as multistage pipelines, yet existing transparency mechanisms typically operate at a model level: they describe what a system is and why it behaves as it does, but not how individual data samples are operationally recorded, tracked, and verified as they traverse the pipeline. This absence of verifiable, sample-level traceability leaves practitioners and users unable to determine whether a specific sample was used, when it was processed, or whether the corresponding records remain intact over time. We introduce FG-Trac, a model-agnostic framework that establishes verifiable, fine-grained sample-level traceability throughout machine learning pipelines. FG-Trac defines an explicit mechanism for capturing and verifying sample lifecycle events across preprocessing and training, computes contribution scores explicitly grounded in training checkpoints, and anchors these traces to tamper-evident cryptographic commitments. The framework integrates without modifying model architectures or training objectives, reconstructing complete and auditable data-usage histories with practical computational overhead. Experiments on a canonical convolutional neural network and a multimodal graph learning pipeline demonstrate that FG-Trac preserves predictive performance while enabling machine learning systems to furnish verifiable evidence of how individual samples were used and propagated during model execution.",
      "authors": [
        "Liping Chen",
        "Mujie Liu",
        "Haytham Fayek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21T13:21:30+00:00",
      "link": "https://arxiv.org/pdf/2601.14971v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05930v1",
      "title": "Can We Predict Before Executing Machine Learning Agents?",
      "abstract": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.",
      "authors": [
        "Jingsheng Zheng",
        "Jintian Zhang",
        "Yujie Luo",
        "Yuren Mao",
        "Yunjun Gao",
        "Lun Du",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-09T16:44:17+00:00",
      "link": "https://arxiv.org/pdf/2601.05930v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22977v1",
      "title": "Quantifying Model Uniqueness in Heterogeneous AI Ecosystems",
      "abstract": "As AI systems evolve from isolated predictors into complex, heterogeneous ecosystems of foundation models and specialized adapters, distinguishing genuine behavioral novelty from functional redundancy becomes a critical governance challenge. Here, we introduce a statistical framework for auditing model uniqueness based on In-Silico Quasi-Experimental Design (ISQED). By enforcing matched interventions across models, we isolate intrinsic model identity and quantify uniqueness as the Peer-Inexpressible Residual (PIER), i.e. the component of a target's behavior strictly irreducible to any stochastic convex combination of its peers, with vanishing PIER characterizing when such a routing-based substitution becomes possible. We establish the theoretical foundations of ecosystem auditing through three key contributions. First, we prove a fundamental limitation of observational logs: uniqueness is mathematically non-identifiable without intervention control. Second, we derive a scaling law for active auditing, showing that our adaptive query protocol achieves minimax-optimal sample efficiency ($dσ^2γ^{-2}\\log(Nd/δ)$). Third, we demonstrate that cooperative game-theoretic methods, such as Shapley values, fundamentally fail to detect redundancy. We implement this framework via the DISCO (Design-Integrated Synthetic Control) estimator and deploy it across diverse ecosystems, including computer vision models (ResNet/ConvNeXt/ViT), large language models (BERT/RoBERTa), and city-scale traffic forecasters. These results move trustworthy AI beyond explaining single models: they establish a principled, intervention-based science of auditing and governing heterogeneous model ecosystems.",
      "authors": [
        "Lei You"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T13:41:53+00:00",
      "link": "https://arxiv.org/pdf/2601.22977v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05307v1",
      "title": "MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning",
      "abstract": "Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.",
      "authors": [
        "Haojin Wang",
        "Yike Wang",
        "Shangbin Feng",
        "Hannaneh Hajishirzi",
        "Yulia Tsvetkov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-05T04:58:16+00:00",
      "link": "https://arxiv.org/pdf/2602.05307v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18771v1",
      "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Zixuan Yan",
        "Yanxin Shen",
        "Wenjie Xu",
        "Yuefeng Huang",
        "Xinyi Wang",
        "Jiannan Cao",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-26T18:42:33+00:00",
      "link": "https://arxiv.org/pdf/2601.18771v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.10995v1",
      "title": "GP-DHT: A Dual-Head Transformer with Contras-tive Learning for Predicting Gene Regulatory Rela-tionships across Species from Single-Cell Data",
      "abstract": "Gene regulatory networks (GRNs) are essential for understanding cell fate decisions and disease mechanisms, yet cross-species GRN inference from single-cell RNA-seq data remains challenging due to noise, sparsity, and cross-species distribution shifts. We propose GP-DHT (GenePair DualHeadTransformer), a cross-species single-cell GRN inference framework that models genes and cells in a heterogeneous graph with multi-level expression relations and learns structured regulatory representations via multi-relational graph attention. A dual-head Transformer further captures local gene pair regulatory dependencies and global cross-cell interaction patterns. To improve robustness under sparse and cross-species settings, GP-DHT introduces gene pair level supervised contrastive learning. Experiments on seven BEELINE benchmark datasets show consistent gains over representative baselines, improving AUROC and AUPRC by approximately 5 to 7 percent on most datasets. GP-DHT also recovers known regulatory modules and helps distinguish conserved from species-specific regulations.",
      "authors": [
        "Shuai Yan",
        "Qingzhi Yu",
        "Wengfeng Dai",
        "Xiang Cheng"
      ],
      "primary_category": "q-bio.GN",
      "categories": [
        "q-bio.GN"
      ],
      "published": "2026-01-16T05:04:57+00:00",
      "link": "https://arxiv.org/pdf/2601.10995v1",
      "tags": [
        "keyword:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05182v1",
      "title": "The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems",
      "abstract": "Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.",
      "authors": [
        "Shangbin Feng",
        "Kishan Panaganti",
        "Yulia Tsvetkov",
        "Wenhao Yu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-05T01:20:32+00:00",
      "link": "https://arxiv.org/pdf/2602.05182v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.21882v1",
      "title": "How Expressive Are Graph Neural Networks in the Presence of Node Identifiers?",
      "abstract": "Graph neural networks (GNNs) are a widely used class of machine learning models for graph-structured data, based on local aggregation over neighbors. GNNs have close connections to logic. In particular, their expressive power is linked to that of modal logics and bounded-variable logics with counting. In many practical scenarios, graphs processed by GNNs have node features that act as unique identifiers. In this work, we study how such identifiers affect the expressive power of GNNs. We initiate a study of the key-invariant expressive power of GNNs, inspired by the notion of order-invariant definability in finite model theory: which node queries that depend only on the underlying graph structure can GNNs express on graphs with unique node identifiers? We provide answers for various classes of GNNs with local max- or sum-aggregation.",
      "authors": [
        "Arie Soeteman",
        "Michael Benedikt",
        "Martin Grohe",
        "Balder ten Cate"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.LG"
      ],
      "published": "2026-01-29T15:46:35+00:00",
      "link": "https://arxiv.org/pdf/2601.21882v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01626v1",
      "title": "Toward Enhancing Representation Learning in Federated Multi-Task Settings",
      "abstract": "Federated multi-task learning (FMTL) seeks to collaboratively train customized models for users with different tasks while preserving data privacy. Most existing approaches assume model congruity (i.e., the use of fully or partially homogeneous models) across users, which limits their applicability in realistic settings. To overcome this limitation, we aim to learn a shared representation space across tasks rather than shared model parameters. To this end, we propose Muscle loss, a novel contrastive learning objective that simultaneously aligns representations from all participating models. Unlike existing multi-view or multi-model contrastive methods, which typically align models pairwise, Muscle loss can effectively capture dependencies across tasks because its minimization is equivalent to the maximization of mutual information among all the models' representations. Building on this principle, we develop FedMuscle, a practical and communication-efficient FMTL algorithm that naturally handles both model and task heterogeneity. Experiments on diverse image and language tasks demonstrate that FedMuscle consistently outperforms state-of-the-art baselines, delivering substantial improvements and robust performance across heterogeneous settings.",
      "authors": [
        "Mehdi Setayesh",
        "Mahdi Beitollahi",
        "Yasser H. Khalil",
        "Hongliang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T04:39:36+00:00",
      "link": "https://arxiv.org/pdf/2602.01626v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18204v1",
      "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning",
      "abstract": "Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.",
      "authors": [
        "Juexiang Ye",
        "Xue Li",
        "Xinyu Yang",
        "Chengkai Huang",
        "Lanshun Nie",
        "Lina Yao",
        "Dechen Zhan"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-26T06:39:27+00:00",
      "link": "https://arxiv.org/pdf/2601.18204v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07794v1",
      "title": "Kinship Data Benchmark for Multi-hop Reasoning",
      "abstract": "Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.",
      "authors": [
        "Tianda Sun",
        "Dimitar Kazakov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-12T18:07:41+00:00",
      "link": "https://arxiv.org/pdf/2601.07794v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03006v1",
      "title": "Distilling LLM Reasoning into Graph of Concept Predictors",
      "abstract": "Deploying Large Language Models (LLMs) for discriminative workloads is often limited by inference latency, compute, and API costs at scale. Active distillation reduces these costs by querying an LLM oracle to train compact discriminative students, but most pipelines distill only final labels, discarding intermediate reasoning signals and offering limited diagnostics of what reasoning is missing and where errors arise. We propose Graph of Concept Predictors (GCP), a reasoning-aware active distillation framework that externalizes the teacher's decision process as a directed acyclic graph and mirrors it with modular concept predictors in the student. GCP enhances sample efficiency through a graph-aware acquisition strategy that targets uncertainty and disagreement at critical reasoning nodes. Additionally, it improves training stability and efficiency by performing targeted sub-module retraining, which attributes downstream loss to specific concept predictors and updates only the most influential modules. Experiments on eight NLP classification benchmarks demonstrate that GCP enhances performance under limited annotation budgets while yielding more interpretable and controllable training dynamics. Code is available at: https://github.com/Ziyang-Yu/GCP.",
      "authors": [
        "Ziyang Yu",
        "Liang Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-03T02:19:14+00:00",
      "link": "https://arxiv.org/pdf/2602.03006v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22563v2",
      "title": "EUGens: Efficient, Unified, and General Dense Layers",
      "abstract": "Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \\textbf{E}fficient, \\textbf{U}nified and \\textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \\textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \\textbf{27}\\%) and memory efficiency (up to \\textbf{30}\\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios.",
      "authors": [
        "Sang Min Kim",
        "Byeongchan Kim",
        "Arijit Sehanobish",
        "Somnath Basu Roy Chowdhury",
        "Rahul Kidambi",
        "Dongseok Shim",
        "Avinava Dubey",
        "Snigdha Chaturvedi",
        "Min-hwan Oh",
        "Krzysztof Choromanski"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T05:01:03+00:00",
      "link": "https://arxiv.org/pdf/2601.22563v2",
      "tags": [
        "keyword:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.06019v1",
      "title": "Multi-Token Prediction via Self-Distillation",
      "abstract": "Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\\times$ faster on average at $<5\\%$ drop in accuracy relative to single token decoding performance.",
      "authors": [
        "John Kirchenbauer",
        "Abhimanyu Hans",
        "Brian Bartoldson",
        "Micah Goldblum",
        "Ashwinee Panda",
        "Tom Goldstein"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-05T18:54:48+00:00",
      "link": "https://arxiv.org/pdf/2602.06019v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.11340v1",
      "title": "Neural Chain-of-Thought Search: Searching the Optimal Reasoning Path to Enhance Large Language Models",
      "abstract": "Chain-of-Thought reasoning has significantly enhanced the problem-solving capabilities of Large Language Models. Unfortunately, current models generate reasoning steps sequentially without foresight, often becoming trapped in suboptimal reasoning paths with redundant steps. In contrast, we introduce Neural Chain-of-Thought Search (NCoTS), a framework that reformulates reasoning as a dynamic search for the optimal thinking strategy. By quantitatively characterizing the solution space, we reveal the existence of sparse superior reasoning paths that are simultaneously more accurate and concise than standard outputs. Our method actively navigates towards these paths by evaluating candidate reasoning operators using a dual-factor heuristic that optimizes for both correctness and computational cost. Consequently, NCoTS achieves a Pareto improvement across diverse reasoning benchmarks, boosting accuracy by over 3.5% while reducing generation length by over 22%. Our code and data are available at https://github.com/MilkThink-Lab/Neural-CoT-Search.",
      "authors": [
        "Guoming Ling",
        "Zhongzhan Huang",
        "Yupei Lin",
        "Junxin Li",
        "Shanshan Zhong",
        "Hefeng Wu",
        "Liang Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-16T14:38:18+00:00",
      "link": "https://arxiv.org/pdf/2601.11340v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.05353v1",
      "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction",
      "abstract": "Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black boxes to users. We address this by introducing Agentic Workflow Reconstruction (AWR), a new task aiming to synthesize an explicit, interpretable stand-in workflow that approximates a black-box system using only input--output access. We propose AgentXRay, a search-based framework that formulates AWR as a combinatorial optimization problem over discrete agent roles and tool invocations in a chain-structured workflow space. Unlike model distillation, AgentXRay produces editable white-box workflows that match target outputs under an observable, output-based proxy metric, without accessing model parameters. To navigate the vast search space, AgentXRay employs Monte Carlo Tree Search enhanced by a scoring-based Red-Black Pruning mechanism, which dynamically integrates proxy quality with search depth. Experiments across diverse domains demonstrate that AgentXRay achieves higher proxy similarity and reduces token consumption compared to unpruned search, enabling deeper workflow exploration under fixed iteration budgets.",
      "authors": [
        "Ruijie Shi",
        "Houbin Zhang",
        "Yuecheng Han",
        "Yuheng Wang",
        "Jingru Fan",
        "Runde Yang",
        "Yufan Dang",
        "Huatao Li",
        "Dewen Liu",
        "Yuan Cheng",
        "Chen Qian"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-05T06:24:15+00:00",
      "link": "https://arxiv.org/pdf/2602.05353v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18949v1",
      "title": "Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions",
      "abstract": "Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.",
      "authors": [
        "Cole Granger",
        "Dipin Khati",
        "Daniel Rodriguez-Cardenas",
        "Denys Poshyvanyk"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-26T20:41:16+00:00",
      "link": "https://arxiv.org/pdf/2601.18949v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.16530v1",
      "title": "Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification",
      "abstract": "Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.",
      "authors": [
        "Gaurav Maheshwari",
        "Kevin El Haddad"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-23T08:04:09+00:00",
      "link": "https://arxiv.org/pdf/2601.16530v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.08517v1",
      "title": "Closed-Loop LLM Discovery of Non-Standard Channel Priors in Vision Models",
      "abstract": "Channel configuration search the optimization of layer specifications such as layer widths in deep neural networks presents a complex combinatorial challenge constrained by tensor shape compatibility and computational budgets. We posit that Large Language Models (LLMs) offer a transformative approach to Neural Architecture Search (NAS), capable of reasoning about architectural code structure in ways that traditional heuristics cannot. In this paper, we investigate the application of an LLM-driven NAS framework to the problem of channel configuration. We formulate the search as a sequence of conditional code generation tasks, where an LLM refines architectural specifications based on performance telemetry. Crucially, we address the data scarcity problem by generating a vast corpus of valid, shape-consistent architectures via Abstract Syntax Tree (AST) mutations. While these mutated networks are not necessarily high-performing, they provide the critical volume of structural data required for the LLM to learn the latent relationship between channel configurations and model performance. This allows the LLM to internalize complex design patterns and apply them to optimize feature extraction strategies. Experimental results on CIFAR-100 validate the efficacy of this approach, demonstrating that the model yields statistically significant improvements in accuracy. Our analysis confirms that the LLM successfully acquires domain-specific architectural priors, distinguishing this method from random search and highlighting the immense potential of language-driven design in deep learning.",
      "authors": [
        "Tolgay Atinc Uzun",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-13T13:00:30+00:00",
      "link": "https://arxiv.org/pdf/2601.08517v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01171v1",
      "title": "ASP-Bench: From Natural Language to Logic Programs",
      "abstract": "Automating the translation of natural-language specifications into logic programs is a challenging task that affects neurosymbolic engineering. We present ASP-Bench, a benchmark comprising 128 natural language problem instances, 64 base problems with easy and hard variants. It evaluates systems that translate natural-language problems into Answer Set Programs (ASPs), a prominent form of logic programming. It provides systematic coverage of ASP features, including choice rules, aggregates, and optimization. Each problem includes reference validators that check whether solutions satisfy the problem specification.   We characterize problems along seven largely independent reasoning aspects (optimization, temporal reasoning, default logic, resource allocation, recursion, spatial reasoning, and quantitative complexity), providing a multidimensional view of modeling difficulty.   We test the benchmark using an agentic approach based on the ReAct (Reason and Act) framework, which achieves full saturation, demonstrating that feedback-driven iterative refinement with solver feedback provides a reliable and robust approach for modeling natural language in ASP. Our analysis across multiple agent runs enables us to gain insights into what determines a problem's modeling hardness.",
      "authors": [
        "Stefan Szeider"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "published": "2026-02-01T11:48:36+00:00",
      "link": "https://arxiv.org/pdf/2602.01171v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01711v1",
      "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
      "abstract": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
      "authors": [
        "Wei Chen",
        "Yanbin Fang",
        "Shuran Fu",
        "Fasheng Xu",
        "Xuan Wei"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-02T06:37:11+00:00",
      "link": "https://arxiv.org/pdf/2602.01711v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13387v1",
      "title": "Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning",
      "abstract": "Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.",
      "authors": [
        "Zhenjiang Mao",
        "Anirudhh Venkat",
        "Artem Bisliouk",
        "Akshat Kothiyal",
        "Sindhura Kumbakonam Subramanian",
        "Saithej Singhu",
        "Ivan Ruchkin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-19T20:48:06+00:00",
      "link": "https://arxiv.org/pdf/2601.13387v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03695v1",
      "title": "Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems",
      "abstract": "While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to error accumulation and instability in long-context, multi-stage interactions within internal agent histories.   In this work, we propose \\textbf{Agent Primitives}, a set of reusable latent building blocks for LLM-based MAS. Inspired by neural network design, where complex models are built from reusable components, we observe that many existing MAS architectures can be decomposed into a small number of recurring internal computation patterns. Based on this observation, we instantiate three primitives: Review, Voting and Selection, and Planning and Execution. All primitives communicate internally via key-value (KV) cache, which improves both robustness and efficiency by mitigating information degradation across multi-stage interactions. To enable automatic system construction, an Organizer agent selects and composes primitives for each query, guided by a lightweight knowledge pool of previously successful configurations, forming a primitive-based MAS.   Experiments show that primitives-based MAS improve average accuracy by 12.0-16.5\\% over single-agent baselines, reduce token usage and inference latency by approximately 3$\\times$-4$\\times$ compared to text-based MAS, while incurring only 1.3$\\times$-1.6$\\times$ overhead relative to single-agent inference and providing more stable performance across model backbones.",
      "authors": [
        "Haibo Jin",
        "Kuang Peng",
        "Ye Yu",
        "Xiaopeng Yuan",
        "Haohan Wang"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-03T16:17:53+00:00",
      "link": "https://arxiv.org/pdf/2602.03695v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22997v1",
      "title": "TriCEGAR: A Trace-Driven Abstraction Mechanism for Agentic AI",
      "abstract": "Agentic AI systems act through tools and evolve their behavior over long, stochastic interaction traces. This setting complicates assurance, because behavior depends on nondeterministic environments and probabilistic model outputs. Prior work introduced runtime verification for agentic AI via Dynamic Probabilistic Assurance (DPA), learning an MDP online and model checking quantitative properties. A key limitation is that developers must manually define the state abstraction, which couples verification to application-specific heuristics and increases adoption friction. This paper proposes TriCEGAR, a trace-driven abstraction mechanism that automates state construction from execution logs and supports online construction of an agent behavioral MDP. TriCEGAR represents abstractions as predicate trees learned from traces and refined using counterexamples. We describe a framework-native implementation that (i) captures typed agent lifecycle events, (ii) builds abstractions from traces, (iii) constructs an MDP, and (iv) performs probabilistic model checking to compute bounds such as Pmax(success) and Pmin(failure). We also show how run likelihoods enable anomaly detection as a guardrailing signal.",
      "authors": [
        "Roham Koohestani",
        "Ateş Görpelioğlu",
        "Egor Klimov",
        "Burcu Kulahcioglu Ozkan",
        "Maliheh Izadi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-01-30T14:01:47+00:00",
      "link": "https://arxiv.org/pdf/2601.22997v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.09281v1",
      "title": "STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.",
      "authors": [
        "Jingjing Zhou",
        "Gaoxiang Cong",
        "Li Su",
        "Liang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-14T08:35:23+00:00",
      "link": "https://arxiv.org/pdf/2601.09281v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.11124v1",
      "title": "Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings",
      "abstract": "Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.",
      "authors": [
        "Xiaoyu Liang",
        "Yuchen Peng",
        "Jiale Luo",
        "Wenhao Wang",
        "Haoji Hu",
        "Xincheng Zhou"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-16T09:35:29+00:00",
      "link": "https://arxiv.org/pdf/2601.11124v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.14446v1",
      "title": "Diffusion Large Language Models for Black-Box Optimization",
      "abstract": "Offline black-box optimization (BBO) aims to find optimal designs based solely on an offline dataset of designs and their labels. Such scenarios frequently arise in domains like DNA sequence design and robotics, where only a few labeled data points are available. Traditional methods typically rely on task-specific proxy or generative models, overlooking the in-context learning capabilities of pre-trained large language models (LLMs). Recent efforts have adapted autoregressive LLMs to BBO by framing task descriptions and offline datasets as natural language prompts, enabling direct design generation. However, these designs often contain bidirectional dependencies, which left-to-right models struggle to capture. In this paper, we explore diffusion LLMs for BBO, leveraging their bidirectional modeling and iterative refinement capabilities. This motivates our in-context denoising module: we condition the diffusion LLM on the task description and the offline dataset, both formatted in natural language, and prompt it to denoise masked designs into improved candidates. To guide the generation toward high-performing designs, we introduce masked diffusion tree search, which casts the denoising process as a step-wise Monte Carlo Tree Search that dynamically balances exploration and exploitation. Each node represents a partially masked design, each denoising step is an action, and candidates are evaluated via expected improvement under a Gaussian Process trained on the offline dataset. Our method, dLLM, achieves state-of-the-art results in few-shot settings on design-bench.",
      "authors": [
        "Ye Yuan",
        "Can",
        "Chen",
        "Zipeng Sun",
        "Dinghuai Zhang",
        "Christopher Pal",
        "Xue Liu"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "published": "2026-01-20T19:59:29+00:00",
      "link": "https://arxiv.org/pdf/2601.14446v1",
      "tags": [
        "keyword:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.06352v1",
      "title": "CARD: Cluster-level Adaptation with Reward-guided Decoding for Personalized Text Generation",
      "abstract": "Adapting large language models to individual users remains challenging due to the tension between fine-grained personalization and scalable deployment. We present CARD, a hierarchical framework that achieves effective personalization through progressive refinement. CARD first clusters users according to shared stylistic patterns and learns cluster-specific LoRA adapters, enabling robust generalization and strong low-resource performance. To capture individual differences within each cluster, we propose an implicit preference learning mechanism that contrasts user-authored text with cluster-level generations, allowing the model to infer user-specific style preferences without manual annotation. At inference time, CARD injects personalization exclusively at decoding via lightweight user preference vectors and low-rank logit corrections, while keeping the base model frozen. Experiments on the LaMP and LongLaMP benchmarks show that CARD achieves competitive or superior generation quality compared to state-of-the-art baselines, while significantly improving efficiency and scalability for practical personalized text generation.",
      "authors": [
        "Yutong Song",
        "Jiang Wu",
        "Weijia Zhang",
        "Chengze Shen",
        "Shaofan Yuan",
        "Weitao Lu",
        "Jian Wang",
        "Amir Rahmani",
        "Nikil Dutt",
        "Yu Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-09T23:16:39+00:00",
      "link": "https://arxiv.org/pdf/2601.06352v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09195v1",
      "title": "ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection",
      "abstract": "Supervised fine-tuning (SFT) is a fundamental post-training strategy to align Large Language Models (LLMs) with human intent. However, traditional SFT often ignores the one-to-many nature of language by forcing alignment with a single reference answer, leading to the model overfitting to non-core expressions. Although our empirical analysis suggests that introducing multiple reference answers can mitigate this issue, the prohibitive data and computational costs necessitate a strategic shift: prioritizing the mitigation of single-reference overfitting over the costly pursuit of answer diversity. To achieve this, we reveal the intrinsic connection between token probability and semantic importance: high-probability tokens carry the core logical framework, while low-probability tokens are mostly replaceable expressions. Based on this insight, we propose ProFit, which selectively masks low-probability tokens to prevent surface-level overfitting. Extensive experiments confirm that ProFit consistently outperforms traditional SFT baselines on general reasoning and mathematical benchmarks.",
      "authors": [
        "Tao Liu",
        "Taiqiang Wu",
        "Runming Yang",
        "Shaoning Sun",
        "Junjie Wang",
        "Yujiu Yang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-14T05:50:40+00:00",
      "link": "https://arxiv.org/pdf/2601.09195v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07477v2",
      "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge",
      "abstract": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose JudgeFlow, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces particularly failed runs and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate JudgeFlow on mathematical reasoning and code generation benchmarks, where JudgeFlow achieves superior performance and efficiency compared to existing methods.",
      "authors": [
        "Zihan Ma",
        "Zhikai Zhao",
        "Chuanbo Hua",
        "Federico Berto",
        "Jinkyoo Park"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-12T12:30:14+00:00",
      "link": "https://arxiv.org/pdf/2601.07477v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02834v2",
      "title": "Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers",
      "abstract": "Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\\mathsf{TC}^0$-complete and cannot solve graph connectivity in constant depth, implying $Ω(k)$ layers are necessary for $k$-hop reasoning regardless of model size or training data. We introduce RASA (Relation-Aware Sparse Attention), a minimal architectural modification that provides structural inductive bias for relational reasoning. RASA adds: (1) sparse adjacency masking that restricts attention to graph-connected positions, reducing the attention pattern search space from $O(2^{n^2})$ to $O(2^m)$ for graphs with $m$ edges; and (2) learnable edge-type biases that encode relation-specific attention preferences. While RASA does not circumvent asymptotic depth requirements, the exponential reduction in attention pattern space provides stronger inductive bias for learning graph-structured functions. Empirically, on the MetaQA knowledge graph QA benchmark, RASA achieves 97.7% accuracy on 3-hop questions, outperforming EmbedKGQA (94.8%) by 2.9 percentage points. Notably, RASA's advantage grows with reasoning depth, validating that structural inductive bias is most beneficial for complex multi-hop queries. Our results demonstrate that minimal architectural modifications, grounded in complexity-theoretic analysis, can substantially improve multi-hop reasoning.",
      "authors": [
        "Jonas Petersen",
        "Camilla Mazzoleni",
        "Riccardo Maggioni"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T21:35:39+00:00",
      "link": "https://arxiv.org/pdf/2602.02834v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02010v1",
      "title": "NEAT: Neuron-Based Early Exit for Large Reasoning Models",
      "abstract": "Large Reasoning Models (LRMs) often suffer from \\emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \\textbf{NEAT}, a \\textbf{N}euron-based \\textbf{E}arly re\\textbf{A}soning exi\\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\\% to 28\\% when averaged over the four benchmarks, while maintaining accuracy.",
      "authors": [
        "Kang Liu",
        "Yongkang Liu",
        "Xiaocui Yang",
        "Peidong Wang",
        "Wen Zhang",
        "Shi Feng",
        "Yifei Zhang",
        "Daling Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-02T12:09:59+00:00",
      "link": "https://arxiv.org/pdf/2602.02010v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02909v1",
      "title": "Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs",
      "abstract": "Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $Ω(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.",
      "authors": [
        "Kiran Tomlinson",
        "Tobias Schnabel",
        "Adith Swaminathan",
        "Jennifer Neville"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "published": "2026-02-02T23:33:34+00:00",
      "link": "https://arxiv.org/pdf/2602.02909v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02138v1",
      "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems",
      "abstract": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.   We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.",
      "authors": [
        "Lyu Zongyi",
        "Ji Zhenlan",
        "Chen Songqiang",
        "Wang Liwen",
        "Huang Yuheng",
        "Wang Shuai",
        "Cheung Shing-Chi"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-02-02T14:19:08+00:00",
      "link": "https://arxiv.org/pdf/2602.02138v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07641v1",
      "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning",
      "abstract": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.",
      "authors": [
        "Jiaxuan Lu",
        "Ziyu Kong",
        "Yemin Wang",
        "Rong Fu",
        "Haiyuan Wan",
        "Cheng Yang",
        "Wenjie Lou",
        "Haoran Sun",
        "Lilong Wang",
        "Yankai Jiang",
        "Xiaosong Wang",
        "Xiao Sun",
        "Dongzhan Zhou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "published": "2026-01-12T15:22:51+00:00",
      "link": "https://arxiv.org/pdf/2601.07641v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.05705v1",
      "title": "Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning",
      "abstract": "Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.",
      "authors": [
        "Ali Farjami",
        "Luca Redondi",
        "Marco Valentino"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "published": "2026-01-09T10:47:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05705v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.05798v1",
      "title": "Learning False Discovery Rate Control via Model-Based Neural Networks",
      "abstract": "Controlling the false discovery rate (FDR) in high-dimensional variable selection requires balancing rigorous error control with statistical power. Existing methods with provable guarantees are often overly conservative, creating a persistent gap between the realized false discovery proportion (FDP) and the target FDR level. We introduce a learning-augmented enhancement of the T-Rex Selector framework that narrows this gap. Our approach replaces the analytical FDP estimator with a neural network trained solely on diverse synthetic datasets, enabling a substantially tighter and more accurate approximation of the FDP. This refinement allows the procedure to operate much closer to the desired FDR level, thereby increasing discovery power while maintaining effective approximate control. Through extensive simulations and a challenging synthetic genome-wide association study (GWAS), we demonstrate that our method achieves superior detection of true variables compared to existing approaches.",
      "authors": [
        "Arnau Vilella",
        "Jasin Machkour",
        "Michael Muma",
        "Daniel P. Palomar"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "cs.LG",
        "eess.SP",
        "stat.ML"
      ],
      "published": "2026-02-05T15:53:11+00:00",
      "link": "https://arxiv.org/pdf/2602.05798v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03772v1",
      "title": "UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining",
      "abstract": "The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \\textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \\textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \\textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \\textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \\textbf{2.0$\\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.",
      "authors": [
        "Changhao Wang",
        "Yunfei Yu",
        "Xinhao Yao",
        "Jiaolong Yang",
        "Riccardo Cantoro",
        "Chaobo Li",
        "Qing Cui",
        "Jun Zhou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T17:32:56+00:00",
      "link": "https://arxiv.org/pdf/2602.03772v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01848v1",
      "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems",
      "abstract": "Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.",
      "authors": [
        "Salaheddin Alzu'bi",
        "Baran Nama",
        "Arda Kaz",
        "Anushri Eswaran",
        "Weiyuan Chen",
        "Sarvesh Khetan",
        "Rishab Bala",
        "Tu Vu",
        "Sewoong Oh"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-02-02T09:20:59+00:00",
      "link": "https://arxiv.org/pdf/2602.01848v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18734v1",
      "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
      "abstract": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
      "authors": [
        "Siyan Zhao",
        "Zhihui Xie",
        "Mengchen Liu",
        "Jing Huang",
        "Guan Pang",
        "Feiyu Chen",
        "Aditya Grover"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-26T17:56:50+00:00",
      "link": "https://arxiv.org/pdf/2601.18734v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22040v1",
      "title": "A Separable Architecture for Continuous Token Representation in Language Models",
      "abstract": "Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \\times$ more parameters.",
      "authors": [
        "Reza T. Batley",
        "Sourav Saha"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-29T17:44:25+00:00",
      "link": "https://arxiv.org/pdf/2601.22040v1",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17426v1",
      "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models",
      "abstract": "Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.",
      "authors": [
        "Zhengqing Zang",
        "Yuqi Ding",
        "Yanmei Gu",
        "Changkai Song",
        "Zhengkai Yang",
        "Guoping Du",
        "Junbo Zhao",
        "Haobo Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-24T11:51:52+00:00",
      "link": "https://arxiv.org/pdf/2601.17426v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.20055v1",
      "title": "VERGE: Formal Refinement and Guidance Engine for Verifiable LLM Reasoning",
      "abstract": "Despite the syntactic fluency of Large Language Models (LLMs), ensuring their logical correctness in high-stakes domains remains a fundamental challenge. We present a neurosymbolic framework that combines LLMs with SMT solvers to produce verification-guided answers through iterative refinement. Our approach decomposes LLM outputs into atomic claims, autoformalizes them into first-order logic, and verifies their logical consistency using automated theorem proving. We introduce three key innovations: (1) multi-model consensus via formal semantic equivalence checking to ensure logic-level alignment between candidates, eliminating the syntactic bias of surface-form metrics, (2) semantic routing that directs different claim types to appropriate verification strategies: symbolic solvers for logical claims and LLM ensembles for commonsense reasoning, and (3) precise logical error localization via Minimal Correction Subsets (MCS), which pinpoint the exact subset of claims to revise, transforming binary failure signals into actionable feedback. Our framework classifies claims by their logical status and aggregates multiple verification signals into a unified score with variance-based penalty. The system iteratively refines answers using structured feedback until acceptance criteria are met or convergence is achieved. This hybrid approach delivers formal guarantees where possible and consensus verification elsewhere, advancing trustworthy AI. With the GPT-OSS-120B model, VERGE demonstrates an average performance uplift of 18.7% at convergence across a set of reasoning benchmarks compared to single-pass approaches.",
      "authors": [
        "Vikash Singh",
        "Darion Cassel",
        "Nathaniel Weir",
        "Nick Feng",
        "Sam Bayless"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-27T20:59:11+00:00",
      "link": "https://arxiv.org/pdf/2601.20055v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22269v1",
      "title": "JAF: Judge Agent Forest",
      "abstract": "Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge's collective perspective.   Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs.   To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.",
      "authors": [
        "Sahil Garg",
        "Brad Cheezum",
        "Sridhar Dutta",
        "Vishal Agarwal"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-29T19:42:42+00:00",
      "link": "https://arxiv.org/pdf/2601.22269v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.10101v2",
      "title": "Matrix as Plan: Structured Logical Reasoning with Feedback-Driven Replanning",
      "abstract": "As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs)' comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. The LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions and attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan thus becomes a verifiable artifact and execution becomes more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both the robustness and interpretability of LLMs when tackling complex symbolic reasoning tasks, while maintaining competitive performance.",
      "authors": [
        "Ke Chen",
        "Jiandian Zeng",
        "Zihao Peng",
        "Guo Li",
        "Guangxue Zhang",
        "Tian Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-15T06:12:00+00:00",
      "link": "https://arxiv.org/pdf/2601.10101v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.19847v1",
      "title": "Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering",
      "abstract": "Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.",
      "authors": [
        "Fangan Dong",
        "Zuming Yan",
        "Xuri Ge",
        "Zhiwei Xu",
        "Mengqi Zhang",
        "Xuanang Chen",
        "Ben He",
        "Xin Xin",
        "Zhumin Chen",
        "Ying Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-27T17:53:01+00:00",
      "link": "https://arxiv.org/pdf/2601.19847v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.07593v1",
      "title": "GRPO with State Mutations: Improving LLM-Based Hardware Test Plan Generation",
      "abstract": "RTL design often relies heavily on ad-hoc testbench creation early in the design cycle. While large language models (LLMs) show promise for RTL code generation, their ability to reason about hardware specifications and generate targeted test plans remains largely unexplored. We present the first systematic study of LLM reasoning capabilities for RTL verification stimuli generation, establishing a two-stage framework that decomposes test plan generation from testbench execution. Our benchmark reveals that state-of-the-art models, including DeepSeek-R1 and Claude-4.0-Sonnet, achieve only 15.7-21.7% success rates on generating stimuli that pass golden RTL designs. To improve LLM generated stimuli, we develop a comprehensive training methodology combining supervised fine-tuning with a novel reinforcement learning approach, GRPO with State Mutation (GRPO-SMu), which enhances exploration by varying input mutations. Our approach leverages a tree-based branching mutation strategy to construct training data comprising equivalent and mutated trees, moving beyond linear mutation approaches to provide rich learning signals. Training on this curated dataset, our 7B parameter model achieves a 33.3% golden test pass rate and a 13.9% mutation detection rate, representing a 17.6% absolute improvement over baseline and outperforming much larger general-purpose models. These results demonstrate that specialized training methodologies can significantly enhance LLM reasoning capabilities for hardware verification tasks, establishing a foundation for automated sub-unit testing in semiconductor design workflows.",
      "authors": [
        "Dimple Vijay Kochar",
        "Nathaniel Pinckney",
        "Guan-Ting Liu",
        "Chia-Tung Ho",
        "Chenhui Deng",
        "Haoxing Ren",
        "Brucek Khailany"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-12T14:42:42+00:00",
      "link": "https://arxiv.org/pdf/2601.07593v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.03550v1",
      "title": "Formal Evidence Generation for Assurance Cases for Robotic Software Models",
      "abstract": "Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach.",
      "authors": [
        "Fang Yan",
        "Simon Foster",
        "Ana Cavalcanti",
        "Ibrahim Habli",
        "James Baxter"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.FL",
        "cs.LO",
        "cs.RO"
      ],
      "published": "2026-02-03T14:01:30+00:00",
      "link": "https://arxiv.org/pdf/2602.03550v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.14349v1",
      "title": "MARBLE: Multi-Agent Reasoning for Bioinformatics Learning and Evolution",
      "abstract": "Motivation: Developing high-performing bioinformatics models typically requires repeated cycles of hypothesis formulation, architectural redesign, and empirical validation, making progress slow, labor-intensive, and difficult to reproduce. Although recent LLM-based assistants can automate isolated steps, they lack performance-grounded reasoning and stability-aware mechanisms required for reliable, iterative model improvement in bioinformatics workflows. Results: We introduce MARBLE, an execution-stable autonomous model refinement framework for bioinformatics models. MARBLE couples literature-aware reference selection with structured, debate-driven architectural reasoning among role-specialized agents, followed by autonomous execution, evaluation, and memory updates explicitly grounded in empirical performance. Across spatial transcriptomics domain segmentation, drug-target interaction prediction, and drug response prediction, MARBLE consistently achieves sustained performance improvements over strong baselines across multiple refinement cycles, while maintaining high execution robustness and low regression rates. Framework-level analyses demonstrate that structured debate, balanced evidence selection, and performance-grounded memory are critical for stable, repeatable model evolution, rather than single-run or brittle gains. Availability: Source code, data and Supplementary Information are available at https://github.com/PRISM-DGU/MARBLE.",
      "authors": [
        "Sunghyun Kim",
        "Seokwoo Yun",
        "Youngseo Yun",
        "Youngrak Lee",
        "Sangsoo Lim"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.LG"
      ],
      "published": "2026-01-20T17:10:47+00:00",
      "link": "https://arxiv.org/pdf/2601.14349v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.08058v1",
      "title": "Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models",
      "abstract": "Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, we find that steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. We further observe that this reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. Overall, our results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.",
      "authors": [
        "Zhenghao He",
        "Guangzhi Xiong",
        "Bohan Liu",
        "Sanchit Sinha",
        "Aidong Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-12T23:01:21+00:00",
      "link": "https://arxiv.org/pdf/2601.08058v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.06779v1",
      "title": "CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation",
      "abstract": "Large Language Models (LLMs) such as Gemma-2B have shown strong performance in various natural language processing tasks. However, general-purpose models often lack the domain expertise required for cybersecurity applications. This work presents a methodology to fine-tune the Gemma-2B model into a domain-specific cybersecurity LLM. We detail the processes of dataset preparation, fine-tuning, and synthetic data generation, along with implications for real-world applications in threat detection, forensic investigation, and attack analysis.   Experiments highlight challenges in prompt length distribution during domain-specific fine-tuning. Uneven prompt lengths limit the model's effective use of the context window, constraining local inference to 200-400 tokens despite hardware support for longer sequences. Chain-of-thought styled prompts, paired with quantized weights, yielded the best performance under these constraints. To address context limitations, we employed a hybrid strategy using cloud LLMs for synthetic data generation and local fine-tuning for deployment efficiency.   To extend the evaluation, we introduce a Retrieval-Augmented Generation (RAG) pipeline and graph-based reasoning framework. This approach enables structured alignment with MITRE ATT&CK techniques through STIX-based threat intelligence, enhancing recall in multi-hop and long-context scenarios. Graph modules encode entity-neighborhood context and tactic chains, helping mitigate the constraints of short prompt windows. Results demonstrate improved model alignment with tactic, technique, and procedure (TTP) coverage, validating the utility of graph-augmented LLMs in cybersecurity threat intelligence applications.",
      "authors": [
        "Vasanth Iyer",
        "Leonardo Bobadilla",
        "S. S. Iyengar"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-11T05:07:57+00:00",
      "link": "https://arxiv.org/pdf/2601.06779v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.12986v2",
      "title": "KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing",
      "abstract": "Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.",
      "authors": [
        "Zhenhua Xu",
        "Xiaoning Tian",
        "Wenjun Zeng",
        "Wenpeng Xing",
        "Tianliang Lu",
        "Gaolei Li",
        "Chaochao Chen",
        "Meng Han"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-19T12:06:20+00:00",
      "link": "https://arxiv.org/pdf/2601.12986v2",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.21571v2",
      "title": "Shaping capabilities with token-level data filtering",
      "abstract": "Current approaches to reducing undesired capabilities in language models are largely post hoc, and can thus be easily bypassed by adversaries. A natural alternative is to shape capabilities during pretraining itself. On the proxy task of removing medical capabilities, we show that the simple intervention of filtering pretraining data is highly effective, robust, and inexpensive at scale. Inspired by work on data attribution, we show that filtering tokens is more effective than filtering documents, achieving the same hit to undesired capabilities at a lower cost to benign ones. Training models spanning two orders of magnitude, we then demonstrate that filtering gets more effective with scale: for our largest models, token filtering leads to a 7000x compute slowdown on the forget domain. We also show that models trained with token filtering can still be aligned on the forget domain. Along the way, we introduce a methodology for labeling tokens with sparse autoencoders and distilling cheap, high-quality classifiers. We also demonstrate that filtering can be robust to noisy labels with sufficient pretraining compute.",
      "authors": [
        "Neil Rathi",
        "Alec Radford"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-29T11:34:01+00:00",
      "link": "https://arxiv.org/pdf/2601.21571v2",
      "tags": [
        "keyword:SR",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20071v2",
      "title": "Distributional value gradients for stochastic environments",
      "abstract": "Gradient-regularized value learning methods improve sample efficiency by leveraging learned models of transition dynamics and rewards to estimate return gradients. However, existing approaches, such as MAGE, struggle in stochastic or noisy environments, limiting their applicability. In this work, we address these limitations by extending distributional reinforcement learning on continuous state-action spaces to model not only the distribution over scalar state-action value functions but also over their gradients. We refer to this approach as Distributional Sobolev Training. Inspired by Stochastic Value Gradients (SVG), our method utilizes a one-step world model of reward and transition distributions implemented via a conditional Variational Autoencoder (cVAE). The proposed framework is sample-based and employs Max-sliced Maximum Mean Discrepancy (MSMMD) to instantiate the distributional Bellman operator. We prove that the Sobolev-augmented Bellman operator is a contraction with a unique fixed point, and highlight a fundamental smoothness trade-off underlying contraction in gradient-aware RL. To validate our method, we first showcase its effectiveness on a simple stochastic reinforcement learning toy problem, then benchmark its performance on several MuJoCo environments.",
      "authors": [
        "Baptiste Debes",
        "Tinne Tuytelaars"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T21:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.20071v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.20585v1",
      "title": "Ranking-aware Reinforcement Learning for Ordinal Ranking",
      "abstract": "Ordinal regression and ranking are challenging due to inherent ordinal dependencies that conventional methods struggle to model. We propose Ranking-Aware Reinforcement Learning (RARL), a novel RL framework that explicitly learns these relationships. At its core, RARL features a unified objective that synergistically integrates regression and Learning-to-Rank (L2R), enabling mutual improvement between the two tasks. This is driven by a ranking-aware verifiable reward that jointly assesses regression precision and ranking accuracy, facilitating direct model updates via policy optimization. To further enhance training, we introduce Response Mutation Operations (RMO), which inject controlled noise to improve exploration and prevent stagnation at saddle points. The effectiveness of RARL is validated through extensive experiments on three distinct benchmarks.",
      "authors": [
        "Aiming Hao",
        "Chen Zhu",
        "Jiashu Zhu",
        "Jiahong Wu",
        "Xiangxiang Chu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T13:22:42+00:00",
      "link": "https://arxiv.org/pdf/2601.20585v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05999v1",
      "title": "On Computation and Reinforcement Learning",
      "abstract": "How does the amount of compute available to a reinforcement learning (RL) policy affect its learning? Can policies using a fixed amount of parameters, still benefit from additional compute? The standard RL framework does not provide a language to answer these questions formally. Empirically, deep RL policies are often parameterized as neural networks with static architectures, conflating the amount of compute and the number of parameters. In this paper, we formalize compute bounded policies and prove that policies which use more compute can solve problems and generalize to longer-horizon tasks that are outside the scope of policies with less compute. Building on prior work in algorithmic learning and model-free planning, we propose a minimal architecture that can use a variable amount of compute. Our experiments complement our theory. On a set 31 different tasks spanning online and offline RL, we show that $(1)$ this architecture achieves stronger performance simply by using more compute, and $(2)$ stronger generalization on longer-horizon test tasks compared to standard feedforward networks or deep residual network using up to 5 times more parameters.",
      "authors": [
        "Raj Ghugare",
        "Michał Bortkiewicz",
        "Alicja Ziarko",
        "Benjamin Eysenbach"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T18:45:57+00:00",
      "link": "https://arxiv.org/pdf/2602.05999v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02978v1",
      "title": "Structuring Value Representations via Geometric Coherence in Markov Decision Processes",
      "abstract": "Geometric properties can be leveraged to stabilize and speed reinforcement learning. Existing examples include encoding symmetry structure, geometry-aware data augmentation, and enforcing structural restrictions. In this paper, we take a novel view of RL through the lens of order theory and recast value function estimates into learning a desired poset (partially ordered set). We propose \\emph{GCR-RL} (Geometric Coherence Regularized Reinforcement Learning) that computes a sequence of super-poset refinements -- by refining posets in previous steps and learning additional order relationships from temporal difference signals -- thus ensuring geometric coherence across the sequence of posets underpinning the learned value functions. Two novel algorithms by Q-learning and by actor--critic are developed to efficiently realize these super-poset refinements. Their theoretical properties and convergence rates are analyzed. We empirically evaluate GCR-RL in a range of tasks and demonstrate significant improvements in sample efficiency and stable performance over strong baselines.",
      "authors": [
        "Zuyuan Zhang",
        "Zeyu Fang",
        "Tian Lan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-03T01:35:58+00:00",
      "link": "https://arxiv.org/pdf/2602.02978v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.20714v1",
      "title": "Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions",
      "abstract": "Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments to learning and exploration hyperparameters, MORPHIN adapts agents to changes in both the reward function and on-the-fly expansions of the agent's action space, while preserving prior policy knowledge to prevent catastrophic forgetting. We validate our approach using a Gridworld benchmark and a traffic signal control simulation. The results demonstrate that MORPHIN achieves superior convergence speed and continuous adaptation compared to a standard Q-learning baseline, improving learning efficiency by up to 1.7x.",
      "authors": [
        "Raul de la Rosa",
        "Ivana Dusparic",
        "Nicolas Cardozo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T15:46:51+00:00",
      "link": "https://arxiv.org/pdf/2601.20714v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03816v1",
      "title": "SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving",
      "abstract": "We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.",
      "authors": [
        "Yesom Park",
        "Annie C. Lu",
        "Shao-Ching Huang",
        "Qiyang Hu",
        "Y. Sungtaek Ju",
        "Stanley Osher"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T18:18:30+00:00",
      "link": "https://arxiv.org/pdf/2602.03816v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07118v2",
      "title": "Reward-Preserving Attacks For Robust Reinforcement Learning",
      "abstract": "Adversarial training in reinforcement learning (RL) is challenging because perturbations cascade through trajectories and compound over time, making fixed-strength attacks either overly destructive or too conservative. We propose reward-preserving attacks, which adapt adversarial strength so that an $α$ fraction of the nominal-to-worst-case return gap remains achievable at each state. In deep RL, perturbation magnitudes $η$ are selected dynamically, using a learned critic $Q((s,a),η)$ that estimates the expected return of $α$-reward-preserving rollouts. For intermediate values of $α$, this adaptive training yields policies that are robust across a wide range of perturbation magnitudes while preserving nominal performance, outperforming fixed-radius and uniformly sampled-radius adversarial training.",
      "authors": [
        "Lucas Schott",
        "Elies Gherbi",
        "Hatem Hajri",
        "Sylvain Lamprier"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-12T01:14:03+00:00",
      "link": "https://arxiv.org/pdf/2601.07118v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04181v1",
      "title": "Piece of CAKE: Adaptive Execution Engines via Microsecond-Scale Learning",
      "abstract": "Low-level database operators often admit multiple physical implementations (\"kernels\") that are semantically equivalent but have vastly different performance characteristics depending on the input data distribution. Existing database systems typically rely on static heuristics or worst-case optimal defaults to select these kernels, often missing significant performance opportunities. In this work, we propose CAKE (Counterfactual Adaptive Kernel Execution), a system that learns to select the optimal kernel for each data \"morsel\" using a microsecond-scale contextual multi-armed bandit. CAKE circumvents the high latency of traditional reinforcement learning by exploiting the cheapness of counterfactuals -- selectively running multiple kernels to obtain full feedback -- and compiling policies into low-latency regret trees. Experimentally, we show that CAKE can reduce end-to-end workload latency by up to 2x compared to state-of-the-art static heuristics.",
      "authors": [
        "Zijie Zhao",
        "Ryan Marcus"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.LG"
      ],
      "published": "2026-02-04T03:41:07+00:00",
      "link": "https://arxiv.org/pdf/2602.04181v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.19720v1",
      "title": "Improving Policy Exploitation in Online Reinforcement Learning with Instant Retrospect Action",
      "abstract": "Existing value-based online reinforcement learning (RL) algorithms suffer from slow policy exploitation due to ineffective exploration and delayed policy updates. To address these challenges, we propose an algorithm called Instant Retrospect Action (IRA). Specifically, we propose Q-Representation Discrepancy Evolution (RDE) to facilitate Q-network representation learning, enabling discriminative representations for neighboring state-action pairs. In addition, we adopt an explicit method to policy constraints by enabling Greedy Action Guidance (GAG). This is achieved through backtracking historical actions, which effectively enhances the policy update process. Our proposed method relies on providing the learning algorithm with accurate $k$-nearest-neighbor action value estimates and learning to design a fast-adaptable policy through policy constraints. We further propose the Instant Policy Update (IPU) mechanism, which enhances policy exploitation by systematically increasing the frequency of policy updates. We further discover that the early-stage training conservatism of the IRA method can alleviate the overestimation bias problem in value-based RL. Experimental results show that IRA can significantly improve the learning efficiency and final performance of online RL algorithms on eight MuJoCo continuous control tasks.",
      "authors": [
        "Gong Gao",
        "Weidong Zhao",
        "Xianhui Liu",
        "Ning Jia"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T15:43:02+00:00",
      "link": "https://arxiv.org/pdf/2601.19720v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05890v1",
      "title": "DFPO: Scaling Value Modeling via Distributional Flow towards Robust and Generalizable LLM Post-Training",
      "abstract": "Training reinforcement learning (RL) systems in real-world environments remains challenging due to noisy supervision and poor out-of-domain (OOD) generalization, especially in LLM post-training. Recent distributional RL methods improve robustness by modeling values with multiple quantile points, but they still learn each quantile independently as a scalar. This results in rough-grained value representations that lack fine-grained conditioning on state information, struggling under complex and OOD conditions. We propose DFPO (Distributional Value Flow Policy Optimization with Conditional Risk and Consistency Control), a robust distributional RL framework that models values as continuous flows across time steps. By scaling value modeling through learning of a value flow field instead of isolated quantile predictions, DFPO captures richer state information for more accurate advantage estimation. To stabilize training under noisy feedback, DFPO further integrates conditional risk control and consistency constraints along value flow trajectories. Experiments on dialogue, math reasoning, and scientific tasks show that DFPO outperforms PPO, FlowRL, and other robust baselines under noisy supervision, achieving improved training stability and generalization.",
      "authors": [
        "Dingwei Zhu",
        "Zhiheng Xi",
        "Shihan Dou",
        "Jiahan Li",
        "Chenhao Huang",
        "Junjie Ye",
        "Sixian Li",
        "Mingxu Chai",
        "Yuhui Wang",
        "Yajie Yang",
        "Ming Zhang",
        "Jiazheng Zhang",
        "Shichun Liu",
        "Caishuang Huang",
        "Yunke Zhang",
        "Yuran Wang",
        "Tao Gui",
        "Xipeng Qiu",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-05T17:07:42+00:00",
      "link": "https://arxiv.org/pdf/2602.05890v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09236v2",
      "title": "Reward Learning through Ranking Mean Squared Error",
      "abstract": "Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., \"bad,\" \"neutral,\" \"good\"). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher's ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.",
      "authors": [
        "Chaitanya Kharyal",
        "Calarina Muslimani",
        "Matthew E. Taylor"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-14T07:18:12+00:00",
      "link": "https://arxiv.org/pdf/2601.09236v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.23075v1",
      "title": "RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning",
      "abstract": "On-policy deep reinforcement learning remains a dominant paradigm for continuous control, yet standard implementations rely on Gaussian actors and relatively shallow MLP policies, often leading to brittle optimization when gradients are noisy and policy updates must be conservative. In this paper, we revisit policy representation as a first-class design choice for on-policy optimization. We study discretized categorical actors that represent each action dimension with a distribution over bins, yielding a policy objective that resembles a cross-entropy loss. Building on architectural advances from supervised learning, we further propose regularized actor networks, while keeping critic design fixed. Our results show that simply replacing the standard actor network with our discretized regularized actor yields consistent gains and achieve the state-of-the-art performance across diverse continuous-control benchmarks.",
      "authors": [
        "Yuexin Bian",
        "Jie Feng",
        "Tao Wang",
        "Yijiang Li",
        "Sicun Gao",
        "Yuanyuan Shi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-30T15:24:34+00:00",
      "link": "https://arxiv.org/pdf/2601.23075v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22350v1",
      "title": "Learning Policy Representations for Steerable Behavior Synthesis",
      "abstract": "Given a Markov decision process (MDP), we seek to learn representations for a range of policies to facilitate behavior steering at test time. As policies of an MDP are uniquely determined by their occupancy measures, we propose modeling policy representations as expectations of state-action feature maps with respect to occupancy measures. We show that these representations can be approximated uniformly for a range of policies using a set-based architecture. Our model encodes a set of state-action samples into a latent embedding, from which we decode both the policy and its value functions corresponding to multiple rewards. We use variational generative approach to induce a smooth latent space, and further shape it with contrastive learning so that latent distances align with differences in value functions. This geometry permits gradient-based optimization directly in the latent space. Leveraging this capability, we solve a novel behavior synthesis task, where policies are steered to satisfy previously unseen value function constraints without additional training.",
      "authors": [
        "Beiming Li",
        "Sergio Rozada",
        "Alejandro Ribeiro"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T21:52:06+00:00",
      "link": "https://arxiv.org/pdf/2601.22350v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22823v1",
      "title": "Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment",
      "abstract": "We study offline reinforcement learning of style-conditioned policies using explicit style supervision via subtrajectory labeling functions. In this setting, aligning style with high task performance is particularly challenging due to distribution shift and inherent conflicts between style and reward. Existing methods, despite introducing numerous definitions of style, often fail to reconcile these objectives effectively. To address these challenges, we propose a unified definition of behavior style and instantiate it into a practical framework. Building on this, we introduce Style-Conditioned Implicit Q-Learning (SCIQL), which leverages offline goal-conditioned RL techniques, such as hindsight relabeling and value learning, and combine it with a new Gated Advantage Weighted Regression mechanism to efficiently optimize task performance while preserving style alignment. Experiments demonstrate that SCIQL achieves superior performance on both objectives compared to prior offline methods. Code, datasets and visuals are available in: https://sciql-iclr-2026.github.io/.",
      "authors": [
        "Mathieu Petitbois",
        "Rémy Portelas",
        "Sylvain Lamprier"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-30T10:49:22+00:00",
      "link": "https://arxiv.org/pdf/2601.22823v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05379v1",
      "title": "Variance Reduction Based Experience Replay for Policy Optimization",
      "abstract": "Effective reinforcement learning (RL) for complex stochastic systems requires leveraging historical data collected in previous iterations to accelerate policy optimization. Classical experience replay treats all past observations uniformly and fails to account for their varying contributions to learning. To overcome this limitation, we propose Variance Reduction Experience Replay (VRER), a principled framework that selectively reuses informative samples to reduce variance in policy gradient estimation. VRER is algorithm-agnostic and integrates seamlessly with existing policy optimization methods, forming the basis of our sample-efficient off-policy algorithm, Policy Gradient with VRER (PG-VRER). Motivated by the lack of rigorous theoretical analysis of experience replay, we develop a novel framework that explicitly captures dependencies introduced by Markovian dynamics and behavior-policy interactions. Using this framework, we establish finite-time convergence guarantees for PG-VRER and reveal a fundamental bias-variance trade-off: reusing older experience increases bias but simultaneously reduces gradient variance. Extensive empirical experiments demonstrate that VRER consistently accelerates policy learning and improves performance over state-of-the-art policy optimization algorithms.",
      "authors": [
        "Hua Zheng",
        "Wei Xie",
        "M. Ben Feng",
        "Keilung Choy"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-05T06:58:28+00:00",
      "link": "https://arxiv.org/pdf/2602.05379v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.19452v1",
      "title": "APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition",
      "abstract": "Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.",
      "authors": [
        "Finn Rietz",
        "Pedro Zuidberg dos Martires",
        "Johannes Andreas Stork"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27T10:38:32+00:00",
      "link": "https://arxiv.org/pdf/2601.19452v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08271v1",
      "title": "Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces",
      "abstract": "Tool-augmented LLM systems expose a control regime that learning theory has largely ignored: sequential decision-making with a massive discrete action universe (tools, APIs, documents) in which only a small, unknown subset is relevant for any fixed task distribution. We formalize this setting as Sparse Agentic Control (SAC), where policies admit block-sparse representations over M >> 1 actions and rewards depend on sparse main effects and (optionally) sparse synergies. We study ell_{1,2}-regularized policy learning through a convex surrogate and establish sharp, compressed-sensing-style results: (i) estimation and value suboptimality scale as k (log M / T)^{1/2} under a Policy-RSC condition; (ii) exact tool-support recovery holds via primal-dual witness arguments when T > k log M under incoherence and beta-min; and (iii) any dense policy class requires Omega(M) samples, explaining the instability of prompt-only controllers. We further show that under partial observability, LLMs matter only through a belief/representation error epsilon_b, yielding an additive O(epsilon_b) degradation while preserving logarithmic dependence on M. Extensions cover tuning-free, online, robust, group-sparse, and interaction-aware SAC.",
      "authors": [
        "Angshul Majumdar"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-13T06:56:53+00:00",
      "link": "https://arxiv.org/pdf/2601.08271v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08107v1",
      "title": "STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order",
      "abstract": "Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order), an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL's robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL.",
      "authors": [
        "Chengyang Gu",
        "Yuxin Pan",
        "Hui Xiong",
        "Yize Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-01-13T00:57:45+00:00",
      "link": "https://arxiv.org/pdf/2601.08107v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08726v1",
      "title": "Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts",
      "abstract": "Reinforcement Learning (RL) remains a central optimisation framework in machine learning. Although RL agents can converge to optimal solutions, the definition of ``optimality'' depends on the environment's statistical properties. The Bellman equation, central to most RL algorithms, is formulated in terms of expected values of future rewards. However, when ergodicity is broken, long-term outcomes depend on the specific trajectory rather than on the ensemble average. In such settings, the ensemble average diverges from the time-average growth experienced by individual agents, with expected-value formulations yielding systematically suboptimal policies. Prior studies demonstrated that traditional RL architectures fail to recover the true optimum in non-ergodic environments. We extend this analysis to deep RL implementations and show that these, too, produce suboptimal policies under non-ergodic dynamics. Introducing explicit time dependence into the learning process can correct this limitation. By allowing the network's function approximation to incorporate temporal information, the agent can estimate value functions consistent with the process's intrinsic growth rate. This improvement does not require altering the environmental feedback, such as reward transformations or modified objective functions, but arises naturally from the agent's exposure to temporal trajectories. Our results contribute to the growing body of research on reinforcement learning methods for non-ergodic systems.",
      "authors": [
        "Bert Verbruggen",
        "Arne Vanhoyweghen",
        "Vincent Ginis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-13T16:53:40+00:00",
      "link": "https://arxiv.org/pdf/2601.08726v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18952v1",
      "title": "Vector-Valued Distributional Reinforcement Learning Policy Evaluation: A Hilbert Space Embedding Approach",
      "abstract": "We propose an (offline) multi-dimensional distributional reinforcement learning framework (KE-DRL) that leverages Hilbert space mappings to estimate the kernel mean embedding of the multi-dimensional value distribution under a proposed target policy. In our setting, the state-action variables are multi-dimensional and continuous. By mapping probability measures into a reproducing kernel Hilbert space via kernel mean embeddings, our method replaces Wasserstein metrics with an integral probability metric. This enables efficient estimation in multi-dimensional state-action spaces and reward settings, where direct computation of Wasserstein distances is computationally challenging. Theoretically, we establish contraction properties of the distributional Bellman operator under our proposed metric involving the Matern family of kernels and provide uniform convergence guarantees. Simulations and empirical results demonstrate robust off-policy evaluation and recovery of the kernel mean embedding under mild assumptions, namely, Lipschitz continuity and boundedness of the kernels, highlighting the potential of embedding-based approaches in complex real-world decision-making scenarios and risk evaluation.",
      "authors": [
        "Mehrdad Mohammadi",
        "Qi Zheng",
        "Ruoqing Zhu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-01-26T20:46:00+00:00",
      "link": "https://arxiv.org/pdf/2601.18952v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21301v1",
      "title": "Achieving $\\varepsilon^{-2}$ Dependence for Average-Reward Q-Learning with a New Contraction Principle",
      "abstract": "We present the convergence rates of synchronous and asynchronous Q-learning for average-reward Markov decision processes, where the absence of contraction poses a fundamental challenge. Existing non-asymptotic results overcome this challenge by either imposing strong assumptions to enforce seminorm contraction or relying on discounted or episodic Markov decision processes as successive approximations, which either require unknown parameters or result in suboptimal sample complexity. In this work, under a reachability assumption, we establish optimal $\\widetilde{O}(\\varepsilon^{-2})$ sample complexity guarantees (up to logarithmic factors) for a simple variant of synchronous and asynchronous Q-learning that samples from the lazified dynamics, where the system remains in the current state with some fixed probability. At the core of our analysis is the construction of an instance-dependent seminorm and showing that, after a lazy transformation of the Markov decision process, the Bellman operator becomes one-step contractive under this seminorm.",
      "authors": [
        "Zijun Chen",
        "Zaiwei Chen",
        "Nian Si",
        "Shengbo Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-29T05:54:31+00:00",
      "link": "https://arxiv.org/pdf/2601.21301v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08136v1",
      "title": "Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies",
      "abstract": "Diffusion and flow policies are gaining prominence in online reinforcement learning (RL) due to their expressive power, yet training them efficiently remains a critical challenge. A fundamental difficulty in online RL is the lack of direct samples from the target distribution; instead, the target is an unnormalized Boltzmann distribution defined by the Q-function. To address this, two seemingly distinct families of methods have been proposed for diffusion policies: a noise-expectation family, which utilizes a weighted average of noise as the training target, and a gradient-expectation family, which employs a weighted average of Q-function gradients. Yet, it remains unclear how these objectives relate formally or if they can be synthesized into a more general formulation. In this paper, we propose a unified framework, reverse flow matching (RFM), which rigorously addresses the problem of training diffusion and flow models without direct target samples. By adopting a reverse inferential perspective, we formulate the training target as a posterior mean estimation problem given an intermediate noisy sample. Crucially, we introduce Langevin Stein operators to construct zero-mean control variates, deriving a general class of estimators that effectively reduce importance sampling variance. We show that existing noise-expectation and gradient-expectation methods are two specific instances within this broader class. This unified view yields two key advancements: it extends the capability of targeting Boltzmann distributions from diffusion to flow policies, and enables the principled combination of Q-value and Q-gradient information to derive an optimal, minimum-variance estimator, thereby improving training efficiency and stability. We instantiate RFM to train a flow policy in online RL, and demonstrate improved performance on continuous-control benchmarks compared to diffusion policy baselines.",
      "authors": [
        "Zeyang Li",
        "Sunbochen Tang",
        "Navid Azizan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-01-13T01:58:24+00:00",
      "link": "https://arxiv.org/pdf/2601.08136v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05494v1",
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "abstract": "Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likelihood ratios. This paper introduces a unified clipping framework that characterizes existing methods via a general notion of policy divergence, encompassing both likelihood ratios and Kullback-Leibler (KL) divergences and extending to alternative measures. The framework provides a principled foundation for systematically analyzing how different policy divergence measures affect exploration and performance. We further identify the KL3 estimator, a variance-reduced Monte Carlo estimator of the KL divergence, as a key policy divergence constraint. We theoretically demonstrate that the KL3-based constraint is mathematically equivalent to an asymmetric ratio-based clipping that reallocates probability mass toward high-confidence actions, promoting stronger exploration while retaining the simplicity of GRPO-style methods. Empirical results on mathematical reasoning benchmarks demonstrate that incorporating the KL3 estimator into GRPO improves both training stability and final performance, highlighting the importance of principled policy divergence constraints in policy optimization.",
      "authors": [
        "Qingyuan Wu",
        "Yuhui Wang",
        "Simon Sinong Zhan",
        "Yanning Dai",
        "Shilong Deng",
        "Sarra Habchi",
        "Qi Zhu",
        "Matthias Gallé",
        "Chao Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-05T09:56:16+00:00",
      "link": "https://arxiv.org/pdf/2602.05494v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18907v1",
      "title": "Implicit Q-Learning and SARSA: Liberating Policy Control from Step-Size Calibration",
      "abstract": "Q-learning and SARSA are foundational reinforcement learning algorithms whose practical success depends critically on step-size calibration. Step-sizes that are too large can cause numerical instability, while step-sizes that are too small can lead to slow progress. We propose implicit variants of Q-learning and SARSA that reformulate their iterative updates as fixed-point equations. This yields an adaptive step-size adjustment that scales inversely with feature norms, providing automatic regularization without manual tuning. Our non-asymptotic analyses demonstrate that implicit methods maintain stability over significantly broader step-size ranges. Under favorable conditions, it permits arbitrarily large step-sizes while achieving comparable convergence rates. Empirical validation across benchmark environments spanning discrete and continuous state spaces shows that implicit Q-learning and SARSA exhibit substantially reduced sensitivity to step-size selection, achieving stable performance with step-sizes that would cause standard methods to fail.",
      "authors": [
        "Hwanwoo Kim",
        "Eric Laber"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-26T19:17:48+00:00",
      "link": "https://arxiv.org/pdf/2601.18907v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02098v1",
      "title": "Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning",
      "abstract": "Multi-task reinforcement learning trains generalist policies that can execute multiple tasks. While recent years have seen significant progress, existing approaches rarely provide formal performance guarantees, which are indispensable when deploying policies in safety-critical settings. We present an approach for computing high-confidence guarantees on the performance of a multi-task policy on tasks not seen during training. Concretely, we introduce a new generalisation bound that composes (i) per-task lower confidence bounds from finitely many rollouts with (ii) task-level generalisation from finitely many sampled tasks, yielding a high-confidence guarantee for new tasks drawn from the same arbitrary and unknown distribution. Across state-of-the-art multi-task RL methods, we show that the guarantees are theoretically sound and informative at realistic sample sizes.",
      "authors": [
        "Yannik Schnitzer",
        "Mathias Jackermeier",
        "Alessandro Abate",
        "David Parker"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T13:41:47+00:00",
      "link": "https://arxiv.org/pdf/2602.02098v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03171v1",
      "title": "StepScorer: Accelerating Reinforcement Learning with Step-wise Scoring and Psychological Regret Modeling",
      "abstract": "Reinforcement learning algorithms often suffer from slow convergence due to sparse reward signals, particularly in complex environments where feedback is delayed or infrequent. This paper introduces the Psychological Regret Model (PRM), a novel approach that accelerates learning by incorporating regret-based feedback signals after each decision step. Rather than waiting for terminal rewards, PRM computes a regret signal based on the difference between the expected value of the optimal action and the value of the action taken in each state. This transforms sparse rewards into dense feedback signals through a step-wise scoring framework, enabling faster convergence. We demonstrate that PRM achieves stable performance approximately 36\\% faster than traditional Proximal Policy Optimization (PPO) in benchmark environments such as Lunar Lander. Our results indicate that PRM is particularly effective in continuous control tasks and environments with delayed feedback, making it suitable for real-world applications such as robotics, finance, and adaptive education where rapid policy adaptation is critical. The approach formalizes human-inspired counterfactual thinking as a computable regret signal, bridging behavioral economics and reinforcement learning.",
      "authors": [
        "Zhe Xu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T06:39:20+00:00",
      "link": "https://arxiv.org/pdf/2602.03171v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18107v1",
      "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions",
      "abstract": "Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.",
      "authors": [
        "Pedram Agand",
        "Mo Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.HC",
        "cs.RO"
      ],
      "published": "2026-01-26T03:38:27+00:00",
      "link": "https://arxiv.org/pdf/2601.18107v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22211v1",
      "title": "Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions",
      "abstract": "Reinforcement learning (RL) with combinatorial action spaces remains challenging because feasible action sets are exponentially large and governed by complex feasibility constraints, making direct policy parameterization impractical. Existing approaches embed task-specific value functions into constrained optimization programs or learn deterministic structured policies, sacrificing generality and policy expressiveness. We propose a solver-induced \\emph{latent spherical flow policy} that brings the expressiveness of modern generative policies to combinatorial RL while guaranteeing feasibility by design. Our method, LSFlow, learns a \\emph{stochastic} policy in a compact continuous latent space via spherical flow matching, and delegates feasibility to a combinatorial optimization solver that maps each latent sample to a valid structured action. To improve efficiency, we train the value network directly in the latent space, avoiding repeated solver calls during policy optimization. To address the piecewise-constant and discontinuous value landscape induced by solver-based action selection, we introduce a smoothed Bellman operator that yields stable, well-defined learning targets. Empirically, our approach outperforms state-of-the-art baselines by an average of 20.6\\% across a range of challenging combinatorial RL tasks.",
      "authors": [
        "Lingkai Kong",
        "Anagha Satish",
        "Hezi Jiang",
        "Akseli Kangaslahti",
        "Andrew Ma",
        "Wenbo Chen",
        "Mingxiao Song",
        "Lily Xu",
        "Milind Tambe"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T18:49:07+00:00",
      "link": "https://arxiv.org/pdf/2601.22211v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21845v1",
      "title": "Constrained Meta Reinforcement Learning with Provable Test-Time Safety",
      "abstract": "Meta reinforcement learning (RL) allows agents to leverage experience across a distribution of tasks on which the agent can train at will, enabling faster learning of optimal policies on new test tasks. Despite its success in improving sample complexity on test tasks, many real-world applications, such as robotics and healthcare, impose safety constraints during testing. Constrained meta RL provides a promising framework for integrating safety into meta RL. An open question in constrained meta RL is how to ensure the safety of the policy on the real-world test task, while reducing the sample complexity and thus, enabling faster learning of optimal policies. To address this gap, we propose an algorithm that refines policies learned during training, with provable safety and sample complexity guarantees for learning a near optimal policy on the test tasks. We further derive a matching lower bound, showing that this sample complexity is tight.",
      "authors": [
        "Tingting Ni",
        "Maryam Kamgarpour"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T15:21:37+00:00",
      "link": "https://arxiv.org/pdf/2601.21845v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.13642v1",
      "title": "Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning",
      "abstract": "Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{\\varepsilon^3}\\right)$, where $\\|h^{\\star}\\|_{\\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}^2}{\\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{M\\varepsilon^3}\\right)$, with only $\\widetilde{O}\\left(\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}}{\\varepsilon}\\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity.",
      "authors": [
        "Yuchen Jiao",
        "Jiin Woo",
        "Gen Li",
        "Gauri Joshi",
        "Yuejie Chi"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-20T06:21:54+00:00",
      "link": "https://arxiv.org/pdf/2601.13642v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18626v1",
      "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
      "abstract": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.",
      "authors": [
        "Yingxiao Huo",
        "Satya Prakash Dash",
        "Radu Stoican",
        "Samuel Kaski",
        "Mingfei Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-26T16:02:18+00:00",
      "link": "https://arxiv.org/pdf/2601.18626v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05323v1",
      "title": "GAS: Enhancing Reward-Cost Balance of Generative Model-assisted Offline Safe RL",
      "abstract": "Offline Safe Reinforcement Learning (OSRL) aims to learn a policy to achieve high performance in sequential decision-making while satisfying constraints, using only pre-collected datasets. Recent works, inspired by the strong capabilities of Generative Models (GMs), reformulate decision-making in OSRL as a conditional generative process, where GMs generate desirable actions conditioned on predefined reward and cost values. However, GM-assisted methods face two major challenges in OSRL: (1) lacking the ability to \"stitch\" optimal transitions from suboptimal trajectories within the dataset, and (2) struggling to balance reward targets with cost targets, particularly when they are conflict. To address these issues, we propose Goal-Assisted Stitching (GAS), a novel algorithm designed to enhance stitching capabilities while effectively balancing reward maximization and constraint satisfaction. To enhance the stitching ability, GAS first augments and relabels the dataset at the transition level, enabling the construction of high-quality trajectories from suboptimal ones. GAS also introduces novel goal functions, which estimate the optimal achievable reward and cost goals from the dataset. These goal functions, trained using expectile regression on the relabeled and augmented dataset, allow GAS to accommodate a broader range of reward-cost return pairs and achieve a better tradeoff between reward maximization and constraint satisfaction compared to human-specified values. The estimated goals then guide policy training, ensuring robust performance under constrained settings. Furthermore, to improve training stability and efficiency, we reshape the dataset to achieve a more uniform reward-cost return distribution. Empirical results validate the effectiveness of GAS, demonstrating superior performance in balancing reward maximization and constraint satisfaction compared to existing methods.",
      "authors": [
        "Zifan Liu",
        "Xinran Li",
        "Shibo Chen",
        "Jun Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-05T05:44:48+00:00",
      "link": "https://arxiv.org/pdf/2602.05323v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04599v1",
      "title": "Stochastic Decision Horizons for Constrained Reinforcement Learning",
      "abstract": "Constrained Markov decision processes (CMDPs) provide a principled model for handling constraints, such as safety and other auxiliary objectives, in reinforcement learning. The common approach of using additive-cost constraints and dual variables often hinders off-policy scalability. We propose a Control as Inference formulation based on stochastic decision horizons, where constraint violations attenuate reward contributions and shorten the effective planning horizon via state-action-dependent continuation. This yields survival-weighted objectives that remain replay-compatible for off-policy actor-critic learning. We propose two violation semantics, absorbing and virtual termination, that share the same survival-weighted return but result in distinct optimization structures that lead to SAC/MPO-style policy improvement. Experiments demonstrate improved sample efficiency and favorable return-violation trade-offs on standard benchmarks. Moreover, MPO with virtual termination (VT-MPO) scales effectively to our high-dimensional musculoskeletal Hyfydy setup.",
      "authors": [
        "Nikola Milosevic",
        "Leonard Franz",
        "Daniel Haeufle",
        "Georg Martius",
        "Nico Scherf",
        "Pavel Kolev"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T14:27:16+00:00",
      "link": "https://arxiv.org/pdf/2602.04599v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16399v2",
      "title": "A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning",
      "abstract": "We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).",
      "authors": [
        "Sihan Zeng",
        "Sujay Bhatt",
        "Sumitra Ganesh",
        "Alec Koppel"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-23T02:12:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16399v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15014v1",
      "title": "Efficient and Minimax-optimal In-context Nonparametric Regression with Transformers",
      "abstract": "We study in-context learning for nonparametric regression with $α$-Hölder smooth regression functions, for some $α>0$. We prove that, with $n$ in-context examples and $d$-dimensional regression covariates, a pretrained transformer with $Θ(\\log n)$ parameters and $Ω\\bigl(n^{2α/(2α+d)}\\log^3 n\\bigr)$ pretraining sequences can achieve the minimax-optimal rate of convergence $O\\bigl(n^{-2α/(2α+d)}\\bigr)$ in mean squared error. Our result requires substantially fewer transformer parameters and pretraining sequences than previous results in the literature. This is achieved by showing that transformers are able to approximate local polynomial estimators efficiently by implementing a kernel-weighted polynomial basis and then running gradient descent.",
      "authors": [
        "Michelle Ching",
        "Ioana Popescu",
        "Nico Smith",
        "Tianyi Ma",
        "William G. Underwood",
        "Richard J. Samworth"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-01-21T14:13:38+00:00",
      "link": "https://arxiv.org/pdf/2601.15014v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.22891v1",
      "title": "PlatoLTL: Learning to Generalize Across Symbols in LTL Instructions for Multi-Task RL",
      "abstract": "A central challenge in multi-task reinforcement learning (RL) is to train generalist policies capable of performing tasks not seen during training. To facilitate such generalization, linear temporal logic (LTL) has recently emerged as a powerful formalism for specifying structured, temporally extended tasks to RL agents. While existing approaches to LTL-guided multi-task RL demonstrate successful generalization across LTL specifications, they are unable to generalize to unseen vocabularies of propositions (or \"symbols\"), which describe high-level events in LTL. We present PlatoLTL, a novel approach that enables policies to zero-shot generalize not only compositionally across LTL formula structures, but also parametrically across propositions. We achieve this by treating propositions as instances of parameterized predicates rather than discrete symbols, allowing policies to learn shared structure across related propositions. We propose a novel architecture that embeds and composes predicates to represent LTL specifications, and demonstrate successful zero-shot generalization to novel propositions and tasks across challenging environments.",
      "authors": [
        "Jacques Cloete",
        "Mathias Jackermeier",
        "Ioannis Havoutis",
        "Alessandro Abate"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T12:11:55+00:00",
      "link": "https://arxiv.org/pdf/2601.22891v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.09083v1",
      "title": "SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache",
      "abstract": "We present Speculative Rollout with Tree-Structured Cache (SRT), a simple, model-free approach to accelerate on-policy reinforcement learning (RL) for language models without sacrificing distributional correctness. SRT exploits the empirical similarity of rollouts for the same prompt across training steps by storing previously generated continuations in a per-prompt tree-structured cache. During generation, the current policy uses this tree as the draft model for performing speculative decoding. To keep the cache fresh and improve draft model quality, SRT updates trees online from ongoing rollouts and proactively performs run-ahead generation during idle GPU bubbles. Integrated into standard RL pipelines (\\textit{e.g.}, PPO, GRPO and DAPO) and multi-turn settings, SRT consistently reduces generation and step latency and lowers per-token inference cost, achieving up to 2.08x wall-clock time speedup during rollout.",
      "authors": [
        "Chi-Chih Chang",
        "Siqi Zhu",
        "Zhichen Zeng",
        "Haibin Lin",
        "Jiaxuan You",
        "Mohamed S. Abdelfattah",
        "Ziheng Jiang",
        "Xuehai Qian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-14T02:34:48+00:00",
      "link": "https://arxiv.org/pdf/2601.09083v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.11217v2",
      "title": "Model-free policy gradient for discrete-time mean-field control",
      "abstract": "We study model-free policy learning for discrete-time mean-field control (MFC) problems with finite state space and compact action space. In contrast to the extensive literature on value-based methods for MFC, policy-based approaches remain largely unexplored due to the intrinsic dependence of transition kernels and rewards on the evolving population state distribution, which prevents the direct use of likelihood-ratio estimators of policy gradients from classical single-agent reinforcement learning. We introduce a novel perturbation scheme on the state-distribution flow and prove that the gradient of the resulting perturbed value function converges to the true policy gradient as the perturbation magnitude vanishes. This construction yields a fully model-free estimator based solely on simulated trajectories and an auxiliary estimate of the sensitivity of the state distribution. Building on this framework, we develop MF-REINFORCE, a model-free policy gradient algorithm for MFC, and establish explicit quantitative bounds on its bias and mean-squared error. Numerical experiments on representative mean-field control tasks demonstrate the effectiveness of the proposed approach.",
      "authors": [
        "Matthieu Meunier",
        "Huyên Pham",
        "Christoph Reisinger"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-16T11:49:25+00:00",
      "link": "https://arxiv.org/pdf/2601.11217v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21476v1",
      "title": "SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models",
      "abstract": "On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\\textbf{S}$ingle-sample Mix-p$\\textbf{O}$licy $\\textbf{U}$nified $\\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.",
      "authors": [
        "Lei Yang",
        "Wei Bi",
        "Chenxi Sun",
        "Renren Jin",
        "Deyi Xiong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-29T09:56:15+00:00",
      "link": "https://arxiv.org/pdf/2601.21476v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21391v1",
      "title": "Intrinsic Reward Policy Optimization for Sparse-Reward Environments",
      "abstract": "Exploration is essential in reinforcement learning as an agent relies on trial and error to learn an optimal policy. However, when rewards are sparse, naive exploration strategies, like noise injection, are often insufficient. Intrinsic rewards can also provide principled guidance for exploration by, for example, combining them with extrinsic rewards to optimize a policy or using them to train subpolicies for hierarchical learning. However, the former approach suffers from unstable credit assignment, while the latter exhibits sample inefficiency and sub-optimality. We propose a policy optimization framework that leverages multiple intrinsic rewards to directly optimize a policy for an extrinsic reward without pretraining subpolicies. Our algorithm -- intrinsic reward policy optimization (IRPO) -- achieves this by using a surrogate policy gradient that provides a more informative learning signal than the true gradient in sparse-reward environments. We demonstrate that IRPO improves performance and sample efficiency relative to baselines in discrete and continuous environments, and formally analyze the optimization problem solved by IRPO. Our code is available at https://github.com/Mgineer117/IRPO.",
      "authors": [
        "Minjae Cho",
        "Huy Trong Tran"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T08:25:14+00:00",
      "link": "https://arxiv.org/pdf/2601.21391v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14234v2",
      "title": "Q-learning with Adjoint Matching",
      "abstract": "We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.",
      "authors": [
        "Qiyang Li",
        "Sergey Levine"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "published": "2026-01-20T18:45:34+00:00",
      "link": "https://arxiv.org/pdf/2601.14234v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03301v1",
      "title": "Periodic Regularized Q-Learning",
      "abstract": "In reinforcement learning (RL), Q-learning is a fundamental algorithm whose convergence is guaranteed in the tabular setting. However, this convergence guarantee does not hold under linear function approximation. To overcome this limitation, a significant line of research has introduced regularization techniques to ensure stable convergence under function approximation. In this work, we propose a new algorithm, periodic regularized Q-learning (PRQ). We first introduce regularization at the level of the projection operator and explicitly construct a regularized projected value iteration (RP-VI), subsequently extending it to a sample-based RL algorithm. By appropriately regularizing the projection operator, the resulting projected value iteration becomes a contraction. By extending this regularized projection into the stochastic setting, we establish the PRQ algorithm and provide a rigorous theoretical analysis that proves finite-time convergence guarantees for PRQ under linear function approximation.",
      "authors": [
        "Hyukjun Yang",
        "Han-Dong Lim",
        "Donghwan Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T09:28:06+00:00",
      "link": "https://arxiv.org/pdf/2602.03301v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03201v1",
      "title": "From Scalar Rewards to Potential Trends: Shaping Potential Landscapes for Model-Based Reinforcement Learning",
      "abstract": "Model-based reinforcement learning (MBRL) achieves high sample efficiency by simulating future trajectories with learned dynamics and reward models. However, its effectiveness is severely compromised in sparse reward settings. The core limitation lies in the standard paradigm of regressing ground-truth scalar rewards: in sparse environments, this yields a flat, gradient-free landscape that fails to provide directional guidance for planning. To address this challenge, we propose Shaping Landscapes with Optimistic Potential Estimates (SLOPE), a novel framework that shifts reward modeling from predicting scalars to constructing informative potential landscapes. SLOPE employs optimistic distributional regression to estimate high-confidence upper bounds, which amplifies rare success signals and ensures sufficient exploration gradients. Evaluations on 30+ tasks across 5 benchmarks demonstrate that SLOPE consistently outperforms leading baselines in fully sparse, semi-sparse, and dense rewards.",
      "authors": [
        "Yao-Hui Li",
        "Zeyu Wang",
        "Xin Li",
        "Wei Pang",
        "Yingfang Yuan",
        "Zhengkun Chen",
        "Boya Zhang",
        "Riashat Islam",
        "Alex Lamb",
        "Yonggang Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T07:13:26+00:00",
      "link": "https://arxiv.org/pdf/2602.03201v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21924v1",
      "title": "Optimistic Transfer under Task Shift via Bellman Alignment",
      "abstract": "We study online transfer reinforcement learning (RL) in episodic Markov decision processes, where experience from related source tasks is available during learning on a target task. A fundamental difficulty is that task similarity is typically defined in terms of rewards or transitions, whereas online RL algorithms operate on Bellman regression targets. As a result, naively reusing source Bellman updates introduces systematic bias and invalidates regret guarantees.   We identify one-step Bellman alignment as the correct abstraction for transfer in online RL and propose re-weighted targeting (RWT), an operator-level correction that retargets continuation values and compensates for transition mismatch via a change of measure. RWT reduces task mismatch to a fixed one-step correction and enables statistically sound reuse of source data.   This alignment yields a two-stage RWT $Q$-learning framework that separates variance reduction from bias correction. Under RKHS function approximation, we establish regret bounds that scale with the complexity of the task shift rather than the target MDP. Empirical results in both tabular and neural network settings demonstrate consistent improvements over single-task learning and naïve pooling, highlighting Bellman alignment as a model-agnostic transfer principle for online RL.",
      "authors": [
        "Jinhang Chai",
        "Enpei Zhang",
        "Elynn Chen",
        "Yujun Yan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-29T16:16:24+00:00",
      "link": "https://arxiv.org/pdf/2601.21924v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15761v1",
      "title": "Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning",
      "abstract": "Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \\textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.",
      "authors": [
        "Xiefeng Wu",
        "Mingyu Hu",
        "Shu Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22T08:51:16+00:00",
      "link": "https://arxiv.org/pdf/2601.15761v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02150v1",
      "title": "ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning",
      "abstract": "Test-time reinforcement learning generates multiple candidate answers via repeated rollouts and performs online updates using pseudo-labels constructed by majority voting. To reduce overhead and improve exploration, prior work introduces tree structured rollouts, which share reasoning prefixes and branch at key nodes to improve sampling efficiency. However, this paradigm still faces two challenges: (1) high entropy branching can trigger rollout collapse, where the branching budget concentrates on a few trajectories with consecutive high-entropy segments, rapidly reducing the number of effective branches; (2) early pseudo-labels are noisy and biased, which can induce self-reinforcing overfitting, causing the policy to sharpen prematurely and suppress exploration. To address these issues, we propose Entropy Confidence Hybrid Group Relative Policy Optimization (ECHO). During rollout, ECHO jointly leverages local entropy and group level confidence to adaptively control branch width, and further introduces online confidence-based pruning to terminate persistently low confidence branches, avoiding high entropy traps and mitigating collapse. During policy updates, ECHO employs confidence adaptive clipping and an entropy confidence hybrid advantage shaping approach to enhance training robustness and mitigate early stage bias. Experiments demonstrate that ECHO achieves consistent gains on multiple mathematical and visual reasoning benchmarks, and generalizes more effectively under a limited rollout budget.",
      "authors": [
        "Chu Zhao",
        "Enneng Yang",
        "Yuting Liu",
        "Jianzhe Zhao",
        "Guibing Guo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T14:27:02+00:00",
      "link": "https://arxiv.org/pdf/2602.02150v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02847v1",
      "title": "Causal Flow Q-Learning for Robust Offline Reinforcement Learning",
      "abstract": "Expressive policies based on flow-matching have been successfully applied in reinforcement learning (RL) more recently due to their ability to model complex action distributions from offline data. These algorithms build on standard policy gradients, which assume that there is no unmeasured confounding in the data. However, this condition does not necessarily hold for pixel-based demonstrations when a mismatch exists between the demonstrator's and the learner's sensory capabilities, leading to implicit confounding biases in offline data. We address the challenge by investigating the problem of confounded observations in offline RL from a causal perspective. We develop a novel causal offline RL objective that optimizes policies' worst-case performance that may arise due to confounding biases. Based on this new objective, we introduce a practical implementation that learns expressive flow-matching policies from confounded demonstrations, employing a deep discriminator to assess the discrepancy between the target policy and the nominal behavioral policy. Experiments across 25 pixel-based tasks demonstrate that our proposed confounding-robust augmentation procedure achieves a success rate 120\\% that of confounding-unaware, state-of-the-art offline RL methods.",
      "authors": [
        "Mingxuan Li",
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-02-02T21:50:52+00:00",
      "link": "https://arxiv.org/pdf/2602.02847v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00587v1",
      "title": "Safe Langevin Soft Actor Critic",
      "abstract": "Balancing reward and safety in constrained reinforcement learning remains challenging due to poor generalization from sharp value minima and inadequate handling of heavy-tailed risk distribution. We introduce Safe Langevin Soft Actor-Critic (SL-SAC), a principled algorithm that addresses both issues through parameter-space exploration and distributional risk control. Our approach combines three key mechanisms: (1) Adaptive Stochastic Gradient Langevin Dynamics (aSGLD) for reward critics, promoting ensemble diversity and escape from poor optima; (2) distributional cost estimation via Implicit Quantile Networks (IQN) with Conditional Value-at-Risk (CVaR) optimization for tail-risk mitigation; and (3) a reactive Lagrangian relaxation scheme that adapts constraint enforcement based on the empirical CVaR of episodic costs. We provide theoretical guarantees on CVaR estimation error and demonstrate that CVaR-based Lagrange updates yield stronger constraint violation signals than expected-cost updates. On Safety-Gymnasium benchmarks, SL-SAC achieves the lowest cost in 7 out of 10 tasks while maintaining competitive returns, with cost reductions of 19-63% in velocity tasks compared to state-of-the-art baselines.",
      "authors": [
        "Mahesh Keswani",
        "Samyak Jain",
        "Raunak P. Bhattacharyya"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-31T08:06:35+00:00",
      "link": "https://arxiv.org/pdf/2602.00587v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03309v1",
      "title": "Entropy-Gated Selective Policy Optimization:Token-Level Gradient Allocation for Hybrid Training of Large Language Models",
      "abstract": "Hybrid training methods for large language models combine supervised fine tuning (SFT) on expert demonstrations with reinforcement learning (RL) on model rollouts, typically at the sample level. We propose Entropy Gated Selective Policy Optimization (EGSPO), a three stage framework that extends sample level mixing with token level gradient modulation.   Stage 1, SFT expert learning, establishes a reliable warm up policy using expert demonstrations with a pure SFT loss. Stage 2, RL rollout generation, samples trajectories from the current policy and computes per token predictive entropy. Stage 3, the EGSPO mechanism, applies entropy gated gradient allocation: a predictive entropy module routes high entropy tokens to full PPO updates to encourage exploration, and low entropy tokens to attenuated PPO updates to reduce variance and preserve knowledge. Critically, both branches incorporate the advantage function A_t, ensuring that incorrect trajectories receive consistent negative learning signals and preventing reinforcement of confident errors.   EGSPO achieves consistent improvements on mathematical reasoning benchmarks, with gains of 3.8 percent on AIME and 2.9 percent on MATH over the CHORD phi baseline, while incurring only 3.4 percent additional computational overhead.",
      "authors": [
        "Yuelin Hu",
        "Zhengxue Cheng",
        "Wei Liu",
        "Li Song"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T09:38:21+00:00",
      "link": "https://arxiv.org/pdf/2602.03309v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03073v1",
      "title": "TMS: Trajectory-Mixed Supervision for Reward-Free, On-Policy SFT",
      "abstract": "Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT) are the two dominant paradigms for enhancing Large Language Model (LLM) performance on downstream tasks. While RL generally preserves broader model capabilities (retention) better than SFT, it comes with significant costs: complex reward engineering, instability, and expensive on-policy sampling. In contrast, SFT is efficient but brittle, often suffering from catastrophic forgetting due to $\\textbf{Supervision Mismatch}$: the divergence between the model's evolving policy and static training labels. We address this trade-off with $\\textbf{Trajectory-Mixed Supervision (TMS)}$, a reward-free framework that approximates the on-policy benefits of RL by creating a dynamic curriculum from the model's own historical checkpoints. TMS minimizes $\\textit{Policy-Label Divergence (PLD)}$, preventing the mode collapse that drives forgetting in standard SFT. Experiments across reasoning (MATH, GSM8K) and instruction-following benchmarks demonstrate that TMS effectively shifts the accuracy--retention Pareto frontier. While RL remains the gold standard for retention, TMS significantly outperforms standard and iterative SFT, bridging the gap to RL without requiring reward models or verifiers. Mechanistic analysis confirms that PLD drift accurately predicts forgetting and that TMS successfully mitigates this drift.",
      "authors": [
        "Rana Muhammad Shahroz Khan",
        "Zijie Liu",
        "Zhen Tan",
        "Charles Fleming",
        "Tianlong Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T04:01:26+00:00",
      "link": "https://arxiv.org/pdf/2602.03073v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07164v1",
      "title": "Offline Meta-Reinforcement Learning with Flow-Based Task Inference and Adaptive Correction of Feature Overgeneralization",
      "abstract": "Offline meta-reinforcement learning (OMRL) combines the strengths of learning from diverse datasets in offline RL with the adaptability to new tasks of meta-RL, promising safe and efficient knowledge acquisition by RL agents. However, OMRL still suffers extrapolation errors due to out-of-distribution (OOD) actions, compromised by broad task distributions and Markov Decision Process (MDP) ambiguity in meta-RL setups. Existing research indicates that the generalization of the $Q$ network affects the extrapolation error in offline RL. This paper investigates this relationship by decomposing the $Q$ value into feature and weight components, observing that while decomposition enhances adaptability and convergence in the case of high-quality data, it often leads to policy degeneration or collapse in complex tasks. We observe that decomposed $Q$ values introduce a large estimation bias when the feature encounters OOD samples, a phenomenon we term ''feature overgeneralization''. To address this issue, we propose FLORA, which identifies OOD samples by modeling feature distributions and estimating their uncertainties. FLORA integrates a return feedback mechanism to adaptively adjust feature components. Furthermore, to learn precise task representations, FLORA explicitly models the complex task distribution using a chain of invertible transformations. We theoretically and empirically demonstrate that FLORA achieves rapid adaptation and meta-policy improvement compared to baselines across various environments.",
      "authors": [
        "Min Wang",
        "Xin Li",
        "Mingzhong Wang",
        "Hasnaa Bennis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-12T03:16:07+00:00",
      "link": "https://arxiv.org/pdf/2601.07164v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01705v2",
      "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
      "abstract": "Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.",
      "authors": [
        "Haoqiang Kang",
        "Yizhe Zhang",
        "Nikki Lijing Kuang",
        "Yi-An Ma",
        "Lianhui Qin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T06:26:31+00:00",
      "link": "https://arxiv.org/pdf/2602.01705v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22496v1",
      "title": "Action-Sufficient Goal Representations",
      "abstract": "Hierarchical policies in offline goal-conditioned reinforcement learning (GCRL) addresses long-horizon tasks by decomposing control into high-level subgoal planning and low-level action execution. A critical design choice in such architectures is the goal representation-the compressed encoding of goals that serves as the interface between these levels. Existing approaches commonly derive goal representations while learning value functions, implicitly assuming that preserving information sufficient for value estimation is adequate for optimal control. We show that this assumption can fail, even when the value estimation is exact, as such representations may collapse goal states that need to be differentiated for action learning. To address this, we introduce an information-theoretic framework that defines action sufficiency, a condition on goal representations necessary for optimal action selection. We prove that value sufficiency does not imply action sufficiency and empirically verify that the latter is more strongly associated with control success in a discrete environment. We further demonstrate that standard log-loss training of low-level policies naturally induces action-sufficient representations. Our experimental results a popular benchmark demonstrate that our actor-derived representations consistently outperform representations learned via value estimation.",
      "authors": [
        "Jinu Hyeon",
        "Woobin Park",
        "Hongjoon Ahn",
        "Taesup Moon"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T03:08:37+00:00",
      "link": "https://arxiv.org/pdf/2601.22496v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.04417v1",
      "title": "EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL",
      "abstract": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential Moving Average (EMA), similar to a target network in deep Q-learning. Second, we introduce Top-k KL estimator, which allows for flexible interpolation between exact KL and sampled KL. We derive the stability conditions for using EMA anchor; moreover, we show that our Top-k KL estimator yields both unbiased KL values and unbiased gradients at any k, while bringing the benefits of exact KL. When combined with GRPO, the two techniques (EMA-PG) lead to a significant performance boost. On math reasoning, it allows R1-distilled Qwen-1.5B to reach 53.9% on OlympiadBench compared to 50.8% by GRPO. On agentic RL domains, with Qwen-3B base, EMA-PG improves GRPO by an average of 33.3% across 7 datasets of Q&A with search engines, including 29.7% $\\rightarrow$ 44.1% on HotpotQA, 27.4% $\\rightarrow$ 40.1% on 2WikiMultiHopQA. Overall, we show that EMA-PG is a simple, principled, and powerful approach to scaling RL for LLMs. Code: https://github.com/LunjunZhang/ema-pg",
      "authors": [
        "Lunjun Zhang",
        "Jimmy Ba"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-04T10:50:17+00:00",
      "link": "https://arxiv.org/pdf/2602.04417v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.23010v1",
      "title": "Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning",
      "abstract": "Offline Reinforcement Learning (RL) relies on policy constraints to mitigate extrapolation error, where both the constraint form and constraint strength critically shape performance. However, most existing methods commit to a single constraint family: weighted behavior cloning, density regularization, or support constraints, without a unified principle that explains their connections or trade-offs. In this work, we propose Continuous Constraint Interpolation (CCI), a unified optimization framework in which these three constraint families arise as special cases along a common constraint spectrum. The CCI framework introduces a single interpolation parameter that enables smooth transitions and principled combinations across constraint types. Building on CCI, we develop Automatic Constraint Policy Optimization (ACPO), a practical primal--dual algorithm that adapts the interpolation parameter via a Lagrangian dual update. Moreover, we establish a maximum-entropy performance difference lemma and derive performance lower bounds for both the closed-form optimal policy and its parametric projection. Experiments on D4RL and NeoRL2 demonstrate robust gains across diverse domains, achieving state-of-the-art performance overall.",
      "authors": [
        "Xinchen Han",
        "Qiuyang Fang",
        "Hossam Afifi",
        "Michel Marot"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T14:21:41+00:00",
      "link": "https://arxiv.org/pdf/2601.23010v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05863v1",
      "title": "Constrained Group Relative Policy Optimization",
      "abstract": "While Group Relative Policy Optimization (GRPO) has emerged as a scalable framework for critic-free policy learning, extending it to settings with explicit behavioral constraints remains underexplored. We introduce Constrained GRPO, a Lagrangian-based extension of GRPO for constrained policy optimization. Constraints are specified via indicator cost functions, enabling direct optimization of violation rates through a Lagrangian relaxation. We show that a naive multi-component treatment in advantage estimation can break constrained learning: mismatched component-wise standard deviations distort the relative importance of the different objective terms, which in turn corrupts the Lagrangian signal and prevents meaningful constraint enforcement. We formally derive this effect to motivate our scalarized advantage construction that preserves the intended trade-off between reward and constraint terms. Experiments in a toy gridworld confirm the predicted optimization pathology and demonstrate that scalarizing advantages restores stable constraint control. In addition, we evaluate Constrained GRPO on robotics tasks, where it improves constraint satisfaction while increasing task success, establishing a simple and effective recipe for constrained policy optimization in embodied AI domains that increasingly rely on large multimodal foundation models.",
      "authors": [
        "Roger Girgis",
        "Rodrigue de Schaetzen",
        "Luke Rowe",
        "Azalée Robitaille",
        "Christopher Pal",
        "Liam Paull"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.RO"
      ],
      "published": "2026-02-05T16:44:23+00:00",
      "link": "https://arxiv.org/pdf/2602.05863v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22491v1",
      "title": "SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization",
      "abstract": "Reinforcement learning with verifiable rewards has emerged as a powerful paradigm for training intelligent agents. However, existing methods typically employ binary rewards that fail to capture quality differences among trajectories achieving identical outcomes, thereby overlooking potential diversity within the solution space. Inspired by the ``sweet spot'' concept in tennis-the racket's core region that produces optimal hitting effects, we introduce \\textbf{S}weet \\textbf{S}pot \\textbf{L}earning (\\textbf{SSL}), a novel framework that provides differentiated guidance for agent optimization. SSL follows a simple yet effective principle: progressively amplified, tiered rewards guide policies toward the sweet-spot region of the solution space. This principle naturally adapts across diverse tasks: visual perception tasks leverage distance-tiered modeling to reward proximity, while complex reasoning tasks reward incremental progress toward promising solutions. We theoretically demonstrate that SSL preserves optimal solution ordering and enhances the gradient signal-to-noise ratio, thereby fostering more directed optimization. Extensive experiments across GUI perception, short/long-term planning, and complex reasoning tasks show consistent improvements over strong baselines on 12 benchmarks, achieving up to 2.5X sample efficiency gains and effective cross-task transferability. Our work establishes SSL as a general principle for training capable and robust agents.",
      "authors": [
        "Jinyang Wu",
        "Changpeng Yang",
        "Yuhao Shen",
        "Fangzhi Xu",
        "Bolin Ni",
        "Chonghua Liao",
        "Yuchen Liu",
        "Hongzhen Wang",
        "Shuai Nie",
        "Shuai Zhang",
        "Haoran Luo",
        "Jiaming Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-30T03:02:18+00:00",
      "link": "https://arxiv.org/pdf/2601.22491v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08646v3",
      "title": "Provably Safe Reinforcement Learning for Stochastic Reach-Avoid Problems with Entropy Regularization",
      "abstract": "We consider the problem of learning the optimal policy for Markov decision processes with safety constraints. We formulate the problem in a reach-avoid setup. Our goal is to design online reinforcement learning algorithms that ensure safety constraints with arbitrarily high probability during the learning phase. To this end, we first propose an algorithm based on the optimism in the face of uncertainty (OFU) principle. Based on the first algorithm, we propose our main algorithm, which utilizes entropy regularization. We investigate the finite-sample analysis of both algorithms and derive their regret bounds. We demonstrate that the inclusion of entropy regularization improves the regret and drastically controls the episode-to-episode variability that is inherent in OFU-based safe RL algorithms.",
      "authors": [
        "Abhijit Mazumdar",
        "Rafal Wisniewski",
        "Manuela L. Bujorianu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-13T15:23:19+00:00",
      "link": "https://arxiv.org/pdf/2601.08646v3",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01606v1",
      "title": "Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching",
      "abstract": "Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \\textbf{F}low-based \\textbf{L}og-likelihood-\\textbf{A}ware \\textbf{M}aximum \\textbf{E}ntropy RL (\\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at https://github.com/lzqw/FLAME.",
      "authors": [
        "Zeqiao Li",
        "Yijing Wang",
        "Haoyu Wang",
        "Zheng Li",
        "Zhiqiang Zuo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T03:54:11+00:00",
      "link": "https://arxiv.org/pdf/2602.01606v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.06336v2",
      "title": "Future-as-Label: Scalable Supervision from Real-World Outcomes",
      "abstract": "Time creates free supervision: forecasts about real-world events resolve to verifiable outcomes. The passage of time provides labels that require no annotation. To exploit this structure, we extend reinforcement learning with verifiable rewards to real-world prediction over time. We train language models to make probabilistic forecasts from causally masked information, using proper scoring rules as the reward function once events resolve. Learning is driven entirely by realized outcomes, enabling scalable outcome-based supervision in open-world prediction. On real-world forecasting benchmarks, Qwen3-32B trained using Foresight Learning improves Brier score by 27% and halves calibration error relative to its pretrained baseline, and outperforms Qwen3-235B on both constructed future-event prediction tasks and the Metaculus benchmark despite a 7x parameter disadvantage.",
      "authors": [
        "Benjamin Turtel",
        "Paul Wilczewski",
        "Danny Franklin",
        "Kris Skothiem"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-09T22:15:12+00:00",
      "link": "https://arxiv.org/pdf/2601.06336v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.05870v1",
      "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck",
      "abstract": "Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.",
      "authors": [
        "Huilin Deng",
        "Hongchen Luo",
        "Yue Zhu",
        "Long Li",
        "Zhuoyue Chen",
        "Xinghao Zhao",
        "Ming Li",
        "Jihai Zhang",
        "Mengchang Wang",
        "Yang Cao",
        "Yu Kang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-09T15:46:40+00:00",
      "link": "https://arxiv.org/pdf/2601.05870v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02722v1",
      "title": "Hierarchical Entity-centric Reinforcement Learning with Factored Subgoal Diffusion",
      "abstract": "We propose a hierarchical entity-centric framework for offline Goal-Conditioned Reinforcement Learning (GCRL) that combines subgoal decomposition with factored structure to solve long-horizon tasks in domains with multiple entities. Achieving long-horizon goals in complex environments remains a core challenge in Reinforcement Learning (RL). Domains with multiple entities are particularly difficult due to their combinatorial complexity. GCRL facilitates generalization across goals and the use of subgoal structure, but struggles with high-dimensional observations and combinatorial state-spaces, especially under sparse reward. We employ a two-level hierarchy composed of a value-based GCRL agent and a factored subgoal-generating conditional diffusion model. The RL agent and subgoal generator are trained independently and composed post hoc through selective subgoal generation based on the value function, making the approach modular and compatible with existing GCRL algorithms. We introduce new variations to benchmark tasks that highlight the challenges of multi-entity domains, and show that our method consistently boosts performance of the underlying RL agent on image-based long-horizon tasks with sparse rewards, achieving over 150% higher success rates on the hardest task in our suite and generalizing to increasing horizons and numbers of entities. Rollout videos are provided at: https://sites.google.com/view/hecrl",
      "authors": [
        "Dan Haramati",
        "Carl Qi",
        "Tal Daniel",
        "Amy Zhang",
        "Aviv Tamar",
        "George Konidaris"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.RO"
      ],
      "published": "2026-02-02T19:40:54+00:00",
      "link": "https://arxiv.org/pdf/2602.02722v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00629v1",
      "title": "Action-Free Offline-to-Online RL via Discretised State Policies",
      "abstract": "Most existing offline RL methods presume the availability of action labels within the dataset, but in many practical scenarios, actions may be missing due to privacy, storage, or sensor limitations. We formalise the setting of action-free offline-to-online RL, where agents must learn from datasets consisting solely of $(s,r,s')$ tuples and later leverage this knowledge during online interaction. To address this challenge, we propose learning state policies that recommend desirable next-state transitions rather than actions. Our contributions are twofold. First, we introduce a simple yet novel state discretisation transformation and propose Offline State-Only DecQN (\\algo), a value-based algorithm designed to pre-train state policies from action-free data. \\algo{} integrates the transformation to scale efficiently to high-dimensional problems while avoiding instability and overfitting associated with continuous state prediction. Second, we propose a novel mechanism for guided online learning that leverages these pre-trained state policies to accelerate the learning of online agents. Together, these components establish a scalable and practical framework for leveraging action-free datasets to accelerate online RL. Empirical results across diverse benchmarks demonstrate that our approach improves convergence speed and asymptotic performance, while analyses reveal that discretisation and regularisation are critical to its effectiveness.",
      "authors": [
        "Natinael Solomon Neggatu",
        "Jeremie Houssineau",
        "Giovanni Montana"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-31T09:53:04+00:00",
      "link": "https://arxiv.org/pdf/2602.00629v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.01460v1",
      "title": "Non-Uniform Noise-to-Signal Ratio in the REINFORCE Policy-Gradient Estimator",
      "abstract": "Policy-gradient methods are widely used in reinforcement learning, yet training often becomes unstable or slows down as learning progresses. We study this phenomenon through the noise-to-signal ratio (NSR) of a policy-gradient estimator, defined as the estimator variance (noise) normalized by the squared norm of the true gradient (signal). Our main result is that, for (i) finite-horizon linear systems with Gaussian policies and linear state-feedback, and (ii) finite-horizon polynomial systems with Gaussian policies and polynomial feedback, the NSR of the REINFORCE estimator can be characterized exactly-either in closed form or via numerical moment-evaluation algorithms-without approximation. For general nonlinear dynamics and expressive policies (including neural policies), we further derive a general upper bound on the variance. These characterizations enable a direct examination of how NSR varies across policy parameters and how it evolves along optimization trajectories (e.g. SGD and Adam). Across a range of examples, we find that the NSR landscape is highly non-uniform and typically increases as the policy approaches an optimum; in some regimes it blows up, which can trigger training instability and policy collapse.",
      "authors": [
        "Haoyu Han",
        "Heng Yang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-02-01T22:05:48+00:00",
      "link": "https://arxiv.org/pdf/2602.01460v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22044v1",
      "title": "SIA: Symbolic Interpretability for Anticipatory Deep Reinforcement Learning in Network Control",
      "abstract": "Deep reinforcement learning (DRL) promises adaptive control for future mobile networks but conventional agents remain reactive: they act on past and current measurements and cannot leverage short-term forecasts of exogenous KPIs such as bandwidth. Augmenting agents with predictions can overcome this temporal myopia, yet uptake in networking is scarce because forecast-aware agents act as closed-boxes; operators cannot tell whether predictions guide decisions or justify the added complexity. We propose SIA, the first interpreter that exposes in real time how forecast-augmented DRL agents operate. SIA fuses Symbolic AI abstractions with per-KPI Knowledge Graphs to produce explanations, and includes a new Influence Score metric. SIA achieves sub-millisecond speed, over 200x faster than existing XAI methods. We evaluate SIA on three diverse networking use cases, uncovering hidden issues, including temporal misalignment in forecast integration and reward-design biases that trigger counter-productive policies. These insights enable targeted fixes: a redesigned agent achieves a 9% higher average bitrate in video streaming, and SIA's online Action-Refinement module improves RAN-slicing reward by 25% without retraining. By making anticipatory DRL transparent and tunable, SIA lowers the barrier to proactive control in next-generation mobile networks.",
      "authors": [
        "MohammadErfan Jabbari",
        "Abhishek Duttagupta",
        "Claudio Fiandrino",
        "Leonardo Bonati",
        "Salvatore D'Oro",
        "Michele Polese",
        "Marco Fiore",
        "Tommaso Melodia"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "published": "2026-01-29T17:46:46+00:00",
      "link": "https://arxiv.org/pdf/2601.22044v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02708v1",
      "title": "BinaryPPO: Efficient Policy Optimization for Binary Classification",
      "abstract": "Supervised fine-tuning (SFT) is the standard approach for binary classification tasks such as toxicity detection, factuality verification, and causal inference. However, SFT often performs poorly in real-world settings with label noise, class imbalance, or sparse supervision. We introduce BinaryPPO, an offline reinforcement learning large language model (LLM) framework that reformulates binary classification as a reward maximization problem. Our method leverages a variant of Proximal Policy Optimization (PPO) with a confidence-weighted reward function that penalizes uncertain or incorrect predictions, enabling the model to learn robust decision policies from static datasets without online interaction. Across eight domain-specific benchmarks and multiple models with differing architectures, BinaryPPO improves accuracy by 40-60 percentage points, reaching up to 99%, substantially outperforming supervised baselines. We provide an in-depth analysis of the role of reward shaping, advantage scaling, and policy stability in enabling this improvement. Overall, we demonstrate that confidence-based reward design provides a robust alternative to SFT for binary classification. Our code is available at https://github.com/psyonp/BinaryPPO.",
      "authors": [
        "Punya Syon Pandey",
        "Zhijing Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-02T19:22:45+00:00",
      "link": "https://arxiv.org/pdf/2602.02708v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.18795v2",
      "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
      "abstract": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.",
      "authors": [
        "Amrith Setlur",
        "Zijian Wang",
        "Andrew Cohen",
        "Paria Rashidinejad",
        "Sang Michael Xie"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-26T18:57:00+00:00",
      "link": "https://arxiv.org/pdf/2601.18795v2",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07408v1",
      "title": "Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning",
      "abstract": "Group Relative Policy Optimization (GRPO) has emerged as a promising critic-free reinforcement learning paradigm for reasoning tasks. However, standard GRPO employs a coarse-grained credit assignment mechanism that propagates group-level rewards uniformly to to every token in a sequence, neglecting the varying contribution of individual reasoning steps. We address this limitation by introducing Outcome-grounded Advantage Reshaping (OAR), a fine-grained credit assignment mechanism that redistributes advantages based on how much each token influences the model's final answer. We instantiate OAR via two complementary strategies: (1) OAR-P, which estimates outcome sensitivity through counterfactual token perturbations, serving as a high-fidelity attribution signal; (2) OAR-G, which uses an input-gradient sensitivity proxy to approximate the influence signal with a single backward pass. These importance signals are integrated with a conservative Bi-Level advantage reshaping scheme that suppresses low-impact tokens and boosts pivotal ones while preserving the overall advantage mass. Empirical results on extensive mathematical reasoning benchmarks demonstrate that while OAR-P sets the performance upper bound, OAR-G achieves comparable gains with negligible computational overhead, both significantly outperforming a strong GRPO baseline, pushing the boundaries of critic-free LLM reasoning.",
      "authors": [
        "Ziheng Li",
        "Liu Kang",
        "Feng Xiao",
        "Luxi Xing",
        "Qingyi Si",
        "Zhuoran Li",
        "Weikang Gong",
        "Deqing Yang",
        "Yanghua Xiao",
        "Hongcheng Guo"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-12T10:48:02+00:00",
      "link": "https://arxiv.org/pdf/2601.07408v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.05776v1",
      "title": "Cross-Domain Offline Policy Adaptation via Selective Transition Correction",
      "abstract": "It remains a critical challenge to adapt policies across domains with mismatched dynamics in reinforcement learning (RL). In this paper, we study cross-domain offline RL, where an offline dataset from another similar source domain can be accessed to enhance policy learning upon a target domain dataset. Directly merging the two datasets may lead to suboptimal performance due to potential dynamics mismatches. Existing approaches typically mitigate this issue through source domain transition filtering or reward modification, which, however, may lead to insufficient exploitation of the valuable source domain data. Instead, we propose to modify the source domain data into the target domain data. To that end, we leverage an inverse policy model and a reward model to correct the actions and rewards of source transitions, explicitly achieving alignment with the target dynamics. Since limited data may result in inaccurate model training, we further employ a forward dynamics model to retain corrected samples that better match the target dynamics than the original transitions. Consequently, we propose the Selective Transition Correction (STC) algorithm, which enables reliable usage of source domain data for policy adaptation. Experiments on various environments with dynamics shifts demonstrate that STC achieves superior performance against existing baselines.",
      "authors": [
        "Mengbei Yan",
        "Jiafei Lyu",
        "Shengjie Sun",
        "Zhongjian Qiao",
        "Jingwen Yang",
        "Zichuan Lin",
        "Deheng Ye",
        "Xiu Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T15:37:29+00:00",
      "link": "https://arxiv.org/pdf/2602.05776v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22595v1",
      "title": "Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR",
      "abstract": "Large Language Models (LLMs) have recently improved mathematical reasoning through Reinforcement Learning with Verifiable Reward (RLVR). However, existing RLVR algorithms require large query budgets, making annotation costly. We investigate whether fewer but more informative queries can yield similar or superior performance, introducing active learning (AL) into RLVR. We identify that classic AL sampling strategies fail to outperform random selection in this setting, due to ignoring objective uncertainty when only selecting by subjective uncertainty. This work proposes an uncertainty consistency metric to evaluate how well subjective uncertainty aligns with objective uncertainty. In the offline setting, this alignment is measured using the Point-Biserial Correlation Coefficient (PBC). For online training, because of limited sampling and dynamically shifting output distributions, PBC estimation is difficult. Therefore, we introduce a new online variant, computed from normalized advantage and subjective uncertainty. Theoretically, we prove that the online variant is strictly negatively correlated with offline PBC and supports better sample selection. Experiments show our method consistently outperforms random and classic AL baselines, achieving full-dataset performance while training on only 30% of the data, effectively reducing the cost of RLVR for reasoning tasks.",
      "authors": [
        "Hao Yi",
        "Yulan Hu",
        "Xin Li",
        "Sheng Ouyang",
        "Lizhong Ding",
        "Yong Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T05:41:55+00:00",
      "link": "https://arxiv.org/pdf/2601.22595v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.05019v1",
      "title": "A Simple Reduction Scheme for Constrained Contextual Bandits with Adversarial Contexts via Regression",
      "abstract": "We study constrained contextual bandits (CCB) with adversarially chosen contexts, where each action yields a random reward and incurs a random cost. We adopt the standard realizability assumption: conditioned on the observed context, rewards and costs are drawn independently from fixed distributions whose expectations belong to known function classes. We consider the continuing setting, in which the algorithm operates over the entire horizon even after the budget is exhausted. In this setting, the objective is to simultaneously control regret and cumulative constraint violation. Building on the seminal SquareCB framework of Foster et al. (2018), we propose a simple and modular algorithmic scheme that leverages online regression oracles to reduce the constrained problem to a standard unconstrained contextual bandit problem with adaptively defined surrogate reward functions. In contrast to most prior work on CCB, which focuses on stochastic contexts, our reduction yields improved guarantees for the more general adversarial context setting, together with a compact and transparent analysis.",
      "authors": [
        "Dhruv Sarkar",
        "Abhishek Sinha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T20:19:55+00:00",
      "link": "https://arxiv.org/pdf/2602.05019v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05281v1",
      "title": "Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an indispensable paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard policy optimization methods, such as Group Relative Policy Optimization (GRPO), often converge to low-entropy policies, leading to severe mode collapse and limited output diversity. We analyze this issue from the perspective of sampling probability dynamics, identifying that the standard objective disproportionately reinforces the highest-likelihood paths, thereby suppressing valid alternative reasoning chains. To address this, we propose a novel Advantage Re-weighting Mechanism (ARM) designed to equilibrate the confidence levels across all correct responses. By incorporating Prompt Perplexity and Answer Confidence into the advantage estimation, our method dynamically reshapes the reward signal to attenuate the gradient updates of over-confident reasoning paths, while redistributing probability mass toward under-explored correct solutions. Empirical results demonstrate that our approach significantly enhances generative diversity and response entropy while maintaining competitive accuracy, effectively achieving a superior trade-off between exploration and exploitation in reasoning tasks. Empirical results on Qwen2.5 and DeepSeek models across mathematical and coding benchmarks show that ProGRPO significantly mitigates entropy collapse. Specifically, on Qwen2.5-7B, our method outperforms GRPO by 5.7% in Pass@1 and, notably, by 13.9% in Pass@32, highlighting its superior capability in generating diverse correct reasoning paths.",
      "authors": [
        "Pengyi Li",
        "Elizaveta Goncharova",
        "Andrey Kuznetsov",
        "Ivan Oseledets"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-05T04:06:55+00:00",
      "link": "https://arxiv.org/pdf/2602.05281v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2602.02900v1",
      "title": "Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning",
      "abstract": "Model-based offline reinforcement learning is brittle under distribution shift: policy improvement drives rollouts into state--action regions weakly supported by the dataset, where compounding model error yields severe value overestimation. We propose Manifold-Constrained Energy-based Transition Models (MC-ETM), which train conditional energy-based transition models using a manifold projection--diffusion negative sampler. MC-ETM learns a latent manifold of next states and generates near-manifold hard negatives by perturbing latent codes and running Langevin dynamics in latent space with the learned conditional energy, sharpening the energy landscape around the dataset support and improving sensitivity to subtle out-of-distribution deviations. For policy optimization, the learned energy provides a single reliability signal: rollouts are truncated when the minimum energy over sampled next states exceeds a threshold, and Bellman backups are stabilized via pessimistic penalties based on Q-value-level dispersion across energy-guided samples. We formalize MC-ETM through a hybrid pessimistic MDP formulation and derive a conservative performance bound separating in-support evaluation error from truncation risk. Empirically, MC-ETM improves multi-step dynamics fidelity and yields higher normalized returns on standard offline control benchmarks, particularly under irregular dynamics and sparse data coverage.",
      "authors": [
        "Zeyu Fang",
        "Zuyuan Zhang",
        "Mahdi Imani",
        "Tian Lan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T23:15:43+00:00",
      "link": "https://arxiv.org/pdf/2602.02900v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.19612v1",
      "title": "Safe Exploration via Policy Priors",
      "abstract": "Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative policy prior if needed. We prove that SOOPER guarantees safety throughout learning, and establish convergence to an optimal policy by bounding its cumulative regret. Extensive experiments on key safe RL benchmarks and real-world hardware demonstrate that SOOPER is scalable, outperforms the state-of-the-art and validate our theoretical guarantees in practice.",
      "authors": [
        "Manuel Wendl",
        "Yarden As",
        "Manish Prajapat",
        "Anton Pollak",
        "Stelian Coros",
        "Andreas Krause"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-27T13:45:28+00:00",
      "link": "https://arxiv.org/pdf/2601.19612v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.10079v1",
      "title": "Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts",
      "abstract": "Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment.",
      "authors": [
        "Sijia Luo",
        "Xiaokang Zhang",
        "Yuxuan Hu",
        "Bohan Zhang",
        "Ke Wang",
        "Jinbo Su",
        "Mengshu Sun",
        "Lei Liang",
        "Jing Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-15T05:12:03+00:00",
      "link": "https://arxiv.org/pdf/2601.10079v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05630v1",
      "title": "Rewards as Labels: Revisiting RLVR from a Classification Perspective",
      "abstract": "Reinforcement Learning with Verifiable Rewards has recently advanced the capabilities of Large Language Models in complex reasoning tasks by providing explicit rule-based supervision. Among RLVR methods, GRPO and its variants have achieved strong empirical performance. Despite their success, we identify that they suffer from Gradient Misassignment in Positives and Gradient Domination in Negatives, which lead to inefficient and suboptimal policy updates. To address these issues, we propose Rewards as Labels (REAL), a novel framework that revisits verifiable rewards as categorical labels rather than scalar weights, thereby reformulating policy optimization as a classification problem. Building on this, we further introduce anchor logits to enhance policy learning. Our analysis reveals that REAL induces a monotonic and bounded gradient weighting, enabling balanced gradient allocation across rollouts and effectively mitigating the identified mismatches. Extensive experiments on mathematical reasoning benchmarks show that REAL improves training stability and consistently outperforms GRPO and strong variants such as DAPO. On the 1.5B model, REAL improves average Pass@1 over DAPO by 6.7%. These gains further scale to 7B model, REAL continues to outperform DAPO and GSPO by 6.2% and 1.7%, respectively. Notably, even with a vanilla binary cross-entropy, REAL remains stable and exceeds DAPO by 4.5% on average.",
      "authors": [
        "Zepeng Zhai",
        "Meilin Chen",
        "Jiaxuan Zhao",
        "Junlang Qian",
        "Lei Shen",
        "Yuan Lu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-02-05T13:11:36+00:00",
      "link": "https://arxiv.org/pdf/2602.05630v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02555v1",
      "title": "Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) improves LLM reasoning, yet growing evidence indicates an exploration ceiling: it often reweights existing solution traces rather than discovering new strategies, limiting gains under large sampling budgets (e.g., pass-at-256). We address this limitation with PSN-RLVR, which perturbs policy parameters before rollout generation to induce temporally consistent, trajectory-level exploration that better preserves long-horizon chain-of-thought coherence than action-space noise. To mitigate the resulting sampling-update mismatch, we incorporate truncated importance sampling (TIS). To avoid expensive KL-based adaptive noise control, we propose a computationally efficient real-time adaptive noise scheduler driven by a lightweight surrogate that combines semantic diversity with normalized self-certainty. Instantiated on GRPO, a widely used RLVR method, PSN-GRPO consistently expands the effective reasoning capability boundary across multiple mathematical reasoning benchmarks and model families, yielding higher pass-at-k under large sampling budgets and outperforming prior exploration-oriented RLVR methods (e.g., Pass-at-k-style training) while remaining orthogonal and thus composable for additional gains.",
      "authors": [
        "Bizhe Bai",
        "Xinyue Wang",
        "Peng Ye",
        "Tao Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T13:10:30+00:00",
      "link": "https://arxiv.org/pdf/2602.02555v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.20193v1",
      "title": "Meta-Cognitive Reinforcement Learning with Self-Doubt and Recovery",
      "abstract": "Robust reinforcement learning methods typically focus on suppressing unreliable experiences or corrupted rewards, but they lack the ability to reason about the reliability of their own learning process. As a result, such methods often either overreact to noise by becoming overly conservative or fail catastrophically when uncertainty accumulates.   In this work, we propose a meta-cognitive reinforcement learning framework that enables an agent to assess, regulate, and recover its learning behavior based on internally estimated reliability signals. The proposed method introduces a meta-trust variable driven by Value Prediction Error Stability (VPES), which modulates learning dynamics via fail-safe regulation and gradual trust recovery.   Experiments on continuous-control benchmarks with reward corruption demonstrate that recovery-enabled meta-cognitive control achieves higher average returns and significantly reduces late-stage training failures compared to strong robustness baselines.",
      "authors": [
        "Zhipeng Zhang",
        "Wenting Ma",
        "Kai Li",
        "Meng Guo",
        "Lei Yang",
        "Wei Yu",
        "Hongji Cui",
        "Yichen Zhang",
        "Mo Zhang",
        "Jinzhe Lin",
        "Zhenjie Yao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T02:43:03+00:00",
      "link": "https://arxiv.org/pdf/2601.20193v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02924v1",
      "title": "How Does the Lagrangian Guide Safe Reinforcement Learning through Diffusion Models?",
      "abstract": "Diffusion policy sampling enables reinforcement learning (RL) to represent multimodal action distributions beyond suboptimal unimodal Gaussian policies. However, existing diffusion-based RL methods primarily focus on offline settings for reward maximization, with limited consideration of safety in online settings. To address this gap, we propose Augmented Lagrangian-Guided Diffusion (ALGD), a novel algorithm for off-policy safe RL. By revisiting optimization theory and energy-based model, we show that the instability of primal-dual methods arises from the non-convex Lagrangian landscape. In diffusion-based safe RL, the Lagrangian can be interpreted as an energy function guiding the denoising dynamics. Counterintuitively, direct usage destabilizes both policy generation and training. ALGD resolves this issue by introducing an augmented Lagrangian that locally convexifies the energy landscape, yielding a stabilized policy generation and training process without altering the distribution of the optimal policy. Theoretical analysis and extensive experiments demonstrate that ALGD is both theoretically grounded and empirically effective, achieving strong and stable performance across diverse environments.",
      "authors": [
        "Xiaoyuan Cheng",
        "Wenxuan Yuan",
        "Boyang Li",
        "Yuanchao Xu",
        "Yiming Yang",
        "Hao Liang",
        "Bei Peng",
        "Robert Loftin",
        "Zhuo Sun",
        "Yukun Hu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "published": "2026-02-02T23:53:53+00:00",
      "link": "https://arxiv.org/pdf/2602.02924v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.11401v1",
      "title": "Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning",
      "abstract": "Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constructions can be difficult to estimate and ill-behaved in infinite-horizon settings. We introduce the Diffusion Value Function (DVF), a factored value function for GMDPs that assigns to each agent a value component by diffusing rewards over the influence graph with temporal discounting and spatial attenuation. We show that DVF is well-defined, admits a Bellman fixed point, and decomposes the global discounted value via an averaging property. DVF can be used as a drop-in critic in standard RL algorithms and estimated scalably with graph neural networks. Building on DVF, we propose Diffusion A2C (DA2C) and a sparse message-passing actor, Learned DropEdge GNN (LD-GNN), for learning decentralised algorithms under communication costs. Across the firefighting benchmark and three distributed computation tasks (vector graph colouring and two transmit power optimisation problems), DA2C consistently outperforms local and global critic baselines, improving average reward by up to 11%.",
      "authors": [
        "Ahmed Rashwan",
        "Keith Briggs",
        "Chris Budd",
        "Lisa Kreusser"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-16T16:11:50+00:00",
      "link": "https://arxiv.org/pdf/2601.11401v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.07524v1",
      "title": "Stagewise Reinforcement Learning and the Geometry of the Regret Landscape",
      "abstract": "Singular learning theory characterizes Bayesian learning as an evolving tradeoff between accuracy and complexity, with transitions between qualitatively different solutions as sample size increases. We extend this theory to deep reinforcement learning, proving that the concentration of the generalized posterior over policies is governed by the local learning coefficient (LLC), an invariant of the geometry of the regret function. This theory predicts that Bayesian phase transitions in reinforcement learning should proceed from simple policies with high regret to complex policies with low regret. We verify this prediction empirically in a gridworld environment exhibiting stagewise policy development: phase transitions over SGD training manifest as \"opposing staircases\" where regret decreases sharply while the LLC increases. Notably, the LLC detects phase transitions even when estimated on a subset of states where the policies appear identical in terms of regret, suggesting it captures changes in the underlying algorithm rather than just performance.",
      "authors": [
        "Chris Elliott",
        "Einar Urdshals",
        "David Quarel",
        "Matthew Farrugia-Roberts",
        "Daniel Murfet"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-12T13:25:21+00:00",
      "link": "https://arxiv.org/pdf/2601.07524v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.02488v1",
      "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
      "abstract": "We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized via consistency feedback, which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench, respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
      "authors": [
        "Yinjie Wang",
        "Tianbao Xie",
        "Ke Shen",
        "Mengdi Wang",
        "Ling Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-02-02T18:59:04+00:00",
      "link": "https://arxiv.org/pdf/2602.02488v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18751v1",
      "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",
      "abstract": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.",
      "authors": [
        "Seyed Amir Hosseini",
        "Maryam Abdolali",
        "Amirhosein Tavakkoli",
        "Fardin Ayar",
        "Ehsan Javanmardi",
        "Manabu Tsukada",
        "Mahdi Javanmardi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-26T18:21:48+00:00",
      "link": "https://arxiv.org/pdf/2601.18751v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03876v1",
      "title": "GOPO: Policy Optimization using Ranked Rewards",
      "abstract": "Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitudes during training. In settings where the rewards are non-verifiable such as summarization, instruction following, and chat completion, this misalignment often leads to suboptimal performance. We introduce Group Ordinal Policy Optimization (GOPO), a policy optimization method that uses only the ranking of the rewards and discards their magnitudes. Our rank-based transformation of rewards provides several gains, compared to Group Relative Policy Optimization (GRPO), in settings with non-verifiable rewards: (1) consistently higher training/validation reward trajectories, (2) improved LLM-as-judge evaluations across most intermediate training steps, and (3) reaching a policy of comparable quality in substantially less training steps than GRPO. We demonstrate consistent improvements across a range of tasks and model sizes.",
      "authors": [
        "Kyuseong Choi",
        "Dwaipayan Saha",
        "Woojeong Kim",
        "Anish Agarwal",
        "Raaz Dwivedi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-01T22:07:11+00:00",
      "link": "https://arxiv.org/pdf/2602.03876v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16403v1",
      "title": "Towards a Theoretical Understanding to the Generalization of RLHF",
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \\textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\\mathcal{O}(n^{-\\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.",
      "authors": [
        "Zhaochun Li",
        "Mingyang Yi",
        "Yue Wang",
        "Shisheng Cui",
        "Yong Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-23T02:30:16+00:00",
      "link": "https://arxiv.org/pdf/2601.16403v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.19707v1",
      "title": "Scalable Exploration for High-Dimensional Continuous Control via Value-Guided Flow",
      "abstract": "Controlling high-dimensional systems in biological and robotic applications is challenging due to expansive state-action spaces, where effective exploration is critical. Commonly used exploration strategies in reinforcement learning are largely undirected with sharp degradation as action dimensionality grows. Many existing methods resort to dimensionality reduction, which constrains policy expressiveness and forfeits system flexibility. We introduce Q-guided Flow Exploration (Qflex), a scalable reinforcement learning method that conducts exploration directly in the native high-dimensional action space. During training, Qflex traverses actions from a learnable source distribution along a probability flow induced by the learned value function, aligning exploration with task-relevant gradients rather than isotropic noise. Our proposed method substantially outperforms representative online reinforcement learning baselines across diverse high-dimensional continuous-control benchmarks. Qflex also successfully controls a full-body human musculoskeletal model to perform agile, complex movements, demonstrating superior scalability and sample efficiency in very high-dimensional settings. Our results indicate that value-guided flows offer a principled and practical route to exploration at scale.",
      "authors": [
        "Yunyue Wei",
        "Chenhui Zuo",
        "Yanan Sui"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-27T15:30:10+00:00",
      "link": "https://arxiv.org/pdf/2601.19707v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05933v1",
      "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
      "abstract": "Policy mirror descent (PMD) provides a principled framework for reinforcement learning (RL) by iteratively solving KL-regularized policy improvement subproblems. While this approach has been adopted in training advanced LLMs such as Kimi K1.5/K2, the ideal closed-form PMD updates require reliable partition function estimation, a significant challenge when working with limited rollouts in the vast action spaces of LLMs. We investigate a practical algorithm, termed PMD-mean, that approximates the log-partition term with the mean reward under the sampling policy and performs regression in log-policy space. Specifically, we characterize the population solution of PMD-mean and demonstrate that it implicitly optimizes mirror descent subproblems with an adaptive mixed KL--$χ^2$ regularizer. This additional $χ^2$ regularization constrains large probability changes, producing more conservative updates when expected rewards are low and enhancing robustness against finite-sample estimation errors. Experiments on math reasoning tasks show that PMD-mean achieves superior performance with improved stability and time efficiency. These findings deepen our understanding of PMD-mean and illuminate pathways toward principled improvements in RL algorithms for LLMs. Code is available at https://github.com/horizon-rl/OpenKimi.",
      "authors": [
        "Zhenghao Xu",
        "Qin Lu",
        "Changlong Yu",
        "Tuo Zhao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T17:44:28+00:00",
      "link": "https://arxiv.org/pdf/2602.05933v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.01511v1",
      "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
      "abstract": "Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.",
      "authors": [
        "Ran Xu",
        "Tianci Liu",
        "Zihan Dong",
        "Tony You",
        "Ilgee Hong",
        "Carl Yang",
        "Linjun Zhang",
        "Tao Zhao",
        "Haoyu Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-02-02T00:50:53+00:00",
      "link": "https://arxiv.org/pdf/2602.01511v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.22900v1",
      "title": "MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is widely used to improve reasoning in multiple domains, yet outcome-only scalar rewards are often sparse and uninformative, especially on failed samples, where they merely indicate failure and provide no insight into why the reasoning fails. In this paper, we investigate how to leverage richer verbal feedback to guide RLVR training on failed samples, and how to convert such feedback into a trainable learning signal. Specifically, we propose a multi-turn feedback-guided reinforcement learning framework. It builds on three mechanisms: (1) dynamic multi-turn regeneration guided by feedback, triggered only on failed samples, (2) two complementary learning signals for within-turn and cross-turn optimization, and (3) structured feedback injection into the model's reasoning process. Trained on sampled OpenR1-Math, the approach outperforms supervised fine-tuning and RLVR baselines in-domain and generalizes well out-of-domain.",
      "authors": [
        "Xuancheng Li",
        "Haitao Li",
        "Yujia Zhou",
        "YiqunLiu",
        "Qingyao Ai"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-30T12:19:54+00:00",
      "link": "https://arxiv.org/pdf/2601.22900v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.00921v1",
      "title": "On the Convergence of Jacobian-Free Backpropagation for Optimal Control Problems with Implicit Hamiltonians",
      "abstract": "Optimal feedback control with implicit Hamiltonians poses a fundamental challenge for learning-based value function methods due to the absence of closed-form optimal control laws. Recent work~\\cite{gelphman2025end} introduced an implicit deep learning approach using Jacobian-Free Backpropagation (JFB) to address this setting, but only established sample-wise descent guarantees. In this paper, we establish convergence guarantees for JFB in the stochastic minibatch setting, showing that the resulting updates converge to stationary points of the expected optimal control objective. We further demonstrate scalability on substantially higher-dimensional problems, including multi-agent optimal consumption and swarm-based quadrotor and bicycle control. Together, our results provide both theoretical justification and empirical evidence for using JFB in high-dimensional optimal control with implicit Hamiltonians.",
      "authors": [
        "Eric Gelphman",
        "Deepanshu Verma",
        "Nicole Tianjiao Yang",
        "Stanley Osher",
        "Samy Wu Fung"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-01-31T22:25:46+00:00",
      "link": "https://arxiv.org/pdf/2602.00921v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15363v1",
      "title": "Non-Stationary Functional Bilevel Optimization",
      "abstract": "Functional bilevel optimization (FBO) provides a powerful framework for hierarchical learning in function spaces, yet current methods are limited to static offline settings and perform suboptimally in online, non-stationary scenarios. We propose SmoothFBO, the first algorithm for non-stationary FBO with both theoretical guarantees and practical scalability. SmoothFBO introduces a time-smoothed stochastic hypergradient estimator that reduces variance through a window parameter, enabling stable outer-loop updates with sublinear regret. Importantly, the classical parametric bilevel case is a special reduction of our framework, making SmoothFBO a natural extension to online, non-stationary settings. Empirically, SmoothFBO consistently outperforms existing FBO methods in non-stationary hyperparameter optimization and model-based reinforcement learning, demonstrating its practical effectiveness. Together, these results establish SmoothFBO as a general, theoretically grounded, and practically viable foundation for bilevel optimization in online, non-stationary scenarios.",
      "authors": [
        "Jason Bohne",
        "Ieva Petrulionyte",
        "Michael Arbel",
        "Julien Mairal",
        "Paweł Polak"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-21T14:35:23+00:00",
      "link": "https://arxiv.org/pdf/2601.15363v1",
      "tags": [
        "keyword:SR",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.15141v1",
      "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning",
      "abstract": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub",
      "authors": [
        "Tianshi Xu",
        "Yuteng Chen",
        "Meng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21T16:14:30+00:00",
      "link": "https://arxiv.org/pdf/2601.15141v1",
      "tags": [
        "keyword:SR"
      ]
    },
    {
      "id": "2601.21958v1",
      "title": "Linear systems on rational surfaces",
      "abstract": "Motivated by various equivalent versions of the SHGH conjecture for $\\mathbb{P}^2$ blown up at very general points, we propose a similar conjecture for Hirzebruch surfaces. We prove that this conjecture is true for the Hirzebruch surface $\\mathbb{F}_e$ blown up at $r\\leqslant e+4$ very general points.",
      "authors": [
        "Cyril J. Jacob",
        "Ronnie Sebastian"
      ],
      "primary_category": "math.AG",
      "categories": [
        "math.AG"
      ],
      "published": "2026-01-29T16:35:44+00:00",
      "link": "https://arxiv.org/pdf/2601.21958v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR",
        "query:SR-LNS",
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.03642v2",
      "title": "The largest prime factor of an irreducible cubic polynomial",
      "abstract": "Heath-Brown proved that for a positive proportion of integers $n$, $n^3+2$ has a prime factor larger than $n^{1+c}$ with $c=10^{-303}$.   We generalize this result to arbitrary monic irreducible cubic polynomial of $\\mathbb{Z}[x]$ with $c$ replaced by an exponent $c_p$ dependent on the polynomial.",
      "authors": [
        "Ivan Ermoshin"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-03T15:26:31+00:00",
      "link": "https://arxiv.org/pdf/2602.03642v2",
      "tags": [
        "query:SR",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13953v2",
      "title": "Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition",
      "abstract": "Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to \"fuzzy\" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.   We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.",
      "authors": [
        "Gorgi Pavlov"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AR",
        "cs.LO"
      ],
      "published": "2026-01-20T13:26:52+00:00",
      "link": "https://arxiv.org/pdf/2601.13953v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07372v1",
      "title": "Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models",
      "abstract": "While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated via Engram, a module that modernizes classic $N$-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, we scale Engram to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. Most notably, while the memory module is expected to aid knowledge retrieval (e.g., MMLU +3.4; CMMLU +4.0), we observe even larger gains in general reasoning (e.g., BBH +5.0; ARC-Challenge +3.7) and code/math domains~(HumanEval +3.0; MATH +2.4). Mechanistic analyses reveal that Engram relieves the backbone's early layers from static reconstruction, effectively deepening the network for complex reasoning. Furthermore, by delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval (e.g., Multi-Query NIAH: 84.2 to 97.0). Finally, Engram establishes infrastructure-aware efficiency: its deterministic addressing enables runtime prefetching from host memory, incurring negligible overhead. We envision conditional memory as an indispensable modeling primitive for next-generation sparse models.",
      "authors": [
        "Xin Cheng",
        "Wangding Zeng",
        "Damai Dai",
        "Qinyu Chen",
        "Bingxuan Wang",
        "Zhenda Xie",
        "Kezhao Huang",
        "Xingkai Yu",
        "Zhewen Hao",
        "Yukun Li",
        "Han Zhang",
        "Huishuai Zhang",
        "Dongyan Zhao",
        "Wenfeng Liang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-12T09:54:49+00:00",
      "link": "https://arxiv.org/pdf/2601.07372v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21623v1",
      "title": "LAMP: Look-Ahead Mixed-Precision Inference of Large Language Models",
      "abstract": "Mixed-precision computations are a hallmark of the current stage of AI, driving the progress in large language models towards efficient, locally deployable solutions. This article addresses the floating-point computation of compositionally-rich functions, concentrating on transformer inference. Based on the rounding error analysis of a composition $f(g(\\mathrm{x}))$, we provide an adaptive strategy that selects a small subset of components of $g(\\mathrm{x})$ to be computed more accurately while all other computations can be carried out with lower accuracy. We then explain how this strategy can be applied to different compositions within a transformer and illustrate its overall effect on transformer inference. We study the effectiveness of this algorithm numerically on GPT-2 models and demonstrate that already very low recomputation rates allow for improvements of up to two orders of magnitude in accuracy.",
      "authors": [
        "Stanislav Budzinskiy",
        "Marian Gloser",
        "Tolunay Yilmaz",
        "Ying Hong Tham",
        "Yuanyi Lin",
        "Wenyi Fang",
        "Fan Wu",
        "Philipp Petersen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "published": "2026-01-29T12:26:00+00:00",
      "link": "https://arxiv.org/pdf/2601.21623v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03539v2",
      "title": "Optimal neural network approximation of smooth compositional functions on sets with low intrinsic dimension",
      "abstract": "We study approximation and statistical learning properties of deep ReLU networks under structural assumptions that mitigate the curse of dimensionality. We prove minimax-optimal uniform approximation rates for $s$-Hölder smooth functions defined on sets with low Minkowski dimension using fully connected networks with flexible width and depth, improving existing results by logarithmic factors even in classical full-dimensional settings. A key technical ingredient is a new memorization result for deep ReLU networks that enables efficient point fitting with dense architectures. We further introduce a class of compositional models in which each component function is smooth and acts on a domain of low intrinsic dimension. This framework unifies two common assumptions in the statistical learning literature, structural constraints on the target function and low dimensionality of the covariates, within a single model. We show that deep networks can approximate such functions at rates determined by the most difficult function in the composition. As an application, we derive improved convergence rates for empirical risk minimization in nonparametric regression that adapt to smoothness, compositional structure, and intrinsic dimensionality.",
      "authors": [
        "Thomas Nagler",
        "Sophie Langer"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-02-03T13:54:31+00:00",
      "link": "https://arxiv.org/pdf/2602.03539v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15214v1",
      "title": "A Complete Propositional Dynamic Logic for Regular Expressions with Lookahead",
      "abstract": "We consider (logical) reasoning for regular expressions with lookahead (REwLA). In this paper, we give an axiomatic characterization for both the (match-)language equivalence and the largest substitution-closed equivalence that is sound for the (match-)language equivalence. To achieve this, we introduce a variant of propositional dynamic logic (PDL) on finite linear orders, extended with two operators: the restriction to the identity relation and the restriction to its complement. Our main contribution is a sound and complete Hilbert-style finite axiomatization for the logic, which captures the equivalences of REwLA. Using the extended operators, the completeness is established via a reduction into an identity-free variant of PDL on finite strict linear orders. Moreover, the extended PDL has the same computational complexity as REwLA.",
      "authors": [
        "Yoshiki Nakamura"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO",
        "cs.FL"
      ],
      "published": "2026-01-21T17:39:30+00:00",
      "link": "https://arxiv.org/pdf/2601.15214v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21601v1",
      "title": "Dynamics Reveals Structure: Challenging the Linear Propagation Assumption",
      "abstract": "Neural networks adapt through first-order parameter updates, yet it remains unclear whether such updates preserve logical coherence. We investigate the geometric limits of the Linear Propagation Assumption (LPA), the premise that local updates coherently propagate to logical consequences. To formalize this, we adopt relation algebra and study three core operations on relations: negation flips truth values, converse swaps argument order, and composition chains relations. For negation and converse, we prove that guaranteeing direction-agnostic first-order propagation necessitates a tensor factorization separating entity-pair context from relation content. However, for composition, we identify a fundamental obstruction. We show that composition reduces to conjunction, and prove that any conjunction well-defined on linear features must be bilinear. Since bilinearity is incompatible with negation, this forces the feature map to collapse. These results suggest that failures in knowledge editing, the reversal curse, and multi-hop reasoning may stem from common structural limitations inherent to the LPA.",
      "authors": [
        "Hoyeon Chang",
        "Bálint Mucsányi",
        "Seong Joon Oh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T12:08:00+00:00",
      "link": "https://arxiv.org/pdf/2601.21601v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16038v1",
      "title": "Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval",
      "abstract": "Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.",
      "authors": [
        "Olga Bunkova",
        "Lorenzo Di Fruscia",
        "Sophia Rupprecht",
        "Artur M. Schweidtmann",
        "Marcel J. T. Reinders",
        "Jana M. Weber"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22T15:11:02+00:00",
      "link": "https://arxiv.org/pdf/2601.16038v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03290v1",
      "title": "Universal Approximation of Continuous Functionals on Compact Subsets via Linear Measurements and Scalar Nonlinearities",
      "abstract": "We study universal approximation of continuous functionals on compact subsets of products of Hilbert spaces. We prove that any such functional can be uniformly approximated by models that first take finitely many continuous linear measurements of the inputs and then combine these measurements through continuous scalar nonlinearities. We also extend the approximation principle to maps with values in a Banach space, yielding finite-rank approximations. These results provide a compact-set justification for the common ``measure, apply scalar nonlinearities, then combine'' design pattern used in operator learning and imaging.",
      "authors": [
        "Andrey Krylov",
        "Maksim Penkin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.FA"
      ],
      "published": "2026-02-03T09:16:50+00:00",
      "link": "https://arxiv.org/pdf/2602.03290v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01075v2",
      "title": "ConvexBench: Can LLMs Recognize Convex Functions?",
      "abstract": "Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \\cb, a scalable and mechanically verifiable benchmark for testing \\textit{whether LLMs can identify the convexity of a symbolic objective under deep functional composition.} Experiments on frontier LLMs reveal a sharp compositional reasoning gap: performance degrades rapidly with increasing depth, dropping from an F1-score of $1.0$ at depth $2$ to approximately $0.2$ at depth $100$. Inspection of models' reasoning traces indicates two failure modes: \\textit{parsing failure} and \\textit{lazy reasoning}. To address these limitations, we propose an agentic divide-and-conquer framework that (i) offloads parsing to an external tool to construct an abstract syntax tree (AST) and (ii) enforces recursive reasoning over each intermediate sub-expression with focused context. This framework reliably mitigates deep-composition failures, achieving substantial performance improvement at large depths (e.g., F1-Score $= 1.0$ at depth $100$).",
      "authors": [
        "Yepeng Liu",
        "Yu Huang",
        "Yu-Xiang Wang",
        "Yingbin Liang",
        "Yuheng Bu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-01T07:41:17+00:00",
      "link": "https://arxiv.org/pdf/2602.01075v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17188v1",
      "title": "Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction",
      "abstract": "The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.",
      "authors": [
        "Swapn Shah",
        "Wlodek Zadrozny"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-23T21:38:19+00:00",
      "link": "https://arxiv.org/pdf/2601.17188v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14710v1",
      "title": "Case-Guided Sequential Assay Planning in Drug Discovery",
      "abstract": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.",
      "authors": [
        "Tianchi Chen",
        "Jan Bima",
        "Sean L. Wu",
        "Otto Ritter",
        "Bingjia Yang",
        "Xiang Yu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2026-01-21T06:58:01+00:00",
      "link": "https://arxiv.org/pdf/2601.14710v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02201v1",
      "title": "Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction",
      "abstract": "Drug discovery motivates efficient molecular property prediction under limited labeled data. Chemical space is vast, often estimated at approximately 10^60 drug-like molecules, while only thousands of drugs have been approved. As a result, self-supervised pretraining on large unlabeled molecular corpora has become essential for data-efficient molecular representation learning. We introduce **CardinalGraphFormer**, a graph transformer that incorporates Graphormer-inspired structural biases, including shortest-path distance and centrality, as well as direct-bond edge bias, within a structured sparse attention regime limited to shortest-path distance <= 3. The model further augments this design with a cardinality-preserving unnormalized aggregation channel over the same support set. Pretraining combines contrastive graph-level alignment with masked attribute reconstruction. Under a fully matched evaluation protocol, CardinalGraphFormer improves mean performance across all 11 evaluated tasks and achieves statistically significant gains on 10 of 11 public benchmarks spanning MoleculeNet, OGB, and TDC ADMET tasks when compared to strong reproduced baselines.",
      "authors": [
        "Abhijit Gupta"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T15:05:46+00:00",
      "link": "https://arxiv.org/pdf/2602.02201v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04696v1",
      "title": "Beyond Learning on Molecules by Weakly Supervising on Molecules",
      "abstract": "Molecular representations are inherently task-dependent, yet most pre-trained molecular encoders are not. Task conditioning promises representations that reorganize based on task descriptions, but existing approaches rely on expensive labeled data. We show that weak supervision on programmatically derived molecular motifs is sufficient. Our Adaptive Chemical Embedding Model (ACE-Mol) learns from hundreds of motifs paired with natural language descriptors that are cheap to compute, trivial to scale. Conventional encoders slowly search the embedding space for task-relevant structure, whereas ACE-Mol immediately aligns its representations with the task. ACE-Mol achieves state-of-the-art performance across molecular property prediction benchmarks with interpretable, chemically meaningful representations.",
      "authors": [
        "Gordan Prastalo",
        "Kevin Maik Jablonka"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "published": "2026-02-04T16:03:20+00:00",
      "link": "https://arxiv.org/pdf/2602.04696v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09693v2",
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "abstract": "Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves competitive zero-shot virtual screening performance, substantially outperforms existing methods on a challenging target fishing task, and demonstrates state-of-the-art ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.",
      "authors": [
        "Lisa Schneckenreiter",
        "Sohvi Luukkonen",
        "Lukas Friedrich",
        "Daniel Kuhn",
        "Günter Klambauer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-14T18:45:08+00:00",
      "link": "https://arxiv.org/pdf/2601.09693v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20043v1",
      "title": "Regime-Adaptive Bayesian Optimization via Dirichlet Process Mixtures of Gaussian Processes",
      "abstract": "Standard Bayesian Optimization (BO) assumes uniform smoothness across the search space an assumption violated in multi-regime problems such as molecular conformation search through distinct energy basins or drug discovery across heterogeneous molecular scaffolds. A single GP either oversmooths sharp transitions or hallucinates noise in smooth regions, yielding miscalibrated uncertainty. We propose RAMBO, a Dirichlet Process Mixture of Gaussian Processes that automatically discovers latent regimes during optimization, each modeled by an independent GP with locally-optimized hyperparameters. We derive collapsed Gibbs sampling that analytically marginalizes latent functions for efficient inference, and introduce adaptive concentration parameter scheduling for coarse-to-fine regime discovery. Our acquisition functions decompose uncertainty into intra-regime and inter-regime components. Experiments on synthetic benchmarks and real-world applications, including molecular conformer optimization, virtual screening for drug discovery, and fusion reactor design, demonstrate consistent improvements over state-of-the-art baselines on multi-regime objectives.",
      "authors": [
        "Yan Zhang",
        "Xuefeng Liu",
        "Sipeng Chen",
        "Sascha Ranftl",
        "Chong Liu",
        "Shibo Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-27T20:45:50+00:00",
      "link": "https://arxiv.org/pdf/2601.20043v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17112v1",
      "title": "Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.",
      "authors": [
        "A. El Ichi",
        "K. Jbilou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-23T18:37:17+00:00",
      "link": "https://arxiv.org/pdf/2601.17112v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12442v1",
      "title": "Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery",
      "abstract": "Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.",
      "authors": [
        "Shahnawaz Alam",
        "Mohammed Mudassir Uddin",
        "Mohammed Kaif Pasha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-18T14:57:35+00:00",
      "link": "https://arxiv.org/pdf/2601.12442v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02780v2",
      "title": "A Study of Adaptive Modeling Towards Robust Generalization",
      "abstract": "Large language models (LLMs) increasingly support reasoning over biomolecular structures, but most existing approaches remain modality-specific and rely on either sequence-style encodings or fixed-length connector tokens for structural inputs. These designs can under-expose explicit geometric cues and impose rigid fusion bottlenecks, leading to over-compression and poor token allocation as structural complexity grows. We present a unified all-atom framework that grounds language reasoning in geometric information while adaptively scaling structural tokens. The method first constructs variable-size structural patches on molecular graphs using an instruction-conditioned gating policy, enabling complexity-aware allocation of query tokens. It then refines the resulting patch tokens via cross-attention with modality embeddings and injects geometry-informed tokens into the language model to improve structure grounding and reduce structural hallucinations. Across diverse all-atom benchmarks, the proposed approach yields consistent gains in heterogeneous structure-grounded reasoning. An anonymized implementation is provided in the supplementary material.",
      "authors": [
        "Zihao Jing",
        "Qiuhao Zeng",
        "Ruiyi Fang",
        "Yan Yi Li",
        "Yan Sun",
        "Boyu Wang",
        "Pingzhao Hu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-02T20:35:44+00:00",
      "link": "https://arxiv.org/pdf/2602.02780v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06002v2",
      "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning",
      "abstract": "Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.",
      "authors": [
        "Qiguang Chen",
        "Yantao Du",
        "Ziniu Li",
        "Jinhao Liu",
        "Songyao Duan",
        "Jiarui Guo",
        "Minghao Liu",
        "Jiaheng Liu",
        "Tong Yang",
        "Ge Zhang",
        "Libo Qin",
        "Wanxiang Che",
        "Wenhao Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-09T18:39:01+00:00",
      "link": "https://arxiv.org/pdf/2601.06002v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11616v1",
      "title": "Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective",
      "abstract": "Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.",
      "authors": [
        "Feilong Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-09T23:07:14+00:00",
      "link": "https://arxiv.org/pdf/2601.11616v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14173v1",
      "title": "Penalizing Localized Dirichlet Energies in Low Rank Tensor Products",
      "abstract": "We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.",
      "authors": [
        "Paris A. Karakasis",
        "Nicholas D. Sidiropoulos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-20T17:25:47+00:00",
      "link": "https://arxiv.org/pdf/2601.14173v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22610v1",
      "title": "Local-Global Multimodal Contrastive Learning for Molecular Property Prediction",
      "abstract": "Accurate molecular property prediction requires integrating complementary information from molecular structure and chemical semantics. In this work, we propose LGM-CL, a local-global multimodal contrastive learning framework that jointly models molecular graphs and textual representations derived from SMILES and chemistry-aware augmented texts. Local functional group information and global molecular topology are captured using AttentiveFP and Graph Transformer encoders, respectively, and aligned through self-supervised contrastive learning. In addition, chemically enriched textual descriptions are contrasted with original SMILES to incorporate physicochemical semantics in a task-agnostic manner. During fine-tuning, molecular fingerprints are further integrated via Dual Cross-attention multimodal fusion. Extensive experiments on MoleculeNet benchmarks demonstrate that LGM-CL achieves consistent and competitive performance across both classification and regression tasks, validating the effectiveness of unified local-global and multimodal representation learning.",
      "authors": [
        "Xiayu Liu",
        "Zhengyi Lu",
        "Yunhong Liao",
        "Chan Fan",
        "Hou-biao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T06:06:17+00:00",
      "link": "https://arxiv.org/pdf/2601.22610v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02686v1",
      "title": "Monotonicity as an Architectural Bias for Robust Language Models",
      "abstract": "Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.   We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.   We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.",
      "authors": [
        "Patrick Cooper",
        "Alireza Nadali",
        "Ashutosh Trivedi",
        "Alvaro Velasquez"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-02-02T19:03:19+00:00",
      "link": "https://arxiv.org/pdf/2602.02686v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.08073v1",
      "title": "Monte Carlo to Las Vegas for Recursively Composed Functions",
      "abstract": "For a (possibly partial) Boolean function $f\\colon\\{0,1\\}^n\\to\\{0,1\\}$ as well as a query complexity measure $M$ which maps Boolean functions to real numbers, define the composition limit of $M$ on $f$ by $M^*(f)=\\lim_{k\\to\\infty} M(f^k)^{1/k}$.   We study the composition limits of general measures in query complexity. We show this limit converges under reasonable assumptions about the measure. We then give a surprising result regarding the composition limit of randomized query complexity: we show $R_0^*(f)=\\max\\{R^*(f),C^*(f)\\}$. Among other things, this implies that any bounded-error randomized algorithm for recursive 3-majority can be turned into a zero-error randomized algorithm for the same task. Our result extends also to quantum algorithms: on recursively composed functions, a bounded-error quantum algorithm can be converted into a quantum algorithm that finds a certificate with high probability.   Along the way, we prove various combinatorial properties of measures and composition limits.",
      "authors": [
        "Bandar Al-Dhalaan",
        "Shalev Ben-David"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "quant-ph"
      ],
      "published": "2026-01-12T23:34:37+00:00",
      "link": "https://arxiv.org/pdf/2601.08073v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05977v1",
      "title": "Clifford Kolmogorov-Arnold Networks",
      "abstract": "We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering, and is validated in synthetic and physics inspired tasks.",
      "authors": [
        "Matthias Wolff",
        "Francesco Alesiani",
        "Christof Duhme",
        "Xiaoyi Jiang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-05T18:25:40+00:00",
      "link": "https://arxiv.org/pdf/2602.05977v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17260v1",
      "title": "The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment",
      "abstract": "Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively \"better\" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.",
      "authors": [
        "Marco Pollanen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-24T02:19:20+00:00",
      "link": "https://arxiv.org/pdf/2601.17260v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22327v1",
      "title": "Molecular Representations in Implicit Functional Space via Hyper-Networks",
      "abstract": "Molecular representations fundamentally shape how machine learning systems reason about molecular structure and physical properties. Most existing approaches adopt a discrete pipeline: molecules are encoded as sequences, graphs, or point clouds, mapped to fixed-dimensional embeddings, and then used for task-specific prediction. This paradigm treats molecules as discrete objects, despite their intrinsically continuous and field-like physical nature. We argue that molecular learning can instead be formulated as learning in function space. Specifically, we model each molecule as a continuous function over three-dimensional (3D) space and treat this molecular field as the primary object of representation. From this perspective, conventional molecular representations arise as particular sampling schemes of an underlying continuous object. We instantiate this formulation with MolField, a hyper-network-based framework that learns distributions over molecular fields. To ensure physical consistency, these functions are defined over canonicalized coordinates, yielding invariance to global SE(3) transformations. To enable learning directly over functions, we introduce a structured weight tokenization and train a sequence-based hyper-network to model a shared prior over molecular fields. We evaluate MolField on molecular dynamics and property prediction. Our results show that treating molecules as continuous functions fundamentally changes how molecular representations generalize across tasks and yields downstream behavior that is stable to how molecules are discretized or queried.",
      "authors": [
        "Zehong Wang",
        "Xiaolong Han",
        "Qi Yang",
        "Xiangru Tang",
        "Fang Wu",
        "Xiaoguang Guo",
        "Weixiang Sun",
        "Tianyi Ma",
        "Pietro Lio",
        "Le Cong",
        "Sheng Wang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T21:13:37+00:00",
      "link": "https://arxiv.org/pdf/2601.22327v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09981v2",
      "title": "DR$^2$Seg: Decomposed Two-Stage Rollouts for Efficient Reasoning Segmentation in Multimodal Large Language Models",
      "abstract": "Reasoning segmentation is an emerging vision-language task that requires reasoning over intricate text queries to precisely segment objects. However, existing methods typically suffer from overthinking, generating verbose reasoning chains that interfere with object localization in multimodal large language models (MLLMs). To address this issue, we propose DR$^2$Seg, a self-rewarding framework that improves both reasoning efficiency and segmentation accuracy without requiring extra thinking supervision. DR$^2$Seg employs a two-stage rollout strategy that decomposes reasoning segmentation into multimodal reasoning and referring segmentation. In the first stage, the model generates a self-contained description that explicitly specifies the target object. In the second stage, this description replaces the original complex query to verify its self-containment. Based on this design, two self-rewards are introduced to mitigate overthinking and the associated attention dispersion. Extensive experiments conducted on 3B and 7B variants of Qwen2.5-VL, as well as on both SAM2 and SAM3, demonstrate that DR$^2$Seg consistently improves reasoning efficiency and overall segmentation accuracy.",
      "authors": [
        "Yulin He",
        "Wei Chen",
        "Zhikang Jian",
        "Tianhang Guo",
        "Wenjuan Zhou",
        "Minglong Li",
        "Shaowu Yang",
        "Wenjing Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-15T01:48:45+00:00",
      "link": "https://arxiv.org/pdf/2601.09981v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02940v1",
      "title": "A vector logic for intensional formal semantics",
      "abstract": "Formal semantics and distributional semantics are distinct approaches to linguistic meaning: the former models meaning as reference via model-theoretic structures; the latter represents meaning as vectors in high-dimensional spaces shaped by usage. This paper proves that these frameworks are structurally compatible for intensional semantics. We establish that Kripke-style intensional models embed injectively into vector spaces, with semantic functions lifting to (multi)linear maps that preserve composition. The construction accommodates multiple index sorts (worlds, times, locations) via a compound index space, representing intensions as linear operators. Modal operators are derived algebraically: accessibility relations become linear operators, and modal conditions reduce to threshold checks on accumulated values. For uncountable index domains, we develop a measure-theoretic generalization in which necessity becomes truth almost everywhere and possibility becomes truth on a set of positive measure, a non-classical logic natural for continuous parameters.",
      "authors": [
        "Daniel Quigley"
      ],
      "primary_category": "math.LO",
      "categories": [
        "math.LO",
        "cs.CL",
        "cs.FL",
        "cs.LO"
      ],
      "published": "2026-02-03T00:24:37+00:00",
      "link": "https://arxiv.org/pdf/2602.02940v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12023v1",
      "title": "A Kernel Approach for Semi-implicit Variational Inference",
      "abstract": "Semi-implicit variational inference (SIVI) enhances the expressiveness of variational families through hierarchical semi-implicit distributions, but the intractability of their densities makes standard ELBO-based optimization biased. Recent score-matching approaches to SIVI (SIVI-SM) address this issue via a minimax formulation, at the expense of an additional lower-level optimization problem. In this paper, we propose kernel semi-implicit variational inference (KSIVI), a principled and tractable alternative that eliminates the lower-level optimization by leveraging kernel methods. We show that when optimizing over a reproducing kernel Hilbert space, the lower-level problem admits an explicit solution, reducing the objective to the kernel Stein discrepancy (KSD). Exploiting the hierarchical structure of semi-implicit distributions, the resulting KSD objective can be efficiently optimized using stochastic gradient methods. We establish optimization guarantees via variance bounds on Monte Carlo gradient estimators and derive statistical generalization bounds of order $\\tilde{\\mathcal{O}}(1/\\sqrt{n})$. We further introduce a multi-layer hierarchical extension that improves expressiveness while preserving tractability. Empirical results on synthetic and real-world Bayesian inference tasks demonstrate the effectiveness of KSIVI.",
      "authors": [
        "Longlin Yu",
        "Ziheng Cheng",
        "Shiyue Zhang",
        "Cheng Zhang"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-17T12:06:12+00:00",
      "link": "https://arxiv.org/pdf/2601.12023v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16200v2",
      "title": "Feature-Space Adversarial Robustness Certification for Multimodal Large Language Models",
      "abstract": "Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose Feature-space Smoothing (FS), a general framework that provides certified robustness guarantees at the feature representation level of MLLMs. We theoretically prove that FS converts a given feature extractor into a smoothed variant that is guaranteed a certified lower bound on the cosine similarity between clean and adversarial features under $\\ell_2$-bounded perturbations. Moreover, we establish that the value of this Feature Cosine Similarity Bound (FCSB) is determined by the intrinsic Gaussian robustness score of the given encoder. Building on this insight, we introduce the Gaussian Smoothness Booster (GSB), a plug-and-play module that enhances the Gaussian robustness score of pretrained MLLMs, thereby strengthening the robustness guaranteed by FS, without requiring additional MLLM retraining. Extensive experiments demonstrate that applying the FS to various MLLMs yields strong certified feature-space robustness and consistently leads to robust task-oriented performance across diverse applications.",
      "authors": [
        "Song Xia",
        "Meiwen Ding",
        "Chenqi Kong",
        "Wenhan Yang",
        "Xudong Jiang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-22T18:52:21+00:00",
      "link": "https://arxiv.org/pdf/2601.16200v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15333v2",
      "title": "Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference",
      "abstract": "Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.",
      "authors": [
        "Xuanning Hu",
        "Anchen Li",
        "Qianli Xing",
        "Jinglong Ji",
        "Hao Tuo",
        "Bo Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "published": "2026-01-20T08:10:48+00:00",
      "link": "https://arxiv.org/pdf/2601.15333v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01587v1",
      "title": "Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment",
      "abstract": "Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.",
      "authors": [
        "Zehua Cheng",
        "Jianwei Yang",
        "Wei Dai",
        "Jiahao Sun"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-02T03:26:45+00:00",
      "link": "https://arxiv.org/pdf/2602.01587v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05266v1",
      "title": "Beyond Cosine Similarity",
      "abstract": "Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.",
      "authors": [
        "Xinbo Ai"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-05T03:46:21+00:00",
      "link": "https://arxiv.org/pdf/2602.05266v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00913v1",
      "title": "Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts",
      "abstract": "Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\\rightarrow$HO$\\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.",
      "authors": [
        "Víctor Yeste",
        "Paolo Rosso"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-31T21:50:35+00:00",
      "link": "https://arxiv.org/pdf/2602.00913v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10131v2",
      "title": "M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints",
      "abstract": "Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \\textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reasoner performs retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II : RL-based fine-grained optimization: a fragment-level optimizer trained with Group Relative Policy Optimization (GRPO) applies one- or multi-hop refinements to explicitly minimize the property errors toward our target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.",
      "authors": [
        "Yizhan Li",
        "Florence Cloutier",
        "Sifan Wu",
        "Ali Parviz",
        "Boris Knyazev",
        "Yan Zhang",
        "Glen Berseth",
        "Bang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-15T07:18:05+00:00",
      "link": "https://arxiv.org/pdf/2601.10131v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21835v2",
      "title": "Scalable Linearized Laplace Approximation via Surrogate Neural Kernel",
      "abstract": "We introduce a scalable method to approximate the kernel of the Linearized Laplace Approximation (LLA). For this, we use a surrogate deep neural network (DNN) that learns a compact feature representation whose inner product replicates the Neural Tangent Kernel (NTK). This avoids the need to compute large Jacobians. Training relies solely on efficient Jacobian-vector products, allowing to compute predictive uncertainty on large-scale pre-trained DNNs. Experimental results show similar or improved uncertainty estimation and calibration compared to existing LLA approximations. Notwithstanding, biasing the learned kernel significantly enhances out-of-distribution detection. This remarks the benefits of the proposed method for finding better kernels than the NTK in the context of LLA to compute prediction uncertainty given a pre-trained DNN.",
      "authors": [
        "Luis A. Ortega",
        "Simón Rodríguez-Santana",
        "Daniel Hernández-Lobato"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T15:15:41+00:00",
      "link": "https://arxiv.org/pdf/2601.21835v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21191v1",
      "title": "From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning",
      "abstract": "What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.",
      "authors": [
        "Xiulin Yang",
        "Heidi Getz",
        "Ethan Gotlieb Wilcox"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-29T02:42:12+00:00",
      "link": "https://arxiv.org/pdf/2601.21191v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09253v1",
      "title": "RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning",
      "abstract": "While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.",
      "authors": [
        "Zehua Liu",
        "Shuqi Liu",
        "Tao Zhong",
        "Mingxuan Yuan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-14T07:41:03+00:00",
      "link": "https://arxiv.org/pdf/2601.09253v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02759v1",
      "title": "Near-Universal Multiplicative Updates for Nonnegative Einsum Factorization",
      "abstract": "Despite the ubiquity of multiway data across scientific domains, there are few user-friendly tools that fit tailored nonnegative tensor factorizations. Researchers may use gradient-based automatic differentiation (which often struggles in nonnegative settings), choose between a limited set of methods with mature implementations, or implement their own model from scratch. As an alternative, we introduce NNEinFact, an einsum-based multiplicative update algorithm that fits any nonnegative tensor factorization expressible as a tensor contraction by minimizing one of many user-specified loss functions (including the $(α,β)$-divergence). To use NNEinFact, the researcher simply specifies their model with a string. NNEinFact converges to a local minimum of the loss, supports missing data, and fits to tensors with hundreds of millions of entries in seconds. Empirically, NNEinFact fits custom models which outperform standard ones in heldout prediction tasks on real-world tensor data by over $37\\%$ and attains less than half the test loss of gradient-based methods while converging up to 90 times faster.",
      "authors": [
        "John Hood",
        "Aaron Schein"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-02T20:09:57+00:00",
      "link": "https://arxiv.org/pdf/2602.02759v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02920v1",
      "title": "A Reproducible Framework for Bias-Resistant Machine Learning on Small-Sample Neuroimaging Data",
      "abstract": "We introduce a reproducible, bias-resistant machine learning framework that integrates domain-informed feature engineering, nested cross-validation, and calibrated decision-threshold optimization for small-sample neuroimaging data. Conventional cross-validation frameworks that reuse the same folds for both model selection and performance estimation yield optimistically biased results, limiting reproducibility and generalization. Demonstrated on a high-dimensional structural MRI dataset of deep brain stimulation cognitive outcomes, the framework achieved a nested-CV balanced accuracy of 0.660\\,$\\pm$\\,0.068 using a compact, interpretable subset selected via importance-guided ranking. By combining interpretability and unbiased evaluation, this work provides a generalizable computational blueprint for reliable machine learning in data-limited biomedical domains.",
      "authors": [
        "Jagan Mohan Reddy Dwarampudi",
        "Jennifer L Purks",
        "Joshua Wong",
        "Renjie Hu",
        "Tania Banerjee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "q-bio.NC",
        "q-bio.QM"
      ],
      "published": "2026-02-02T23:47:57+00:00",
      "link": "https://arxiv.org/pdf/2602.02920v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19092v2",
      "title": "Axe: A Simple Unified Layout Abstraction for Machine Learning Compilers",
      "abstract": "Scaling modern deep learning workloads demands coordinated placement of data and compute across device meshes, memory hierarchies, and heterogeneous accelerators. We present Axe Layout, a hardware-aware abstraction that maps logical tensor coordinates to a multi-axis physical space via named axes. Axe unifies tiling, sharding, replication, and offsets across inter-device distribution and on-device layouts, enabling collective primitives to be expressed consistently from device meshes to threads. Building on Axe, we design a multi-granularity, distribution-aware DSL and compiler that composes thread-local control with collective operators in a single kernel. Experiments show that our unified approach can bring performance close to hand-tuned kernels on across latest GPU devices and multi-device environments and accelerator backends.",
      "authors": [
        "Bohan Hou",
        "Hongyi Jin",
        "Guanjie Wang",
        "Jinqi Chen",
        "Yaxing Cai",
        "Lijie Yang",
        "Zihao Ye",
        "Yaoyao Ding",
        "Ruihang Lai",
        "Tianqi Chen"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "published": "2026-01-27T01:57:29+00:00",
      "link": "https://arxiv.org/pdf/2601.19092v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06300v1",
      "title": "$\\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials",
      "abstract": "Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \\textit{eligibility criteria amendment prediction}, a novel NLP task that aims to forecast whether the eligibility criteria of an initial trial protocol will undergo future amendments. To support this task, we release $\\texttt{AMEND++}$, a benchmark suite comprising two datasets: $\\texttt{AMEND}$, which captures eligibility-criteria version histories and amendment labels from public clinical trials, and $\\verb|AMEND_LLM|$, a refined subset curated using an LLM-based denoising pipeline to isolate substantive changes. We further propose $\\textit{Change-Aware Masked Language Modeling}$ (CAMLM), a revision-aware pretraining strategy that leverages historical edits to learn amendment-sensitive representations. Experiments across diverse baselines show that CAMLM consistently improves amendment prediction, enabling more robust and cost-effective clinical trial design.",
      "authors": [
        "Trisha Das",
        "Mandis Beigi",
        "Jacob Aptekar",
        "Jimeng Sun"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-09T20:32:04+00:00",
      "link": "https://arxiv.org/pdf/2601.06300v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12700v1",
      "title": "Improving Audio Question Answering with Variational Inference",
      "abstract": "Variational inference (VI) provides a principled framework for estimating posterior distributions over model parameters, enabling explicit modeling of weight uncertainty during optimization. By capturing this uncertainty, VI improves the reliability of predictions, yielding better calibrated outputs. In this work, we investigate the benefits of VI for challenging multimodal understanding and reasoning by applying the Improved Variational Online Newton (IVON), a recent VI optimizer, to fine-tuning a multimodal large language model on audio question answering tasks. Our results show that VI not only enhances predictive accuracy but also significantly improves calibration, reducing the model's overconfidence. These advances further support risk-sensitive applications such as selective prediction, where reliable confidence estimates are crucial.",
      "authors": [
        "Haolin Chen"
      ],
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.SD"
      ],
      "published": "2026-01-19T03:48:03+00:00",
      "link": "https://arxiv.org/pdf/2601.12700v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22408v1",
      "title": "Minimal-Action Discrete Schrödinger Bridge Matching for Peptide Sequence Design",
      "abstract": "Generative modeling of peptide sequences requires navigating a discrete and highly constrained space in which many intermediate states are chemically implausible or unstable. Existing discrete diffusion and flow-based methods rely on reversing fixed corruption processes or following prescribed probability paths, which can force generation through low-likelihood regions and require countless sampling steps. We introduce Minimal-action discrete Schrödinger Bridge Matching (MadSBM), a rate-based generative framework for peptide design that formulates generation as a controlled continuous-time Markov process on the amino-acid edit graph. To yield probability trajectories that remain near high-likelihood sequence neighborhoods throughout generation, MadSBM 1) defines generation relative to a biologically informed reference process derived from pre-trained protein language model logits and 2) learns a time-dependent control field that biases transition rates to produce low-action transport paths from a masked prior to the data distribution. We finally introduce guidance to the MadSBM sampling procedure towards a specific functional objective, expanding the design space of therapeutic peptides; to our knowledge, this represents the first-ever application of discrete classifier guidance to Schrödinger bridge-based generative models.",
      "authors": [
        "Shrey Goel",
        "Pranam Chatterjee"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM",
        "cs.LG"
      ],
      "published": "2026-01-29T23:38:36+00:00",
      "link": "https://arxiv.org/pdf/2601.22408v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05549v1",
      "title": "Logical Guidance for the Exact Composition of Diffusion Models",
      "abstract": "We propose LOGDIFF (Logical Guidance for the Exact Composition of Diffusion Models), a guidance framework for diffusion models that enables principled constrained generation with complex logical expressions at inference time.   We study when exact score-based guidance for complex logical formulas can be obtained from guidance signals associated with atomic properties.   First, we derive an exact Boolean calculus that provides a sufficient condition for exact logical guidance.   Specifically, if a formula admits a circuit representation in which conjunctions combine conditionally independent subformulas and disjunctions combine subformulas that are either conditionally independent or mutually exclusive, exact logical guidance is achievable.   In this case, the guidance signal can be computed exactly from atomic scores and posterior probabilities using an efficient recursive algorithm.   Moreover, we show that, for commonly encountered classes of distributions, any desired Boolean formula is compilable into such a circuit representation.   Second, by combining atomic guidance scores with posterior probability estimates, we introduce a hybrid guidance approach that bridges classifierguidance and classifier-free guidance, applicable to both compositional logical guidance and standard conditional generation.   We demonstrate the effectiveness of our framework on multiple image and protein structure generation tasks.",
      "authors": [
        "Francesco Alesiani",
        "Jonathan Warrell",
        "Tanja Bien",
        "Henrik Christiansen",
        "Matheus Ferraz",
        "Mathias Niepert"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T11:10:06+00:00",
      "link": "https://arxiv.org/pdf/2602.05549v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01956v1",
      "title": "Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation",
      "abstract": "Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.",
      "authors": [
        "Seonghyeon Park",
        "Jewon Yeom",
        "Jaewon Sok",
        "Jeongjae Park",
        "Heejun Kim",
        "Taesup Kim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T11:03:37+00:00",
      "link": "https://arxiv.org/pdf/2602.01956v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12219v1",
      "title": "Persistent Sheaf Laplacian Analysis of Protein Stability and Solubility Changes upon Mutation",
      "abstract": "Genetic mutations frequently disrupt protein structure, stability, and solubility, acting as primary drivers for a wide spectrum of diseases. Despite the critical importance of these molecular alterations, existing computational models often lack interpretability, and fail to integrate essential physicochemical interaction. To overcome these limitations, we propose SheafLapNet, a unified predictive framework grounded in the mathematical theory of Topological Deep Learning (TDL) and Persistent Sheaf Laplacian (PSL). Unlike standard Topological Data Analysis (TDA) tools such as persistent homology, which are often insensitive to heterogeneous information, PSL explicitly encodes specific physical and chemical information such as partial charges directly into the topological analysis. SheafLapNet synergizes these sheaf-theoretic invariants with advanced protein transformer features and auxiliary physical descriptors to capture intrinsic molecular interactions in a multiscale and mechanistic manner. To validate our framework, we employ rigorous benchmarks for both regression and classification tasks. For stability prediction, we utilize the comprehensive S2648 and S350 datasets. For solubility prediction, we employ the PON-Sol2 dataset, which provides annotations for increased, decreased, or neutral solubility changes. By integrating these multi-perspective features, SheafLapNet achieves state-of-the-art performance across these diverse benchmarks, demonstrating that sheaf-theoretic modeling significantly enhances both interpretability and generalizability in predicting mutation-induced structural and functional changes.",
      "authors": [
        "Yiming Ren",
        "Junjie Wee",
        "Xi Chen",
        "Grace Qian",
        "Guo-Wei Wei"
      ],
      "primary_category": "math.SP",
      "categories": [
        "math.SP",
        "cs.LG",
        "q-bio.QM"
      ],
      "published": "2026-01-18T01:45:12+00:00",
      "link": "https://arxiv.org/pdf/2601.12219v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21964v2",
      "title": "From Tokens to Blocks: A Block-Diffusion Perspective on Molecular Generation",
      "abstract": "Drug discovery can be viewed as a combinatorial search over an immense chemical space, motivating the development of deep generative models for de novo molecular design. Among these, GPT-based molecular language models (MLM) have shown strong molecular design performance by learning chemical syntax and semantics from large-scale data. However, existing MLMs face two fundamental limitations: they inadequately capture the graph-structured nature of molecules when formulated as next-token prediction problems, and they typically lack explicit mechanisms for target-aware generation. Here, we propose SoftMol, a unified framework that co-designs molecular representation, model architecture, and search strategy for target-aware molecular generation. SoftMol introduces soft fragments, a rule-free block representation of SMILES that enables diffusion-native modeling, and develops SoftBD, the first block-diffusion molecular language model that combines local bidirectional diffusion with autoregressive generation under molecular structural constraints. To favor generated molecules with high drug-likeness and synthetic accessibility, SoftBD is trained on a carefully curated dataset named ZINC-Curated. SoftMol further integrates a gated Monte Carlo tree search to assemble fragments in a target-aware manner. Experimental results show that, compared with current state-of-the-art models, SoftMol achieves 100% chemical validity, improves binding affinity by 9.7%, yields a 2-3x increase in molecular diversity, and delivers a 6.6x speedup in inference efficiency. Code is available at https://github.com/szu-aicourse/softmol",
      "authors": [
        "Qianwei Yang",
        "Dong Xu",
        "Zhangfan Yang",
        "Sisi Yuan",
        "Zexuan Zhu",
        "Jianqiang Li",
        "Junkai Ji"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T16:42:24+00:00",
      "link": "https://arxiv.org/pdf/2601.21964v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06599v1",
      "title": "How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs",
      "abstract": "Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.",
      "authors": [
        "Shivam Adarsh",
        "Maria Maistro",
        "Christina Lioma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-10T15:43:26+00:00",
      "link": "https://arxiv.org/pdf/2601.06599v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22760v1",
      "title": "AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation",
      "abstract": "The performance of deep learning models critically depends on efficient kernel implementations, yet developing high-performance kernels for specialized accelerators remains time-consuming and expertise-intensive. While recent work demonstrates that large language models (LLMs) can generate correct and performant GPU kernels, kernel generation for neural processing units (NPUs) remains largely underexplored due to domain-specific programming models, limited public examples, and sparse documentation. Consequently, directly generating AscendC kernels with LLMs yields extremely low correctness, highlighting a substantial gap between GPU and NPU kernel generation.   We present AscendCraft, a DSL-guided approach for automatic AscendC kernel generation. AscendCraft introduces a lightweight DSL that abstracts non-essential complexity while explicitly modeling Ascend-specific execution semantics. Kernels are first generated in the DSL using category-specific expert examples and then transcompiled into AscendC through structured, constraint-driven LLM lowering passes. Evaluated on MultiKernelBench across seven operator categories, AscendCraft achieves 98.1% compilation success and 90.4% functional correctness. Moreover, 46.2% of generated kernels match or exceed PyTorch eager execution performance, demonstrating that DSL-guided transcompilation can enable LLMs to generate both correct and competitive NPU kernels. Beyond benchmarks, AscendCraft further demonstrates its generality by successfully generating two correct kernels for newly proposed mHC architecture, achieving performance that substantially surpasses PyTorch eager execution.",
      "authors": [
        "Zhongzhen Wen",
        "Shudi Shao",
        "Zhong Li",
        "Yu Ge",
        "Tongtong Xu",
        "Yuanyi Lin",
        "Tian Zhang"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.LG",
        "cs.PF",
        "cs.SE"
      ],
      "published": "2026-01-30T09:34:59+00:00",
      "link": "https://arxiv.org/pdf/2601.22760v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00944v1",
      "title": "Monte-Carlo Irreducibility and Imprimitivity Detection of Polynomials over $\\mathbb{Q}$",
      "abstract": "We study fast Monte-Carlo methods for testing irreducibility and detecting arithmetic imprimitivity of polynomials over $\\mathbb{Q}$. Building on the subset-sum criterion of Pemantle-Peres-Rivin, we develop a probabilistic irreducibility test whose expected running time, measured in the number of primes examined, is logarithmic in the degree for generic inputs. Unlike the standard modular irreducibility test, the method aggregates information from modular factorizations rather than discarding unsuccessful trials.   We show that failure of this test, when combined with a standard modular irreducibility certificate, is a strong indicator of non-generic algebraic structure. In particular, it often signals arithmetic imprimitivity of the Galois action. We present an explicit and efficient Monte-Carlo algorithm for detecting such imprimitivity via subfield extraction, yielding constructive algebraic certificates in the imprimitive case. To our knowledge, this is the first practical algorithm for detecting arithmetic imprimitivity of polynomials over $\\mathbb{Q}$ in high degree. We further show that the subset-sum data produced by the Pemantle--Peres--Rivin test provides a warm start for polynomial factorization by sharply restricting the possible degrees of rational factors, significantly accelerating subsequent lifting procedures. The proposed methods are orders of magnitude faster in practice than known deterministic algorithms, and are effective in degrees far beyond the reach of current deterministic techniques.",
      "authors": [
        "Igor Rivin"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-02-01T00:14:22+00:00",
      "link": "https://arxiv.org/pdf/2602.00944v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10157v1",
      "title": "MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning",
      "abstract": "Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.",
      "authors": [
        "Yusong Wang",
        "Jialun Shen",
        "Zhihao Wu",
        "Yicheng Xu",
        "Shiyin Tan",
        "Mingkun Xu",
        "Changshuo Wang",
        "Zixing Song",
        "Prayag Tiwari"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-15T07:57:28+00:00",
      "link": "https://arxiv.org/pdf/2601.10157v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21662v1",
      "title": "Epistemic Uncertainty Quantification for Pre-trained VLMs via Riemannian Flow Matching",
      "abstract": "Vision-Language Models (VLMs) are typically deterministic in nature and lack intrinsic mechanisms to quantify epistemic uncertainty, which reflects the model's lack of knowledge or ignorance of its own representations. We theoretically motivate negative log-density of an embedding as a proxy for the epistemic uncertainty, where low-density regions signify model ignorance. The proposed method REPVLM computes the probability density on the hyperspherical manifold of the VLM embeddings using Riemannian Flow Matching. We empirically demonstrate that REPVLM achieves near-perfect correlation between uncertainty and prediction error, significantly outperforming existing baselines. Beyond classification, we also demonstrate that the model also provides a scalable metric for out-of-distribution detection and automated data curation.",
      "authors": [
        "Li Ju",
        "Mayank Nautiyal",
        "Andreas Hellander",
        "Ekta Vats",
        "Prashant Singh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T12:58:42+00:00",
      "link": "https://arxiv.org/pdf/2601.21662v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01105v1",
      "title": "OLion: Approaching the Hadamard Ideal by Intersecting Spectral and $\\ell_{\\infty}$ Implicit Biases",
      "abstract": "Many optimizers can be interpreted as steepest-descent methods under norm-induced geometries, and thus inherit corresponding implicit biases. We introduce \\nameA{} (\\fullname{}), which combines spectral control from orthogonalized update directions with $\\ell_\\infty$-style coordinate control from sign updates. \\nameA{} forms a Lion-style momentum direction, approximately orthogonalizes it via a few Newton--Schulz iterations, and then applies an entrywise sign, providing an efficient approximation to taking a maximal step over the intersection of the spectral and $\\ell_\\infty$ constraint sets (a scaled Hadamard-like set for matrix parameters). Despite the strong nonlinearity of orthogonalization and sign, we prove convergence under a mild, empirically verified diagonal-isotropy assumption. Across large-scale language and vision training, including GPT-2 and Llama pretraining, SiT image pretraining, and supervised fine-tuning, \\nameA{} matches or outperforms AdamW and Muon under comparable tuning while using only momentum-level optimizer state, and it mitigates optimizer mismatch when fine-tuning AdamW-pretrained checkpoints.",
      "authors": [
        "Zixiao Wang",
        "Yifei Shen",
        "Huishuai Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-01T08:59:45+00:00",
      "link": "https://arxiv.org/pdf/2602.01105v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11491v2",
      "title": "Extractive summarization on a CMOS Ising machine",
      "abstract": "Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.",
      "authors": [
        "Ziqing Zeng",
        "Abhimanyu Kumar",
        "Ahmet Efe",
        "Ruihong Yin",
        "Chris H. Kim",
        "Ulya R. Karpuzcu",
        "Sachin S. Sapatnekar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.ET"
      ],
      "published": "2026-01-16T18:14:02+00:00",
      "link": "https://arxiv.org/pdf/2601.11491v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03134v1",
      "title": "SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass",
      "abstract": "Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.",
      "authors": [
        "Chen Qian",
        "Xinran Yu",
        "Danyang Li",
        "Guoxuan Chi",
        "Zheng Yang",
        "Qiang Ma",
        "Xin Miao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-02-03T05:42:51+00:00",
      "link": "https://arxiv.org/pdf/2602.03134v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.08584v1",
      "title": "Ministral 3",
      "abstract": "We introduce the Ministral 3 series, a family of parameter-efficient dense language models designed for compute and memory constrained applications, available in three model sizes: 3B, 8B, and 14B parameters. For each model size, we release three variants: a pretrained base model for general-purpose use, an instruction finetuned, and a reasoning model for complex problem-solving. In addition, we present our recipe to derive the Ministral 3 models through Cascade Distillation, an iterative pruning and continued training with distillation technique. Each model comes with image understanding capabilities, all under the Apache 2.0 license.",
      "authors": [
        "Alexander H. Liu",
        "Kartik Khandelwal",
        "Sandeep Subramanian",
        "Victor Jouault",
        "Abhinav Rastogi",
        "Adrien Sadé",
        "Alan Jeffares",
        "Albert Jiang",
        "Alexandre Cahill",
        "Alexandre Gavaudan",
        "Alexandre Sablayrolles",
        "Amélie Héliou",
        "Amos You",
        "Andy Ehrenberg",
        "Andy Lo",
        "Anton Eliseev",
        "Antonia Calvi",
        "Avinash Sooriyarachchi",
        "Baptiste Bout",
        "Baptiste Rozière",
        "Baudouin De Monicault",
        "Clémence Lanfranchi",
        "Corentin Barreau",
        "Cyprien Courtot",
        "Daniele Grattarola",
        "Darius Dabert",
        "Diego de las Casas",
        "Elliot Chane-Sane",
        "Faruk Ahmed",
        "Gabrielle Berrada",
        "Gaëtan Ecrepont",
        "Gauthier Guinet",
        "Georgii Novikov",
        "Guillaume Kunsch",
        "Guillaume Lample",
        "Guillaume Martin",
        "Gunshi Gupta",
        "Jan Ludziejewski",
        "Jason Rute",
        "Joachim Studnia",
        "Jonas Amar",
        "Joséphine Delas",
        "Josselin Somerville Roberts",
        "Karmesh Yadav",
        "Khyathi Chandu",
        "Kush Jain",
        "Laurence Aitchison",
        "Laurent Fainsin",
        "Léonard Blier",
        "Lingxiao Zhao",
        "Louis Martin",
        "Lucile Saulnier",
        "Luyu Gao",
        "Maarten Buyl",
        "Margaret Jennings",
        "Marie Pellat",
        "Mark Prins",
        "Mathieu Poirée",
        "Mathilde Guillaumin",
        "Matthieu Dinot",
        "Matthieu Futeral",
        "Maxime Darrin",
        "Maximilian Augustin",
        "Mia Chiquier",
        "Michel Schimpf",
        "Nathan Grinsztajn",
        "Neha Gupta",
        "Nikhil Raghuraman",
        "Olivier Bousquet",
        "Olivier Duchenne",
        "Patricia Wang",
        "Patrick von Platen",
        "Paul Jacob",
        "Paul Wambergue",
        "Paula Kurylowicz",
        "Pavankumar Reddy Muddireddy",
        "Philomène Chagniot",
        "Pierre Stock",
        "Pravesh Agrawal",
        "Quentin Torroba",
        "Romain Sauvestre",
        "Roman Soletskyi",
        "Rupert Menneer",
        "Sagar Vaze",
        "Samuel Barry",
        "Sanchit Gandhi",
        "Siddhant Waghjale",
        "Siddharth Gandhi",
        "Soham Ghosh",
        "Srijan Mishra",
        "Sumukh Aithal",
        "Szymon Antoniak",
        "Teven Le Scao",
        "Théo Cachet",
        "Theo Simon Sorg",
        "Thibaut Lavril",
        "Thiziri Nait Saada",
        "Thomas Chabal",
        "Thomas Foubert",
        "Thomas Robert",
        "Thomas Wang",
        "Tim Lawson",
        "Tom Bewley",
        "Tom Bewley",
        "Tom Edwards",
        "Umar Jamil",
        "Umberto Tomasini",
        "Valeriia Nemychnikova",
        "Van Phung",
        "Vincent Maladière",
        "Virgile Richard",
        "Wassim Bouaziz",
        "Wen-Ding Li",
        "William Marshall",
        "Xinghui Li",
        "Xinyu Yang",
        "Yassine El Ouahidi",
        "Yihan Wang",
        "Yunhao Tang",
        "Zaccharie Ramzi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-13T14:06:03+00:00",
      "link": "https://arxiv.org/pdf/2601.08584v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01667v1",
      "title": "Quantifying Epistemic Predictive Uncertainty in Conformal Prediction",
      "abstract": "We study the problem of quantifying epistemic predictive uncertainty (EPU) -- that is, uncertainty faced at prediction time due to the existence of multiple plausible predictive models -- within the framework of conformal prediction (CP). To expose the implicit model multiplicity underlying CP, we build on recent results showing that, under a mild assumption, any full CP procedure induces a set of closed and convex predictive distributions, commonly referred to as a credal set. Importantly, the conformal prediction region (CPR) coincides exactly with the set of labels to which all distributions in the induced credal set assign probability at least $1-α$. As our first contribution, we prove that this characterisation also holds in split CP. Building on this connection, we then propose a computationally efficient and analytically tractable uncertainty measure, based on \\emph{Maximum Mean Imprecision}, to quantify the EPU by measuring the degree of conflicting information within the induced credal set. Experiments on active learning and selective classification demonstrate that the quantified EPU provides substantially more informative and fine-grained uncertainty assessments than reliance on CPR size alone. More broadly, this work highlights the potential of CP serving as a principled basis for decision-making under epistemic uncertainty.",
      "authors": [
        "Siu Lun Chau",
        "Soroush H. Zargarbashi",
        "Yusuf Sale",
        "Michele Caprio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T05:38:07+00:00",
      "link": "https://arxiv.org/pdf/2602.01667v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19259v1",
      "title": "Learning Collective Medication Effects via Multi-level Abstraction for Medication Recommendation",
      "abstract": "Historical prescriptions and selected candidate drugs relevant to the current visit serve as important references for medication recommendation. However, in the absence of explicit intrinsic principles for semantic composition, existing methods treat synergistic drugs as independent entities and fail to capture their collective therapeutic effects, resulting in a mismatch between medication-level references and longitudinal patient representations. In this paper, we propose MSAM, a novel medication recommendation model that bridges the gap via multi-level medication abstraction. The model introduces a multi-head graph reasoning mechanism to organize flat daily medication sets into clinically meaningful semantic units, serving as intermediate abstraction results to propagate features from individual drugs to higher-level representations. Building on these units, MSAM performs two-stage abstraction over historical prescriptions and selected candidates via intra- and inter-level feature propagation across heterogeneous clinical structures, capturing collective therapeutic effects aligned with patient conditions. Experiments on two real-world clinical datasets show that MSAM consistently outperforms state-of-the-art methods, validating the effectiveness of structural medication abstraction for recommendation.",
      "authors": [
        "Yanda Wang",
        "Weitong Chen",
        "Chao Tan",
        "Ian Nabney",
        "Lin Yue",
        "Genlin Ji"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-27T06:40:50+00:00",
      "link": "https://arxiv.org/pdf/2601.19259v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19257v1",
      "title": "PCEvo: Path-Consistent Molecular Representation via Virtual Evolutionary",
      "abstract": "Molecular representation learning aims to learn vector embeddings that capture molecular structure and geometry, thereby enabling property prediction and downstream scientific applications. In many AI for science tasks, labeled data are expensive to obtain and therefore limited in availability. Under the few-shot setting, models trained with scarce supervision often learn brittle structure-property relationships, resulting in substantially higher prediction errors and reduced generalization to unseen molecules. To address this limitation, we propose PCEvo, a path-consistent representation method that learns from virtual paths through dynamic structural evolution. PCEvo enumerates multiple chemically feasible edit paths between retrieved similar molecular pairs under topological dependency constraints. It transforms the labels of the two molecules into stepwise supervision along each virtual evolutionary path. It introduces a path-consistency objective that enforces prediction invariance across alternative paths connecting the same two molecules. Comprehensive experiments on the QM9 and MoleculeNet datasets demonstrate that PCEvo substantially improves the few-shot generalization performance of baseline methods. The code is available at https://anonymous.4open.science/r/PCEvo-4BF2.",
      "authors": [
        "Kun Li",
        "Longtao Hu",
        "Yida Xiong",
        "Jiajun Yu",
        "Hongzhi Zhang",
        "Jiameng Chen",
        "Xiantao Cai",
        "Jia Wu",
        "Wenbin Hu"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-27T06:40:11+00:00",
      "link": "https://arxiv.org/pdf/2601.19257v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14732v1",
      "title": "DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling",
      "abstract": "AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of-the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM.",
      "authors": [
        "Jing Lan",
        "Hexiao Ding",
        "Hongzhao Chen",
        "Yufeng Jiang",
        "Nga-Chun Ng",
        "Gwing Kei Yip",
        "Gerald W. Y. Cheng",
        "Yunlin Mao",
        "Jing Cai",
        "Liang-ting Lin",
        "Jung Sun Yoo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.MM"
      ],
      "published": "2026-01-21T07:41:59+00:00",
      "link": "https://arxiv.org/pdf/2601.14732v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02742v1",
      "title": "Entropy-Guided Dynamic Tokens for Graph-LLM Alignment in Molecular Understanding",
      "abstract": "Molecular understanding is central to advancing areas such as scientific discovery, yet Large Language Models (LLMs) struggle to understand molecular graphs effectively. Existing graph-LLM bridges often adapt the Q-Former-style connector with fixed-length static tokens, which is originally designed for vision tasks. These designs overlook stereochemistry and substructural context and typically require costly LLM-backbone fine-tuning, limiting efficiency and generalization. We introduce EDT-Former, an Entropy-guided Dynamic Token Transformer that generates tokens aligned with informative molecular patches, thereby preserving both local and global structural features for molecular graph understanding. Beyond prior approaches, EDT-Former enables alignment between frozen graph encoders and LLMs without tuning the LLM backbone (excluding the embedding layer), resulting in computationally efficient finetuning, and achieves stateof-the-art results on MoleculeQA, Molecule-oriented Mol-Instructions, and property prediction benchmarks (TDC, MoleculeNet), underscoring its effectiveness for scalable and generalizable multimodal molecular understanding",
      "authors": [
        "Zihao Jing",
        "Qiuhao Zeng",
        "Ruiyi Fang",
        "Yan Sun",
        "Boyu Wang",
        "Pingzhao Hu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-02T19:56:21+00:00",
      "link": "https://arxiv.org/pdf/2602.02742v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10667v1",
      "title": "Stable evaluation of derivatives for barycentric and continued fraction representations of rational functions",
      "abstract": "Fast algorithms for approximation by rational functions exist for both barycentric and Thiele continued fraction (TCF) representations. We present the first numerically stable methods for derivative evaluation in the barycentric representation, including an $O(n)$ algorithm for all derivatives. We also extend an earlier $O(n)$ algorithm for evaluation of the TCF first derivative to higher orders. Numerical experiments confirm the robustness and efficiency of the proposed methods.",
      "authors": [
        "Tobin A. Driscoll",
        "Yuxing Zhou"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-15T18:33:30+00:00",
      "link": "https://arxiv.org/pdf/2601.10667v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03096v1",
      "title": "PRISM: Structured Optimization via Anisotropic Spectral Shaping",
      "abstract": "We propose PRISM, an optimizer that enhances first-order spectral descent methods like Muon with partial second-order information. It constructs an efficient, low-rank quasi-second-order preconditioner via innovation-augmented polar decomposition. This mechanism enables PRISM to perform anisotropic spectral shaping, which adaptively suppresses updates in high-variance subspaces while preserving update strength in signal-dominated directions. Crucially, this is achieved with minimal computational overhead and zero additional memory compared to first-order baselines. PRISM demonstrates a practical strategy for integrating curvature-adaptive properties into the spectral optimization paradigm.",
      "authors": [
        "Yujie Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T04:41:11+00:00",
      "link": "https://arxiv.org/pdf/2602.03096v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19551v1",
      "title": "Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations",
      "abstract": "Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.",
      "authors": [
        "Geunhyeok Yu",
        "Hyoseok Hwang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27T12:44:20+00:00",
      "link": "https://arxiv.org/pdf/2601.19551v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00547v1",
      "title": "Contrastive Domain Generalization for Cross-Instrument Molecular Identification in Mass Spectrometry",
      "abstract": "Identifying molecules from mass spectrometry (MS) data remains a fundamental challenge due to the semantic gap between physical spectral peaks and underlying chemical structures. Existing deep learning approaches often treat spectral matching as a closed-set recognition task, limiting their ability to generalize to unseen molecular scaffolds. To overcome this limitation, we propose a cross-modal alignment framework that directly maps mass spectra into the chemically meaningful molecular structure embedding space of a pretrained chemical language model. On a strict scaffold-disjoint benchmark, our model achieves a Top-1 accuracy of 42.2% in fixed 256-way zero-shot retrieval and demonstrates strong generalization under a global retrieval setting. Moreover, the learned embedding space demonstrates strong chemical coherence, reaching 95.4% accuracy in 5-way 5-shot molecular re-identification. These results suggest that explicitly integrating physical spectral resolution with molecular structure embedding is key to solving the generalization bottleneck in molecular identification from MS data.",
      "authors": [
        "Seunghyun Yoo",
        "Sanghong Kim",
        "Namkyung Yoon",
        "Hwangnam Kim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-31T06:18:47+00:00",
      "link": "https://arxiv.org/pdf/2602.00547v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05479v1",
      "title": "Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction",
      "abstract": "Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.",
      "authors": [
        "Zhe Wang",
        "Zijing Liu",
        "Chencheng Xu",
        "Yuan Yao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-05T09:39:22+00:00",
      "link": "https://arxiv.org/pdf/2602.05479v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03394v1",
      "title": "Improving the Linearized Laplace Approximation via Quadratic Approximations",
      "abstract": "Deep neural networks (DNNs) often produce overconfident out-of-distribution predictions, motivating Bayesian uncertainty quantification. The Linearized Laplace Approximation (LLA) achieves this by linearizing the DNN and applying Laplace inference to the resulting model. Importantly, the linear model is also used for prediction. We argue this linearization in the posterior may degrade fidelity to the true Laplace approximation. To alleviate this problem, without increasing significantly the computational cost, we propose the Quadratic Laplace Approximation (QLA). QLA approximates each second order factor in the approximate Laplace log-posterior using a rank-one factor obtained via efficient power iterations. QLA is expected to yield a posterior precision closer to that of the full Laplace without forming the full Hessian, which is typically intractable. For prediction, QLA also uses the linearized model. Empirically, QLA yields modest yet consistent uncertainty estimation improvements over LLA on five regression datasets.",
      "authors": [
        "Pedro Jiménez",
        "Luis A. Ortega",
        "Pablo Morales-Álvarez",
        "Daniel Hernández-Lobato"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-03T11:15:38+00:00",
      "link": "https://arxiv.org/pdf/2602.03394v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21678v1",
      "title": "Scale-Dependent Semantic Dynamics Revealed by Allan Deviation",
      "abstract": "While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.",
      "authors": [
        "Debayan Dasgupta"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "physics.data-an"
      ],
      "published": "2026-01-29T13:10:59+00:00",
      "link": "https://arxiv.org/pdf/2601.21678v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16945v1",
      "title": "A new class of colored Gaussian graphical models with explicit normalizing constants",
      "abstract": "We study Bayesian model selection in colored Gaussian graphical models (CGGMs), which combine sparsity of conditional independencies with symmetry constraints encoded by vertex- and edge-colored graphs. A computational bottleneck in Bayesian inference for CGGMs is the evaluation of Diaconis-Ylvisaker normalizing constants, given by gamma-type integrals over cones of precision matrices with prescribed zeros and equality constraints. While explicit formulas are known for standard Gaussian graphical models only in special cases (e.g. decomposable graphs) and for a limited class of RCOP models, no general tractable framework has been available for broader families of CGGMs.   We introduce a new subclass of RCON models for which these normalizing constants admit closed-form expressions. On the algebraic side, we identify conditions on spaces of colored precision matrices that guarantee tractability of the associated integrals, leading to Block-Cholesky spaces (BC-spaces) and Diagonally Commutative Block-Cholesky spaces (DCBC-spaces). On the combinatorial side, we characterize the colored graphs inducing such spaces via a color perfect elimination ordering and a 2-path regularity condition, and define the resulting Color Elimination-Regular (CER) graphs and their symmetric variants. This class strictly extends decomposable graphs in the uncolored setting and contains all RCOP models associated with decomposable graphs. In the one-color case, our framework reveals a close connection between DCBC-spaces and Bose-Mesner algebras.   For models defined on BC- and DCBC-spaces, we derive explicit closed-form formulas for the normalizing constants in terms of a finite collection of structure constants and propose an efficient method for computing them in the commutative case. Our results broaden the range of CGGMs amenable to principled Bayesian structure learning in high-dimensional applications.",
      "authors": [
        "Adam Chojecki",
        "Piotr Graczyk",
        "Hideyuki Ishi",
        "Bartosz Kołodziejek"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.PR"
      ],
      "published": "2026-01-23T18:01:37+00:00",
      "link": "https://arxiv.org/pdf/2601.16945v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15890v1",
      "title": "Existential Positive Transductions of Sparse Graphs",
      "abstract": "Monadic stability generalizes many tameness notions from structural graph theory such as planarity, bounded degree, bounded tree-width, and nowhere density. The sparsification conjecture predicts that the (possibly dense) monadically stable graph classes are exactly those that can be logically encoded by first-order (FO) transductions in the (always sparse) nowhere dense classes. So far this conjecture has been verified for several special cases, such as for classes of bounded shrub-depth, and for the monadically stable fragments of bounded (linear) clique-width, twin-width, and merge-width.   In this work we propose the existential positive sparsification conjecture, predicting that the more restricted co-matching-free, monadically stable classes are exactly those that can be transduced from nowhere dense classes using only existential positive FO formulas. While the general conjecture remains open, we verify its truth for all known special cases of the original conjecture. Even stronger, we find the sparse preimages as subgraphs of the dense input graphs.   As a key ingredient, we introduce a new combinatorial operation, called subflip, that arises as the natural co-matching-free analog of the flip operation, which is a central tool in the characterization of monadic stability. Using subflips, we characterize the co-matching-free fragment of monadic stability by appropriate strengthenings of the known flip-flatness and flipper game characterizations for monadic stability. In an attempt to generalize our results to the more expressive MSO logic, we discover (rediscover?) that on relational structures (existential) positive MSO has the same expressive power as (existential) positive FO.",
      "authors": [
        "Nikolas Mählmann",
        "Sebastian Siebertz"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM",
        "cs.LO",
        "math.CO",
        "math.LO"
      ],
      "published": "2026-01-22T12:11:48+00:00",
      "link": "https://arxiv.org/pdf/2601.15890v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04936v1",
      "title": "Deterministic Retrieval at Scale: Optimal-Space LCP Indexing and 308x Energy Reduction on Modern GPUs",
      "abstract": "We study deterministic top-k retrieval under Longest Common Prefix (LCP) similarity for N sequences of length L. We prove a tight Omega(N) space lower bound (cell-probe model) and present a trie-based index using O(N*L) space with O(L+k) query time. We contrast this with pairwise materialization (Theta(N^2)), which hits a practical OOM wall at scale, while our indexed approach remains O(N) in memory. We then introduce Thermal-Aware Logic (TAL), which turns prefix structure into range-bounded scans. In hardware measurements, TAL reduces energy per query by 308x (0.0145 J vs 4.46 J) and cuts p95 latency by 329x (0.114 ms vs 37.5 ms) on a 20M-item range-scan benchmark, while sustaining near-peak utilization (~99%) under long runs. The result is a deterministic retrieval primitive with receipts in regimes where approximate methods are unacceptable.",
      "authors": [
        "Stanislav Byriukov"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.IR"
      ],
      "published": "2026-02-04T15:40:42+00:00",
      "link": "https://arxiv.org/pdf/2602.04936v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00987v1",
      "title": "Scalable Random Wavelet Features: Efficient Non-Stationary Kernel Approximation with Convergence Guarantees",
      "abstract": "Modeling non-stationary processes, where statistical properties vary across the input domain, is a critical challenge in machine learning; yet most scalable methods rely on a simplifying assumption of stationarity. This forces a difficult trade-off: use expressive but computationally demanding models like Deep Gaussian Processes, or scalable but limited methods like Random Fourier Features (RFF). We close this gap by introducing Random Wavelet Features (RWF), a framework that constructs scalable, non-stationary kernel approximations by sampling from wavelet families. By harnessing the inherent localization and multi-resolution structure of wavelets, RWF generates an explicit feature map that captures complex, input-dependent patterns. Our framework provides a principled way to generalize RFF to the non-stationary setting and comes with a comprehensive theoretical analysis, including positive definiteness, unbiasedness, and uniform convergence guarantees. We demonstrate empirically on a range of challenging synthetic and real-world datasets that RWF outperforms stationary random features and offers a compelling accuracy-efficiency trade-off against more complex models, unlocking scalable and expressive kernel methods for a broad class of real-world non-stationary problems.",
      "authors": [
        "Sawan Kumar",
        "Souvik Chakraborty"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-01T02:56:56+00:00",
      "link": "https://arxiv.org/pdf/2602.00987v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22382v1",
      "title": "Purely Agentic Black-Box Optimization for Biological Design",
      "abstract": "Many key challenges in biological design-such as small-molecule drug discovery, antimicrobial peptide development, and protein engineering-can be framed as black-box optimization over vast, complex structured spaces. Existing methods rely mainly on raw structural data and struggle to exploit the rich scientific literature. While large language models (LLMs) have been added to these pipelines, they have been confined to narrow roles within structure-centered optimizers. We instead cast biological black-box optimization as a fully agentic, language-based reasoning process. We introduce Purely Agentic BLack-box Optimization (PABLO), a hierarchical agentic system that uses scientific LLMs pretrained on chemistry and biology literature to generate and iteratively refine biological candidates. On both the standard GuacaMol molecular design and antimicrobial peptide optimization tasks, PABLO achieves state-of-the-art performance, substantially improving sample efficiency and final objective values over established baselines. Compared to prior optimization methods that incorporate LLMs, PABLO achieves competitive token usage per run despite relying on LLMs throughout the optimization loop. Beyond raw performance, the agentic formulation offers key advantages for realistic design: it naturally incorporates semantic task descriptions, retrieval-augmented domain knowledge, and complex constraints. In follow-up in vitro validation, PABLO-optimized peptides showed strong activity against drug-resistant pathogens, underscoring the practical potential of PABLO for therapeutic discovery.",
      "authors": [
        "Natalie Maus",
        "Yimeng Zeng",
        "Haydn Thomas Jones",
        "Yining Huang",
        "Gaurav Ng Goel",
        "Alden Rose",
        "Kyurae Kim",
        "Hyun-Su Lee",
        "Marcelo Der Torossian Torres",
        "Fangping Wan",
        "Cesar de la Fuente-Nunez",
        "Mark Yatskar",
        "Osbert Bastani",
        "Jacob R. Gardner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T22:45:07+00:00",
      "link": "https://arxiv.org/pdf/2601.22382v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01042v1",
      "title": "On Condensation of Block Sensitivity, Certificate Complexity and the $\\mathsf{AND}$ (and $\\mathsf{OR}$) Decision Tree Complexity",
      "abstract": "Given an $n$-bit Boolean function with a complexity measure (such as block sensitivity, query complexity, etc.) $M(f) = k$, the hardness condensation question asks whether $f$ can be restricted to $O(k)$ variables such that the complexity measure is $Ω(k)$?   In this work, we study the condensability of block sensitivity, certificate complexity, AND (and OR) query complexity and Fourier sparsity. We show that block sensitivity does not condense under restrictions, unlike sensitivity: there exists a Boolean function $f$ with query complexity $k$ such that any restriction of $f$ to $O(k)$ variables has block sensitivity $O(k^{\\frac{2}{3}})$. This answers an open question in Göös, Newman, Riazanov, and Sokolov (2024) in the negative. The same function yields an analogous incondensable result for certificate complexity. We further show that $\\mathsf{AND}$(and $\\mathsf{OR}$) decision trees are also incondensable. In contrast, we prove that Fourier sparsity admits a weak form of condensation.",
      "authors": [
        "Sai Soumya Nalli",
        "Karthikeya Polisetty",
        "Jayalal Sarma"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC"
      ],
      "published": "2026-02-01T06:03:31+00:00",
      "link": "https://arxiv.org/pdf/2602.01042v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07261v1",
      "title": "Pseudodata-guided Invariant Representation Learning Boosts the Out-of-Distribution Generalization in Enzymatic Kinetic Parameter Prediction",
      "abstract": "Accurate prediction of enzyme kinetic parameters is essential for understanding catalytic mechanisms and guiding enzyme engineering.However, existing deep learning-based enzyme-substrate interaction (ESI) predictors often exhibit performance degradation on sequence-divergent, out-of-distribution (OOD) cases, limiting robustness under biologically relevant perturbations.We propose O$^2$DENet, a lightweight, plug-and-play module that enhances OOD generalization via biologically and chemically informed perturbation augmentation and invariant representation learning.O$^2$DENet introduces enzyme-substrate perturbations and enforces consistency between original and augmented enzyme-substrate-pair representations to encourage invariance to distributional shifts.When integrated with representative ESI models, O$^2$DENet consistently improves predictive performance for both $k_{cat}$ and $K_m$ across stringent sequence-identity-based OOD benchmarks, achieving state-of-the-art results among the evaluated methods in terms of accuracy and robustness metrics.Overall, O$^2$DENet provides a general and effective strategy to enhance the stability and deployability of data-driven enzyme kinetics predictors for real-world enzyme engineering applications.",
      "authors": [
        "Haomin Wu",
        "Zhiwei Nie",
        "Hongyu Zhang",
        "Zhixiang Ren"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "published": "2026-01-12T07:03:07+00:00",
      "link": "https://arxiv.org/pdf/2601.07261v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07892v1",
      "title": "Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification",
      "abstract": "The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. While ternary quantization offers a compelling solution by reducing weights to {-1, 0, +1}, current implementations suffer from a fundamental misalignment with commodity hardware. Most existing methods must choose between 2-bit aligned packing, which incurs significant bit wastage, or 1.67-bit irregular packing, which degrades inference speed. To resolve this tension, we propose Sherry, a hardware-efficient ternary quantization framework. Sherry introduces a 3:4 fine-grained sparsity that achieves a regularized 1.25-bit width by packing blocks of four weights into five bits, restoring power-of-two alignment. Furthermore, we identify weight trapping issue in sparse ternary training, which leads to representational collapse. To address this, Sherry introduces Arenas, an annealing residual synapse mechanism that maintains representational diversity during training. Empirical evaluations on LLaMA-3.2 across five benchmarks demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size. Notably, on an Intel i7-14700HX CPU, our 1B model achieves zero accuracy loss compared to SOTA baselines while providing 25% bit savings and 10% speed up. The code is available at https://github.com/Tencent/AngelSlim .",
      "authors": [
        "Hong Huang",
        "Decheng Wu",
        "Qiangqiang Hu",
        "Guanghua Yu",
        "Jinhai Yang",
        "Jianchen Zhu",
        "Xue Liu",
        "Dapeng Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-12T08:49:34+00:00",
      "link": "https://arxiv.org/pdf/2601.07892v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19232v1",
      "title": "Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model",
      "abstract": "RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.",
      "authors": [
        "Qi Si",
        "Xuyang Liu",
        "Penglei Wang",
        "Xin Guo",
        "Yuan Qi",
        "Yuan Cheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27T06:04:02+00:00",
      "link": "https://arxiv.org/pdf/2601.19232v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04916v1",
      "title": "AFD-INSTRUCTION: A Comprehensive Antibody Instruction Dataset with Functional Annotations for LLM-Based Understanding and Design",
      "abstract": "Large language models (LLMs) have significantly advanced protein representation learning. However, their capacity to interpret and design antibodies through natural language remains limited. To address this challenge, we present AFD-Instruction, the first large-scale instruction dataset with functional annotations tailored to antibodies. This dataset encompasses two key components: antibody understanding, which infers functional attributes directly from sequences, and antibody design, which enables de novo sequence generation under functional constraints. These components provide explicit sequence-function alignment and support antibody design guided by natural language instructions. Extensive instruction-tuning experiments on general-purpose LLMs demonstrate that AFD-Instruction consistently improves performance across diverse antibody-related tasks. By linking antibody sequences with textual descriptions of function, AFD-Instruction establishes a new foundation for advancing antibody modeling and accelerating therapeutic discovery.",
      "authors": [
        "Ling Luo",
        "Wenbin Jiang",
        "Xushi Zhang",
        "Hongyuan Chang",
        "Xinkang Wang",
        "Yueting Xiong",
        "Mengsha Tong",
        "Rongshan Yu"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM",
        "cs.CL"
      ],
      "published": "2026-02-04T05:09:39+00:00",
      "link": "https://arxiv.org/pdf/2602.04916v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04489v1",
      "title": "Deconstructing sentence disambiguation by joint latent modeling of reading paradigms: LLM surprisal is not enough",
      "abstract": "Using temporarily ambiguous garden-path sentences (\"While the team trained the striker wondered ...\") as a test case, we present a latent-process mixture model of human reading behavior across four different reading paradigms (eye tracking, uni- and bidirectional self-paced reading, Maze). The model distinguishes between garden-path probability, garden-path cost, and reanalysis cost, and yields more realistic processing cost estimates by taking into account trials with inattentive reading. We show that the model is able to reproduce empirical patterns with regard to rereading behavior, comprehension question responses, and grammaticality judgments. Cross-validation reveals that the mixture model also has better predictive fit to human reading patterns and end-of-trial task data than a mixture-free model based on GPT-2-derived surprisal values. We discuss implications for future work.",
      "authors": [
        "Dario Paape",
        "Tal Linzen",
        "Shravan Vasishth"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-04T12:27:49+00:00",
      "link": "https://arxiv.org/pdf/2602.04489v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10254v1",
      "title": "NoReGeo: Non-Reasoning Geometry Benchmark",
      "abstract": "We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.",
      "authors": [
        "Irina Abdullaeva",
        "Anton Vasiliuk",
        "Elizaveta Goncharova",
        "Temurbek Rahmatullaev",
        "Zagorulko Ivan",
        "Maxim Kurkin",
        "Andrey Kuznetsov"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-15T10:22:55+00:00",
      "link": "https://arxiv.org/pdf/2601.10254v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00161v1",
      "title": "Block removal for large language models through constrained binary optimization",
      "abstract": "Compressing resource-intensive large language models by removing whole transformer blocks is a seemingly simple idea, but identifying which blocks to remove constitutes an exponentially difficult combinatorial problem. In this paper, we formulate block removal as a constrained binary optimization problem that can be mapped to a physical system (Ising model), whose energies are a strong proxy for downstream model performance. This formulation enables an efficient ranking of a large number of candidate block-removal configurations and yields many high-quality, non-trivial solutions beyond consecutive regions. We demonstrate that our approach outperforms state-of-the-art block-removal methods across several benchmarks, with performance gains persisting after short retraining, and reaching improvements of up to 6 points on the MMLU benchmark. Our method requires only forward and backward passes for a few active parameters, together with an (at least approximate) Ising solver, and can be readily applied to any architecture. We illustrate this generality on the recent NVIDIA-Nemotron-3-Nano-30B-A3B-FP8 model, which exhibits a highly inhomogeneous and challenging block structure.",
      "authors": [
        "David Jansen",
        "Roman Rausch",
        "David Montero",
        "Roman Orus"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "quant-ph"
      ],
      "published": "2026-01-29T19:46:39+00:00",
      "link": "https://arxiv.org/pdf/2602.00161v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.23182v1",
      "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
      "abstract": "Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details. Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation. FourierSampler outperforms other inference enhancement strategies on LLADA and SDAR, achieving relative improvements of 20.4% on LLaDA1.5-8B and 16.0% on LLaDA-8B-Instruct. It notably surpasses similarly sized autoregressive models like Llama3.1-8B-Instruct.",
      "authors": [
        "Siyang He",
        "Qiqi Wang",
        "Xiaoran Liu",
        "Hongnan Ma",
        "Yiwei Shi",
        "Yuerong Song",
        "Ying Zhu",
        "Tianyi Liang",
        "Zengfeng Huang",
        "Ziwei He",
        "Xipeng Qiu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-30T17:06:41+00:00",
      "link": "https://arxiv.org/pdf/2601.23182v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00663v1",
      "title": "SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent",
      "abstract": "Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.",
      "authors": [
        "Fabian P. Krüger",
        "Andrea Hunklinger",
        "Adrian Wolny",
        "Tim J. Adler",
        "Igor Tetko",
        "Santiago David Villalba"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "published": "2026-01-31T11:23:48+00:00",
      "link": "https://arxiv.org/pdf/2602.00663v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21287v1",
      "title": "Towards Zero Rotation and Beyond: Architecting Neural Networks for Fast Secure Inference with Homomorphic Encryption",
      "abstract": "Privacy-preserving deep learning addresses privacy concerns in Machine Learning as a Service (MLaaS) by using Homomorphic Encryption (HE) for linear computations. However, the computational overhead remains a major challenge. While prior work has improved efficiency, most approaches build on models originally designed for plaintext inference. Such models incur architectural inefficiencies when adapted to HE. We argue that substantial gains require networks tailored to HE rather than retrofitting plaintext architectures. Our design has two components: the building block and the overall architecture. First, StriaBlock targets the most expensive HE operation, rotation. It integrates ExRot-Free Convolution and a novel Cross Kernel, eliminating external rotations and requiring only 19% of the internal rotations used by plaintext models. Second, our architectural principles include (i) the Focused Constraint Principle, which limits cost-sensitive factors while preserving flexibility elsewhere, and (ii) the Channel Packing-Aware Scaling Principle, which adapts bottleneck ratios to ciphertext channel capacity that varies with depth. Together, these strategies control both local and end-to-end HE cost, enabling a balanced HE-tailored network. We evaluate the resulting StriaNet across datasets of varying scales, including ImageNet, Tiny ImageNet, and CIFAR-10. At comparable accuracy, StriaNet achieves speedups of 9.78x, 6.01x, and 9.24x on ImageNet, Tiny ImageNet, and CIFAR-10, respectively.",
      "authors": [
        "Yifei Cai",
        "Yizhou Feng",
        "Qiao Zhang",
        "Chunsheng Xin",
        "Hongyi Wu"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR"
      ],
      "published": "2026-01-29T05:40:05+00:00",
      "link": "https://arxiv.org/pdf/2601.21287v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11135v1",
      "title": "Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction",
      "abstract": "Molecular property prediction is becoming one of the major applications of graph learning in Web-based services, e.g., online protein structure prediction and drug discovery. A key challenge arises in few-shot scenarios, where only a few labeled molecules are available for predicting unseen properties. Recently, several studies have used in-context learning to capture relationships among molecules and properties, but they face two limitations in: (1) exploiting prior knowledge of functional groups that are causally linked to properties and (2) identifying key substructures directly correlated with properties. We propose CaMol, a context-aware graph causality inference framework, to address these challenges by using a causal inference perspective, assuming that each molecule consists of a latent causal structure that determines a specific property. First, we introduce a context graph that encodes chemical knowledge by linking functional groups, molecules, and properties to guide the discovery of causal substructures. Second, we propose a learnable atom masking strategy to disentangle causal substructures from confounding ones. Third, we introduce a distribution intervener that applies backdoor adjustment by combining causal substructures with chemically grounded confounders, disentangling causal effects from real-world chemical variations. Experiments on diverse molecular datasets showed that CaMol achieved superior accuracy and sample efficiency in few-shot tasks, showing its generalizability to unseen properties. Also, the discovered causal substructures were strongly aligned with chemical knowledge about functional groups, supporting the model interpretability.",
      "authors": [
        "Van Thuy Hoang",
        "O-Joun Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-16T09:49:50+00:00",
      "link": "https://arxiv.org/pdf/2601.11135v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00461v1",
      "title": "Decomposable shuffles",
      "abstract": "We develop a combinatorial and order-theoretic framework for shuffles, understood as ordered concatenations of indexed families of sequences that induce total orders on the natural numbers. Motivated by the classical Šarkovskiĭ order, we introduce elementary building blocks that encode finite and infinite order patterns and focus on decomposable shuffles constructed from finite ordinals together with $ω$ and its dual $ω^*$. We define representations that allow individual elements to be located within a shuffle and show how suitable structural conditions yield total orders on $\\mathbb{N}$",
      "authors": [
        "João Dias",
        "Bruno Dinis",
        "Carlos Correia Ramos"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO",
        "math.LO"
      ],
      "published": "2026-01-31T02:30:23+00:00",
      "link": "https://arxiv.org/pdf/2602.00461v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12220v1",
      "title": "Canonicalization of Batched Einstein Summations for Tuning Retrieval",
      "abstract": "We present an algorithm for normalizing \\emph{Batched Einstein Summation}   expressions by mapping mathematically equivalent formulations to a unique   normal form. Batches of einsums with the same Einstein notation that exhibit   substantial data reuse appear frequently in finite element methods (FEM),   numerical linear algebra, and computational chemistry. To effectively exploit   this temporal locality for high performance, we consider groups of einsums in   batched form.   Representations of equivalent batched einsums may differ due to index   renaming, permutations within the batch, and, due to the commutativity and   associativity of multiplication operation. The lack of a canonical   representation hinders the reuse of optimization and tuning knowledge in   software systems. To this end, we develop a novel encoding of batched einsums   as colored graphs and apply graph canonicalization to derive a normal form.   In addition to the canonicalization algorithm, we propose a representation of   einsums using functional array operands and provide a strategy to transfer   transformations operating on the normal form to \\emph{functional batched   einsums} that exhibit the same normal form; crucial for fusing surrounding   computations for memory bound einsums. We evaluate our approach against JAX,   and observe a geomean speedup of $4.7\\times$ for einsums from the TCCG   benchmark suite and an FEM solver.",
      "authors": [
        "Kaushik Kulkarni",
        "Andreas Klöckner"
      ],
      "primary_category": "cs.MS",
      "categories": [
        "cs.MS",
        "cs.DC"
      ],
      "published": "2026-01-18T01:50:28+00:00",
      "link": "https://arxiv.org/pdf/2601.12220v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01200v1",
      "title": "Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis",
      "abstract": "Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\\% on CT-RATE and 44.99\\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.",
      "authors": [
        "Haoran Lai",
        "Zihang Jiang",
        "Kun Zhang",
        "Qingsong Yao",
        "Rongsheng Wang",
        "Zhiyang He",
        "Xiaodong Tao",
        "Wei Wei",
        "Shaohua Kevin Zhou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-01T12:43:11+00:00",
      "link": "https://arxiv.org/pdf/2602.01200v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.11028v1",
      "title": "AVP-Pro: An Adaptive Multi-Modal Fusion and Contrastive Learning Approach for Comprehensive Two-Stage Antiviral Peptide Identification",
      "abstract": "The accurate identification of antiviral peptides (AVPs) is crucial for novel drug development. However, existing methods still have limitations in capturing complex sequence dependencies and distinguishing confusing samples with high similarity. To address these challenges, we propose AVP-Pro, a novel two-stage predictive framework that integrates adaptive feature fusion and contrastive learning. To comprehensively capture the physicochemical properties and deep-seated patterns of peptide sequences, we constructed a panoramic feature space encompassing 10 distinct descriptors and designed a hierarchical fusion architecture. This architecture integrates self-attention and adaptive gating mechanisms to dynamically modulate the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Targeting the blurred decision boundary caused by the high similarity between positive and negative sample sequences, we adopted an Online Hard Example Mining (OHEM)-driven contrastive learning strategy enhanced by BLOSUM62. This approach significantly sharpened the model's discriminative power. Model evaluation results show that in the first stage of general AVP identification, the model achieved an accuracy of 0.9531 and an MCC of 0.9064, outperforming existing state-of-the-art (SOTA) methods. In the second stage of functional subtype prediction, combined with a transfer learning strategy, the model realized accurate classification of 6 viral families and 8 specific viruses under small-sample conditions. AVP-Pro provides a powerful and interpretable new tool for the high-throughput screening of antiviral drugs. To further enhance accessibility for users, we have developed a user-friendly web interface, which is available at https://wwwy1031-avp-pro.hf.space.",
      "authors": [
        "Xinru Wen",
        "Weizhong Lin",
        "zi liu",
        "Xuan Xiao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-16T06:48:36+00:00",
      "link": "https://arxiv.org/pdf/2601.11028v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16086v1",
      "title": "Random Walks Across Dimensions: Exploring Simplicial Complexes",
      "abstract": "We introduce a novel operator to describe a random walk process on a simplicial complex. Walkers are allowed to wonder across simplices of various dimensions, bridging nodes to edges, and edges to triangles, via a nested organization that hierarchically extends to higher structures of arbitrary large, but finite, dimension. The asymptotic distribution of the walkers provides a natural ranking to gauge the relative importance of higher order simplices. Optimal search strategies in presence of stochastic teleportation are addressed and the peculiar interplay of noise with higher order structures unraveled.",
      "authors": [
        "Diego Febbe",
        "Duccio Fanelli",
        "Timoteo Carletti"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "nlin.AO",
        "physics.soc-ph"
      ],
      "published": "2026-01-22T16:33:24+00:00",
      "link": "https://arxiv.org/pdf/2601.16086v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01216v1",
      "title": "A Class of Generalised Quantifiers for k-Variable Logics",
      "abstract": "We introduce k-quantifier logics -- logics with access to k-tuples of elements and very general quantification patterns for transitions between k-tuples. The framework is very expressive and encompasses e.g. the k-variable fragments of first-order logic, modal logic, and monotone neighbourhood semantics. We introduce a corresponding notion of bisimulation and prove variants of the classical Ehrenfeucht-Fraisse and Hennessy-Milner theorem. Finally, we show a Lindstrom-style characterisation for k-quantifier logics that satisfy Los' theorem by proving that they are the unique maximally expressive logics that satisfy Los' theorem and are invariant under the associated bisimulation relations.",
      "authors": [
        "Janek Härtter",
        "Martin Otto"
      ],
      "primary_category": "math.LO",
      "categories": [
        "math.LO"
      ],
      "published": "2026-02-01T13:17:56+00:00",
      "link": "https://arxiv.org/pdf/2602.01216v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.23212v1",
      "title": "Disentangling multispecific antibody function with graph neural networks",
      "abstract": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of comprehensive experimental data. Here, we introduce a computational framework to address part of this gap. First, we present a generative method for creating large-scale, realistic synthetic functional landscapes that capture non-linear interactions where biological activity depends on domain connectivity. Second, we propose a graph neural network architecture that explicitly encodes these topological constraints, distinguishing between format configurations that appear identical to sequence-only models. We demonstrate that this model, trained on synthetic landscapes, recapitulates complex functional properties and, via transfer learning, has the potential to achieve high predictive accuracy on limited biological datasets. We showcase the model's utility by optimizing trade-offs between efficacy and toxicity in trispecific T-cell engagers and retrieving optimal common light chains. This work provides a robust benchmarking environment for disentangling the combinatorial complexity of multispecifics, accelerating the design of next-generation therapeutics.",
      "authors": [
        "Joshua Southern",
        "Changpeng Lu",
        "Santrupti Nerli",
        "Samuel D. Stanton",
        "Andrew M. Watkins",
        "Franziska Seeger",
        "Frédéric A. Dreyer"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "published": "2026-01-30T17:36:19+00:00",
      "link": "https://arxiv.org/pdf/2601.23212v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.09285v1",
      "title": "Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction",
      "abstract": "Metal-organic frameworks (MOFs) are porous crystalline materials with broad applications such as carbon capture and drug delivery, yet accurately predicting their 3D structures remains a significant challenge. While Large Language Models (LLMs) have shown promise in generating crystals, their application to MOFs is hindered by MOFs' high atomic complexity. Inspired by the success of block-wise paradigms in deep generative models, we pioneer the use of LLMs in this domain by introducing MOF-LLM, the first LLM framework specifically adapted for block-level MOF structure prediction. To effectively harness LLMs for this modular assembly task, our training paradigm integrates spatial-aware continual pre-training (CPT), structural supervised fine-tuning (SFT), and matching-driven reinforcement learning (RL). By incorporating explicit spatial priors and optimizing structural stability via Soft Adaptive Policy Optimization (SAPO), our approach substantially enhances the spatial reasoning capability of a Qwen-3 8B model for accurate MOF structure prediction. Comprehensive experiments demonstrate that MOF-LLM outperforms state-of-the-art denoising-based and LLM-based methods while exhibiting superior sampling efficiency.",
      "authors": [
        "Mianzhi Pan",
        "JianFei Li",
        "Peishuo Liu",
        "Botian Wang",
        "Yawen Ouyang",
        "Yiming Rong",
        "Hao Zhou",
        "Jianbing Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-14T08:45:07+00:00",
      "link": "https://arxiv.org/pdf/2601.09285v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05605v2",
      "title": "AntibodyDesignBFN: High-Fidelity Fixed-Backbone Antibody Design via Discrete Bayesian Flow Networks",
      "abstract": "The computational design of antibodies with high specificity and affinity is a cornerstone of modern therapeutic development. While deep generative models, particularly Denoising Diffusion Probabilistic Models (DDPMs), have demonstrated the ability to generate realistic antibody structures, they often suffer from high computational costs and the difficulty of modeling discrete variables like amino acid sequences. In this work, we present AntibodyDesignBFN, a novel framework for fixed-backbone antibody design based on Discrete Bayesian Flow Networks(BFN). Unlike standard diffusion models that rely on Gaussian noise removal or complex discrete corruption processes, BFNs operate directly on the parameters of the data distribution, enabling a continuous-time, fully differentiable generative process on the probability simplex. While recent pioneering works like IgCraft and AbBFN have introduced BFNs to the domain of antibody sequence generation and inpainting, our work focuses specifically on the inverse folding task-designing sequences that fold into a fixed 3D backbone. By integrating a lightweight Geometric Transformer utilizing Invariant Point Attention (IPA) and a resource-efficient training strategy with gradient accumulation, our model achieves superior performance. Evaluations on a rigorous 2025 temporal test set reveal that AntibodyDesignBFN achieves a robust Amino Acid Recovery (AAR) , demonstrating that BFNs, when conditioned on 3D geometric constraints, offer a robust mathematical framework for high-fidelity antibody design.Code and model checkpoints are available at https://github.com/YueHuLab/AntibodyDesignBFN and https://huggingface.co/YueHuLab/AntibodyDesignBFN, respectively.",
      "authors": [
        "Yue Hu",
        "YingChao Liu"
      ],
      "primary_category": "q-bio.QM",
      "categories": [
        "q-bio.QM"
      ],
      "published": "2026-01-09T07:50:57+00:00",
      "link": "https://arxiv.org/pdf/2601.05605v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12703v1",
      "title": "Towards Spectroscopy: Susceptibility Clusters in Language Models",
      "abstract": "Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts \"for similar reasons\" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.",
      "authors": [
        "Andrew Gordon",
        "Garrett Baker",
        "George Wang",
        "William Snell",
        "Stan van Wingerden",
        "Daniel Murfet"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-19T04:01:17+00:00",
      "link": "https://arxiv.org/pdf/2601.12703v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13927v1",
      "title": "Towards Modality-Agnostic Continual Domain-Incremental Brain Lesion Segmentation",
      "abstract": "Brain lesion segmentation from multi-modal MRI often assumes fixed modality sets or predefined pathologies, making existing models difficult to adapt across cohorts and imaging protocols. Continual learning (CL) offers a natural solution but current approaches either impose a maximum modality configuration or suffer from severe forgetting in buffer-free settings. We introduce CLMU-Net, a replay-based CL framework for 3D brain lesion segmentation that supports arbitrary and variable modality combinations without requiring prior knowledge of the maximum set. A conceptually simple yet effective channel-inflation strategy maps any modality subset into a unified multi-channel representation, enabling a single model to operate across diverse datasets. To enrich inherently local 3D patch features, we incorporate lightweight domain-conditioned textual embeddings that provide global modality-disease context for each training case. Forgetting is further reduced through principled replay using a compact buffer composed of both prototypical and challenging samples. Experiments on five heterogeneous MRI brain datasets demonstrate that CLMU-Net consistently outperforms popular CL baselines. Notably, our method yields an average Dice score improvement of $\\geq$ 18\\% while remaining robust under heterogeneous-modality conditions. These findings underscore the value of flexible modality handling, targeted replay, and global contextual cues for continual medical image segmentation. Our implementation is available at https://github.com/xmindflow/CLMU-Net.",
      "authors": [
        "Yousef Sadegheih",
        "Dorit Merhof",
        "Pratibha Kumari"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-01-20T13:00:12+00:00",
      "link": "https://arxiv.org/pdf/2601.13927v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19016v1",
      "title": "Average-Case Reductions for $k$-XOR and Tensor PCA",
      "abstract": "We study two canonical planted average-case problems -- noisy $k\\mathsf{\\text{-}XOR}$ and Tensor PCA -- and relate their computational properties via poly-time average-case reductions. In fact, we consider a \\emph{family of problems} that interpolates between $k\\mathsf{\\text{-}XOR}$ and Tensor PCA, allowing intermediate densities and signal levels. We introduce two \\emph{densifying} reductions that increase the number of observed entries while controlling the decrease in signal, and, in particular, reduce any $k\\mathsf{\\text{-}XOR}$ instance at the computational threshold to Tensor PCA at the computational threshold. Additionally, we give new order-reducing maps (e.g., $5\\to 4$ $k\\mathsf{\\text{-}XOR}$ and $7\\to 4$ Tensor PCA) at fixed entry density.",
      "authors": [
        "Guy Bresler",
        "Alina Harbuzova"
      ],
      "primary_category": "cs.CC",
      "categories": [
        "cs.CC",
        "cs.CR",
        "math.PR",
        "math.ST"
      ],
      "published": "2026-01-26T23:05:54+00:00",
      "link": "https://arxiv.org/pdf/2601.19016v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04272v1",
      "title": "Bures-Wasserstein Importance-Weighted Evidence Lower Bound: Exposition and Applications",
      "abstract": "The Importance-Weighted Evidence Lower Bound (IW-ELBO) has emerged as an effective objective for variational inference (VI), tightening the standard ELBO and mitigating the mode-seeking behaviour.   However, optimizing the IW-ELBO in Euclidean space is often inefficient, as its gradient estimators suffer from a vanishing signal-to-noise ratio (SNR). This paper formulates the optimisation of the IW-ELBO in Bures-Wasserstein space, a manifold of Gaussian distributions equipped with the 2-Wasserstein metric. We derive the Wasserstein gradient of the IW-ELBO and project it onto the Bures-Wasserstein space to yield a tractable algorithm for Gaussian VI.   A pivotal contribution of our analysis concerns the stability of the gradient estimator. While the SNR of the standard Euclidean gradient estimator is known to vanish as the number of importance samples $K$ increases, we prove that the SNR of the Wasserstein gradient scales favourably as $Ω(\\sqrt{K})$, ensuring optimisation efficiency even for large $K$. We further extend this geometric analysis to the Variational Rényi Importance-Weighted Autoencoder bound, establishing analogous stability guarantees. Experiments demonstrate that the proposed framework achieves superior approximation performance compared to other baselines.",
      "authors": [
        "Peiwen Jiang",
        "Takuo Matsubara",
        "Minh-Ngoc Tran"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO",
        "cs.LG",
        "stat.ME"
      ],
      "published": "2026-02-04T07:01:56+00:00",
      "link": "https://arxiv.org/pdf/2602.04272v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13921v2",
      "title": "The properad of quadratic Poisson structures is Koszul",
      "abstract": "In this paper, we suggest a sufficient condition on the properadic envelope of a quadratic dioperad to be Koszul in terms of twisted associative algebras.   As a particular new example, we show that the properad of quadratic Poisson structures is Koszul.",
      "authors": [
        "Anton Khoroshkin"
      ],
      "primary_category": "math.QA",
      "categories": [
        "math.QA",
        "math-ph",
        "math.KT"
      ],
      "published": "2026-01-20T12:50:28+00:00",
      "link": "https://arxiv.org/pdf/2601.13921v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22049v1",
      "title": "On homogeneous involutions on matrix algebras",
      "abstract": "We study the homogeneous involutions on the full square matrices over an algebraically closed field endowed with a division grading with commutative support. We obtain the classification of the isomorphism and equivalence classes for the Pauli grading. We also investigate the homogeneous involutions on the full square matrices with entries in a finite-dimensional graded-division algebra over an algebraically closed field of characteristic not $2$ endowed with an arbitrary grading by an arbitrary group.",
      "authors": [
        "Micael Said Garcia",
        "Cassia Ferreira Sampaio"
      ],
      "primary_category": "math.RA",
      "categories": [
        "math.RA"
      ],
      "published": "2026-01-29T17:48:58+00:00",
      "link": "https://arxiv.org/pdf/2601.22049v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.16729v1",
      "title": "Derived equivalences for complexes with support",
      "abstract": "For a Serre subcategory $\\mathscr L$ and a resolving subcategory $\\mathscr A$ of an abelian category, we show that the derived equivalence $D^b(\\overline{\\mathscr A} \\cap \\mathscr L) \\simeq D^b_{\\mathscr L}(\\mathscr A)$ holds under certain conditions. We apply this to obtain derived equivalences in the contexts of chain complexes of graded modules or coherent sheaves, with finite $\\mathscr A$-dimension, supported on closed sets having eventually finite $\\mathscr A$-dimension.",
      "authors": [
        "K. Ganapathy",
        "Sarang Sane"
      ],
      "primary_category": "math.CT",
      "categories": [
        "math.CT",
        "math.AC",
        "math.AG"
      ],
      "published": "2026-01-23T13:22:38+00:00",
      "link": "https://arxiv.org/pdf/2601.16729v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02385v1",
      "title": "Transformers learn factored representations",
      "abstract": "Transformers pretrained via next token prediction learn to factor their world into parts, representing these factors in orthogonal subspaces of the residual stream. We formalize two representational hypotheses: (1) a representation in the product space of all factors, whose dimension grows exponentially with the number of parts, or (2) a factored representation in orthogonal subspaces, whose dimension grows linearly. The factored representation is lossless when factors are conditionally independent, but sacrifices predictive fidelity otherwise, creating a tradeoff between dimensional efficiency and accuracy. We derive precise predictions about the geometric structure of activations for each, including the number of subspaces, their dimensionality, and the arrangement of context embeddings within them. We test between these hypotheses on transformers trained on synthetic processes with known latent structure. Models learn factored representations when factors are conditionally independent, and continue to favor them early in training even when noise or hidden dependencies undermine conditional independence, reflecting an inductive bias toward factoring at the cost of fidelity. This provides a principled explanation for why transformers decompose the world into parts, and suggests that interpretable low dimensional structure may persist even in models trained on complex data.",
      "authors": [
        "Adam Shai",
        "Loren Amdahl-Culleton",
        "Casper L. Christensen",
        "Henry R. Bigelow",
        "Fernando E. Rosas",
        "Alexander B. Boyd",
        "Eric A. Alt",
        "Kyle J. Ray",
        "Paul M. Riechers"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T17:49:06+00:00",
      "link": "https://arxiv.org/pdf/2602.02385v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17257v1",
      "title": "A Constrained Optimization Perspective of Unrolled Transformers",
      "abstract": "We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.",
      "authors": [
        "Javier Porras-Valenzuela",
        "Samar Hadou",
        "Alejandro Ribeiro"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-24T02:12:39+00:00",
      "link": "https://arxiv.org/pdf/2601.17257v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.05647v1",
      "title": "Transformer Is Inherently a Causal Learner",
      "abstract": "We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.",
      "authors": [
        "Xinyue Wang",
        "Stephen Wang",
        "Biwei Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-09T09:10:04+00:00",
      "link": "https://arxiv.org/pdf/2601.05647v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21929v1",
      "title": "LoRIF: Low-Rank Influence Functions for Scalable Training Data Attribution",
      "abstract": "Training data attribution (TDA) identifies which training examples most influenced a model's prediction. The best-performing TDA methods exploits gradients to define an influence function. To overcome the scalability challenge arising from gradient computation, the most popular strategy is random projection (e.g., TRAK, LoGRA). However, this still faces two bottlenecks when scaling to large training sets and high-quality attribution: \\emph{(i)} storing and loading projected per-example gradients for all $N$ training examples, where query latency is dominated by I/O; and \\emph{(ii)} forming the $D \\times D$ inverse Hessian approximation, which costs $O(D^2)$ memory. Both bottlenecks scale with the projection dimension $D$, yet increasing $D$ is necessary for attribution quality -- creating a quality-scalability tradeoff. We introduce \\textbf{LoRIF (Low-Rank Influence Functions)}, which exploits low-rank structures of gradient to address both bottlenecks. First, we store rank-$c$ factors of the projected per-example gradients rather than full matrices, reducing storage and query-time I/O from $O(D)$ to $O(c\\sqrt{D})$ per layer per sample. Second, we use truncated SVD with the Woodbury identity to approximate the Hessian term in an $r$-dimensional subspace, reducing memory from $O(D^2)$ to $O(Dr)$. On models from 0.1B to 70B parameters trained on datasets with millions of examples, LoRIF achieves up to 20$\\times$ storage reduction and query-time speedup compared to LoGRA, while matching or exceeding its attribution quality. LoRIF makes gradient-based TDA practical at frontier scale.",
      "authors": [
        "Shuangqi Li",
        "Hieu Le",
        "Jingyi Xu",
        "Mathieu Salzmann"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T16:18:34+00:00",
      "link": "https://arxiv.org/pdf/2601.21929v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22257v1",
      "title": "Symmetry Breaking in Transformers for Efficient and Interpretable Training",
      "abstract": "The attention mechanism in its standard implementation contains extraneous rotational degrees of freedom that are carried through computation but do not affect model activations or outputs. We introduce a simple symmetry-breaking protocol that inserts a preferred direction into this rotational space through batchwise-sampled, unlearned query and value biases. This modification has two theoretically motivated and empirically validated consequences. First, it can substantially improve the performance of simple, memory-efficient optimizers, narrowing -- and in some cases closing -- the gap to successful but more complex memory-intensive adaptive methods. We demonstrate this by pretraining 124M parameter transformer models with four optimization algorithms (AdamW, SOAP, SGDM, and Energy Conserving Descent(ECD)) and evaluating both validation loss and downstream logical reasoning. Second, it enables an interpretable use of otherwise redundant rotational degrees of freedom, selectively amplifying semantically meaningful token classes within individual attention heads. Overall, our results show that minimal, principled architectural changes can simultaneously improve performance and interpretability.",
      "authors": [
        "Eva Silverstein",
        "Daniel Kunin",
        "Vasudev Shyam"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T19:29:09+00:00",
      "link": "https://arxiv.org/pdf/2601.22257v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.23208v1",
      "title": "A Random Matrix Theory of Masked Self-Supervised Regression",
      "abstract": "In the era of transformer models, masked self-supervised learning (SSL) has become a foundational training paradigm. A defining feature of masked SSL is that training aggregates predictions across many masking patterns, giving rise to a joint, matrix-valued predictor rather than a single vector-valued estimator. This object encodes how coordinates condition on one another and poses new analytical challenges. We develop a precise high-dimensional analysis of masked modeling objectives in the proportional regime where the number of samples scales with the ambient dimension. Our results provide explicit expressions for the generalization error and characterize the spectral structure of the learned predictor, revealing how masked modeling extracts structure from data. For spiked covariance models, we show that the joint predictor undergoes a Baik--Ben Arous--Péché (BBP)-type phase transition, identifying when masked SSL begins to recover latent signals. Finally, we identify structured regimes in which masked self-supervised learning provably outperforms PCA, highlighting potential advantages of SSL objectives over classical unsupervised methods",
      "authors": [
        "Arie Wortsman Zurich",
        "Federica Gerace",
        "Bruno Loureiro",
        "Yue M. Lu"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-30T17:32:33+00:00",
      "link": "https://arxiv.org/pdf/2601.23208v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03641v1",
      "title": "CTTVAE: Latent Space Structuring for Conditional Tabular Data Generation on Imbalanced Datasets",
      "abstract": "Generating synthetic tabular data under severe class imbalance is essential for domains where rare but high-impact events drive decision-making. However, most generative models either overlook minority groups or fail to produce samples that are useful for downstream learning. We introduce CTTVAE, a Conditional Transformer-based Tabular Variational Autoencoder equipped with two complementary mechanisms: (i) a class-aware triplet margin loss that restructures the latent space for sharper intra-class compactness and inter-class separation, and (ii) a training-by-sampling strategy that adaptively increases exposure to underrepresented groups. Together, these components form CTTVAE+TBS, a framework that consistently yields more representative and utility-aligned samples without destabilizing training. Across six real-world benchmarks, CTTVAE+TBS achieves the strongest downstream utility on minority classes, often surpassing models trained on the original imbalanced data while maintaining competitive fidelity and bridging the gap for privacy for interpolation-based sampling methods and deep generative methods. Ablation studies further confirm that both latent structuring and targeted sampling contribute to these gains. By explicitly prioritizing downstream performance in rare categories, CTTVAE+TBS provides a robust and interpretable solution for conditional tabular data generation, with direct applicability to industries such as healthcare, fraud detection, and predictive maintenance where even small gains in minority cases can be critical.",
      "authors": [
        "Milosh Devic",
        "Jordan Gierschendorf",
        "David Garson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T15:25:26+00:00",
      "link": "https://arxiv.org/pdf/2602.03641v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02015v1",
      "title": "Robust Domain Generalization under Divergent Marginal and Conditional Distributions",
      "abstract": "Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains. Most existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., primarily addressing changes in $P(X\\mid Y)$ while assuming $P(Y)$ remains stable). However, real-world scenarios with multiple domains often involve compound distribution shifts where both the marginal label distribution $P(Y)$ and the conditional distribution $P(X\\mid Y)$ vary simultaneously. To address this, we propose a unified framework for robust domain generalization under divergent marginal and conditional distributions. We derive a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. To operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. Empirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging multi-domain long-tailed recognition settings where both marginal and conditional shifts are pronounced.",
      "authors": [
        "Jewon Yeom",
        "Kyubyung Chae",
        "Hyunggyu Lim",
        "Yoonna Oh",
        "Dongyoon Yang",
        "Taesup Kim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T12:13:41+00:00",
      "link": "https://arxiv.org/pdf/2602.02015v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02162v1",
      "title": "Interpretable Tabular Foundation Models via In-Context Kernel Regression",
      "abstract": "Tabular foundation models like TabPFN and TabICL achieve state-of-the-art performance through in-context learning, yet their architectures remain fundamentally opaque. We introduce KernelICL, a framework to enhance tabular foundation models with quantifiable sample-based interpretability. Building on the insight that in-context learning is akin to kernel regression, we make this mechanism explicit by replacing the final prediction layer with kernel functions (Gaussian, dot-product, kNN) so that every prediction is a transparent weighted average of training labels. We introduce a two-dimensional taxonomy that formally unifies standard kernel methods, modern neighbor-based approaches, and attention mechanisms under a single framework, and quantify inspectability via the perplexity of the weight distribution over training samples. On 55 TALENT benchmark datasets, KernelICL achieves performance on par with existing tabular foundation models, demonstrating that explicit kernel constraints on the final layer enable inspectable predictions without sacrificing performance.",
      "authors": [
        "Ratmir Miftachov",
        "Bruno Charron",
        "Simon Valentin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T14:37:10+00:00",
      "link": "https://arxiv.org/pdf/2602.02162v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18253v1",
      "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation",
      "abstract": "Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.",
      "authors": [
        "Peng Sun",
        "Xiangyu Zhang",
        "Duan Wu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-26T08:20:02+00:00",
      "link": "https://arxiv.org/pdf/2601.18253v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12681v2",
      "title": "HyFormer: Revisiting the Roles of Sequence Modeling and Feature Interaction in CTR Prediction",
      "abstract": "Industrial large-scale recommendation models (LRMs) face the challenge of jointly modeling long-range user behavior sequences and heterogeneous non-sequential features under strict efficiency constraints. However, most existing architectures employ a decoupled pipeline: long sequences are first compressed with a query-token based sequence compressor like LONGER, followed by fusion with dense features through token-mixing modules like RankMixer, which thereby limits both the representation capacity and the interaction flexibility. This paper presents HyFormer, a unified hybrid transformer architecture that tightly integrates long-sequence modeling and feature interaction into a single backbone. From the perspective of sequence modeling, we revisit and redesign query tokens in LRMs, and frame the LRM modeling task as an alternating optimization process that integrates two core components: Query Decoding which expands non-sequential features into Global Tokens and performs long sequence decoding over layer-wise key-value representations of long behavioral sequences; and Query Boosting which enhances cross-query and cross-sequence heterogeneous interactions via efficient token mixing. The two complementary mechanisms are performed iteratively to refine semantic representations across layers. Extensive experiments on billion-scale industrial datasets demonstrate that HyFormer consistently outperforms strong LONGER and RankMixer baselines under comparable parameter and FLOPs budgets, while exhibiting superior scaling behavior with increasing parameters and FLOPs. Large-scale online A/B tests in high-traffic production systems further validate its effectiveness, showing significant gains over deployed state-of-the-art models. These results highlight the practicality and scalability of HyFormer as a unified modeling framework for industrial LRMs.",
      "authors": [
        "Yunwen Huang",
        "Shiyong Hong",
        "Xijun Xiao",
        "Jinqiu Jin",
        "Xuanyuan Luo",
        "Zhe Wang",
        "Zheng Chai",
        "Shikang Wu",
        "Yuchao Zheng",
        "Jingjian Lin"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-19T02:55:05+00:00",
      "link": "https://arxiv.org/pdf/2601.12681v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.19208v1",
      "title": "How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability",
      "abstract": "Semantic associations such as the link between \"bird\" and \"flew\" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.",
      "authors": [
        "Shawn Im",
        "Changdae Oh",
        "Zhen Fang",
        "Sharon Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-27T05:22:34+00:00",
      "link": "https://arxiv.org/pdf/2601.19208v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17533v1",
      "title": "Reconstructing Training Data from Adapter-based Federated Large Language Models",
      "abstract": "Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs).   Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 > 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.",
      "authors": [
        "Silong Chen",
        "Yuchuan Luo",
        "Guilin Deng",
        "Yi Liu",
        "Min Xu",
        "Shaojing Fu",
        "Xiaohua Jia"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-24T17:15:16+00:00",
      "link": "https://arxiv.org/pdf/2601.17533v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22538v1",
      "title": "Learning to Defer in Non-Stationary Time Series via Switching State-Space Models",
      "abstract": "We study Learning to Defer for non-stationary time series with partial feedback and time-varying expert availability. At each time step, the router selects an available expert, observes the target, and sees only the queried expert's prediction. We model signed expert residuals using L2D-SLDS, a factorized switching linear-Gaussian state-space model with context-dependent regime transitions, a shared global factor enabling cross-expert information transfer, and per-expert idiosyncratic states. The model supports expert entry and pruning via a dynamic registry. Using one-step-ahead predictive beliefs, we propose an IDS-inspired routing rule that trades off predicted cost against information gained about the latent regime and shared factor. Experiments show improvements over contextual-bandit baselines and a no-shared-factor ablation.",
      "authors": [
        "Yannis Montreuil",
        "Letian Yu",
        "Axel Carlier",
        "Lai Xing Ng",
        "Wei Tsang Ooi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP"
      ],
      "published": "2026-01-30T04:18:42+00:00",
      "link": "https://arxiv.org/pdf/2601.22538v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21795v2",
      "title": "Effective LoRA Adapter Routing using Task Representations",
      "abstract": "Low-rank adaptation (LoRA) enables parameter efficient specialization of large language models (LLMs) through modular adapters, resulting in rapidly growing public adapter pools spanning diverse tasks. Effectively using these adapters requires routing: selecting and composing the appropriate adapters for a query. We introduce LORAUTER, a novel routing framework that selects and composes LoRA adapters using task representations rather than adapter characteristics. Unlike existing approaches that map queries directly to adapters, LORAUTER routes queries via task embeddings derived from small validation sets and does not require adapter training data. By operating at the task level, LORAUTER achieves efficient routing that scales with the number of tasks rather than the number of adapters. Experiments across multiple tasks show that LORAUTER consistently outperforms baseline routing approaches, matching Oracle performance (101.2%) when task-aligned adapters exist and achieving state-of-the-art results on unseen tasks (+5.2 points). We further demonstrate the robustness of LORAUTER to very large, noisy adapter pools by scaling it to over 1500 adapters.",
      "authors": [
        "Akash Dhasade",
        "Anne-Marie Kermarrec",
        "Igor Pavlovic",
        "Diana Petrescu",
        "Rafael Pires",
        "Mathis Randl",
        "Martijn de Vos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T14:41:24+00:00",
      "link": "https://arxiv.org/pdf/2601.21795v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22336v1",
      "title": "Dependence-Aware Label Aggregation for LLM-as-a-Judge via Ising Models",
      "abstract": "Large-scale AI evaluation increasingly relies on aggregating binary judgments from $K$ annotators, including LLMs used as judges. Most classical methods, e.g., Dawid-Skene or (weighted) majority voting, assume annotators are conditionally independent given the true label $Y\\in\\{0,1\\}$, an assumption often violated by LLM judges due to shared data, architectures, prompts, and failure modes. Ignoring such dependencies can yield miscalibrated posteriors and even confidently incorrect predictions. We study label aggregation through a hierarchy of dependence-aware models based on Ising graphical models and latent factors. For class-dependent Ising models, the Bayes log-odds is generally quadratic in votes; for class-independent couplings, it reduces to a linear weighted vote with correlation-adjusted parameters. We present finite-$K$ examples showing that methods based on conditional independence can flip the Bayes label despite matching per-annotator marginals. We prove separation results demonstrating that these methods remain strictly suboptimal as the number of judges grows, incurring nonvanishing excess risk under latent factors. Finally, we evaluate the proposed method on three real-world datasets, demonstrating improved performance over the classical baselines.",
      "authors": [
        "Krishnakumar Balasubramanian",
        "Aleksandr Podkopaev",
        "Shiva Prasad Kasiviswanathan"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "published": "2026-01-29T21:26:50+00:00",
      "link": "https://arxiv.org/pdf/2601.22336v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17986v1",
      "title": "Federated learning for unpaired multimodal data through a homogeneous transformer model",
      "abstract": "Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.",
      "authors": [
        "Anders Eklund"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-25T20:30:21+00:00",
      "link": "https://arxiv.org/pdf/2601.17986v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.08991v2",
      "title": "Optimising for Energy Efficiency and Performance in Machine Learning",
      "abstract": "The ubiquity of machine learning (ML) and the demand for ever-larger models bring an increase in energy consumption and environmental impact. However, little is known about the energy scaling laws in ML, and existing research focuses on training cost -- ignoring the larger cost of inference. Furthermore, tools for measuring the energy consumption of ML do not provide actionable feedback.   To address these gaps, we developed Energy Consumption Optimiser (ECOpt): a hyperparameter tuner that optimises for energy efficiency and model performance. ECOpt quantifies the trade-off between these metrics as an interpretable Pareto frontier. This enables ML practitioners to make informed decisions about energy cost and environmental impact, while maximising the benefit of their models and complying with new regulations.   Using ECOpt, we show that parameter and floating-point operation counts can be unreliable proxies for energy consumption, and observe that the energy efficiency of Transformer models for text generation is relatively consistent across hardware. These findings motivate measuring and publishing the energy metrics of ML models. We further show that ECOpt can have a net positive environmental impact and use it to uncover seven models for CIFAR-10 that improve upon the state of the art, when considering accuracy and energy efficiency together.",
      "authors": [
        "Emile Dos Santos Ferreira",
        "Andrei Paleyes",
        "Neil D. Lawrence"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.SE"
      ],
      "published": "2026-01-13T21:28:58+00:00",
      "link": "https://arxiv.org/pdf/2601.08991v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22966v1",
      "title": "A Unified View of Attention and Residual Sinks: Outlier-Driven Rescaling is Essential for Transformer Training",
      "abstract": "We investigate the functional role of emergent outliers in large language models, specifically attention sinks (a few tokens that consistently receive large attention logits) and residual sinks (a few fixed dimensions with persistently large activations across most tokens). We hypothesize that these outliers, in conjunction with the corresponding normalizations (\\textit{e.g.}, softmax attention and RMSNorm), effectively rescale other non-outlier components. We term this phenomenon \\textit{outlier-driven rescaling} and validate this hypothesis across different model architectures and training token counts. This view unifies the origin and mitigation of both sink types. Our main conclusions and observations include: (1) Outliers function jointly with normalization: removing normalization eliminates the corresponding outliers but degrades training stability and performance; directly clipping outliers while retaining normalization leads to degradation, indicating that outlier-driven rescaling contributes to training stability. (2) Outliers serve more as rescale factors rather than contributors, as the final contributions of attention and residual sinks are significantly smaller than those of non-outliers. (3) Outliers can be absorbed into learnable parameters or mitigated via explicit gated rescaling, leading to improved training performance (average gain of 2 points) and enhanced quantization robustness (1.2 points degradation under W4A4 quantization).",
      "authors": [
        "Zihan Qiu",
        "Zeyu Huang",
        "Kaiyue Wen",
        "Peng Jin",
        "Bo Zheng",
        "Yuxin Zhou",
        "Haofeng Huang",
        "Zekun Wang",
        "Xiao Li",
        "Huaqing Zhang",
        "Yang Xu",
        "Haoran Lian",
        "Siqi Zhang",
        "Rui Men",
        "Jianwei Zhang",
        "Ivan Titov",
        "Dayiheng Liu",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-30T13:29:45+00:00",
      "link": "https://arxiv.org/pdf/2601.22966v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22593v1",
      "title": "Heterogeneous Graph Alignment for Joint Reasoning and Interpretability",
      "abstract": "Multi-graph learning is crucial for extracting meaningful signals from collections of heterogeneous graphs. However, effectively integrating information across graphs with differing topologies, scales, and semantics, often in the absence of shared node identities, remains a significant challenge. We present the Multi-Graph Meta-Transformer (MGMT), a unified, scalable, and interpretable framework for cross-graph learning. MGMT first applies Graph Transformer encoders to each graph, mapping structure and attributes into a shared latent space. It then selects task-relevant supernodes via attention and builds a meta-graph that connects functionally aligned supernodes across graphs using similarity in the latent space. Additional Graph Transformer layers on this meta-graph enable joint reasoning over intra- and inter-graph structure. The meta-graph provides built-in interpretability: supernodes and superedges highlight influential substructures and cross-graph alignments. Evaluating MGMT on both synthetic datasets and real-world neuroscience applications, we show that MGMT consistently outperforms existing state-of-the-art models in graph-level prediction tasks while offering interpretable representations that facilitate scientific discoveries. Our work establishes MGMT as a unified framework for structured multi-graph learning, advancing representation techniques in domains where graph-based data plays a central role.",
      "authors": [
        "Zahra Moslemi",
        "Ziyi Liang",
        "Norbert Fortin",
        "Babak Shahbaba"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T05:40:13+00:00",
      "link": "https://arxiv.org/pdf/2601.22593v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05649v1",
      "title": "End-to-End Compression for Tabular Foundation Models",
      "abstract": "The long-standing dominance of gradient-boosted decision trees for tabular data has recently been challenged by in-context learning tabular foundation models. In-context learning methods fit and predict in one forward pass without parameter updates by leveraging the training data as context for predicting on query test points. While recent tabular foundation models achieve state-of-the-art performance, their transformer architecture based on the attention mechanism has quadratic complexity regarding dataset size, which in turn increases the overhead on training and inference time, and limits the capacity of the models to handle large-scale datasets. In this work, we propose TACO, an end-to-end tabular compression model that compresses the training dataset in a latent space. We test our method on the TabArena benchmark, where our proposed method is up to 94x faster in inference time, while consuming up to 97\\% less memory compared to the state-of-the-art tabular transformer architecture, all while retaining performance without significant degradation. Lastly, our method not only scales better with increased dataset sizes, but it also achieves better performance compared to other baselines.",
      "authors": [
        "Guri Zabërgja",
        "Rafiq Kamel",
        "Arlind Kadra",
        "Christian M. M. Frey",
        "Josif Grabocka"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-05T13:33:58+00:00",
      "link": "https://arxiv.org/pdf/2602.05649v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21708v1",
      "title": "FBS: Modeling Native Parallel Reading inside a Transformer",
      "abstract": "Large language models (LLMs) excel across many tasks, yet inference is still dominated by strictly token-by-token autoregression. Existing acceleration methods largely patch this pipeline and miss core human-reading ingredients: content-adaptive foresight, chunk-structure-aware compute allocation, and train--test consistency for preview/skimming. We propose the \\textbf{Fovea-Block-Skip Transformer} (FBS), which injects a causal, trainable loop into Transformers via Parafovea-Attention Window (PAW), Chunk-Head (CH), and Skip-Gate (SG). Across diverse benchmarks, FBS improves the quality-efficiency trade-off without increasing parameters, and ablations show the three modules are complementary.",
      "authors": [
        "Tongxi Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-29T13:39:55+00:00",
      "link": "https://arxiv.org/pdf/2601.21708v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07281v1",
      "title": "Covariance-Driven Regression Trees: Reducing Overfitting in CART",
      "abstract": "Decision trees are powerful machine learning algorithms, widely used in fields such as economics and medicine for their simplicity and interpretability. However, decision trees such as CART are prone to overfitting, especially when grown deep or the sample size is small. Conventional methods to reduce overfitting include pre-pruning and post-pruning, which constrain the growth of uninformative branches. In this paper, we propose a complementary approach by introducing a covariance-driven splitting criterion for regression trees (CovRT). This method is more robust to overfitting than the empirical risk minimization criterion used in CART, as it produces more balanced and stable splits and more effectively identifies covariates with true signals. We establish an oracle inequality of CovRT and prove that its predictive accuracy is comparable to that of CART in high-dimensional settings. We find that CovRT achieves superior prediction accuracy compared to CART in both simulations and real-world tasks.",
      "authors": [
        "Likun Zhang",
        "Wei Ma"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "published": "2026-01-12T07:36:18+00:00",
      "link": "https://arxiv.org/pdf/2601.07281v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.14172v2",
      "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum",
      "abstract": "We study sentence-level detection of the 19 human values in the refined Schwartz continuum in about 74k English sentences from news and political manifestos (ValueEval'24 corpus). Each sentence is annotated with value presence, yielding a binary moral-presence label and a 19-way multi-label task under severe class imbalance. First, we show that moral presence is learnable from single sentences: a DeBERTa-base classifier attains positive-class F1 = 0.74 with calibrated thresholds. Second, we compare direct multi-label value detectors with presence-gated hierarchies under a single 8 GB GPU budget. Under matched compute, presence gating does not improve over direct prediction, indicating that gate recall becomes a bottleneck. Third, we investigate lightweight auxiliary signals - short-range context, LIWC-22 and moral lexica, and topic features - and small ensembles. Our best supervised configuration, a soft-voting ensemble of DeBERTa-based models enriched with such signals, reaches macro-F1 = 0.332 on the 19 values, improving over the best previous English-only baseline on this corpus (macro-F1 $\\approx$ 0.28). We additionally benchmark 7-9B instruction-tuned LLMs (Gemma 2 9B, Llama 3.1 8B, Mistral 8B, Qwen 2.5 7B) in zero-/few-shot and QLoRA setups, and find that they lag behind the supervised ensemble under the same hardware constraint. Overall, our results provide empirical guidance for building compute-efficient, value-aware NLP models under realistic GPU budgets.",
      "authors": [
        "Víctor Yeste",
        "Paolo Rosso"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-20T17:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.14172v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22852v1",
      "title": "Hierarchical Shift Mixing -- Beyond Dense Attention in Transformers",
      "abstract": "Since the introduction of the Transformer architecture for large language models, the softmax-based attention layer has faced increasing scrutinity due to its quadratic-time computational complexity. Attempts have been made to replace it with less complex methods, at the cost of reduced performance in most cases. We introduce Hierarchical Shift Mixing (HSM), a general framework for token mixing that distributes pairwise token interactions across Transformer layers rather than computing them densely within each layer. HSM enables linear-time complexity while remaining agnostic to the specific mixing function. We show that even simple HSM variants achieve performance close to softmax attention, and that hybrid architectures combining HSM with softmax attention can outperform a GPT-style Transformer baseline while reducing computational cost during both training and inference.",
      "authors": [
        "Robert Forchheimer"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T11:23:14+00:00",
      "link": "https://arxiv.org/pdf/2601.22852v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22478v1",
      "title": "Transform-Augmented GRPO Improves Pass@k",
      "abstract": "Large language models trained via next-token prediction are fundamentally pattern-matchers: sensitive to superficial phrasing variations even when the underlying problem is identical. Group Relative Policy Optimization (GRPO) was designed to improve reasoning, but in fact it worsens this situation through two failure modes: diversity collapse, where training amplifies a single solution strategy while ignoring alternatives of gradient signal, and gradient diminishing, where a large portion of questions yield zero gradients because all rollouts receive identical rewards. We propose TA-GRPO (Transform-Augmented GRPO), which generates semantically equivalent transformed variants of each question (via paraphrasing, variable renaming, and format changes) and computes advantages by pooling rewards across the entire group. This pooled computation ensures mixed rewards even when the original question is too easy or too hard, while training on diverse phrasings promotes multiple solution strategies. We provide theoretical justification showing that TA-GRPO reduces zero-gradient probability and improves generalization via reduced train-test distribution shift. Experiments on mathematical reasoning benchmarks show consistent Pass@k improvements, with gains up to 9.84 points on competition math (AMC12, AIME24) and 5.05 points on out-of-distribution scientific reasoning (GPQA-Diamond).",
      "authors": [
        "Khiem Le",
        "Youssef Mroueh",
        "Phuc Nguyen",
        "Chi-Heng Lin",
        "Shangqian Gao",
        "Ting Hua",
        "Nitesh V. Chawla"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T02:43:29+00:00",
      "link": "https://arxiv.org/pdf/2601.22478v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00576v1",
      "title": "Data Distribution as a Lever for Guiding Optimizers Toward Superior Generalization in LLMs",
      "abstract": "Can modifying the training data distribution guide optimizers toward solutions with improved generalization when training large language models (LLMs)? In this work, we theoretically analyze an in-context linear regression model with multi-head linear self-attention, and compare the training dynamics of two gradient based optimizers, namely gradient descent (GD) and sharpness-aware minimization (SAM), the latter exhibiting superior generalization properties but is prohibitively expensive for training even medium-sized LLMs. We show, for the first time, that SAM induces a lower simplicity bias (SB)-the tendency of an optimizer to preferentially learn simpler features earlier in training-and identify this reduction as a key factor underlying its improved generalization performance. Motivated by this insight, we demonstrate that altering the training data distribution by upsampling or augmenting examples learned later in training similarly reduces SB and leads to improved generalization. Our extensive experiments show that our strategy improves the performance of multiple LLMs-including Phi2-2.7B , Llama3.2-1B, Gemma3-1B-PT, and Qwen3-0.6B-Base-achieving relative accuracy gains up to 18% when fine-tuned with AdamW and Muon on mathematical reasoning tasks.",
      "authors": [
        "Tushaar Gangavarapu",
        "Jiping Li",
        "Christopher Vattheuer",
        "Zhangyang Wang",
        "Baharan Mirzasoleiman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-31T07:40:36+00:00",
      "link": "https://arxiv.org/pdf/2602.00576v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.12039v1",
      "title": "Nonlinear Dynamic Factor Analysis With a Transformer Network",
      "abstract": "The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.",
      "authors": [
        "Oliver Snellman"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "cs.LG"
      ],
      "published": "2026-01-17T12:59:58+00:00",
      "link": "https://arxiv.org/pdf/2601.12039v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03351v2",
      "title": "Building Interpretable Models for Moral Decision-Making",
      "abstract": "We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy on Moral Machine data while remaining small enough for detailed analysis. We use different interpretability techniques to uncover how moral reasoning distributes across the network, demonstrating that biases localize to distinct computational stages among other findings.",
      "authors": [
        "Mayank Goel",
        "Aritra Das",
        "Paras Chopra"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "published": "2026-02-03T10:22:42+00:00",
      "link": "https://arxiv.org/pdf/2602.03351v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03422v1",
      "title": "RankSteer: Activation Steering for Pointwise LLM Ranking",
      "abstract": "Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \\textbf{decision direction} that maps hidden states to relevance scores, an \\textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \\textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.",
      "authors": [
        "Yumeng Wang",
        "Catherine Chen",
        "Suzan Verberne"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-03T11:49:00+00:00",
      "link": "https://arxiv.org/pdf/2602.03422v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04906v1",
      "title": "LISA: Laplacian In-context Spectral Analysis",
      "abstract": "We propose Laplacian In-context Spectral Analysis (LISA), a method for inference-time adaptation of Laplacian-based time-series models using only an observed prefix. LISA combines delay-coordinate embeddings and Laplacian spectral learning to produce diffusion-coordinate state representations, together with a frozen nonlinear decoder for one-step prediction. We introduce lightweight latent-space residual adapters based on either Gaussian-process regression or an attention-like Markov operator over context windows. Across forecasting and autoregressive rollout experiments, LISA improves over the frozen baseline and is often most beneficial under changing dynamics. This work links in-context adaptation to nonparametric spectral methods for dynamical systems.",
      "authors": [
        "Julio Candanedo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T22:58:43+00:00",
      "link": "https://arxiv.org/pdf/2602.04906v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13588v1",
      "title": "TREX: Tokenizer Regression for Optimal Data Mixture",
      "abstract": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.",
      "authors": [
        "Inho Won",
        "Hangyeol Yoo",
        "Minkyung Cho",
        "Jungyeul Park",
        "Hoyun Song",
        "KyungTae Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-20T04:41:09+00:00",
      "link": "https://arxiv.org/pdf/2601.13588v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02564v1",
      "title": "Label Curation Using Agentic AI",
      "abstract": "Data annotation is essential for supervised learning, yet producing accurate, unbiased, and scalable labels remains challenging as datasets grow in size and modality. Traditional human-centric pipelines are costly, slow, and prone to annotator variability, motivating reliability-aware automated annotation. We present AURA (Agentic AI for Unified Reliability Modeling and Annotation Aggregation), an agentic AI framework for large-scale, multi-modal data annotation. AURA coordinates multiple AI agents to generate and validate labels without requiring ground truth. At its core, AURA adapts a classical probabilistic model that jointly infers latent true labels and annotator reliability via confusion matrices, using Expectation-Maximization to reconcile conflicting annotations and aggregate noisy predictions. Across the four benchmark datasets evaluated, AURA achieves accuracy improvements of up to 5.8% over baseline. In more challenging settings with poor quality annotators, the improvement is up to 50% over baseline. AURA also accurately estimates the reliability of annotators, allowing assessment of annotator quality even without any pre-validation steps.",
      "authors": [
        "Subhodeep Ghosh",
        "Bayan Divaaniaazar",
        "Md Ishat-E-Rabban",
        "Spencer Clarke",
        "Senjuti Basu Roy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-30T18:58:52+00:00",
      "link": "https://arxiv.org/pdf/2602.02564v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21369v1",
      "title": "Rethinking Federated Graph Foundation Models: A Graph-Language Alignment-based Approach",
      "abstract": "Recent studies of federated graph foundational models (FedGFMs) break the idealized and untenable assumption of having centralized data storage to train graph foundation models, and accommodate the reality of distributed, privacy-restricted data silos. Despite their simplicity and intuition, existing studies that project aligned generalizable knowledge onto a discrete token space via vector-quantized backbones suffer from irreversible knowledge loss during the quantization process. In this context, we argue that reconciling the semantic-structural orthogonality and integrity between pre-trained language models (PLMs) and graph neural networks (GNNs) is paramount for developing effective FedGFMs while simultaneously mitigating the severe data heterogeneity and communication constraints inherent in distributed, resource-limited environments.   To address these issues, we propose FedGALA (Federated Graph And Language Alignment), a framework that resolves graph-based semantic-structural orthogonality and integrity in federated settings by employing unsupervised contrastive learning to align GNNs and frozen PLMs within a continuous embedding space, thereby capturing robust, transferable general knowledge. Subsequently, FedGALA leverages a communication-efficient prompt tuning mechanism to steer these pre-aligned encoders and frozen PLMs, facilitating effective adaptation to diverse downstream tasks while circumventing the prohibitive overhead of full-parameter fine-tuning. The comprehensive experiments validate that FedGALA outperforms all competitive baselines across multi-domain datasets on multiple tasks with up to 14.37% performance improvement.",
      "authors": [
        "Yinlin Zhu",
        "Di Wu",
        "Xianzhi Zhang",
        "Yuming Ai",
        "Xunkai Li",
        "Miao Hu",
        "Guocong Quan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T07:50:00+00:00",
      "link": "https://arxiv.org/pdf/2601.21369v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13288v1",
      "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification",
      "abstract": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.",
      "authors": [
        "Gonzalo Ariel Meyoyan",
        "Luciano Del Corro"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-19T18:40:29+00:00",
      "link": "https://arxiv.org/pdf/2601.13288v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22298v1",
      "title": "Conformal Prediction for Generative Models via Adaptive Cluster-Based Density Estimation",
      "abstract": "Conditional generative models map input variables to complex, high-dimensional distributions, enabling realistic sample generation in a diverse set of domains. A critical challenge with these models is the absence of calibrated uncertainty, which undermines trust in individual outputs for high-stakes applications. To address this issue, we propose a systematic conformal prediction approach tailored to conditional generative models, leveraging density estimation on model-generated samples. We introduce a novel method called CP4Gen, which utilizes clustering-based density estimation to construct prediction sets that are less sensitive to outliers, more interpretable, and of lower structural complexity than existing methods. Extensive experiments on synthetic datasets and real-world applications, including climate emulation tasks, demonstrate that CP4Gen consistently achieves superior performance in terms of prediction set volume and structural simplicity. Our approach offers practitioners a powerful tool for uncertainty estimation associated with conditional generative models, particularly in scenarios demanding rigorous and interpretable prediction sets.",
      "authors": [
        "Qidong Yang",
        "Qianyu Julie Zhu",
        "Jonathan Giezendanner",
        "Youssef Marzouk",
        "Stephen Bates",
        "Sherrie Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "published": "2026-01-29T20:23:33+00:00",
      "link": "https://arxiv.org/pdf/2601.22298v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.10058v1",
      "title": "Unlabeled Data Can Provably Enhance In-Context Learning of Transformers",
      "abstract": "Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel augmented ICL framework, in which the prompt includes a small set of labeled examples alongside a block of unlabeled inputs. We focus on the multi-class linear classification setting and demonstrate that, with chain-of-thought (CoT) prompting, a multi-layer transformer can effectively emulate an expectation-maximization (EM) algorithm. This enables the transformer to implicitly extract useful information from both labeled and unlabeled data, leading to provable improvements in ICL accuracy. Moreover, we show that such a transformer can be trained via teacher forcing, with its parameters converging to the desired solution at a linear rate. Experiments demonstrate that the augmented ICL framework consistently outperforms conventional few-shot ICL, providing empirical support for our theoretical findings. To the best of our knowledge, this is the first theoretical study on the impact of unlabeled data on the ICL performance of transformers.",
      "authors": [
        "Renpu Liu",
        "Jing Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-15T04:23:32+00:00",
      "link": "https://arxiv.org/pdf/2601.10058v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05807v1",
      "title": "Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers",
      "abstract": "Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.",
      "authors": [
        "Mohamed Amine Hallam",
        "Kuo-Kun Tseng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-09T14:25:31+00:00",
      "link": "https://arxiv.org/pdf/2601.05807v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12467v2",
      "title": "Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting",
      "abstract": "Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data, particularly as sequence length and data scale increase. This paper proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the proposed approach, a convolutional neural network operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is applied during representation learning to refine these embeddings, after which a Transformer encoder models inter-patch temporal dependencies to generate forecasts. The method is evaluated on a synthetic multivariate time-series dataset with controlled static and dynamic factors, using an extended sequence length and a larger number of samples. Experimental results demonstrate that the proposed framework consistently outperforms a convolutional baseline under increased temporal context and remains competitive with a strong patch-based Transformer model. These findings indicate that structured patch-level tokenization provides a scalable and effective representation for multivariate time-series forecasting, particularly when longer input sequences are considered.",
      "authors": [
        "Saurish Nagrath",
        "Saroj Kumar Panigrahy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-18T16:16:01+00:00",
      "link": "https://arxiv.org/pdf/2601.12467v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.05588v2",
      "title": "Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders",
      "abstract": "The success of Large Language Models (LLMs) has motivated a shift toward generative approaches to retrieval and ranking, aiming to supersede classical Dual Encoders (DEs) and Cross Encoders (CEs). A prominent paradigm is pointwise Autoregressive Ranking (ARR), where an LLM generates document identifiers (docIDs) token-by-token to enable ranking via beam search. ARR offers the promise of superior expressivity compared to DEs while avoiding the prohibitive computational cost of CEs. However, a formal theoretical foundation for this expressive power has been missing. Moreover, the standard next-token prediction loss is rank-agnostic and inappropriate for finetuning an LLM for ranking tasks.   In this paper, we first prove that the expressive capacity of ARR is strictly superior to DEs. While a DE requires an embedding dimension that grows linearly with corpus size to achieve arbitrary rankings, ARR can solve it with a constant hidden dimension. We then propose SToICaL (Simple Token-Item Calibrated Loss), a generalized rank-aware training loss for LLM finetuning. By using item-level reweighting and prefix-tree marginalization, we distribute probability mass over valid docID tokens based on their ground-truth relevance. Experiments on WordNet and ESCI datasets verify that our loss suppresses invalid docID generations and significantly improves ranking metrics beyond top-1 retrieval.",
      "authors": [
        "Benjamin Rozonoyer",
        "Chong You",
        "Michael Boratko",
        "Himanshu Jain",
        "Nilesh Gupta",
        "Srinadh Bhojanapalli",
        "Andrew McCallum",
        "Felix Yu"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-09T07:16:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05588v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22944v2",
      "title": "Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization",
      "abstract": "Out-of-distribution (OOD) generalization remains challenging when models simultaneously encounter correlation shifts across environments and diversity shifts driven by rare or hard samples. Existing invariant risk minimization (IRM) methods primarily address spurious correlations at the environment level, but often overlook sample-level heterogeneity within environments, which can critically impact OOD performance. In this work, we propose Environment-Conditioned Tail Reweighting for Total Variation Invariant Risk Minimization (ECTR), a unified framework that augments TV-based invariant learning with environment-conditioned tail reweighting to jointly address both types of distribution shift. By integrating environment-level invariance with within-environment robustness, the proposed approach makes these two mechanisms complementary under mixed distribution shifts. We further extend the framework to scenarios without explicit environment annotations by inferring latent environments through a minimax formulation. Experiments across regression, tabular, time-series, and image classification benchmarks under mixed distribution shifts demonstrate consistent improvements in both worst-environment and average OOD performance.",
      "authors": [
        "Yuanchao Wang",
        "Zhao-Rong Lai",
        "Tianqi Zhong",
        "Fengnan Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T13:03:04+00:00",
      "link": "https://arxiv.org/pdf/2601.22944v2",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13525v1",
      "title": "More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval",
      "abstract": "Dense retrievers powered by pretrained embeddings are widely used for document retrieval but struggle in specialized domains due to the mismatches between the training and target domain distributions. Domain adaptation typically requires costly annotation and retraining of query-document pairs. In this work, we revisit an overlooked alternative: applying PCA to domain embeddings to derive lower-dimensional representations that preserve domain-relevant features while discarding non-discriminative components. Though traditionally used for efficiency, we demonstrate that this simple embedding compression can effectively improve retrieval performance. Evaluated across 9 retrievers and 14 MTEB datasets, PCA applied solely to query embeddings improves NDCG@10 in 75.4% of model-dataset pairs, offering a simple and lightweight method for domain adaptation.",
      "authors": [
        "Chunsheng Zuo",
        "Daniel Khashabi"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-20T02:21:03+00:00",
      "link": "https://arxiv.org/pdf/2601.13525v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12051v1",
      "title": "A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models",
      "abstract": "In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \\textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack",
      "authors": [
        "Weixin Ye",
        "Wei Wang",
        "Yahui Liu",
        "Yue Song",
        "Bin Ren",
        "Wei Bi",
        "Rita Cucchiara",
        "Nicu Sebe"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-17T13:32:32+00:00",
      "link": "https://arxiv.org/pdf/2601.12051v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14112v2",
      "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns",
      "abstract": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.",
      "authors": [
        "George Mihaila"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-20T16:06:34+00:00",
      "link": "https://arxiv.org/pdf/2601.14112v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02551v1",
      "title": "EEO-TFV: Escape-Explore Optimizer for Web-Scale Time-Series Forecasting and Vision Analysis",
      "abstract": "Transformer-based foundation models have achieved remarkable progress in tasks such as time-series forecasting and image segmentation. However, they frequently suffer from error accumulation in multivariate long-sequence prediction and exhibit vulnerability to out-of-distribution samples in image-related tasks. Furthermore, these challenges become particularly pronounced in large-scale Web data analysis tasks, which typically involve complex temporal patterns and multimodal features. This complexity substantially increases optimization difficulty, rendering models prone to stagnation at saddle points within high-dimensional parameter spaces. To address these issues, we propose a lightweight Transformer architecture in conjunction with a novel Escape-Explore Optimizer (EEO). The optimizer enhances both exploration and generalization while effectively avoiding sharp minima and saddle-point traps. Experimental results show that, in representative Web data scenarios, our method achieves performance on par with state-of-the-art models across 11 time-series benchmark datasets and the Synapse medical image segmentation task. Moreover, it demonstrates superior generalization and stability, thereby validating its potential as a versatile cross-task foundation model for Web-scale data mining and analysis.",
      "authors": [
        "Hua Wang",
        "Jinghao Lu",
        "Fan Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-30T09:30:16+00:00",
      "link": "https://arxiv.org/pdf/2602.02551v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10566v3",
      "title": "Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure",
      "abstract": "Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales.",
      "authors": [
        "Syed Naveed Mahmood",
        "Md. Rezaur Rahman Bhuiyan",
        "Tasfia Zaman",
        "Jareen Tasneem Khondaker",
        "Md. Sameer Sakib",
        "K. M. Shadman Wadith",
        "Nazia Tasnim",
        "Farig Sadeque"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-15T16:28:14+00:00",
      "link": "https://arxiv.org/pdf/2601.10566v3",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19613v1",
      "title": "Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs",
      "abstract": "Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using \"[mask]\" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.",
      "authors": [
        "Xinzhong Wang",
        "Ya Guo",
        "Jing Li",
        "Huan Chen",
        "Yi Tu",
        "Yijie Hong",
        "Gongshen Liu",
        "Huijia Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-27T13:45:30+00:00",
      "link": "https://arxiv.org/pdf/2601.19613v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03945v1",
      "title": "Grables: Tabular Learning Beyond Independent Rows",
      "abstract": "Tabular learning is still dominated by row-wise predictors that score each row independently, which fits i.i.d. benchmarks but fails on transactional, temporal, and relational tables where labels depend on other rows. We show that row-wise prediction rules out natural targets driven by global counts, overlaps, and relational patterns. To make \"using structure\" precise across architectures, we introduce grables: a modular interface that separates how a table is lifted to a graph (constructor) from how predictions are computed on that graph (node predictor), pinpointing where expressive power comes from. Experiments on synthetic tasks, transaction data, and a RelBench clinical-trials dataset confirm the predicted separations: message passing captures inter-row dependencies that row-local models miss, and hybrid approaches that explicitly extract inter-row structure and feed it to strong tabular learners yield consistent gains.",
      "authors": [
        "Tamara Cucumides",
        "Floris Geerts"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-03T19:05:21+00:00",
      "link": "https://arxiv.org/pdf/2602.03945v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14007v1",
      "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models",
      "abstract": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.",
      "authors": [
        "Junyu Zhang",
        "Yipeng Kang",
        "Jiong Guo",
        "Jiayu Zhan",
        "Junqi Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-20T14:26:58+00:00",
      "link": "https://arxiv.org/pdf/2601.14007v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19266v1",
      "title": "A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation",
      "abstract": "Semi-Supervised Domain Adaptation (SSDA) leverages knowledge from a fully labeled source domain to classify data in a partially labeled target domain. Due to the limited number of labeled samples in the target domain, there can be intrinsic similarity of classes in the feature space, which may result in biased predictions, even when the model is trained on a balanced dataset. To overcome this limitation, we introduce a multi-view consistency framework, which includes two views for training strongly augmented data. One is a debiasing strategy for correcting class-wise prediction probabilities according to the prediction performance of the model. The other involves leveraging pseudo-negative labels derived from the model predictions. Furthermore, we introduce a cross-domain affinity learning aimed at aligning features of the same class across different domains, thereby enhancing overall performance. Experimental results demonstrate that our method outperforms the competing methods on two standard domain adaptation datasets, DomainNet and Office-Home. Combining unsupervised domain adaptation and semi-supervised learning offers indispensable contributions to the industrial sector by enhancing model adaptability, reducing annotation costs, and improving performance.",
      "authors": [
        "Yuting Hong",
        "Li Dong",
        "Xiaojie Qiu",
        "Hui Xiao",
        "Baochen Yao",
        "Siming Zheng",
        "Chengbin Peng"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-27T06:54:13+00:00",
      "link": "https://arxiv.org/pdf/2601.19266v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22694v1",
      "title": "Farewell to Item IDs: Unlocking the Scaling Potential of Large Ranking Models via Semantic Tokens",
      "abstract": "Recent studies on scaling up ranking models have achieved substantial improvement for recommendation systems and search engines. However, most large-scale ranking systems rely on item IDs, where each item is treated as an independent categorical symbol and mapped to a learned embedding. As items rapidly appear and disappear, these embeddings become difficult to train and maintain. This instability impedes effective learning of neural network parameters and limits the scalability of ranking models. In this paper, we show that semantic tokens possess greater scaling potential compared to item IDs. Our proposed framework TRM improves the token generation and application pipeline, leading to 33% reduction in sparse storage while achieving 0.85% AUC increase. Extensive experiments further show that TRM could consistently outperform state-of-the-art models when model capacity scales. Finally, TRM has been successfully deployed on large-scale personalized search engines, yielding 0.26% and 0.75% improvement on user active days and change query ratio respectively through A/B test.",
      "authors": [
        "Zhen Zhao",
        "Tong Zhang",
        "Jie Xu",
        "Qingliang Cai",
        "Qile Zhang",
        "Leyuan Yang",
        "Daorui Xiao",
        "Xiaojia Chang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-30T08:12:59+00:00",
      "link": "https://arxiv.org/pdf/2601.22694v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17408v1",
      "title": "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity",
      "abstract": "Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.",
      "authors": [
        "Harsharaj Pathak",
        "Vineeth N Balasubramanian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-24T10:51:25+00:00",
      "link": "https://arxiv.org/pdf/2601.17408v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.05877v2",
      "title": "iReasoner: Trajectory-Aware Intrinsic Reasoning Supervision for Self-Evolving Large Multimodal Models",
      "abstract": "Recent work shows that large multimodal models (LMMs) can self-improve from unlabeled data via self-play and intrinsic feedback. Yet existing self-evolving frameworks mainly reward final outcomes, leaving intermediate reasoning weakly constrained despite its importance for visually grounded decision making. We propose iReasoner, a self-evolving framework that improves an LMM's implicit reasoning by explicitly eliciting chain-of-thought (CoT) and rewarding its internal agreement. In a Proposer--Solver loop over unlabeled images, iReasoner augments outcome-level intrinsic rewards with a trajectory-aware signal defined over intermediate reasoning steps, providing learning signals that distinguish reasoning paths leading to the same answer without ground-truth labels or external judges. Starting from Qwen2.5-VL-7B, iReasoner yields up to $+2.1$ points across diverse multimodal reasoning benchmarks under fully unsupervised post-training. We hope this work serves as a starting point for reasoning-aware self-improvement in LMMs in purely unsupervised settings.",
      "authors": [
        "Meghana Sunil",
        "Manikandarajan Venmathimaran",
        "Muthu Subash Kavitha"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-09T15:53:42+00:00",
      "link": "https://arxiv.org/pdf/2601.05877v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17958v1",
      "title": "TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors",
      "abstract": "Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.",
      "authors": [
        "Ido Andrew Atad",
        "Itamar Zimerman",
        "Shahar Katz",
        "Lior Wolf"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-25T19:21:25+00:00",
      "link": "https://arxiv.org/pdf/2601.17958v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21759v1",
      "title": "Influence Guided Sampling for Domain Adaptation of Text Retrievers",
      "abstract": "General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on a large pool of training datasets.",
      "authors": [
        "Meet Doshi",
        "Vishwajeet Kumar",
        "Yulong Li",
        "Jaydeep Sen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-01-29T14:14:29+00:00",
      "link": "https://arxiv.org/pdf/2601.21759v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.01217v1",
      "title": "Learning from Anonymized and Incomplete Tabular Data",
      "abstract": "User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values.",
      "authors": [
        "Lucas Lange",
        "Adrian Böttinger",
        "Victor Christen",
        "Anushka Vidanage",
        "Peter Christen",
        "Erhard Rahm"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DB"
      ],
      "published": "2026-02-01T13:18:14+00:00",
      "link": "https://arxiv.org/pdf/2602.01217v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12260v1",
      "title": "Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding",
      "abstract": "Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.",
      "authors": [
        "Yihao Ding",
        "Qiang Sun",
        "Puzhen Wu",
        "Sirui Li",
        "Siwen Luo",
        "Wei Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-18T04:45:09+00:00",
      "link": "https://arxiv.org/pdf/2601.12260v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03980v1",
      "title": "Transformers perform adaptive partial pooling",
      "abstract": "Because language is creative, any reasonable language model must generalize, deciding what to say in novel contexts by using information from similar contexts. But what about contexts that are not novel but merely infrequent? In hierarchical regression, the model's predictions for behavior in a context are affected by observations from other similar contexts to the extent that 1) the current context is infrequent and 2) different contexts behave similarly. This is called adaptive partial pooling of evidence. This paper shows that next-word predictions of a transformer (GPT2) are increasingly unaffected by observations from outside the current context across epochs of training (the amount of pooling reduces with training), and that the extent of pooling is affected by context frequency, context number (type frequency) and context variability in a similar way to hierarchical regression. These characteristics of learning in transformers are argued to be realistic on both rational and empirical grounds.",
      "authors": [
        "Vsevolod Kapatsinski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-03T20:05:01+00:00",
      "link": "https://arxiv.org/pdf/2602.03980v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17309v1",
      "title": "PAR: Plausibility-aware Amortized Recourse Generation",
      "abstract": "Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.",
      "authors": [
        "Anagha Sabu",
        "Vidhya S",
        "Narayanan C Krishnan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-24T05:12:22+00:00",
      "link": "https://arxiv.org/pdf/2601.17309v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.02592v1",
      "title": "Learnable Koopman-Enhanced Transformer-Based Time Series Forecasting with Spectral Control",
      "abstract": "This paper proposes a unified family of learnable Koopman operator parameterizations that integrate linear dynamical systems theory with modern deep learning forecasting architectures. We introduce four learnable Koopman variants-scalar-gated, per-mode gated, MLP-shaped spectral mapping, and low-rank Koopman operators which generalize and interpolate between strictly stable Koopman operators and unconstrained linear latent dynamics. Our formulation enables explicit control over the spectrum, stability, and rank of the linear transition operator while retaining compatibility with expressive nonlinear backbones such as Patchtst, Autoformer, and Informer. We evaluate the proposed operators in a large-scale benchmark that also includes LSTM, DLinear, and simple diagonal State-Space Models (SSMs), as well as lightweight transformer variants. Experiments across multiple horizons and patch lengths show that learnable Koopman models provide a favorable bias-variance trade-off, improved conditioning, and more interpretable latent dynamics. We provide a full spectral analysis, including eigenvalue trajectories, stability envelopes, and learned spectral distributions. Our results demonstrate that learnable Koopman operators are effective, stable, and theoretically principled components for deep forecasting.",
      "authors": [
        "Ali Forootani",
        "Raffaele Iervolino"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "published": "2026-02-01T09:13:49+00:00",
      "link": "https://arxiv.org/pdf/2602.02592v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04486v1",
      "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
      "abstract": "Grounded Multimodal Named Entity Recognition (GMNER) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit $\\textbf{modality bias}$, including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning ($\\textbf{MCR}$), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.",
      "authors": [
        "Jinlong Ma",
        "Yu Zhang",
        "Xuefeng Bai",
        "Kehai Chen",
        "Yuwei Wang",
        "Zeming Liu",
        "Jun Yu",
        "Min Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-04T12:12:49+00:00",
      "link": "https://arxiv.org/pdf/2602.04486v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04941v1",
      "title": "Improving Set Function Approximation with Quasi-Arithmetic Neural Networks",
      "abstract": "Sets represent a fundamental abstraction across many types of data. To handle the unordered nature of set-structured data, models such as DeepSets and PointNet rely on fixed, non-learnable pooling operations (e.g., sum or max) -- a design choice that can hinder the transferability of learned embeddings and limits model expressivity. More recently, learnable aggregation functions have been proposed as more expressive alternatives. In this work, we advance this line of research by introducing the Neuralized Kolmogorov Mean (NKM) -- a novel, trainable framework for learning a generalized measure of central tendency through an invertible neural function. We further propose quasi-arithmetic neural networks (QUANNs), which incorporate the NKM as a learnable aggregation function. We provide a theoretical analysis showing that, QUANNs are universal approximators for a broad class of common set-function decompositions and, thanks to their invertible neural components, learn more structured latent representations. Empirically, QUANNs outperform state-of-the-art baselines across diverse benchmarks, while learning embeddings that transfer effectively even to tasks that do not involve sets.",
      "authors": [
        "Tomas Tokar",
        "Scott Sanner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T18:36:31+00:00",
      "link": "https://arxiv.org/pdf/2602.04941v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21986v1",
      "title": "SpecTran: Spectral-Aware Transformer-based Adapter for LLM-Enhanced Sequential Recommendation",
      "abstract": "Traditional sequential recommendation (SR) models learn low-dimensional item ID embeddings from user-item interactions, often overlooking textual information such as item titles or descriptions. Recent advances in Large Language Models (LLMs) have inspired a surge of research that encodes item textual information with high-dimensional semantic embeddings, and designs transformation methods to inject such embeddings into SR models. These embedding transformation strategies can be categorized into two types, both of which exhibits notable drawbacks: 1) adapter-based methods suffer from pronounced dimension collapse, concentrating information into a few dominant dimensions; 2) SVD-based methods are rigid and manual, considering only a few principal spectral components while discarding rich information in the remaining spectrum.   To address these limitations, we propose SpecTran, a spectral-aware transformer-based adapter that operates in the spectral domain, attending to the full spectrum to select and aggregates informative components. A learnable spectral-position encoding injects singular-value cues as an inductive bias, guiding attention toward salient spectral components and promoting diversity across embedding dimensions. Across four real-world datasets and three SR backbones, it consistently outperforms strong baselines, achieving an average improvement of 9.17%.",
      "authors": [
        "Yu Cui",
        "Feng Liu",
        "Zhaoxiang Wang",
        "Changwang Zhang",
        "Jun Wang",
        "Can Wang",
        "Jiawei Chen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-29T17:00:27+00:00",
      "link": "https://arxiv.org/pdf/2601.21986v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07474v1",
      "title": "Task Prototype-Based Knowledge Retrieval for Multi-Task Learning from Partially Annotated Data",
      "abstract": "Multi-task learning (MTL) is critical in real-world applications such as autonomous driving and robotics, enabling simultaneous handling of diverse tasks. However, obtaining fully annotated data for all tasks is impractical due to labeling costs. Existing methods for partially labeled MTL typically rely on predictions from unlabeled tasks, making it difficult to establish reliable task associations and potentially leading to negative transfer and suboptimal performance. To address these issues, we propose a prototype-based knowledge retrieval framework that achieves robust MTL instead of relying on predictions from unlabeled tasks. Our framework consists of two key components: (1) a task prototype embedding task-specific characteristics and quantifying task associations, and (2) a knowledge retrieval transformer that adaptively refines feature representations based on these associations. To achieve this, we introduce an association knowledge generating (AKG) loss to ensure the task prototype consistently captures task-specific characteristics. Extensive experiments demonstrate the effectiveness of our framework, highlighting its potential for robust multi-task learning, even when only a subset of tasks is annotated.",
      "authors": [
        "Youngmin Oh",
        "Hyung-Il Kim",
        "Jung Uk Kim"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-12T12:27:02+00:00",
      "link": "https://arxiv.org/pdf/2601.07474v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.01186v1",
      "title": "The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics",
      "abstract": "Classical Federated Learning relies on a multi-round iterative process of model exchange and aggregation between server and clients, with high communication costs and privacy risks from repeated model transmissions. In contrast, one-shot federated learning (OFL) alleviates these limitations by reducing communication to a single round, thereby lowering overhead and enhancing practical deployability. Nevertheless, most existing one-shot approaches remain either impractical or constrained, for example, they often depend on the availability of a public dataset, assume homogeneous client models, or require uploading additional data or model information. To overcome these issues, we introduce the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated methods that assume class-conditional Gaussianity of pretrained embeddings. Clients transmit only sufficient statistics (per-class counts and first/second-order moments) and the server builds heads via three components: (i) Closed-form Gaussian heads (NB/LDA/QDA) computed directly from the received statistics; (ii) FisherMix, a linear head with cosine margin trained on synthetic samples drawn in an estimated Fisher subspace; and (iii) Proto-Hyper, a lightweight low-rank residual head that refines Gaussian logits via knowledge distillation on those synthetic samples. In our experiments, GH-OFL methods deliver state-of-the-art robustness and accuracy under strong non-IID skew while remaining strictly data-free.",
      "authors": [
        "Fabio Turazza",
        "Marco Picone",
        "Marco Mamei"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-01T12:17:28+00:00",
      "link": "https://arxiv.org/pdf/2602.01186v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21513v1",
      "title": "Cascaded Transfer: Learning Many Tasks under Budget Constraints",
      "abstract": "Many-Task Learning refers to the setting where a large number of related tasks need to be learned, the exact relationships between tasks are not known. We introduce the Cascaded Transfer Learning, a novel many-task transfer learning paradigm where information (e.g. model parameters) cascades hierarchically through tasks that are learned by individual models of the same class, while respecting given budget constraints. The cascade is organized as a rooted tree that specifies the order in which tasks are learned and refined. We design a cascaded transfer mechanism deployed over a minimum spanning tree structure that connects the tasks according to a suitable distance measure, and allocates the available training budget along its branches. Experiments on synthetic and real many-task settings show that the resulting method enables more accurate and cost effective adaptation across large task collections compared to alternative approaches.",
      "authors": [
        "Eloi Campagne",
        "Yvenn Amara-Ouali",
        "Yannig Goude",
        "Mathilde Mougeot",
        "Argyris Kalogeratos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T10:28:08+00:00",
      "link": "https://arxiv.org/pdf/2601.21513v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09026v2",
      "title": "Layer-Parallel Training for Transformers",
      "abstract": "We present a new training methodology for transformers using a multilevel, layer-parallel approach. Through a neural ODE formulation of transformers, our application of a multilevel parallel-in-time algorithm for the forward and backpropagation phases of training achieves parallel acceleration over the layer dimension. This dramatically enhances parallel scalability as the network depth increases, which is particularly useful for increasingly large foundational models. However, achieving this introduces errors that cause systematic bias in the gradients, which in turn reduces convergence when closer to the minima. We develop an algorithm to detect this critical transition and either switch to serial training or systematically increase the accuracy of layer-parallel training. Results, including BERT, GPT2, ViT, and machine translation architectures, demonstrate parallel-acceleration as well as accuracy commensurate with serial pre-training while fine-tuning is unaffected.",
      "authors": [
        "Shuai Jiang",
        "Marc Salvadó-Benasco",
        "Eric C. Cyr",
        "Alena Kopaničáková",
        "Rolf Krause",
        "Jacob B. Schroder"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-13T23:12:53+00:00",
      "link": "https://arxiv.org/pdf/2601.09026v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12078v1",
      "title": "Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization",
      "abstract": "Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.",
      "authors": [
        "Linfeng Du",
        "Ye Yuan",
        "Zichen Zhao",
        "Fuyuan Lyu",
        "Emiliano Penaloza",
        "Xiuying Chen",
        "Zipeng Sun",
        "Jikun Kang",
        "Laurent Charlin",
        "Xue Liu",
        "Haolun Wu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-17T15:05:36+00:00",
      "link": "https://arxiv.org/pdf/2601.12078v1",
      "tags": [
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.18213v1",
      "title": "Generative Chain of Behavior for User Trajectory Prediction",
      "abstract": "Modeling long-term user behavior trajectories is essential for understanding evolving preferences and enabling proactive recommendations. However, most sequential recommenders focus on next-item prediction, overlooking dependencies across multiple future actions. We propose Generative Chain of Behavior (GCB), a generative framework that models user interactions as an autoregressive chain of semantic behaviors over multiple future steps. GCB first encodes items into semantic IDs via RQ-VAE with k-means refinement, forming a discrete latent space that preserves semantic proximity. On top of this space, a transformer-based autoregressive generator predicts multi-step future behaviors conditioned on user history, capturing long-horizon intent transitions and generating coherent trajectories. Experiments on benchmark datasets show that GCB consistently outperforms state-of-the-art sequential recommenders in multi-step accuracy and trajectory consistency. Beyond these gains, GCB offers a unified generative formulation for capturing user preference evolution.",
      "authors": [
        "Chengkai Huang",
        "Xiaodi Chen",
        "Hongtao Huang",
        "Quan Z. Sheng",
        "Lina Yao"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-26T06:57:31+00:00",
      "link": "https://arxiv.org/pdf/2601.18213v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12711v1",
      "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts",
      "abstract": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",
      "authors": [
        "Kevin Wang",
        "Neel P. Bhatt",
        "Cong Liu",
        "Junbo Li",
        "Runjin Chen",
        "Yihan Xi",
        "Timothy Barclay",
        "Alvaro Velasquez",
        "Ufuk Topcu",
        "Zhangyang Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "published": "2026-01-19T04:24:49+00:00",
      "link": "https://arxiv.org/pdf/2601.12711v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13700v1",
      "title": "DistilMOS: Layer-Wise Self-Distillation For Self-Supervised Learning Model-Based MOS Prediction",
      "abstract": "With the advancement of self-supervised learning (SSL), fine-tuning pretrained SSL models for mean opinion score (MOS) prediction has achieved state-of-the-art performance. However, during fine-tuning, these SSL-based MOS prediction models often suffer from catastrophic forgetting of the pretrained knowledge and tend to overfit the training set, resulting in poor generalization performance. In this study, we propose DistilMOS, a novel method that learns to predict not only MOS but also token IDs obtained by clustering the hidden representations of each layer in the pretrained SSL model. These layer-wise token targets serve as self-distillation signals that enables the MOS prediction model to extract rich internal knowledge from SSL models, enhancing both prediction accuracy and generalization capability. Experimental evaluations demonstrate that our method significantly outperforms standard SSL-based MOS prediction models on both in-domain and out-of-domain evaluations, verifying the effectiveness and practicality of the proposed method.",
      "authors": [
        "Jianing Yang",
        "Wataru Nakata",
        "Yuki Saito",
        "Hiroshi Saruwatari"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD"
      ],
      "published": "2026-01-20T07:52:55+00:00",
      "link": "https://arxiv.org/pdf/2601.13700v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16979v2",
      "title": "A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs",
      "abstract": "Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\\textit{relative critical sharpness}$ ($λ_c^{1\\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.",
      "authors": [
        "Dayal Singh Kalra",
        "Jean-Christophe Gagnon-Audet",
        "Andrey Gromov",
        "Ishita Mediratta",
        "Kelvin Niu",
        "Alexander H Miller",
        "Michael Shvartsman"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-23T18:59:40+00:00",
      "link": "https://arxiv.org/pdf/2601.16979v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04536v1",
      "title": "Forget to Generalize: Iterative Adaptation for Generalization in Federated Learning",
      "abstract": "The Web is naturally heterogeneous with user devices, geographic regions, browsing patterns, and contexts all leading to highly diverse, unique datasets. Federated Learning (FL) is an important paradigm for the Web because it enables privacy-preserving, collaborative machine learning across diverse user devices, web services and clients without needing to centralize sensitive data. However, its performance degrades severely under non-IID client distributions that is prevalent in real-world web systems. In this work, we propose a new training paradigm - Iterative Federated Adaptation (IFA) - that enhances generalization in heterogeneous federated settings through generation-wise forget and evolve strategy. Specifically, we divide training into multiple generations and, at the end of each, select a fraction of model parameters (a) randomly or (b) from the later layers of the model and reinitialize them. This iterative forget and evolve schedule allows the model to escape local minima and preserve globally relevant representations. Extensive experiments on CIFAR-10, MIT-Indoors, and Stanford Dogs datasets show that the proposed approach improves global accuracy, especially when the data cross clients are Non-IID. This method can be implemented on top any federated algorithm to improve its generalization performance. We observe an average of 21.5%improvement across datasets. This work advances the vision of scalable, privacy-preserving intelligence for real-world heterogeneous and distributed web systems.",
      "authors": [
        "Abdulrahman Alotaibi",
        "Irene Tenison",
        "Miriam Kim",
        "Isaac Lee",
        "Lalana Kagal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T13:27:15+00:00",
      "link": "https://arxiv.org/pdf/2602.04536v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.15423v1",
      "title": "Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes",
      "abstract": "We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p < 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.",
      "authors": [
        "Lorian Bannis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21T19:37:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15423v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.21707v1",
      "title": "Adaptive Kernel Methods",
      "abstract": "Kernel methods approximate nonlinear maps in a data-driven manner by projecting the target map onto a finite-dimensional Hilbert space called the solution space. Traditionally, this space is a subspace of a fixed ambient reproducing kernel Hilbert space (RKHS), determined solely by the chosen kernel and the dataset, whose elements identify the basis elements. Consequently, the projection operator underlying the kernel method depends on the loss function, the dataset, and the choice of ambient RKHS. In this study, we consider kernel methods whose solution spaces also depend on learnable parameters that are independent of the dataset. The resulting methods can be viewed as variable projection operators that depend on the loss function, the dataset, and the new learnable parameters instead of a fixed RKHS. This work has two main contributions. First, we propose an efficient approximation of kernels associated with infinite-dimensional RKHSs, commonly used to reduce the solution-space dimension for large datasets. Second, we construct fixed-dimensional, parameter-dependent solution spaces that enable highly efficient kernel models suitable for large-scale problems without the need to approximate kernels of infinite-dimensional RKHSs. Our novel family of adaptive kernel methods generalizes earlier approaches, including Random Fourier Features, and we demonstrate their effectiveness through several numerical experiments.",
      "authors": [
        "Tamás Dózsa",
        "Andrea Angino",
        "Zoltán Szabó",
        "József Bokor",
        "Matthias Voigt"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-29T13:38:47+00:00",
      "link": "https://arxiv.org/pdf/2601.21707v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14059v1",
      "title": "Verifying Floating-Point Programs in Stainless",
      "abstract": "We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.",
      "authors": [
        "Andrea Gilot",
        "Axel Bergström",
        "Eva Darulova"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.LO"
      ],
      "published": "2026-01-20T15:16:35+00:00",
      "link": "https://arxiv.org/pdf/2601.14059v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19453v1",
      "title": "Preprocessing Uncertain Data into Supersequences for Sorting and Gaps",
      "abstract": "In the preprocessing framework for dealing with uncertain data, one is given a set of regions that one is allowed to preprocess to create some auxiliary structure such that when a realization of these regions is given, consisting of one point per region, this auxiliary structure can be used to reconstruct some desired output structure more efficiently than would have been possible without preprocessing. The framework has been successfully applied to several, mostly geometric, computational problems.   In this note, we propose using a supersequence of input items as the auxiliary structure, and explore its potential on the problems of sorting and computing the smallest or largest gap in a set of numbers. That is, our uncertainty regions are intervals on the real line, and in the preprocessing phase we output a supersequence of the intervals such that the sorted order / smallest gap / largest gap of any realization is a subsequence of this sequence.   We argue that supersequences are simpler than specialized auxiliary structures developed in previous work. An advantage of using supersequences as the auxiliary structures is that it allows us to decouple the preprocessing phase from the reconstruction phase in a stronger sense than was possible in previous work, resulting in two separate algorithmic problems for which different solutions may be combined to obtain known and new results. We identify one key open problem which we believe is of independent interest.",
      "authors": [
        "Maarten Löffler",
        "Benjamin Raichel"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.IT"
      ],
      "published": "2026-01-27T10:39:04+00:00",
      "link": "https://arxiv.org/pdf/2601.19453v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07967v1",
      "title": "Scattered Data Histopolation in Averaging Kernel Hilbert Spaces",
      "abstract": "Kernel-based methods offer a powerful and flexible mathematical framework for addressing histopolation problems. In histopolation, the available input data does not consist of pointwise function samples but of averages taken over intervals or higher-dimensional regions, and these mean values serve as a basis for reconstructing or approximating the target function. While classical interpolation requires continuity of the underlying function, histopolation can be performed in larger function spaces. In the framework of kernel methods, we will introduce and study the so-called averaging kernel Hilbert spaces (AKHS's) for this purpose. Within this setting, we develop systematic construction principles for averaging kernels and provide characterizations based on the Fourier-Plancherel transform. In addition, we analyze several representative histopolation scenarios in order to highlight properties of this approximation method, including conditions for unisolvence and possible error estimates. Finally, we present numerical experiments that shed some light on the convergence behavior of the presented approach and demonstrate its practical effectiveness.",
      "authors": [
        "Ludovico Bruni Bruno",
        "Giacomo Cappellazzo",
        "Wolfgang Erb",
        "Mohammad Karimnejad Esfahani"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-12T20:01:49+00:00",
      "link": "https://arxiv.org/pdf/2601.07967v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18728v1",
      "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data",
      "abstract": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.",
      "authors": [
        "Willem Diepeveen",
        "Oscar Leong"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DG",
        "math.OC",
        "math.ST"
      ],
      "published": "2026-01-26T17:51:52+00:00",
      "link": "https://arxiv.org/pdf/2601.18728v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04523v1",
      "title": "Incongruity-sensitive access to highly compressed strings",
      "abstract": "Random access to highly compressed strings -- represented by straight-line programs or Lempel-Ziv parses, for example -- is a well-studied topic. Random access to such strings in strongly sublogarithmic time is impossible in the worst case, but previous authors have shown how to support faster access to specific characters and their neighbourhoods. In this paper we explore whether, since better compression can impede access, we can support faster access to relatively incompressible substrings of highly compressed strings. We first show how, given a run-length compressed straight-line program (RLSLP) of size $g_{rl}$ or a block tree of size $L$, we can build an $O (g_{rl})$-space or an $O (L)$-space data structure, respectively, that supports access to any character in time logarithmic in the length of the longest repeated substring containing that character. That is, the more incongruous a character is with respect to the characters around it in a certain sense, the faster we can support access to it. We then prove a similar but more powerful and sophisticated result for parsings in which phrases' sources do not overlap much larger phrases, with the query time depending also on the number of phrases we must copy from their sources to obtain the queried character.",
      "authors": [
        "Ferdinando Cicalese",
        "Zsuzsanna Lipták",
        "Travis Gagie",
        "Gonzalo Navarro",
        "Nicola Prezza",
        "Cristian Urbina"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-02-04T13:13:48+00:00",
      "link": "https://arxiv.org/pdf/2602.04523v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06535v1",
      "title": "Automated dimensional analysis for PDEs",
      "abstract": "Physical units are fundamental to scientific computing. However, many finite element frameworks lack built-in support for dimensional analysis. In this work, we present a systematic framework for integrating physical units into the Unified Form Language (UFL). We implement a symbolic Quantity class to track units within variational forms. The implementation exploits the abelian group structure of physical dimensions. We represent them as vectors in $\\mathbb{Q}^n$ to simplify operations and improve performance. A graph-based visitor pattern traverses the expression tree to automate consistency checks and factorization. We demonstrate that this automated nondimensionalization functions as the simplest form of Full Operator Preconditioning. It acts as a physics-aware diagonal preconditioner that equilibrates linear systems prior to assembly. Numerical experiments with the Navier--Stokes equations show that this improves the condition number of the saddle-point matrix. Analysis of Neo-Hooke hyperelasticity highlights the detection of floating-point cancellation errors in small deformation regimes. Finally, the Poisson--Nernst--Planck system example illustrates the handling of coupled multiphysics problems with derived scaling parameters. Although the implementation targets the FEniCSx framework, the concepts are general and easily adaptable to other finite element libraries using UFL, such as Firedrake or DUNE.",
      "authors": [
        "Michal Habera",
        "Andreas Zilian"
      ],
      "primary_category": "cs.MS",
      "categories": [
        "cs.MS",
        "math.NA"
      ],
      "published": "2026-01-10T11:32:30+00:00",
      "link": "https://arxiv.org/pdf/2601.06535v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06289v1",
      "title": "How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning?",
      "abstract": "Mass spectrometry (MS) is a powerful analytical technique for identifying small molecules, yet determining complete molecular structures directly from tandem mass spectra (MS/MS) remains a long-standing challenge due to complex fragmentation patterns and the vast diversity of chemical space. Recent progress in large language models (LLMs) has shown promise for reasoning-intensive scientific tasks, but their capability for chemical interpretation is still unclear. In this work, we introduce a Chain-of-Thought (CoT) prompting framework and benchmark that evaluate how LLMs reason about mass spectral data to predict molecular structures. We formalize expert chemists' reasoning steps-such as double bond equivalent (DBE) analysis, neutral loss identification, and fragment assembly-into structured prompts and assess multiple state-of-the-art LLMs (Claude-3.5-Sonnet, GPT-4o-mini, and Llama-3 series) in a zero-shot setting using the MassSpecGym dataset. Our evaluation across metrics of SMILES validity, formula consistency, and structural similarity reveals that while LLMs can produce syntactically valid and partially plausible structures, they fail to achieve chemical accuracy or link reasoning to correct molecular predictions. These findings highlight both the interpretive potential and the current limitations of LLM-based reasoning for molecular elucidation, providing a foundation for future work that combines domain knowledge and reinforcement learning to achieve chemically grounded AI reasoning.",
      "authors": [
        "Yufeng Wang",
        "Lu Wei",
        "Lin Liu",
        "Hao Xu",
        "Haibin Ling"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-09T20:08:42+00:00",
      "link": "https://arxiv.org/pdf/2601.06289v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19250v1",
      "title": "Precision-induced Adaptive Randomized Low-Rank Approximation for SVD and Matrix Inversion",
      "abstract": "Singular value decomposition (SVD) and matrix inversion are ubiquitous in scientific computing. Both tasks are computationally demanding for large scale matrices. Existing algorithms can approximatively solve these problems with a given rank, which however is unknown in practice and requires considerable cost for tuning. In this paper, we tackle the SVD and matrix inversion problems from a new angle, where the optimal rank for the approximate solution is explicitly guided by the distribution of the singular values. Under the framework, we propose a precision-induced random re-normalization procedure for the considered problems without the need of guessing a good rank. The new algorithms built upon the procedure simultaneously calculate the optimal rank for the task at a desired precision level and lead to the corresponding approximate solution with a substantially reduced computational cost. The promising performance of the new algorithms is supported by both theory and numerical examples.",
      "authors": [
        "Weiwei Xu",
        "Weijie Shen",
        "Zhengjian Bai",
        "Chen Xu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-27T06:33:07+00:00",
      "link": "https://arxiv.org/pdf/2601.19250v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13712v1",
      "title": "Nonlinear compressive reduced basis approximation : when Taylor meets Kolmogorov",
      "abstract": "This paper investigates model reduction methods for efficiently approximating the solution of parameter-dependent PDEs with a multi-parameter vector $\\vecμ \\in \\mathbb{R}^p$. In cases where the Kolmogorov $N$-width decays fast enough, it is effective to approximate the solution as a sum of $N$ separable terms, each being the product of a parameter-dependent coefficient and a space-dependent function. This leads to reduced-order models with $N$ degrees of freedom and complexity of order ${\\mathcal O}(N^3)$.   However, when the $N$-width decays slowly, $N$ must be large to achieve acceptable accuracy, making cubic complexity prohibitive. The linear complexity measure in terms of Kolmogorov width must be replaced by the Gelfand width, with its associated sensing number. Recent nonlinear approaches based on this notion decompose the $N$ coordinates into two groups: $n$ free variables and $\\overline{n}$ dependent variables, where the latter are nonlinear functions of the former ($N= n+\\overline n$). Several works have focused on cases where these $\\overline{n}$ functions are homogeneous quadratic forms of the $n$ variables, with optimization strategies for choosing $n$ given a target accuracy.   A rigorous analysis of the local sensing number is carried out, showing that $n = p$ is optimal and appropriate, at least locally, around a reference point. In practical scenarios involving wide parameter ranges, the condition $p\\le n \\le p + k$ (with $k$ small) is valid and more robust from continuity arguments. Additionally, the assumption of a quadratic mapping, while justified in a local sense, becomes insufficient. More expressive nonlinear mappings-including those using machine learning-become necessary. This work contributes a theoretical foundation for such strategies and highlights the need for further investigations to push back the Kolmogorov Barrier.",
      "authors": [
        "Joubine Aghili",
        "Hassan Ballout",
        "Yvon Maday",
        "Christophe Prud'homme"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-20T08:09:30+00:00",
      "link": "https://arxiv.org/pdf/2601.13712v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.07325v1",
      "title": "Variational Approximations for Robust Bayesian Inference via Rho-Posteriors",
      "abstract": "The $ρ$-posterior framework provides universal Bayesian estimation with explicit contamination rates and optimal convergence guarantees, but has remained computationally difficult due to an optimization over reference distributions that precludes intractable posterior computation. We develop a PAC-Bayesian framework that recovers these theoretical guarantees through temperature-dependent Gibbs posteriors, deriving finite-sample oracle inequalities with explicit rates and introducing tractable variational approximations that inherit the robustness properties of exact $ρ$-posteriors. Numerical experiments demonstrate that this approach achieves theoretical contamination rates while remaining computationally feasible, providing the first practical implementation of $ρ$-posterior inference with rigorous finite-sample guarantees.",
      "authors": [
        "EL Mahdi Khribch",
        "Pierre Alquier"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-01-12T08:47:13+00:00",
      "link": "https://arxiv.org/pdf/2601.07325v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.05225v1",
      "title": "Metric space valued Fréchet regression",
      "abstract": "We consider the problem of estimating the Fréchet and conditional Fréchet mean from data taking values in separable metric spaces. Unlike Euclidean spaces, where well-established methods are available, there is no practical estimator that works universally for all metric spaces. Therefore, we introduce a computable estimator for the Fréchet mean based on random quantization techniques and establish its universal consistency across any separable metric spaces. Additionally, we propose another estimator for the conditional Fréchet mean, leveraging data-driven partitioning and quantization, and demonstrate its universal consistency when the output space is any Banach space.",
      "authors": [
        "László Györfi",
        "Pierre Humbert",
        "Batiste Le Bars"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-02-05T02:29:45+00:00",
      "link": "https://arxiv.org/pdf/2602.05225v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20113v1",
      "title": "A Data-Informed Local Subspaces Method for Error-Bounded Lossy Compression of Large-Scale Scientific Datasets",
      "abstract": "The growing volume of scientific simulation data presents a significant challenge for storage and transfer. Error-bounded lossy compression has emerged as a critical solution for mitigating these challenges, providing a means to reduce data size while ensuring that reconstructed data remains valid for scientific analysis. In this paper, we present a data-driven scientific data compressor, called Discontinuous Data-informed Local Subspaces (Discontinuous DLS), to improve compression-to-error ratios over data-agnostic compressors. This error-bounded compressor leverages localized spatial and temporal subspaces, informed by the underlying data structure, to enhance compression efficiency and preserve key features. The presented technique is flexible and applicable to a wide range of scientific data, including fluid dynamics, environmental simulations, and other high-dimensional, time-dependent datasets. We describe the core principles of the method and demonstrate its ability to significantly reduce storage requirements without compromising critical data fidelity. The technique is implemented in a distributed computing environment using MPI, and its performance is evaluated against state-of-the-art error-bounded compression methods in terms of compression ratio and reconstruction accuracy. This study highlights discontinuous DLS as a promising approach for large-scale scientific data compression in high-performance computing environments, providing a robust solution for managing the growing data demands of modern scientific simulations.",
      "authors": [
        "Arshan Khan",
        "Rohit Deshmukh",
        "Ben O'Neill"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "physics.comp-ph"
      ],
      "published": "2026-01-27T23:07:27+00:00",
      "link": "https://arxiv.org/pdf/2601.20113v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16047v1",
      "title": "Enhanced Representation-Based Sampling for the Efficient Generation of Datasets for Machine-Learned Interatomic Potentials",
      "abstract": "In this work, we present Enhanced Representation-Based Sampling (ERBS), a novel enhanced sampling method designed to generate structurally diverse training datasets for machine-learned interatomic potentials. ERBS automatically identifies collective variables by dimensionality reduction of atomic descriptors and applies a bias potential inspired by the On-the-Fly Probability Enhanced Sampling framework. We highlight the ability of Gaussian moment descriptors to capture collective molecular motions and explore the impact of biasing parameters using alanine dipeptide as a benchmark system. We show that free energy surfaces can be reconstructed with high fidelity using only short biased trajectories as training data. Further, we apply the method to the iterative construction of a liquid water dataset and compare the quality of simulated self-diffusion coefficients for models trained with molecular dynamics and ERBS data. Further, we active-learn models for liquid water with and without enhanced sampling and compare the quality of simulated self-diffusion coefficients. The self-diffusion coefficients closely match those simulated with a reference model at a significantly reduced dataset size. Finally, we compare the sampling behaviour of enhanced sampling methods by benchmarking the mean squared displacements of \\ce{BMIM+BF4-} trajectories simulated with uncertainty-driven dynamics and ERBS and find that the latter significantly increases the exploration of configurational space.",
      "authors": [
        "Moritz René Schäfer",
        "Johannes Kästner"
      ],
      "primary_category": "physics.chem-ph",
      "categories": [
        "physics.chem-ph"
      ],
      "published": "2026-01-22T15:26:04+00:00",
      "link": "https://arxiv.org/pdf/2601.16047v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.13195v1",
      "title": "Quantum Data Structure for Range Minimum Query",
      "abstract": "Given an array $a[1..n]$, the Range Minimum Query (RMQ) problem is to maintain a data structure that supports RMQ queries: given a range $[l, r]$, find the index of the minimum element among $a[l..r]$, i.e., $\\operatorname{argmin}_{i \\in [l, r]} a[i]$. In this paper, we propose a quantum data structure that supports RMQ queries and range updates, with an optimal time complexity $\\widetilde Θ(\\sqrt{nq})$ for performing $q = O(n)$ operations without preprocessing, compared to the classical $\\widetildeΘ(n+q)$. As an application, we obtain a time-efficient quantum algorithm for $k$-minimum finding without the use of quantum random access memory.",
      "authors": [
        "Qisheng Wang",
        "Zhean Xu",
        "Zhicheng Zhang"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cs.DS"
      ],
      "published": "2026-01-19T16:19:44+00:00",
      "link": "https://arxiv.org/pdf/2601.13195v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17026v1",
      "title": "Parallel Algorithm For Finding The Minimum s/t Cut in a Structured 3-Dimensional Proper Order Graph",
      "abstract": "We present a parallel algorithm for computing the minimum s-t cut in structured 3-dimensional proper order graphs arising from image segmentation problems. Proper order graphs are multi-column structures where vertices are arranged in parallel columns, with each vertex connected to consecutive vertices in adjacent columns. This graph structure naturally arises in surface extraction problems for geological horizon segmentation in seismic imaging volumes. We develop two parallel approaches: a hierarchical merging variant of the Boykov-Kolmogorov algorithm, and a novel parallel push-relabel algorithm with level synchronized global relabeling. Our primary contribution is the push-relabel variant, which partitions the graph into segments along columns with processor affinity, eliminating the need for a global shared queue. We introduce level synchronized global relabeling that enables concurrent label updates while maintaining correctness through barriers at each frontier level.",
      "authors": [
        "Shridharan Chandramouli"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-17T01:27:01+00:00",
      "link": "https://arxiv.org/pdf/2601.17026v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18524v1",
      "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale",
      "abstract": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.",
      "authors": [
        "Yongqi Jin",
        "Yecheng Wang",
        "Jun-jie Wang",
        "Rong Zhu",
        "Guolin Ke",
        "Weinan E"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-26T14:35:25+00:00",
      "link": "https://arxiv.org/pdf/2601.18524v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.16193v1",
      "title": "Density-based structural frameworks for prime numbers, prime gaps, and Euler products",
      "abstract": "We develop a unified density-based framework for primality, coprimality, and prime pairs, and introduce an intrinsic normalized model for prime gaps constrained by the Prime Number Theorem. Within this setting, a structural tension between Hardy-Littlewood, Cramer, and PNT predictions emerges, leading to quantitative estimates on the rarity of extreme gaps. Additive representations of even integers are reformulated as local density problems, yielding non-conjectural upper and lower bounds compatible with Hardy-Littlewood heuristics. Finally, the Riemann zeta function is analyzed via truncated Euler products, whose stability and oscillatory structure provide a coherent interpretation of the critical line and prime-based numerical criteria for the localization of non-trivial zeros.",
      "authors": [
        "Gregorio Vettori"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT",
        "math.CV"
      ],
      "published": "2026-01-22T18:46:20+00:00",
      "link": "https://arxiv.org/pdf/2601.16193v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17204v2",
      "title": "SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment",
      "abstract": "Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.",
      "authors": [
        "Yinkai Wang",
        "Yan Zhou Chen",
        "Xiaohui Chen",
        "Li-Ping Liu",
        "Soha Hassoun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE"
      ],
      "published": "2026-01-23T22:28:40+00:00",
      "link": "https://arxiv.org/pdf/2601.17204v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00756v1",
      "title": "A New Workflow for Materials Discovery Bridging the Gap Between Experimental Databases and Graph Neural Networks",
      "abstract": "Incorporating Machine Learning (ML) into material property prediction has become a crucial step in accelerating materials discovery. A key challenge is the severe lack of training data, as many properties are too complicated to calculate with high-throughput first principles techniques. To address this, recent research has created experimental databases from information extracted from scientific literature. However, most existing experimental databases do not provide full atomic coordinate information, which prevents them from supporting advanced ML architectures such as Graph Neural Networks (GNNs). In this work, we propose to bridge this gap through an alignment process between experimental databases and Crystallographic Information Files (CIF) from the Inorganic Crystal Structure Database (ICSD). Our approach enables the creation of a database that can fully leverage state-of-the-art model architectures for material property prediction. It also opens the door to utilizing transfer learning to improve prediction accuracy. To validate our approach, we align NEMAD with the ICSD and compare models trained on the resulting database to those trained on NEMAD originally. We demonstrate significant improvements in both Mean Absolute Error (MAE) and Correct Classification Rate (CCR) in predicting the ordering temperatures and magnetic ground states of magnetic materials, respectively.",
      "authors": [
        "Brandon Schoener",
        "Yuting Hu",
        "Pasit Wanlapha",
        "Akshay Rengarajan",
        "Ian Moog",
        "Michael Wang",
        "Peihong Zhang",
        "Jinjun Xiong",
        "Hao Zeng"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ],
      "published": "2026-01-31T14:44:02+00:00",
      "link": "https://arxiv.org/pdf/2602.00756v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00660v1",
      "title": "Phase Transitions in Unsupervised Feature Selection",
      "abstract": "Identifying minimal and informative feature sets is a central challenge in data analysis, particularly when few data points are available. Here we present a theoretical analysis of an unsupervised feature selection pipeline based on the Differentiable Information Imbalance (DII). We consider the specific case of structural and physico-chemical features describing a set of proteins. We show that if one considers the features as coordinates of a (hypothetical) statistical physics model, this model undergoes a phase transition as a function of the number of retained features. For physico-chemical descriptors, this transition is between a glass-like phase when the features are few and a liquid-like phase. The glass-like phase exhibits bimodal order-parameter distributions and Binder cumulant minima. In contrast, for structural descriptors the transition is less sharp. Remarkably, for physico-chemical descriptors the critical number of features identified from the DII coincides with the saturation of downstream binary classification performance. These results provide a principled, unsupervised criterion for minimal feature sets in protein classification and reveal distinct mechanisms of criticality across different feature types.",
      "authors": [
        "Jonathan Fiorentino",
        "Michele Monti",
        "Dimitrios Miltiadis-Vrachnos",
        "Vittorio Del Tatto",
        "Alessandro Laio",
        "Gian Gaetano Tartaglia"
      ],
      "primary_category": "q-bio.BM",
      "categories": [
        "q-bio.BM",
        "physics.data-an"
      ],
      "published": "2026-01-31T11:13:56+00:00",
      "link": "https://arxiv.org/pdf/2602.00660v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12957v1",
      "title": "Random tree Besov priors: Data-driven regularisation parameter selection",
      "abstract": "We develop a data-driven algorithm for automatically selecting the regularisation parameter in Bayesian inversion under random tree Besov priors. One of the key challenges in Bayesian inversion is the construction of priors that are both expressive and computationally feasible. Random tree Besov priors, introduced in Kekkonen et al. (2023), provide a flexible framework for capturing local regularity properties and sparsity patterns in a wavelet basis. In this paper, we extend this approach by introducing a hierarchical model that enables data-driven selection of the wavelet density parameter, allowing the regularisation strength to adapt across scales while retaining computational efficiency. We focus on nonparametric regression and also present preliminary plug-and-play results for a deconvolution problem.",
      "authors": [
        "Hanne Kekkonen",
        "Andreas Tataris"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.PR"
      ],
      "published": "2026-01-19T11:09:52+00:00",
      "link": "https://arxiv.org/pdf/2601.12957v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03523v1",
      "title": "D3PIA: A Discrete Denoising Diffusion Model for Piano Accompaniment Generation From Lead sheet",
      "abstract": "Generating piano accompaniments in the symbolic music domain is a challenging task that requires producing a complete piece of piano music from given melody and chord constraints, such as those provided by a lead sheet. In this paper, we propose a discrete diffusion-based piano accompaniment generation model, D3PIA, leveraging local alignment between lead sheet and accompaniment in piano-roll representation. D3PIA incorporates Neighborhood Attention (NA) to both encode the lead sheet and condition it for predicting note states in the piano accompaniment. This design enhances local contextual modeling by efficiently attending to nearby melody and chord conditions. We evaluate our model using the POP909 dataset, a widely used benchmark for piano accompaniment generation. Objective evaluation results demonstrate that D3PIA preserves chord conditions more faithfully compared to continuous diffusion-based and Transformer-based baselines. Furthermore, a subjective listening test indicates that D3PIA generates more musically coherent accompaniments than the comparison models.",
      "authors": [
        "Eunjin Choi",
        "Hounsu Kim",
        "Hayeon Bang",
        "Taegyun Kwon",
        "Juhan Nam"
      ],
      "primary_category": "cs.SD",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-02-03T13:39:33+00:00",
      "link": "https://arxiv.org/pdf/2602.03523v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15430v1",
      "title": "A numerical characterization of Dunkl systems",
      "abstract": "We give a numerical characterization of weighted hyperplane arrangements arising from Dunkl systems.",
      "authors": [
        "Martin de Borbon",
        "Dmitri Panov"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "math.AG",
        "math.RT"
      ],
      "published": "2026-01-21T19:55:13+00:00",
      "link": "https://arxiv.org/pdf/2601.15430v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19567v1",
      "title": "Learning the Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou Trajectories: A Nonlinear Approach using a Deep Autoencoder Model",
      "abstract": "We address the intrinsic dimensionality (ID) of high-dimensional trajectories, comprising $n_s = 4\\,000\\,000$ data points, of the Fermi-Pasta-Ulam-Tsingou (FPUT) $β$ model with $N = 32$ oscillators. To this end, a deep autoencoder (DAE) model is employed to infer the ID in the weakly nonlinear regime ($β\\lesssim 1$). We find that the trajectories lie on a nonlinear manifold of dimension $m^{\\ast} = 2$ embedded in a $64$-dimensional phase space. The DAE further reveals that this dimensionality increases to $m^{\\ast} = 3$ at $β= 1.1$, coinciding with a symmetry breaking transition, in which additional energy modes with even wave numbers $k = 2, 4$ become excited. Finally, we discuss the limitations of the linear approach based on principal component analysis (PCA), which fails to capture the underlying structure of the data and therefore yields unreliable results in most cases.",
      "authors": [
        "Gionni Marchetti"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cs.LG"
      ],
      "published": "2026-01-27T12:59:29+00:00",
      "link": "https://arxiv.org/pdf/2601.19567v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.12859v1",
      "title": "Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates",
      "abstract": "Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.",
      "authors": [
        "Luca Schaufelberger",
        "Aline Hartgers",
        "Kjell Jorner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.chem-ph"
      ],
      "published": "2026-01-19T09:16:17+00:00",
      "link": "https://arxiv.org/pdf/2601.12859v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18619v1",
      "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
      "abstract": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.",
      "authors": [
        "Jorge Quesada",
        "Ghassan AlRegib"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-26T15:58:04+00:00",
      "link": "https://arxiv.org/pdf/2601.18619v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20254v1",
      "title": "Wavelet Tree Ensembles for Triangulable Manifolds",
      "abstract": "We develop unbalanced Haar (UH) wavelet tree ensembles for regression on triangulable manifolds. Given data sampled on a triangulated manifold, we construct UH wavelet trees whose atoms are supported on geodesic triangles and form an orthonormal system in $L^2(μ_n)$, where $μ_n$ is the empirical measure on the sample, which allows us to use UH trees as weak learners in additive ensembles. Our construction extends classical UH wavelet trees from regular Euclidean grids to generic triangulable manifolds while preserving three key properties: (i) orthogonality and exact reconstruction at the sampled locations, (ii) recursive, data-driven partitions adapted to the geometry of the manifold via geodesic triangulations, and (iii) compatibility with optimization-based and Bayesian ensemble building. In Euclidean settings, the framework reduces to standard UH wavelet tree regression and provides a baseline for comparison. We illustrate the method on synthetic regression on the sphere and on climate anomaly fields on a spherical mesh, where UH ensembles on triangulated manifolds substantially outperform classical tree ensembles and non-adaptive mesh-based wavelets. For completeness, we also report results on image denoising on regular grids. A Bayesian variant (RUHWT) provides posterior uncertainty quantification for function estimates on manifolds. Our implementation is available at http://www.github.com/hrluo/WaveletTrees.",
      "authors": [
        "Hengrui Luo",
        "Akira Horiguchi",
        "Li Ma"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-28T05:01:54+00:00",
      "link": "https://arxiv.org/pdf/2601.20254v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.18264v1",
      "title": "Neural Network Approximation: A View from Polytope Decomposition",
      "abstract": "Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.",
      "authors": [
        "ZeYu Li",
        "ShiJun Zhang",
        "TieYong Zeng",
        "FengLei Fan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-26T08:39:11+00:00",
      "link": "https://arxiv.org/pdf/2601.18264v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.17981v2",
      "title": "Crystal Representation in the Reciprocal Space",
      "abstract": "In crystallography, a structure is typically represented by the arrangement of atoms in the direct space. Furthermore, space group symmetry and Wyckoff site notations are applied to characterize crystal structures with only a few variables. While this representation is effective for data records and human learning, it lacks one-to-one correspondence between the crystal structure and its representation. This is problematic for many applications, such as crystal structure determination, comparison, and more recently, generative model learning. To address this issue, we propose to represent crystals in a four-dimensional (4D) reciprocal space featured by their Cartesian coordinates and scattering factors, which can naturally handle translation invariance and space group symmetry with the help of structure factors. In order to achieve rotational invariance, the 4D coordinates are then transformed into a power spectrum representation under the orthogonal spherical harmonic and radial basis. Hence, this representation captures both periodicity and symmetry of the crystal structure while also providing a continuous representation of the atomic positions and cell parameters in the direct space. Its effectiveness is demonstrated by applying it to several crystal structure matching and reconstruction tasks.",
      "authors": [
        "Osman Goni Ridwan",
        "Hongfei Xue",
        "Youxing Chen",
        "Harish Cherukuri",
        "Qiang Zhu"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "categories": [
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-01-25T20:21:43+00:00",
      "link": "https://arxiv.org/pdf/2601.17981v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22191v2",
      "title": "Partial Rewriting and Value Interpretation of Logically Constrained Terms (Full Version)",
      "abstract": "Logically constrained term rewrite systems (LCTRSs) are a rewriting formalism that naturally supports built-in data structures, including integers and bit-vectors. The recent framework of existentially constrained terms and most general constrained rewriting on them (Takahata et al., 2025) has many advantages over the original approach of rewriting constrained terms. In this paper, we introduce partial constrained rewriting, a variant of rewriting existentially constrained terms whose underlying idea has already appeared implicitly in previous analyses and applications of LCTRSs. We examine the differences between these two notions of constrained rewriting. First, we establish a direct correspondence between them, leveraging subsumption and equivalence of constrained terms where appropriate. Then we give characterizations of each of them, using the interpretation of existentially constrained terms by instantiation. We further introduce the novel notion of value interpretation, that highlights subtle differences between partial and most general rewriting.",
      "authors": [
        "Takahito Aoto",
        "Naoki Nishida",
        "Jonas Schöpf"
      ],
      "primary_category": "cs.LO",
      "categories": [
        "cs.LO"
      ],
      "published": "2026-01-29T07:53:11+00:00",
      "link": "https://arxiv.org/pdf/2601.22191v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.22312v1",
      "title": "SCALAR: Quantifying Structural Hallucination, Consistency, and Reasoning Gaps in Materials Foundation Models",
      "abstract": "Large language models are increasingly applied to materials science reasoning, yet their behavior under physically structured distribution shifts remains poorly understood. We introduce SCALAR (Structural Consistency And Logic Across Regimes), a benchmark for evaluating geometric scale generalization and its connection to structural hallucination, consistency, and reasoning in materials foundation models. Given canonical crystal representations, models must reason about derived nanoparticle structures obtained through supercell expansion and geometric truncation across length scales spanning a few atoms to over 18,000 atoms, totaling $\\approx$100,000 structures from DFT-validated unit cells. SCALAR defines three tasks. (i) CIF to property prediction. (ii) A Chain-of-Thought variant with explicit physics-grounded reasoning. (iii) Inverse retrieval identifying crystals from candidates given target properties. Outputs are evaluated via structured metrics capturing numeric error, hallucination, cross-prompt consistency, monotonic reasoning, output validity, and retrieval regret. Experiments across diverse foundation models reveal large, model-dependent shifts under explicit reasoning, often reducing hallucination and error, but frequently destabilizing consistency or validity. These results demonstrate that geometric scale generalization cannot be inferred from accuracy alone. Supplementary materials are available at https://github.com/KurbanIntelligenceLab/SCALAR.",
      "authors": [
        "Can Polat",
        "Erchin Serpedin",
        "Mustafa Kurban",
        "Hasan Kurban"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.CE"
      ],
      "published": "2026-01-29T20:52:58+00:00",
      "link": "https://arxiv.org/pdf/2601.22312v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04889v1",
      "title": "Templated Assembly Theory: An Extension of the Canonical Assembly Index with Block-Compressed Template",
      "abstract": "Assembly Theory, as developed by Cronin and co-workers, assigns to an object an assembly index: the minimal number of binary join operations required to build at least one copy of the object from a specified set of basic building blocks, allowing reuse of intermediate components. For strings over a finite alphabet, the canonical assembly index can be defined in the free semigroup with universal binary concatenation and a \"no-trash\" condition, and its exact computation has been shown to be NP-complete. In this paper we propose an extension of the canonical, string-based formulation which augments pure concatenation with templated assembly steps. Intermediate objects may contain a distinguished wildcard symbol that represents a compressible block. Templates are restricted to block-compressed substrings of the target string and can be instantiated by inserting previously assembled motifs into one or many wildcard positions, possibly in parallel. This yields a new complexity measure, the templated assembly index, which strictly generalises the canonical index while preserving its operational character. We formalise the model, clarify its relation to the canonical assembly index and to classical problems such as the smallest grammar problem, and discuss the computational complexity of determining the templated assembly index. Finally, we sketch potential applications in sequence analysis, modularity detection, and biosignature design.",
      "authors": [
        "Piotr Masierak"
      ],
      "primary_category": "cs.FL",
      "categories": [
        "cs.FL"
      ],
      "published": "2026-01-26T22:00:54+00:00",
      "link": "https://arxiv.org/pdf/2602.04889v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.06916v2",
      "title": "Active Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems",
      "abstract": "Efficient materials discovery requires reducing costly first-principles calculations for training machine-learned interatomic potentials (MLIPs). We develop an active learning (AL) framework that iteratively selects informative structures from the Materials Project and Open Quantum Materials Database (OQMD) using compositional and property-based descriptors with a neural network ensemble model. Query-by-Committee enables real-time uncertainty quantification. We compare four strategies: random sampling (baseline), uncertainty-based sampling, diversity-based sampling (k-means clustering with farthest-point refinement), and a hybrid approach. Experiments across four material systems (C, Si, Fe, and TiO2) with 5 random seeds demonstrate that diversity sampling achieves competitive or superior performance, with 10.9% improvement on TiO2. Our approach achieves equivalent accuracy with 5-13% fewer labeled samples than random baselines. The complete pipeline executes on Google Colab in under 4 hours per system using less than 8 GB RAM, democratizing MLIP development for resource-limited researchers. Open-source code and configurations are available on GitHub. This multi-system evaluation provides practical guidelines for data-efficient MLIP training and highlights integration with symmetry-aware architectures as a promising future direction.",
      "authors": [
        "Mohammed Azeez Khan",
        "Aaron D'Souza",
        "Vijay Choyal"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-11T13:52:28+00:00",
      "link": "https://arxiv.org/pdf/2601.06916v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.10362v1",
      "title": "Generalized Weight Structure of Polar Codes: Selected Template Polynomials",
      "abstract": "Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.",
      "authors": [
        "Mohammad Rowshan",
        "Vlad-Florin Dragoi"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-15T13:10:15+00:00",
      "link": "https://arxiv.org/pdf/2601.10362v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.15279v1",
      "title": "MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs",
      "abstract": "A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.",
      "authors": [
        "Christoph Bartmann",
        "Johannes Schimunek",
        "Mykyta Ielanskyi",
        "Philipp Seidl",
        "Günter Klambauer",
        "Sohvi Luukkonen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21T18:58:01+00:00",
      "link": "https://arxiv.org/pdf/2601.15279v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.00816v1",
      "title": "Hessian Spectral Analysis at Foundation Model Scale",
      "abstract": "Accurate Hessian spectra of foundation models have remained out of reach, leading most prior work to rely on small models or strong structural approximations. We show that faithful spectral analysis of the true Hessian is tractable at frontier scale. Using shard-local finite-difference Hessian vector products compatible with Fully Sharded Data Parallelism, we perform stochastic Lanczos quadrature on open-source language models with up to 100B parameters, producing the first large-scale spectral density estimates beyond the sub-10B regime. We characterize the numerical behavior of this pipeline, including finite-difference bias, floating-point noise amplification, and their effect on Krylov stability in fp32 and bf16, and derive practical operating regimes that are validated empirically. We further provide end-to-end runtime and memory scaling laws, showing that full-operator spectral probing incurs only a modest constant-factor overhead over first-order training. Crucially, direct access to the Hessian reveals that widely used block-diagonal curvature approximations can fail catastrophically, exhibiting order-one relative error and poor directional alignment even in mid-scale LLMs. Together, our results demonstrate that foundation-model Hessian spectra are both computable and qualitatively misrepresented by prevailing approximations, opening the door to principled curvature-based analysis at scale.",
      "authors": [
        "Diego Granziol",
        "Khurshid Juarev"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-31T16:57:06+00:00",
      "link": "https://arxiv.org/pdf/2602.00816v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04734v1",
      "title": "DMFlow: Disordered Materials Generation by Flow Matching",
      "abstract": "The design of materials with tailored properties is crucial for technological progress. However, most deep generative models focus exclusively on perfectly ordered crystals, neglecting the important class of disordered materials. To address this gap, we introduce DMFlow, a generative framework specifically designed for disordered crystals. Our approach introduces a unified representation for ordered, Substitutionally Disordered (SD), and Positionally Disordered (PD) crystals, and employs a flow matching model to jointly generate all structural components. A key innovation is a Riemannian flow matching framework with spherical reparameterization, which ensures physically valid disorder weights on the probability simplex. The vector field is learned by a novel Graph Neural Network (GNN) that incorporates physical symmetries and a specialized message-passing scheme. Finally, a two-stage discretization procedure converts the continuous weights into multi-hot atomic assignments. To support research in this area, we release a benchmark containing SD, PD, and mixed structures curated from the Crystallography Open Database. Experiments on Crystal Structure Prediction (CSP) and De Novo Generation (DNG) tasks demonstrate that DMFlow significantly outperforms state-of-the-art baselines adapted from ordered crystal generation. We hope our work provides a foundation for the AI-driven discovery of disordered materials.",
      "authors": [
        "Liming Wu",
        "Rui Jiao",
        "Qi Li",
        "Mingze Li",
        "Songyou Li",
        "Shifeng Jin",
        "Wenbing Huang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-04T16:36:58+00:00",
      "link": "https://arxiv.org/pdf/2602.04734v1",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.04767v1",
      "title": "Descent-restricted subsequences via RSK and evacuation",
      "abstract": "The length $\\mathsf{is}(π)$ of a longest increasing subsequence in a permutation $π$ has been extensively studied. An increasing subsequence is one that has no descents. We study generalizations of this statistic by finding longest subsequences with other descent restrictions. We first consider the statistic which encodes the longest length of a subsequence with a given number of descents. We then generalize this to restrict the descent set of the subsequence. Extending the classical result for $\\mathsf{is}(π)$, we show how these statistics can be obtained using the RSK correspondence and the Schützenberger involution. In particular, these statistics only depend on the recording tableau of the permutation.",
      "authors": [
        "Krishna Menon",
        "Anurag Singh"
      ],
      "primary_category": "math.CO",
      "categories": [
        "math.CO"
      ],
      "published": "2026-02-04T17:03:28+00:00",
      "link": "https://arxiv.org/pdf/2602.04767v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.20442v1",
      "title": "Blessing of dimensionality in cross-validated bandwidth selection on the sphere",
      "abstract": "We study the asymptotic behavior of least-squares cross-validation bandwidth selection in kernel density estimation on the $d$-dimensional hypersphere, $d\\geq 1$. We show that the exact rate of convergence with respect to the optimal bandwidth minimizing the mean integrated squared error, shown to exist under mild non-uniformity conditions, is $n^{-d/(2d+8)}$, thus approaching the $n^{-1/2}$ parametric rate as $d$ grows. This ``blessing of dimensionality'' in bandwidth selection offers theoretical support for utilizing the conceptually simpler cross-validation selector over plug-in techniques for larger dimensions $d$. We compare this result for bandwidth estimation on the $d$-dimensional Euclidean space through explicit expressions for the asymptotic variance functionals. Numerical experiments corroborate the speed of this convergence in an array of scenarios and dimensions, precisely illustrating the tipping dimension where cross-validation outperforms plug-in approaches.",
      "authors": [
        "José E. Chacón",
        "Eduardo García-Portugués",
        "Andrea Meilán-Vila"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ME"
      ],
      "published": "2026-01-28T09:53:02+00:00",
      "link": "https://arxiv.org/pdf/2601.20442v1",
      "tags": [
        "keyword:SR-LNS",
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.14598v2",
      "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation",
      "abstract": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build.   On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.",
      "authors": [
        "Yonatan Gizachew Achamyeleh",
        "Harsh Thomare",
        "Mohammad Abdullah Al Faruque"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-21T02:37:33+00:00",
      "link": "https://arxiv.org/pdf/2601.14598v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2602.03875v2",
      "title": "Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra",
      "abstract": "We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.",
      "authors": [
        "Stefan Kuhn",
        "Vandana Dwarka",
        "Przemyslaw Karol Grenda",
        "Eero Vainikko"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "published": "2026-02-01T18:48:31+00:00",
      "link": "https://arxiv.org/pdf/2602.03875v2",
      "tags": [
        "keyword:SR-RL"
      ]
    },
    {
      "id": "2601.19284v2",
      "title": "Model-Free Output Feedback Stabilization via Policy Gradient Methods",
      "abstract": "Stabilizing a dynamical system is a fundamental problem that serves as a cornerstone for many complex tasks in the field of control systems. The problem becomes challenging when the system model is unknown. Among the Reinforcement Learning (RL) algorithms that have been successfully applied to solve problems pertaining to unknown linear dynamical systems, the policy gradient (PG) method stands out due to its ease of implementation and can solve the problem in a model-free manner. However, most of the existing works on PG methods for unknown linear dynamical systems assume full-state feedback. In this paper, we take a step towards model-free learning for partially observable linear dynamical systems with output feedback and focus on the fundamental stabilization problem of the system. We propose an algorithmic framework that stretches the boundary of PG methods to the problem without global convergence guarantees. We show that by leveraging zeroth-order PG update based on system trajectories and its convergence to stationary points, the proposed algorithms return a stabilizing output feedback policy for discrete-time linear dynamical systems. We also explicitly characterize the sample complexity of our algorithm and verify the effectiveness of the algorithm using numerical examples.",
      "authors": [
        "Ankang Zhang",
        "Ming Chi",
        "Xiaoling Wang",
        "Lintao Ye"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-27T07:15:59+00:00",
      "link": "https://arxiv.org/pdf/2601.19284v2",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.17454v1",
      "title": "Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning",
      "abstract": "Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.",
      "authors": [
        "Muhammad Ahmed Atif",
        "Nehal Naeem Haji",
        "Mohammad Shahid Shaikh",
        "Muhammad Ebad Atif"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-24T13:09:01+00:00",
      "link": "https://arxiv.org/pdf/2601.17454v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18142v1",
      "title": "Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods",
      "abstract": "Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\\%, establishing superior effectiveness for Safe RL in complex environments.",
      "authors": [
        "Mingxu Zhang",
        "Huicheng Zhang",
        "Jiaming Ji",
        "Yaodong Yang",
        "Ying Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-26T04:54:57+00:00",
      "link": "https://arxiv.org/pdf/2601.18142v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.18479v1",
      "title": "Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States",
      "abstract": "Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.",
      "authors": [
        "Kyoleen Kwak",
        "Hyoseok Hwang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-26T13:34:34+00:00",
      "link": "https://arxiv.org/pdf/2601.18479v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.12008v1",
      "title": "Extreme Value Policy Optimization for Safe Reinforcement Learning",
      "abstract": "Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.",
      "authors": [
        "Shiqing Gao",
        "Yihang Zhou",
        "Shuai Shao",
        "Haoyu Luo",
        "Yiheng Bing",
        "Jiaxin Ding",
        "Luoyi Fu",
        "Xinbing Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-17T11:12:24+00:00",
      "link": "https://arxiv.org/pdf/2601.12008v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.21477v1",
      "title": "Mean-Field Control on Sparse Graphs: From Local Limits to GNNs via Neighborhood Distributions",
      "abstract": "Mean-field control (MFC) offers a scalable solution to the curse of dimensionality in multi-agent systems but traditionally hinges on the restrictive assumption of exchangeability via dense, all-to-all interactions. In this work, we bridge the gap to real-world network structures by proposing a rigorous framework for MFC on large sparse graphs. We redefine the system state as a probability measure over decorated rooted neighborhoods, effectively capturing local heterogeneity. Our central contribution is a theoretical foundation for scalable reinforcement learning in this setting. We prove horizon-dependent locality: for finite-horizon problems, an agent's optimal policy at time t depends strictly on its (T-t)-hop neighborhood. This result renders the infinite-dimensional control problem tractable and underpins a novel Dynamic Programming Principle (DPP) on the lifted space of neighborhood distributions. Furthermore, we formally and experimentally justify the use of Graph Neural Networks (GNNs) for actor-critic algorithms in this context. Our framework naturally recovers classical MFC as a degenerate case while enabling efficient, theoretically grounded control on complex sparse topologies.",
      "authors": [
        "Tobias Schmidt",
        "Kai Cui"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-01-29T09:57:48+00:00",
      "link": "https://arxiv.org/pdf/2601.21477v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.14957v1",
      "title": "Improving Regret Approximation for Unsupervised Dynamic Environment Generation",
      "abstract": "Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.",
      "authors": [
        "Harry Mead",
        "Bruno Lacerda",
        "Jakob Foerster",
        "Nick Hawes"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-21T12:58:40+00:00",
      "link": "https://arxiv.org/pdf/2601.14957v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2602.05183v1",
      "title": "Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning",
      "abstract": "Large language models (LLMs) are increasingly trained in complex Reinforcement Learning, multi-agent environments, making it difficult to understand how behavior changes over training. Sparse Autoencoders (SAEs) have recently shown to be useful for data-centric interpretability. In this work, we analyze large-scale reinforcement learning training runs from the sophisticated environment of Full-Press Diplomacy by applying pretrained SAEs, alongside LLM-summarizer methods. We introduce Meta-Autointerp, a method for grouping SAE features into interpretable hypotheses about training dynamics. We discover fine-grained behaviors including role-playing patterns, degenerate outputs, language switching, alongside high-level strategic behaviors and environment-specific bugs. Through automated evaluation, we validate that 90% of discovered SAE Meta-Features are significant, and find a surprising reward hacking behavior. However, through two user studies, we find that even subjectively interesting and seemingly helpful SAE features may be worse than useless to humans, along with most LLM generated hypotheses. However, a subset of SAE-derived hypotheses are predictively useful for downstream tasks. We further provide validation by augmenting an untrained agent's system prompt, improving the score by +14.2%. Overall, we show that SAEs and LLM-summarizer provide complementary views into agent behavior, and together our framework forms a practical starting point for future data-centric interpretability work on ensuring trustworthy LLM behavior throughout training.",
      "authors": [
        "John Yan",
        "Michael Yu",
        "Yuqi Sun",
        "Alexander Duffy",
        "Tyler Marques",
        "Matthew Lyle Olson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-05T01:21:22+00:00",
      "link": "https://arxiv.org/pdf/2602.05183v1",
      "tags": [
        "query:SR-RL"
      ]
    },
    {
      "id": "2601.08535v2",
      "title": "Distribution Estimation with Side Information",
      "abstract": "We consider the classical problem of discrete distribution estimation using i.i.d. samples in a novel scenario where additional side information is available on the distribution. In large alphabet datasets such as text corpora, such side information arises naturally through word semantics/similarities that can be inferred by closeness of vector word embeddings, for instance. We consider two specific models for side information--a local model where the unknown distribution is in the neighborhood of a known distribution, and a partial ordering model where the alphabet is partitioned into known higher and lower probability sets. In both models, we theoretically characterize the improvement in a suitable squared-error risk because of the available side information. Simulations over natural language and synthetic data illustrate these gains.",
      "authors": [
        "Haricharan Balasundaram",
        "Andrew Thangaraj"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-13T13:18:26+00:00",
      "link": "https://arxiv.org/pdf/2601.08535v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11420v1",
      "title": "Statistical Robustness of Interval CVaR Based Regression Models under Perturbation and Contamination",
      "abstract": "Robustness under perturbation and contamination is a prominent issue in statistical learning. We address the robust nonlinear regression based on the so-called interval conditional value-at-risk (In-CVaR), which is introduced to enhance robustness by trimming extreme losses. While recent literature shows that the In-CVaR based statistical learning exhibits superior robustness performance than classical robust regression models, its theoretical robustness analysis for nonlinear regression remains largely unexplored. We rigorously quantify robustness under contamination, with a unified study of distributional breakdown point for a broad class of regression models, including linear, piecewise affine and neural network models with $\\ell_1$, $\\ell_2$ and Huber losses. Moreover, we analyze the qualitative robustness of the In-CVaR based estimator under perturbation. We show that under several minor assumptions, the In-CVaR based estimator is qualitatively robust in terms of the Prokhorov metric if and only if the largest portion of losses is trimmed. Overall, this study analyzes robustness properties of In-CVaR based nonlinear regression models under both perturbation and contamination, which illustrates the advantages of In-CVaR risk measure over conditional value-at-risk and expectation for robust regression in both theory and numerical experiments.",
      "authors": [
        "Yulei You",
        "Junyi Liu"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-16T16:41:57+00:00",
      "link": "https://arxiv.org/pdf/2601.11420v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02319v1",
      "title": "Leave-One-Out Neighborhood Smoothing for Graphons: Berry-Esseen Bounds, Confidence Intervals, and Honest Tuning",
      "abstract": "Neighborhood smoothing methods achieve minimax-optimal rates for estimating edge probabilities under graphon models, but their use for statistical inference has remained limited. The main obstacle is that classical neighborhood smoothers select data-driven neighborhoods and average edges using the same adjacency matrix, inducing complex dependencies that invalidate standard concentration and normal approximation arguments.   We introduce a leave-one-out modification of neighborhood smoothing for undirected simple graphs. When estimating a single entry P_ij, the neighborhood of node i is constructed from an adjacency matrix in which the jth row and column are set to zero, thereby decoupling neighborhood selection from the edges being averaged. We show that this construction restores conditional independence of the centered summands, enabling the use of classical probabilistic tools for inference.   Under piecewise Lipschitz graphon assumptions and logarithmic degree growth, we derive variance-adaptive concentration inequalities based on Bousquet's inequality and establish Berry-Esseen bounds with explicit rates for the normalized estimation error. These results yield both finite-sample and asymptotic confidence intervals for individual edge probabilities. The same leave-one-out structure also supports an honest cross-validation scheme for tuning parameter selection, for which we prove an oracle inequality. The proposed estimator retains the optimal row-wise mean-squared error rates of classical neighborhood smoothing while providing valid entrywise uncertainty quantification.",
      "authors": [
        "Behzad Aalipur",
        "Rachel Kilby"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-02-02T16:46:56+00:00",
      "link": "https://arxiv.org/pdf/2602.02319v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.16842v1",
      "title": "Parametric Mean-Field empirical Bayes in high-dimensional linear regression",
      "abstract": "In this paper, we consider the problem of parametric empirical Bayes estimation of an i.i.d. prior in high-dimensional Bayesian linear regression, with random design. We obtain the asymptotic distribution of the variational Empirical Bayes (vEB) estimator, which approximately maximizes a variational lower bound of the intractable marginal likelihood. We characterize a sharp phase transition behavior for the vEB estimator -- namely that it is information theoretically optimal (in terms of limiting variance) up to $p=o(n^{2/3})$ while it suffers from a sub-optimal convergence rate in higher dimensions. In the first regime, i.e., when $p=o(n^{2/3})$, we show how the estimated prior can be calibrated to enable valid coordinate-wise and delocalized inference, both under the \\emph{empirical Bayes posterior} and the oracle posterior. In the second regime, we propose a debiasing technique as a way to improve the performance of the vEB estimator beyond $p=o(n^{2/3})$. Extensive numerical experiments corroborate our theoretical findings.",
      "authors": [
        "Seunghyun Lee",
        "Nabarun Deb"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-23T15:44:01+00:00",
      "link": "https://arxiv.org/pdf/2601.16842v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.01412v1",
      "title": "Importance Weighted Variational Inference without the Reparameterization Trick",
      "abstract": "Importance weighted variational inference (VI) approximates densities known up to a normalizing constant by optimizing bounds that tighten with the number of Monte Carlo samples $N$. Standard optimization relies on reparameterized gradient estimators, which are well-studied theoretically yet restrict both the choice of the data-generating process and the variational approximation. While REINFORCE gradient estimators do not suffer from such restrictions, they lack rigorous theoretical justification. In this paper, we provide the first comprehensive analysis of REINFORCE gradient estimators in importance weighted VI, leveraging this theoretical foundation to diagnose and resolve fundamental deficiencies in current state-of-the-art estimators. Specifically, we introduce and examine a generalized family of variational inference for Monte Carlo objectives (VIMCO) gradient estimators. We prove that state-of-the-art VIMCO gradient estimators exhibit a vanishing signal-to-noise ratio (SNR) as $N$ increases, which prevents effective optimization. To overcome this issue, we propose the novel VIMCO-$\\star$ gradient estimator and show that it averts the SNR collapse of existing VIMCO gradient estimators by achieving a $\\sqrt{N}$ SNR scaling instead. We demonstrate its superior empirical performance compared to current VIMCO implementations in challenging settings where reparameterized gradients are typically unavailable.",
      "authors": [
        "Kamélia Daudel",
        "Minh-Ngoc Tran",
        "Cheng Zhang"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-01T19:39:30+00:00",
      "link": "https://arxiv.org/pdf/2602.01412v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20528v1",
      "title": "Spectral Bayesian Regression on the Sphere",
      "abstract": "We develop a fully intrinsic Bayesian framework for nonparametric regression on the unit sphere based on isotropic Gaussian field priors and the harmonic structure induced by the Laplace-Beltrami operator. Under uniform random design, the regression model admits an exact diagonalization in the spherical harmonic basis, yielding a Gaussian sequence representation with frequency-dependent multiplicities.   Exploiting this structure, we derive closed-form posterior distributions, optimal spectral truncation schemes, and sharp posterior contraction rates under integrated squared loss. For Gaussian priors with polynomially decaying angular power spectra, including spherical Matérn priors, we establish posterior contraction rates over Sobolev classes, which are minimax-optimal under correct prior calibration.   We further show that the posterior mean admits an exact variational characterization as a geometrically intrinsic penalized least-squares estimator, equivalent to a Laplace-Beltrami smoothing spline.",
      "authors": [
        "Claudio Durastanti"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "math.PR",
        "stat.ML"
      ],
      "published": "2026-01-28T12:10:33+00:00",
      "link": "https://arxiv.org/pdf/2601.20528v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.00387v1",
      "title": "Singular Bayesian Neural Networks",
      "abstract": "Bayesian neural networks promise calibrated uncertainty but require $O(mn)$ parameters for standard mean-field Gaussian posteriors. We argue this cost is often unnecessary, particularly when weight matrices exhibit fast singular value decay. By parameterizing weights as $W = AB^{\\top}$ with $A \\in \\mathbb{R}^{m \\times r}$, $B \\in \\mathbb{R}^{n \\times r}$, we induce a posterior that is singular with respect to the Lebesgue measure, concentrating on the rank-$r$ manifold. This singularity captures structured weight correlations through shared latent factors, geometrically distinct from mean-field's independence assumption. We derive PAC-Bayes generalization bounds whose complexity term scales as $\\sqrt{r(m+n)}$ instead of $\\sqrt{m n}$, and prove loss bounds that decompose the error into optimization and rank-induced bias using the Eckart-Young-Mirsky theorem. We further adapt recent Gaussian complexity bounds for low-rank deterministic networks to Bayesian predictive means. Empirically, across MLPs, LSTMs, and Transformers on standard benchmarks, our method achieves predictive performance competitive with 5-member Deep Ensembles while using up to $15\\times$ fewer parameters. Furthermore, it substantially improves OOD detection and often improves calibration relative to mean-field and perturbation baselines.",
      "authors": [
        "Mame Diarra Toure",
        "David A. Stephens"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ],
      "published": "2026-01-30T23:06:34+00:00",
      "link": "https://arxiv.org/pdf/2602.00387v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.08067v1",
      "title": "Bayesian nonparametric models for zero-inflated count-compositional data using ensembles of regression trees",
      "abstract": "Count-compositional data arise in many different fields, including high-throughput microbiome sequencing and palynology experiments, where a common, important goal is to understand how covariates relate to the observed compositions. Existing methods often fail to simultaneously address key challenges inherent in such data, namely: overdispersion, an excess of zeros, cross-sample heterogeneity, and nonlinear covariate effects. To address these concerns, we propose novel Bayesian models based on ensembles of regression trees. Specifically, we leverage the recently introduced zero-and-$N$-inflated multinomial distribution and assign independent nonparametric Bayesian additive regression tree (BART) priors to both the compositional and structural zero probability components of our model, to flexibly capture covariate effects. We further extend this by adding latent random effects to capture overdispersion and more general dependence structures among the categories. We develop an efficient inferential algorithm combining recent data augmentation schemes with established BART sampling routines. We evaluate our proposed models in simulation studies and illustrate their applicability with two case studies in microbiome and palaeoclimate modelling.",
      "authors": [
        "André F. B. Menezes",
        "Andrew C. Parnell",
        "Keefe Murphy"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-12T23:22:16+00:00",
      "link": "https://arxiv.org/pdf/2601.08067v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.04490v1",
      "title": "Randomized Projection Operators onto Piecewise Polynomial Spaces",
      "abstract": "We introduce computable projection operators onto piecewise polynomial spaces, defined via sampling and discrete least-squares polynomial approximations. The resulting mappings exhibit (almost) optimal approximation properties in $L^2$ and $H^{-1}$. As smoothers for incomplete or rough data, they yield computable finite element discretizations with optimal convergence rates.",
      "authors": [
        "Johannes Storn"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-02-04T12:28:01+00:00",
      "link": "https://arxiv.org/pdf/2602.04490v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02753v1",
      "title": "Effect-Wise Inference for Smoothing Spline ANOVA on Tensor-Product Sobolev Space",
      "abstract": "Functional ANOVA provides a nonparametric modeling framework for multivariate covariates, enabling flexible estimation and interpretation of effect functions such as main effects and interaction effects. However, effect-wise inference in such models remains challenging. Existing methods focus primarily on inference for entire functions rather than individual effects. Methods addressing effect-wise inference face substantial limitations: the inability to accommodate interactions, a lack of rigorous theoretical foundations, or restriction to pointwise inference. To address these limitations, we develop a unified framework for effect-wise inference in smoothing spline ANOVA on a subspace of tensor product Sobolev space. For each effect function, we establish rates of convergence, pointwise confidence intervals, and a Wald-type test for whether the effect is zero, with power achieving the minimax distinguishable rate up to a logarithmic factor. Main effects achieve the optimal univariate rates, and interactions achieve optimal rates up to logarithmic factors. The theoretical foundation relies on an orthogonality decomposition of effect subspaces, which enables the extension of the functional Bahadur representation framework to effect-wise inference in smoothing spline ANOVA with interactions. Simulation studies and real-data application to the Colorado temperature dataset demonstrate superior performance compared to existing methods.",
      "authors": [
        "Youngjin Cho",
        "Meimei Liu"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "math.ST"
      ],
      "published": "2026-02-02T20:07:18+00:00",
      "link": "https://arxiv.org/pdf/2602.02753v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.16636v1",
      "title": "Conformal prediction for full and sparse polynomial chaos expansions",
      "abstract": "Polynomial Chaos Expansions (PCEs) are widely recognized for their efficient computational performance in surrogate modeling. Yet, a robust framework to quantify local model errors is still lacking. While the local uncertainty of PCE prediction can be captured using bootstrap resampling, other methods offering more rigorous statistical guarantees are needed, especially in the context of small training datasets. Recently, conformal predictions have demonstrated strong potential in machine learning, providing statistically robust and model-agnostic prediction intervals. Due to its generality and versatility, conformal prediction is especially valuable, as it can be adapted to suit a variety of problems, making it a compelling choice for PCE-based surrogate models. In this contribution, we explore its application to PCE-based surrogate models. More precisely, we present the integration of two conformal prediction methods, namely the full conformal and the Jackknife+ approaches, into both full and sparse PCEs. For full PCEs, we introduce computational shortcuts inspired by the inherent structure of regression methods to optimize the implementation of both conformal methods. For sparse PCEs, we incorporate the two approaches with appropriate modifications to the inference strategy, thereby circumventing the non-symmetrical nature of the regression algorithm and ensuring valid prediction intervals. Our developments yield better-calibrated prediction intervals for both full and sparse PCEs, achieving superior coverage over existing approaches, such as the bootstrap, while maintaining a moderate computational cost.",
      "authors": [
        "A. Hatstatt",
        "X. Zhu",
        "B. Sudret"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-01-23T10:46:46+00:00",
      "link": "https://arxiv.org/pdf/2601.16636v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12121v1",
      "title": "On the Hausdorff Dimension of weighted exactly Approximable Vectors",
      "abstract": "We show that the Hausdorff dimension of $\\boldsymbol w$-weighted $τ$-exactly approximable vectors in $\\mathbb R^d$ coincides with the Hausdorff dimension of $\\boldsymbol w$-weighted $τ$-approximable vectors, generalizing a result of the first named author and De Saxcé.",
      "authors": [
        "Prasuna Bandi",
        "Reynold Fregoli"
      ],
      "primary_category": "math.NT",
      "categories": [
        "math.NT"
      ],
      "published": "2026-01-17T17:45:42+00:00",
      "link": "https://arxiv.org/pdf/2601.12121v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.14013v1",
      "title": "Robustness for free: asymptotic size and power of max-tests in high dimensions",
      "abstract": "Consider testing a zero restriction on the mean of a $d$-dimensional random vector based on an i.i.d. sample of size $n$. Suppose further that the coordinates are only assumed to possess $m>2$ moments. Then, max-tests based on arithmetic means and critical values derived from Gaussian approximations are not guaranteed to be asymptotically valid unless $d$ is relatively small compared to $n$, because said approximation faces a polynomial growth barrier of $d=o(n^{m/2-1})$.   We propose a max-test based on winsorized means, and show that it holds the desired asymptotic size even when $d$ grows at an exponential rate in $n$ and the data are adversarially contaminated. Our characterization of its asymptotic power function shows that these benefits do not come at the cost of reduced asymptotic power: the robustified max-test has identical asymptotic power to that based on arithmetic means whenever the stronger assumptions underlying the latter are satisfied.   We also investigate when -- and when not -- data-driven (bootstrap) critical values can strictly increase asymptotic power of the robustified max-test.",
      "authors": [
        "Anders Bredahl Kock",
        "David Preinerstorfer"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-01-20T14:32:44+00:00",
      "link": "https://arxiv.org/pdf/2601.14013v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.17646v1",
      "title": "A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization",
      "abstract": "Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.",
      "authors": [
        "Karim Bounja",
        "Lahcen Laayouni",
        "Abdeljalil Sakat"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.FA",
        "math.OC",
        "math.ST"
      ],
      "published": "2026-01-25T01:42:44+00:00",
      "link": "https://arxiv.org/pdf/2601.17646v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12637v1",
      "title": "Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction",
      "abstract": "Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",
      "authors": [
        "Long D. Nguyen",
        "Kelin Xia",
        "Binh P. Nguyen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "published": "2026-01-19T00:54:24+00:00",
      "link": "https://arxiv.org/pdf/2601.12637v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.23252v1",
      "title": "Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference",
      "abstract": "Model comparison and calibrated uncertainty quantification often require integrating over parameters, but scalable inference can be challenging for complex, multimodal targets. Nested Sampling is a robust alternative to standard MCMC, yet its typically sequential structure and hard constraints make efficient accelerator implementations difficult. This paper introduces Nested Slice Sampling (NSS), a GPU-friendly, vectorized formulation of Nested Sampling that uses Hit-and-Run Slice Sampling for constrained updates. A tuning analysis yields a simple near-optimal rule for setting the slice width, improving high-dimensional behavior and making per-step compute more predictable for parallel execution. Experiments on challenging synthetic targets, high dimensional Bayesian inference, and Gaussian process hyperparameter marginalization show that NSS maintains accurate evidence estimates and high-quality posterior samples, and is particularly robust on difficult multimodal problems where current state-of-the-art methods such as tempered SMC baselines can struggle. An open-source implementation is released to facilitate adoption and reproducibility.",
      "authors": [
        "David Yallup",
        "Namu Kroupa",
        "Will Handley"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO",
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-30T18:20:32+00:00",
      "link": "https://arxiv.org/pdf/2601.23252v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20480v1",
      "title": "An explainable framework for the relationship between dementia and glucose metabolism patterns",
      "abstract": "High-dimensional neuroimaging data presents challenges for assessing neurodegenerative diseases due to complex non-linear relationships. Variational Autoencoders (VAEs) can encode scans into lower-dimensional latent spaces capturing disease-relevant features. We propose a semi-supervised VAE framework with a flexible similarity regularization term that aligns selected latent variables with clinical or biomarker measures of dementia progression. This allows adapting the similarity metric and supervised variables to specific goals or available data. We demonstrate the approach using PET scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI), guiding the first latent dimension to align with a cognitive score. Using this supervised latent variable, we generate average reconstructions across levels of cognitive impairment. Voxel-wise GLM analysis reveals reduced metabolism in key regions, mainly the hippocampus, and within major Resting State Networks, particularly the Default Mode and Central Executive Networks. The remaining latent variables encode affine transformations and intensity variations, capturing confounds such as inter-subject variability and site effects. Our framework effectively extracts disease-related patterns aligned with established Alzheimer's biomarkers, offering an interpretable and adaptable tool for studying neurodegenerative progression.",
      "authors": [
        "C. Vázquez-García",
        "F. J. Martínez-Murcia",
        "F. Segovia Román",
        "A. Forte",
        "J. Ramírez",
        "I. Illán",
        "A. Hernández-Segura",
        "C. Jiménez-Mesa",
        "Juan M. Górriz"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "q-bio.NC"
      ],
      "published": "2026-01-28T10:50:20+00:00",
      "link": "https://arxiv.org/pdf/2601.20480v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.10248v1",
      "title": "Restoring similarity in randomized Krylov methods with applications to eigenvalue problems and matrix functions",
      "abstract": "The randomized Arnoldi process has been used in large-scale scientific computing because it produces a well-conditioned basis for the Krylov subspace more quickly than the standard Arnoldi process. However, the resulting Hessenberg matrix is generally not similar to the one produced by the standard Arnoldi process, which can lead to delays or spike-like irregularities in convergence. In this paper, we introduce a modification of the randomized Arnoldi process that restores similarity with the Hessenberg matrix generated by the standard Arnoldi process. This is accomplished by enforcing orthogonality between the last Arnoldi vector and the previously generated subspace, which requires solving only one additional least-squares problem. When applied to eigenvalue problems and matrix function evaluations, the modified randomized Arnoldi process produces approximations that are identical to those obtained with the standard Arnoldi process. Numerical experiments demonstrate that our approach is as fast as the randomized Arnoldi process and as robust as the standard Arnoldi process.",
      "authors": [
        "Laura Grigori",
        "Daniel Kressner",
        "Nian Shao",
        "Igor Simunec"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-15T10:07:54+00:00",
      "link": "https://arxiv.org/pdf/2601.10248v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22825v1",
      "title": "Approximation of PDE solution manifolds: Sparse-grid interpolation and quadrature",
      "abstract": "We study fully-discrete approximations and quadratures of infinite-variate functions in abstract Bochner spaces associated with a Hilbert space $X$ and an infinite-tensor-product Jacobi measure. For target infinite-variate functions taking values in $X$ which admit absolutely convergent Jacobi generalized polynomial chaos expansions, with suitable weighted summability conditions for the coefficient sequences, we generalize and improve prior results on construction of sequences of finite sparse-grid tensor-product polynomial interpolation approximations and quadratures, based on the univariate Chebyshev points. For a generic stable discretization of $X$ in terms of a dense sequence $(V_m)_{m \\in \\mathbb{N}_0}$ of finite-dimensional subspaces, we obtain fully-discrete, linear approximations in terms of so-called sparse-grid tensor-product projectors, with convergence rates of approximations as well as of sparse-grid tensor-product quadratures of the target functions.   We verify the abstract assumptions in two fundamental application settings: first, a linear elliptic diffusion equation with affine-parametric coefficients and second, abstract holomorphic maps between separable Hilbert spaces with affine-parametric input data encoding. For these settings, as in [37,20], cancellation of anti-symmetric terms in ultra-spherical Jacobi generalized polynomial chaos expansion coefficients implies crucially improved convergence rates of sparse-grid tensor-product quadrature with respect to the infinite-tensor-product Jacobi weight, free from the ``curse-of-dimension\".   Largely self-contained proofs of all results are developed. Approximation convergence rate results in the present setting which are based on construction of neural network surrogates, for unbounded parameter ranges with Gaussian measures, will be developed in extensions of the present work.",
      "authors": [
        "Dinh Dũng",
        "Van Kien Nguyen",
        "Duong Thanh Pham",
        "Christoph Schwab"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-30T10:52:35+00:00",
      "link": "https://arxiv.org/pdf/2601.22825v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.00901v1",
      "title": "Efficient Bayesian Inference in Strictly Semi-parametric Linear Inverse Problems",
      "abstract": "We consider the efficient inference of finite dimensional parameters arising in the context of inverse problems. Our setup is the observation of a transformation of an unknown infinite dimensional signal $f$ corrupted by statistical noise, with the transformation $K_θ$ being linear but unknown up to a scalar $θ$. We adopt a Bayesian approach and put a prior on the pair $(θ,f)$ and prove a Bernstein-von Mises theorem for the marginal posterior of $θ$ under regularity conditions on the operators $K_θ$ and on the prior. We apply our results to the recovery of location parameters in semi-blind deconvolution problems and to the recovery of attenuation constants in X-ray tomography.",
      "authors": [
        "Adel Magra",
        "Aad van der Vaart"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "published": "2026-01-31T21:07:19+00:00",
      "link": "https://arxiv.org/pdf/2602.00901v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.07074v1",
      "title": "Robust Mean Estimation under Quantization",
      "abstract": "We consider the problem of mean estimation under quantization and adversarial corruption. We construct multivariate robust estimators that are optimal up to logarithmic factors in two different settings. The first is a one-bit setting, where each bit depends only on a single sample, and the second is a partial quantization setting, in which the estimator may use a small fraction of unquantized data.",
      "authors": [
        "Pedro Abdalla",
        "Junren Chen"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "published": "2026-01-11T21:42:46+00:00",
      "link": "https://arxiv.org/pdf/2601.07074v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.01490v1",
      "title": "Reshaping Global Loop Structure to Accelerate Local Optimization by Smoothing Rugged Landscapes",
      "abstract": "Probabilistic graphical models with frustration exhibit rugged energy landscapes that trap iterative optimization dynamics. These landscapes are shaped not only by local interactions, but crucially also by the global loop structure of the graph. The famous Bethe approximation treats the graph as a tree, effectively ignoring global structure, thereby limiting its effectiveness for optimization. Loop expansions capture such global structure in principle, but are often impractical due to combinatorial explosion. The $M$-layer construction provides an alternative: make $M$ copies of the graph and reconnect edges between them uniformly at random. This provides a controlled sequence of approximations from the original graph at $M=1$, to the Bethe approximation as $M \\rightarrow \\infty$. Here we generalize this construction by replacing uniform random rewiring with a structured mixing kernel $Q$ that sets the probability that any two layers are interconnected. As a result, the global loop structure can be shaped without modifying local interactions. We show that, after this copy-and-reconnect transformation, there exists a regime in which layer-to-layer fluctuations decay, increasing the probability of reaching the global minimum of the energy function of the original graph. This yields a highly general and practical tool for optimization. Using this approach, the computational cost required to reach these optimal solutions is reduced across sparse and dense Ising benchmarks, including spin glasses and planted instances. When combined with replica-exchange Monte Carlo, the same construction increases the polynomial-time algorithmic threshold for the maximum independent set problem. A cavity analysis shows that structured inter-layer coupling significantly smooths rugged energy landscapes by collapsing configurational complexity and suppressing many suboptimal metastable states.",
      "authors": [
        "Timothee Leleu",
        "Sam Reifenstein",
        "Atsushi Yamamura",
        "Surya Ganguli"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech"
      ],
      "published": "2026-02-01T23:57:59+00:00",
      "link": "https://arxiv.org/pdf/2602.01490v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.17180v1",
      "title": "Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging",
      "abstract": "Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.",
      "authors": [
        "Inés Gonzalez-Pepe",
        "Vinuyan Sivakolunthu",
        "Jacob Fortin",
        "Yohan Chatelain",
        "Tristan Glatard"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-23T21:13:25+00:00",
      "link": "https://arxiv.org/pdf/2601.17180v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12865v1",
      "title": "Proxy Robustness in Vision Language Models is Effortlessly Transferable",
      "abstract": "As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.",
      "authors": [
        "Xiaowei Fu",
        "Fuxiang Huang",
        "Lei Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-19T09:23:11+00:00",
      "link": "https://arxiv.org/pdf/2601.12865v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12566v1",
      "title": "Partial Identification under Stratified Randomization",
      "abstract": "This paper develops a unified framework for partial identification and inference in stratified experiments with attrition, accommodating both equal and heterogeneous treatment shares across strata. For equal-share designs, we apply recent theory for finely stratified experiments to Lee bounds, yielding closed-form, design-consistent variance estimators and properly sized confidence intervals. Simulations show that the conventional formula can overstate uncertainty, while our approach delivers tighter intervals. When treatment shares differ across strata, we propose a new strategy, which combines inverse probability weighting and global trimming to construct valid bounds even when strata are small or unbalanced. We establish identification, introduce a moment estimator, and extend existing inference results to stratified designs with heterogeneous shares, covering a broad class of moment-based estimators which includes the one we formulate. We also generalize our results to designs in which strata are defined solely by observed labels.",
      "authors": [
        "Bruno Ferman",
        "Davi Siqueira",
        "Vitor Possebom"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM",
        "math.ST",
        "stat.ME"
      ],
      "published": "2026-01-18T20:04:11+00:00",
      "link": "https://arxiv.org/pdf/2601.12566v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02944v1",
      "title": "SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation",
      "abstract": "Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.",
      "authors": [
        "OFM Riaz Rahman Aranya",
        "Kevin Desai"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-02-03T00:38:51+00:00",
      "link": "https://arxiv.org/pdf/2602.02944v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.13645v1",
      "title": "Quadratic Upper Bound for Boosting Robustness",
      "abstract": "Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.",
      "authors": [
        "Euijin You",
        "Hyang-Won Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-20T06:27:34+00:00",
      "link": "https://arxiv.org/pdf/2601.13645v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.11464v1",
      "title": "MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models",
      "abstract": "As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.",
      "authors": [
        "Xiaoran Fan",
        "Zhichao Sun",
        "Tao Ji",
        "Lixing Shen",
        "Tao Gui"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-16T17:45:34+00:00",
      "link": "https://arxiv.org/pdf/2601.11464v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.19026v1",
      "title": "Is Finer Better? The Limits of Microscaling Formats in Large Language Models",
      "abstract": "Microscaling data formats leverage per-block tensor quantization to enable aggressive model compression with limited loss in accuracy. Unlocking their potential for efficient training and inference necessitates hardware-friendly implementations that handle matrix multiplications in a native format and adopt efficient error-mitigation strategies. Herein, we report the emergence of a surprising behavior associated with microscaling quantization, whereas the output of a quantized model degrades as block size is decreased below a given threshold. This behavior clashes with the expectation that a smaller block size should allow for a better representation of the tensor elements. We investigate this phenomenon both experimentally and theoretically, decoupling the sources of quantization error behind it. Experimentally, we analyze the distributions of several Large Language Models and identify the conditions driving the anomalous behavior. Theoretically, we lay down a framework showing remarkable agreement with experimental data from pretrained model distributions and ideal ones. Overall, we show that the anomaly is driven by the interplay between narrow tensor distributions and the limited dynamic range of the quantized scales. Based on these insights, we propose the use of FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for the scales in FP4 microscaling data types. We demonstrate that UE5M3 achieves comparable performance to the conventional FP8 unsigned E4M3 scales while obviating the need of global scaling operations on weights and activations.",
      "authors": [
        "Andrea Fasoli",
        "Monodeep Kar",
        "Chi-Chun Liu",
        "Swagath Venkataramani",
        "Viji Srinivasan",
        "Leland Chang",
        "Naigang Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AR",
        "cs.CL"
      ],
      "published": "2026-01-26T23:21:24+00:00",
      "link": "https://arxiv.org/pdf/2601.19026v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.00580v1",
      "title": "Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification",
      "abstract": "The Traveling Salesman Problem (TSP) is one of the most representative NP-hard problems in route planning and a long-standing benchmark in combinatorial optimization. Traditional heuristic tour constructors, such as Farthest or Nearest Insertion, are computationally efficient and highly practical, but their deterministic behavior limits exploration and often leads to local optima. In contrast, neural-based heuristic tour constructors alleviate this issue through guided-sampling and typically achieve superior solution quality, but at the cost of extensive training and reliance on ground-truth supervision, hindering their practical use. To bridge this gap, we propose TSP-MDF, a novel instance modification framework that equips traditional deterministic heuristic tour constructors with guided-sampling capability. Specifically, TSP-MDF introduces a neural-based instance modifier that strategically shifts node coordinates to sample multiple modified instances, on which the base traditional heuristic tour constructor constructs tours that are mapped back to the original instance, allowing traditional tour constructors to explore higher-quality tours and escape local optima. At the same time, benefiting from our instance modification formulation, the neural-based instance modifier can be trained efficiently without any ground-truth supervision, ensuring the framework maintains practicality. Extensive experiments on large-scale TSP benchmarks and real-world benchmarks demonstrate that TSP-MDF significantly improves the performance of traditional heuristics tour constructors, achieving solution quality comparable to neural-based heuristic tour constructors, but with an extremely short training time.",
      "authors": [
        "Wei Huang",
        "Hanchen Wang",
        "Dong Wen",
        "Wenjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-31T07:47:48+00:00",
      "link": "https://arxiv.org/pdf/2602.00580v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.03258v1",
      "title": "Principled Federated Random Forests for Heterogeneous Data",
      "abstract": "Random Forests (RF) are among the most powerful and widely used predictive models for centralized tabular data, yet few methods exist to adapt them to the federated learning setting. Unlike most federated learning approaches, the piecewise-constant nature of RF prevents exact gradient-based optimization. As a result, existing federated RF implementations rely on unprincipled heuristics: for instance, aggregating decision trees trained independently on clients fails to optimize the global impurity criterion, even under simple distribution shifts. We propose FedForest, a new federated RF algorithm for horizontally partitioned data that naturally accommodates diverse forms of client data heterogeneity, from covariate shift to more complex outcome shift mechanisms. We prove that our splitting procedure, based on aggregating carefully chosen client statistics, closely approximates the split selected by a centralized algorithm. Moreover, FedForest allows splits on client indicators, enabling a non-parametric form of personalization that is absent from prior federated random forest methods. Empirically, we demonstrate that the resulting federated forests closely match centralized performance across heterogeneous benchmarks while remaining communication-efficient.",
      "authors": [
        "Rémi Khellaf",
        "Erwan Scornet",
        "Aurélien Bellet",
        "Julie Josse"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-02-03T08:41:59+00:00",
      "link": "https://arxiv.org/pdf/2602.03258v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.00488v2",
      "title": "OD-DEAL: Dynamic Expert-Guided Adversarial Learning with Online Decomposition for Scalable Capacitated Vehicle Routing",
      "abstract": "Solving large-scale capacitated vehicle routing problems (CVRP) is hindered by the high complexity of heuristics and the limited generalization of neural solvers on massive graphs. We propose OD-DEAL, an adversarial learning framework that tightly integrates hybrid genetic search (HGS) and online barycenter clustering (BCC) decomposition, and leverages high-fidelity knowledge distillation to transfer expert heuristic behavior. OD-DEAL trains a graph attention network (GAT)-based generative policy through a minimax game, in which divide-and-conquer strategies from a hybrid expert are distilled into dense surrogate rewards. This enables high-quality, clustering-free inference on large-scale instances. Empirical results demonstrate that OD-DEAL achieves state-of-the-art (SOTA) real-time CVRP performance, solving 10000-node instances with near-constant neural scaling. This uniquely enables the sub-second, heuristic-quality inference required for dynamic large-scale deployment.",
      "authors": [
        "Dongbin Jiao",
        "Zisheng Chen",
        "Xianyi Wang",
        "Jintao Shi",
        "Shengcai Liu",
        "Shi Yan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-31T03:16:54+00:00",
      "link": "https://arxiv.org/pdf/2602.00488v2",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.08403v1",
      "title": "Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs",
      "abstract": "Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels, a reasoning pattern rarely seen during pretraining. We introduce Owen-Shapley Policy Optimization (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. Unlike value-model-based methods requiring additional computation, OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy, learning directly from task feedback without parametric value models. By forming coalitions of semantically coherent units (phrases describing product attributes or sentences capturing preferences), OSPO identifies which response parts drive performance. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.",
      "authors": [
        "Abhijnan Nath",
        "Alireza Bagheri Garakani",
        "Tianchen Zhou",
        "Fan Yang",
        "Nikhil Krishnaswamy"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-13T10:17:46+00:00",
      "link": "https://arxiv.org/pdf/2601.08403v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.15552v1",
      "title": "BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations",
      "abstract": "We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.",
      "authors": [
        "Phuc Nguyen",
        "Benjamin Zelditch",
        "Joyce Chen",
        "Rohit Patra",
        "Changshuai Wei"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-22T00:48:45+00:00",
      "link": "https://arxiv.org/pdf/2601.15552v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09166v1",
      "title": "DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix",
      "abstract": "Differentially private federated learning (DP-FL) suffers from slow convergence under tight privacy budgets due to the overwhelming noise introduced to preserve privacy. While adaptive optimizers can accelerate convergence, existing second-order methods such as DP-FedNew require O(d^2) memory at each client to maintain local feature covariance matrices, making them impractical for high-dimensional models. We propose DP-FedSOFIM, a server-side second-order optimization framework that leverages the Fisher Information Matrix (FIM) as a natural gradient preconditioner while requiring only O(d) memory per client. By employing the Sherman-Morrison formula for efficient matrix inversion, DP-FedSOFIM achieves O(d) computational complexity per round while maintaining the convergence benefits of second-order methods. Our analysis proves that the server-side preconditioning preserves (epsilon, delta)-differential privacy through the post-processing theorem. Empirical evaluation on CIFAR-10 demonstrates that DP-FedSOFIM achieves superior test accuracy compared to first-order baselines across multiple privacy regimes.",
      "authors": [
        "Sidhant R. Nair",
        "Tanmay Sen",
        "Mrinmay Sen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.DC"
      ],
      "published": "2026-01-14T05:11:28+00:00",
      "link": "https://arxiv.org/pdf/2601.09166v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.01485v1",
      "title": "Predicting and improving test-time scaling laws via reward tail-guided search",
      "abstract": "Test-time scaling has emerged as a critical avenue for enhancing the reasoning capabilities of Large Language Models (LLMs). Though the straight-forward ''best-of-$N$'' (BoN) strategy has already demonstrated significant improvements in performance, it lacks principled guidance on the choice of $N$, budget allocation, and multi-stage decision-making, thereby leaving substantial room for optimization. While many works have explored such optimization, rigorous theoretical guarantees remain limited. In this work, we propose new methodologies to predict and improve scaling properties via tail-guided search. By estimating the tail distribution of rewards, our method predicts the scaling law of LLMs without the need for exhaustive evaluations. Leveraging this prediction tool, we introduce Scaling-Law Guided (SLG) Search, a new test-time algorithm that dynamically allocates compute to identify and exploit intermediate states with the highest predicted potential. We theoretically prove that SLG achieves vanishing regret compared to perfect-information oracles, and achieves expected rewards that would otherwise require a polynomially larger compute budget required when using BoN. Empirically, we validate our framework across different LLMs and reward models, confirming that tail-guided allocation consistently achieves higher reward yields than Best-of-$N$ under identical compute budgets. Our code is available at https://github.com/PotatoJnny/Scaling-Law-Guided-search.",
      "authors": [
        "Muheng Li",
        "Jian Qian",
        "Wenlong Mou"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-01T23:40:25+00:00",
      "link": "https://arxiv.org/pdf/2602.01485v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12400v1",
      "title": "BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training",
      "abstract": "Slow and costly communication is often the main bottleneck in distributed optimization, especially in federated learning where it occurs over wireless networks. We introduce BiCoLoR, a communication-efficient optimization algorithm that combines two widely used and effective strategies: local training, which increases computation between communication rounds, and compression, which encodes high-dimensional vectors into short bitstreams. While these mechanisms have been combined before, compression has typically been applied only to uplink (client-to-server) communication, leaving the downlink (server-to-client) side unaddressed. In practice, however, both directions are costly. We propose BiCoLoR, the first algorithm to combine local training with bidirectional compression using arbitrary unbiased compressors. This joint design achieves accelerated complexity guarantees in both convex and strongly convex heterogeneous settings. Empirically, BiCoLoR outperforms existing algorithms and establishes a new standard in communication efficiency.",
      "authors": [
        "Laurent Condat",
        "Artavazd Maranjyan",
        "Peter Richtárik"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-18T13:23:27+00:00",
      "link": "https://arxiv.org/pdf/2601.12400v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.19395v2",
      "title": "SEAFormer: A Spatial Proximity and Edge-Aware Transformer for Real-World Vehicle Routing Problems",
      "abstract": "Real-world Vehicle Routing Problems (RWVRPs) require solving complex, sequence-dependent challenges at scale with constraints such as delivery time window, replenishment or recharging stops, asymmetric travel cost, etc. While recent neural methods achieve strong results on large-scale classical VRP benchmarks, they struggle to address RWVRPs because their strategies overlook sequence dependencies and underutilize edge-level information, which are precisely the characteristics that define the complexity of RWVRPs. We present SEAFormer, a novel transformer that incorporates both node-level and edge-level information in decision-making through two key innovations. First, our Clustered Proximity Attention (CPA) exploits locality-aware clustering to reduce the complexity of attention from $O(n^2)$ to $O(n)$ while preserving global perspective, allowing SEAFormer to efficiently train on large instances. Second, our lightweight edge-aware module captures pairwise features through residual fusion, enabling effective incorporation of edge-based information and faster convergence. Extensive experiments across four RWVRP variants with various scales demonstrate that SEAFormer achieves superior results over state-of-the-art methods. Notably, SEAFormer is the first neural method to solve 1,000+ node RWVRPs effectively, while also achieving superior performance on classic VRPs, making it a versatile solution for both research benchmarks and real-world applications.",
      "authors": [
        "Saeed Nasehi Basharzad",
        "Farhana Choudhury",
        "Egemen Tanin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T09:27:02+00:00",
      "link": "https://arxiv.org/pdf/2601.19395v2",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.03357v1",
      "title": "Achieving Linear Speedup for Composite Federated Learning",
      "abstract": "This paper proposes FedNMap, a normal map-based method for composite federated learning, where the objective consists of a smooth loss and a possibly nonsmooth regularizer. FedNMap leverages a normal map-based update scheme to handle the nonsmooth term and incorporates a local correction strategy to mitigate the impact of data heterogeneity across clients. Under standard assumptions, including smooth local losses, weak convexity of the regularizer, and bounded stochastic gradient variance, FedNMap achieves linear speedup with respect to both the number of clients $n$ and the number of local updates $Q$ for nonconvex losses, both with and without the Polyak-Łojasiewicz (PL) condition. To our knowledge, this is the first result establishing linear speedup for nonconvex composite federated learning.",
      "authors": [
        "Kun Huang",
        "Shi Pu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-03T10:29:34+00:00",
      "link": "https://arxiv.org/pdf/2602.03357v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.14615v1",
      "title": "SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation",
      "abstract": "Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents.",
      "authors": [
        "Xichen Zhang",
        "Ziyi He",
        "Yinghao Zhu",
        "Sitong Wu",
        "Shaozuo Yu",
        "Meng Chu",
        "Wenhu Zhang",
        "Haoru Tan",
        "Jiaya Jia"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-21T03:16:17+00:00",
      "link": "https://arxiv.org/pdf/2601.14615v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.03304v1",
      "title": "To Search or Not to Search: Aligning the Decision Boundary of Deep Search Agents via Causal Intervention",
      "abstract": "Deep search agents, which autonomously iterate through multi-turn web-based reasoning, represent a promising paradigm for complex information-seeking tasks. However, current agents suffer from critical inefficiency: they conduct excessive searches as they cannot accurately judge when to stop searching and start answering. This stems from outcome-centric training that prioritize final results over the search process itself. We identify the root cause as misaligned decision boundaries, the threshold determining when accumulated information suffices to answer. This causes over-search (redundant searching despite sufficient knowledge) and under-search (premature termination yielding incorrect answers). To address these errors, we propose a comprehensive framework comprising two key components. First, we introduce causal intervention-based diagnosis that identifies boundary errors by comparing factual and counterfactual trajectories at each decision point. Second, we develop Decision Boundary Alignment for Deep Search agents (DAS), which constructs preference datasets from causal feedback and aligns policies via preference optimization. Experiments on public datasets demonstrate that decision boundary errors are pervasive across state-of-the-art agents. Our DAS method effectively calibrates these boundaries, mitigating both over-search and under-search to achieve substantial gains in accuracy and efficiency. Our code and data are publicly available at: https://github.com/Applied-Machine-Learning-Lab/WWW2026_DAS.",
      "authors": [
        "Wenlin Zhang",
        "Kuicai Dong",
        "Junyi Li",
        "Yingyi Zhang",
        "Xiaopeng Li",
        "Pengyue Jia",
        "Yi Wen",
        "Derong Xu",
        "Maolin Wang",
        "Yichao Wang",
        "Yong Liu",
        "Xiangyu Zhao"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-02-03T09:29:06+00:00",
      "link": "https://arxiv.org/pdf/2602.03304v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.12027v1",
      "title": "Generalizing the Fano inequality further",
      "abstract": "Interactive statistical decision making (ISDM) features algorithm-dependent data generated through interaction. Existing information-theoretic lower bounds in ISDM largely target expected risk, while tail-sensitive objectives are less developed. We generalize the interactive Fano framework of Chen et al. by replacing the hard success event with a randomized one-bit statistic representing an arbitrary bounded transform of the loss. This yields a Bernoulli f-divergence inequality, which we invert to obtain a two-sided interval for the transform, recovering the previous result as a special case. Instantiating the transform with a bounded hinge and using the Rockafellar-Uryasev representation, we derive lower bounds on the prior-predictive (Bayesian) CVaR of bounded losses. For KL divergence with the mixture reference distribution, the bound becomes explicit in terms of mutual information via Pinsker's inequality.",
      "authors": [
        "Raghav Bongole",
        "Tobias J. Oechtering",
        "Mikael Skoglund"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-17T12:11:11+00:00",
      "link": "https://arxiv.org/pdf/2601.12027v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.08216v1",
      "title": "One-Shot Federated Ridge Regression: Exact Recovery via Sufficient Statistic Aggregation",
      "abstract": "Federated learning protocols require repeated synchronization between clients and a central server, with convergence rates depending on learning rates, data heterogeneity, and client sampling. This paper asks whether iterative communication is necessary for distributed linear regression. We show it is not. We formulate federated ridge regression as a distributed equilibrium problem where each client computes local sufficient statistics -- the Gram matrix and moment vector -- and transmits them once. The server reconstructs the global solution through a single matrix inversion. We prove exact recovery: under a coverage condition on client feature matrices, one-shot aggregation yields the centralized ridge solution, not an approximation. For heterogeneous distributions violating coverage, we derive non-asymptotic error bounds depending on spectral properties of the aggregated Gram matrix. Communication reduces from $\\mathcal{O}(Rd)$ in iterative methods to $\\mathcal{O}(d^2)$ total; for high-dimensional settings, we propose and experimentally validate random projection techniques reducing this to $\\mathcal{O}(m^2)$ where $m \\ll d$. We establish differential privacy guarantees where noise is injected once per client, eliminating the composition penalty that degrades privacy in multi-round protocols. We further address practical considerations including client dropout robustness, federated cross-validation for hyperparameter selection, and comparison with gradient-based alternatives. Comprehensive experiments on synthetic heterogeneous regression demonstrate that one-shot fusion matches FedAvg accuracy while requiring up to $38\\times$ less communication. The framework applies to kernel methods and random feature models but not to general nonlinear architectures.",
      "authors": [
        "Zahir Alsulaimawi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "published": "2026-01-13T04:47:22+00:00",
      "link": "https://arxiv.org/pdf/2601.08216v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02080v1",
      "title": "Learning Half-Spaces from Perturbed Contrastive Examples",
      "abstract": "We study learning under a two-step contrastive example oracle, as introduced by Mansouri et. al. (2025), where each queried (or sampled) labeled example is paired with an additional contrastive example of opposite label. While Mansouri et al. assume an idealized setting, where the contrastive example is at minimum distance of the originally queried/sampled point, we introduce and analyze a mechanism, parameterized by a non-decreasing noise function $f$, under which this ideal contrastive example is perturbed. The amount of perturbation is controlled by $f(d)$, where $d$ is the distance of the queried/sampled point to the decision boundary. Intuitively, this results in higher-quality contrastive examples for points closer to the decision boundary. We study this model in two settings: (i) when the maximum perturbation magnitude is fixed, and (ii) when it is stochastic.   For one-dimensional thresholds and for half-spaces under the uniform distribution on a bounded domain, we characterize active and passive contrastive sample complexity in dependence on the function $f$. We show that, under certain conditions on $f$, the presence of contrastive examples speeds up learning in terms of asymptotic query complexity and asymptotic expected query complexity.",
      "authors": [
        "Aryan Alavi Razavi Ravari",
        "Farnam Mansouri",
        "Yuxin Chen",
        "Valentio Iverson",
        "Adish Singla",
        "Sandra Zilles"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-02T13:27:23+00:00",
      "link": "https://arxiv.org/pdf/2602.02080v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.14991v1",
      "title": "Consistency of Honest Decision Trees and Random Forests",
      "abstract": "We study various types of consistency of honest decision trees and random forests in the regression setting. In contrast to related literature, our proofs are elementary and follow the classical arguments used for smoothing methods. Under mild regularity conditions on the regression function and data distribution, we establish weak and almost sure convergence of honest trees and honest forest averages to the true regression function, and moreover we obtain uniform convergence over compact covariate domains. The framework naturally accommodates ensemble variants based on subsampling and also a two-stage bootstrap sampling scheme. Our treatment synthesizes and simplifies existing analyses, in particular recovering several results as special cases. The elementary nature of the arguments clarifies the close relationship between data-adaptive partitioning and kernel-type methods, providing an accessible approach to understanding the asymptotic behavior of tree-based methods.",
      "authors": [
        "Martin Bladt",
        "Rasmus Frigaard Lemvig"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "published": "2026-01-21T13:40:36+00:00",
      "link": "https://arxiv.org/pdf/2601.14991v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21200v2",
      "title": "Provably Reliable Classifier Guidance via Cross-Entropy Control",
      "abstract": "Classifier-guided diffusion models generate conditional samples by augmenting the reverse-time score with the gradient of the log-probability predicted by a probabilistic classifier. In practice, this classifier is usually obtained by minimizing an empirical loss function. While existing statistical theory guarantees good generalization performance when the sample size is sufficiently large, it remains unclear whether such training yields an effective guidance mechanism.   We study this question in the context of cross-entropy loss, which is widely used for classifier training. Under mild smoothness assumptions on the classifier, we show that controlling the cross-entropy at each diffusion model step is sufficient to control the corresponding guidance error. In particular, probabilistic classifiers achieving conditional KL divergence $\\varepsilon^2$ induce guidance vectors with mean squared error $\\widetilde O(d \\varepsilon )$, up to constant and logarithmic factors. Our result yields an upper bound on the sampling error of classifier-guided diffusion models and bears resemblance to a reverse log-Sobolev--type inequality. To the best of our knowledge, this is the first result that quantitatively links classifier training to guidance alignment in diffusion models, providing both a theoretical explanation for the empirical success of classifier guidance, and principled guidelines for selecting classifiers that induce effective guidance.",
      "authors": [
        "Sharan Sahu",
        "Arisina Banerjee",
        "Yuchen Wu"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "published": "2026-01-29T02:59:04+00:00",
      "link": "https://arxiv.org/pdf/2601.21200v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22899v1",
      "title": "Uncertainty-Aware Extrapolation in Bayesian Oblique Trees",
      "abstract": "Decision trees are widely used due to their interpretability and efficiency, but they struggle in regression tasks that require reliable extrapolation and well-calibrated uncertainty. Piecewise-constant leaf predictions are bounded by the training targets and often become overconfident under distribution shift. We propose a single-tree Bayesian model that extends VSPYCT by equipping each leaf with a GP predictor. Bayesian oblique splits provide uncertainty-aware partitioning of the input space, while GP leaves model local functional behaviour and enable principled extrapolation beyond the observed target range. We present an efficient inference and prediction scheme that combines posterior sampling of split parameters with \\gls{gp} posterior predictions, and a gating mechanism that activates GP-based extrapolation when inputs fall outside the training support of a leaf. Experiments on benchmark regression tasks show improvements in the predictive performance compared to standard variational oblique trees, and substantial performance gains in extrapolation scenarios.",
      "authors": [
        "Viktor Andonovikj",
        "Sašo Džeroski",
        "Pavle Boškoski"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T12:19:17+00:00",
      "link": "https://arxiv.org/pdf/2601.22899v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.02057v1",
      "title": "QVCache: A Query-Aware Vector Cache",
      "abstract": "Vector databases have become a cornerstone of modern information retrieval, powering applications in recommendation, search, and retrieval-augmented generation (RAG) pipelines. However, scaling approximate nearest neighbor (ANN) search to high recall under strict latency SLOs remains fundamentally constrained by memory capacity and I/O bandwidth. Disk-based vector search systems suffer severe latency degradation at high accuracy, while fully in-memory solutions incur prohibitive memory costs at billion-scale. Despite the central role of caching in traditional databases, vector search lacks a general query-level caching layer capable of amortizing repeated query work.   We present QVCache, the first backend-agnostic, query-level caching system for ANN search with bounded memory footprint. QVCache exploits semantic query repetition by performing similarity-aware caching rather than exact-match lookup. It dynamically learns region-specific distance thresholds using an online learning algorithm, enabling recall-preserving cache hits while bounding lookup latency and memory usage independently of dataset size. QVCache operates as a drop-in layer for existing vector databases. It maintains a megabyte-scale memory footprint and achieves sub-millisecond cache-hit latency, reducing end-to-end query latency by up to 40-1000x when integrated with existing ANN systems. For workloads exhibiting temporal-semantic locality, QVCache substantially reduces latency while preserving recall comparable to the underlying ANN backend, establishing it as a missing but essential caching layer for scalable vector search.",
      "authors": [
        "Anıl Eren Göçer",
        "Ioanna Tsakalidou",
        "Hamish Nicholson",
        "Kyoungmin Kim",
        "Anastasia Ailamaki"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-02-02T12:58:43+00:00",
      "link": "https://arxiv.org/pdf/2602.02057v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.23207v1",
      "title": "Learning to Execute Graph Algorithms Exactly with Graph Neural Networks",
      "abstract": "Understanding what graph neural networks can learn, especially their ability to learn to execute algorithms, remains a central theoretical challenge. In this work, we prove exact learnability results for graph algorithms under bounded-degree and finite-precision constraints. Our approach follows a two-step process. First, we train an ensemble of multi-layer perceptrons (MLPs) to execute the local instructions of a single node. Second, during inference, we use the trained MLP ensemble as the update function within a graph neural network (GNN). Leveraging Neural Tangent Kernel (NTK) theory, we show that local instructions can be learned from a small training set, enabling the complete graph algorithm to be executed during inference without error and with high probability. To illustrate the learning power of our setting, we establish a rigorous learnability result for the LOCAL model of distributed computation. We further demonstrate positive learnability results for widely studied algorithms such as message flooding, breadth-first and depth-first search, and Bellman-Ford.",
      "authors": [
        "Muhammad Fetrat Qharabagh",
        "Artur Back de Luca",
        "George Giapitzakis",
        "Kimon Fountoulakis"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T17:31:26+00:00",
      "link": "https://arxiv.org/pdf/2601.23207v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.21731v1",
      "title": "Amortized Spectral Kernel Discovery via Prior-Data Fitted Network",
      "abstract": "Prior-Data Fitted Networks (PFNs) enable efficient amortized inference but lack transparent access to their learned priors and kernels. This opacity hinders their use in downstream tasks, such as surrogate-based optimization, that require explicit covariance models. We introduce an interpretability-driven framework for amortized spectral discovery from pre-trained PFNs with decoupled attention. We perform a mechanistic analysis on a trained PFN that identifies attention latent output as the key intermediary, linking observed function data to spectral structure. Building on this insight, we propose decoder architectures that map PFN latents to explicit spectral density estimates and corresponding stationary kernels via Bochner's theorem. We study this pipeline in both single-realization and multi-realization regimes, contextualizing theoretical limits on spectral identifiability and proving consistency when multiple function samples are available. Empirically, the proposed decoders recover complex multi-peak spectral mixtures and produce explicit kernels that support Gaussian process regression with accuracy comparable to PFNs and optimization-based baselines, while requiring only a single forward pass. This yields orders-of-magnitude reductions in inference time compared to optimization-based baselines.",
      "authors": [
        "Kaustubh Sharma",
        "Srijan Tiwari",
        "Ojasva Nema",
        "Parikshit Pareek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T13:51:26+00:00",
      "link": "https://arxiv.org/pdf/2601.21731v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.18917v1",
      "title": "GraIP: A Benchmarking Framework For Neural Graph Inverse Problems",
      "abstract": "A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.",
      "authors": [
        "Semih Cantürk",
        "Andrei Manolache",
        "Arman Mielke",
        "Chendi Qian",
        "Antoine Siraudin",
        "Christopher Morris",
        "Mathias Niepert",
        "Guy Wolf"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-26T19:28:16+00:00",
      "link": "https://arxiv.org/pdf/2601.18917v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22274v1",
      "title": "Task-Uniform Convergence and Backward Transfer in Federated Domain-Incremental Learning with Partial Participation",
      "abstract": "Real-world federated systems seldom operate on static data: input distributions drift while privacy rules forbid raw-data sharing. We study this setting as Federated Domain-Incremental Learning (FDIL), where (i) clients are heterogeneous, (ii) tasks arrive sequentially with shifting domains, yet (iii) the label space remains fixed. Two theoretical pillars remain missing for FDIL under realistic deployment: a guarantee of backward knowledge transfer (BKT) and a convergence rate that holds across the sequence of all tasks with partial participation. We introduce SPECIAL (Server-Proximal Efficient Continual Aggregation for Learning), a simple, memory-free FDIL algorithm that adds a single server-side ``anchor'' to vanilla FedAvg: in each round, the server nudges the uniformly sampled participated clients update toward the previous global model with a lightweight proximal term. This anchor curbs cumulative drift without replay buffers, synthetic data, or task-specific heads, keeping communication and model size unchanged. Our theory shows that SPECIAL (i) preserves earlier tasks: a BKT bound caps any increase in prior-task loss by a drift-controlled term that shrinks with more rounds, local epochs, and participating clients; and (ii) learns efficiently across all tasks: the first communication-efficient non-convex convergence rate for FDIL with partial participation, O((E/NT)^(1/2)), with E local epochs, T communication rounds, and N participated clients per round, matching single-task FedAvg while explicitly separating optimization variance from inter-task drift. Experimental results further demonstrate the effectiveness of SPECIAL.",
      "authors": [
        "Longtao Xu",
        "Jian Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T19:44:15+00:00",
      "link": "https://arxiv.org/pdf/2601.22274v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.03329v1",
      "title": "From Inexact Gradients to Byzantine Robustness: Acceleration and Optimization under Similarity",
      "abstract": "Standard federated learning algorithms are vulnerable to adversarial nodes, a.k.a. Byzantine failures. To solve this issue, robust distributed learning algorithms have been developed, which typically replace parameter averaging by robust aggregations. While generic conditions on these aggregations exist to guarantee the convergence of (Stochastic) Gradient Descent (SGD), the analyses remain rather ad-hoc. This hinders the development of more complex robust algorithms, such as accelerated ones. In this work, we show that Byzantine-robust distributed optimization can, under standard generic assumptions, be cast as a general optimization with inexact gradient oracles (with both additive and multiplicative error terms), an active field of research.   This allows for instance to directly show that GD on top of standard robust aggregation procedures obtains optimal asymptotic error in the Byzantine setting. Going further, we propose two optimization schemes to speed up the convergence. The first one is a Nesterov-type accelerated scheme whose proof directly derives from accelerated inexact gradient results applied to our formulation. The second one hinges on Optimization under Similarity, in which the server leverages an auxiliary loss function that approximates the global loss. Both approaches allow to drastically reduce the communication complexity compared to previous methods, as we show theoretically and empirically.",
      "authors": [
        "Renaud Gaucher",
        "Aymeric Dieuleveut",
        "Hadrien Hendrikx"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "published": "2026-02-03T09:56:23+00:00",
      "link": "https://arxiv.org/pdf/2602.03329v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.03647v1",
      "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
      "abstract": "Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy, proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.",
      "authors": [
        "Bowei He",
        "Minda Hu",
        "Zenan Xu",
        "Hongru Wang",
        "Licheng Zong",
        "Yankai Chen",
        "Chen Ma",
        "Xue Liu",
        "Pluto Zhou",
        "Irwin King"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-03T15:32:09+00:00",
      "link": "https://arxiv.org/pdf/2602.03647v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.21608v1",
      "title": "Search-Based Risk Feature Discovery in Document Structure Spaces under a Constrained Budget",
      "abstract": "Enterprise-grade Intelligent Document Processing (IDP) systems support high-stakes workflows across finance, insurance, and healthcare. Early-phase system validation under limited budgets mandates uncovering diverse failure mechanisms, rather than identifying a single worst-case document. We formalize this challenge as a Search-Based Software Testing (SBST) problem, aiming to identify complex interactions between document variables, with the objective to maximize the number of distinct failure types discovered within a fixed evaluation budget. Our methodology operates on a combinatorial space of document configurations, rendering instances of structural \\emph{risk features} to induce realistic failure conditions. We benchmark a diverse portfolio of search strategies spanning evolutionary, swarm-based, quality-diversity, learning-based, and quantum under identical budget constraints. Through configuration-level exclusivity, win-rate, and cross-temporal overlap analyses, we show that different solvers consistently uncover failure modes that remain undiscovered by specific alternatives at comparable budgets. Crucially, cross-temporal analysis reveals persistent solver-specific discoveries across all evaluated budgets, with no single strategy exhibiting absolute dominance. While the union of all solvers eventually recovers the observed failure space, reliance on any individual method systematically delays the discovery of important risks. These results demonstrate intrinsic solver complementarity and motivate portfolio-based SBST strategies for robust industrial IDP validation.",
      "authors": [
        "Saisubramaniam Gopalakrishnan",
        "Harikrishnan P M",
        "Dagnachew Birru"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-29T12:14:18+00:00",
      "link": "https://arxiv.org/pdf/2601.21608v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.18608v1",
      "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
      "abstract": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.   In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.   Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.",
      "authors": [
        "Fabian Fumagalli",
        "R. Teal Witter",
        "Christopher Musco"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-26T15:47:45+00:00",
      "link": "https://arxiv.org/pdf/2601.18608v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.22323v1",
      "title": "Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning",
      "abstract": "Model routing chooses which language model to use for each query. By sending easy queries to cheaper models and hard queries to stronger ones, it can significantly reduce inference cost while maintaining high accuracy. However, most existing routers treat this as a fixed choice among a small set of models, which makes them hard to adapt to new models or changing budget constraints. In this paper, we propose SCOPE (Scalable and Controllable Outcome Performance Estimator), a routing framework that goes beyond model selection by predicting their cost and performance. Trained with reinforcement learning, SCOPE makes reasoning-based predictions by retrieving how models behave on similar problems, rather than relying on fixed model names, enabling it to work with new, unseen models. Moreover, by explicitly predicting how accurate and how expensive a model will be, it turns routing into a dynamic decision problem, allowing users to easily control the trade-off between accuracy and cost. Experiments show that SCOPE is more than just a cost-saving tool. It flexibly adapts to user needs: it can boost accuracy by up to 25.7% when performance is the priority, or cut costs by up to 95.1% when efficiency matters most.",
      "authors": [
        "Qi Cao",
        "Shuhao Zhang",
        "Ruizhe Zhou",
        "Ruiyi Zhang",
        "Peijia Qin",
        "Pengtao Xie"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-29T21:09:36+00:00",
      "link": "https://arxiv.org/pdf/2601.22323v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.03719v1",
      "title": "Training Multi-Turn Search Agent via Contrastive Dynamic Branch Sampling",
      "abstract": "Agentic reinforcement learning has enabled large language models to perform complex multi-turn planning and tool use. However, learning in long-horizon settings remains challenging due to sparse, trajectory-level outcome rewards. While prior tree-based methods attempt to mitigate this issue, they often suffer from high variance and computational inefficiency. Through empirical analysis of search agents, We identify a common pattern: performance diverges mainly due to decisions near the tail. Motivated by this observation, we propose Branching Relative Policy Optimization (BranPO), a value-free method that provides step-level contrastive supervision without dense rewards. BranPO truncates trajectories near the tail and resamples alternative continuations to construct contrastive suffixes over shared prefixes, reducing credit ambiguity in long-horizon rollouts. To further boost efficiency and stabilize training, we introduce difficulty-aware branch sampling to adapt branching frequency across tasks, and redundant step masking to suppress uninformative actions. Extensive experiments on various question answering benchmarks demonstrate that BranPO consistently outperforms strong baselines, achieving significant accuracy gains on long-horizon tasks without increasing the overall training budget. Our code is available at \\href{https://github.com/YubaoZhao/BranPO}{code}.",
      "authors": [
        "Yubao Zhao",
        "Weiquan Huang",
        "Sudong Wang",
        "Ruochen Zhao",
        "Chen Chen",
        "Yao Shu",
        "Chengwei Qin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-03T16:43:09+00:00",
      "link": "https://arxiv.org/pdf/2602.03719v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.05036v1",
      "title": "Feedback Control for Multi-Objective Graph Self-Supervision",
      "abstract": "Can multi-task self-supervised learning on graphs be coordinated without the usual tug-of-war between objectives? Graph self-supervised learning (SSL) offers a growing toolbox of pretext objectives: mutual information, reconstruction, contrastive learning; yet combining them reliably remains a challenge due to objective interference and training instability. Most multi-pretext pipelines use per-update mixing, forcing every parameter update to be a compromise, leading to three failure modes: Disagreement (conflict-induced negative transfer), Drift (nonstationary objective utility), and Drought (hidden starvation of underserved objectives). We argue that coordination is fundamentally a temporal allocation problem: deciding when each objective receives optimization budget, not merely how to weigh them. We introduce ControlG, a control-theoretic framework that recasts multi-objective graph SSL as feedback-controlled temporal allocation by estimating per-objective difficulty and pairwise antagonism, planning target budgets via a Pareto-aware log-hypervolume planner, and scheduling with a Proportional-Integral-Derivative (PID) controller. Across 9 datasets, ControlG consistently outperforms state-of-the-art baselines, while producing an auditable schedule that reveals which objectives drove learning.",
      "authors": [
        "Karish Grover",
        "Theodore Vasiloudis",
        "Han Xie",
        "Sixing Lu",
        "Xiang Song",
        "Christos Faloutsos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T20:42:10+00:00",
      "link": "https://arxiv.org/pdf/2602.05036v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09515v1",
      "title": "SERM: Self-Evolving Relevance Model with Agent-Driven Learning from Massive Query Streams",
      "abstract": "Due to the dynamically evolving nature of real-world query streams, relevance models struggle to generalize to practical search scenarios. A sophisticated solution is self-evolution techniques. However, in large-scale industrial settings with massive query streams, this technique faces two challenges: (1) informative samples are often sparse and difficult to identify, and (2) pseudo-labels generated by the current model could be unreliable. To address these challenges, in this work, we propose a Self-Evolving Relevance Model approach (SERM), which comprises two complementary multi-agent modules: a multi-agent sample miner, designed to detect distributional shifts and identify informative training samples, and a multi-agent relevance annotator, which provides reliable labels through a two-level agreement framework. We evaluate SERM in a large-scale industrial setting, which serves billions of user requests daily. Experimental results demonstrate that SERM can achieve significant performance gains through iterative self-evolution, as validated by extensive offline multilingual evaluations and online testing.",
      "authors": [
        "Chenglong Wang",
        "Canjia Li",
        "Xingzhao Zhu",
        "Yifu Huo",
        "Huiyu Wang",
        "Weixiong Lin",
        "Yun Yang",
        "Qiaozhi He",
        "Tianhua Zhou",
        "Xiaojia Chang",
        "Jingbo Zhu",
        "Tong Xiao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-14T14:31:16+00:00",
      "link": "https://arxiv.org/pdf/2601.09515v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21615v1",
      "title": "Beyond Parameter Finetuning: Test-Time Representation Refinement for Node Classification",
      "abstract": "Graph Neural Networks frequently exhibit significant performance degradation in the out-of-distribution test scenario. While test-time training (TTT) offers a promising solution, existing Parameter Finetuning (PaFT) paradigm suffer from catastrophic forgetting, hindering their real-world applicability. We propose TTReFT, a novel Test-Time Representation FineTuning framework that transitions the adaptation target from model parameters to latent representations. Specifically, TTReFT achieves this through three key innovations: (1) uncertainty-guided node selection for specific interventions, (2) low-rank representation interventions that preserve pre-trained knowledge, and (3) an intervention-aware masked autoencoder that dynamically adjust masking strategy to accommodate the node selection scheme. Theoretically, we establish guarantees for TTReFT in OOD settings. Empirically, extensive experiments across five benchmark datasets demonstrate that TTReFT achieves consistent and superior performance. Our work establishes representation finetuning as a new paradigm for graph TTT, offering both theoretical grounding and immediate practical utility for real-world deployment.",
      "authors": [
        "Jiaxin Zhang",
        "Yiqi Wang",
        "Siwei Wang",
        "Xihong Yang",
        "Yu Shi",
        "Xinwang Liu",
        "En Zhu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T12:17:34+00:00",
      "link": "https://arxiv.org/pdf/2601.21615v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20970v2",
      "title": "The augmented NLP bound for maximum-entropy remote sampling",
      "abstract": "The maximum-entropy remote sampling problem (MERSP) is to select a subset of s random variables from a set of n random variables, so as to maximize the information concerning a set of target random variables that are not directly observable. We assume throughout that the set of all of these random variables follows a joint Gaussian distribution, and that we have the covariance matrix available. Finally, we measure information using Shannon's differential entropy.   The main approach for exact solution of moderate-sized instances of MERSP has been branch-and-bound, and so previous work concentrated on upper bounds. Prior to our work, there were two upper-bounding methods for MERSP: the so-called NLP bound and the spectral bound, both introduced 25 years ago. We are able now to establish domination results between these two upper bounds. We propose an ``augmented NLP bound'' based on a subtle convex relaxation. We provide theoretical guarantees, giving sufficient conditions under which the augmented NLP bound strictly dominates the ordinary NLP bound. In addition, the augmented NLP formulation allows us to derive upper bounds for rank-deficient covariance matrices when they satisfy a technical condition. This is in contrast to the earlier work on the ordinary NLP bound that worked with only positive definite covariance matrices. Finally, we introduce a novel and very effective diagonal-scaling technique for MERSP, employing a positive vector of parameters. Numerical experiments on benchmark instances demonstrate the effectiveness of our approaches in advancing the state of the art for calculating upper bounds on MERSP.",
      "authors": [
        "Gabriel Ponte",
        "Marcia Fampa",
        "Jon Lee"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.IT",
        "cs.LG"
      ],
      "published": "2026-01-28T19:13:28+00:00",
      "link": "https://arxiv.org/pdf/2601.20970v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.09550v2",
      "title": "A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) Rényi Divergence",
      "abstract": "This work investigates binary hypothesis testing between $H_0\\sim P_0$ and $H_1\\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse\" Rényi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.",
      "authors": [
        "Roberto Bruno",
        "Adrien Vandenbroucque",
        "Amedeo Roberto Esposito"
      ],
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT"
      ],
      "published": "2026-01-14T15:09:32+00:00",
      "link": "https://arxiv.org/pdf/2601.09550v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20014v1",
      "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning",
      "abstract": "Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \\textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\\texttt{Sat}/\\texttt{Viol}/\\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \\emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \\textbf{14.9\\%} and \\textbf{5.8\\%} (vs.\\ \\textbf{26.0\\%} and \\textbf{15.7\\%} for the best baseline), while maintaining competitive reference quality.",
      "authors": [
        "Shuhui Qu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-27T19:41:10+00:00",
      "link": "https://arxiv.org/pdf/2601.20014v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.15871v2",
      "title": "Why Inference in Large Models Becomes Decomposable After Training",
      "abstract": "Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.",
      "authors": [
        "Jidong Jin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22T11:20:57+00:00",
      "link": "https://arxiv.org/pdf/2601.15871v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.15124v2",
      "title": "RAG-GFM: Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation",
      "abstract": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.",
      "authors": [
        "Haonan Yuan",
        "Qingyun Sun",
        "Jiacheng Tao",
        "Xingcheng Fu",
        "Jianxin Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21T16:02:43+00:00",
      "link": "https://arxiv.org/pdf/2601.15124v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.21684v1",
      "title": "Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling",
      "abstract": "Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \\textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.",
      "authors": [
        "Xinglin Wang",
        "Jiayi Shi",
        "Shaoxiong Feng",
        "Peiwen Yuan",
        "Yiwei Li",
        "Yueqi Zhang",
        "Chuyi Tan",
        "Ji Zhang",
        "Boyuan Pan",
        "Yao Hu",
        "Kan Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-29T13:18:36+00:00",
      "link": "https://arxiv.org/pdf/2601.21684v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2602.03608v1",
      "title": "Controlling Output Rankings in Generative Engines for LLM-based Search",
      "abstract": "The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility.   In this work, we propose CORE, an optimization method that \\textbf{C}ontrols \\textbf{O}utput \\textbf{R}ankings in g\\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface.   Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \\textbf{91.4\\% @Top-5}, \\textbf{86.6\\% @Top-3}, and \\textbf{80.3\\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.",
      "authors": [
        "Haibo Jin",
        "Ruoxi Chen",
        "Peiyan Zhang",
        "Yifeng Luo",
        "Huimin Zeng",
        "Man Luo",
        "Haohan Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-02-03T14:59:48+00:00",
      "link": "https://arxiv.org/pdf/2602.03608v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.14686v1",
      "title": "IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization",
      "abstract": "Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.",
      "authors": [
        "Shuai Wang",
        "Yaoming Yang",
        "Bingdong Li",
        "Hao Hao",
        "Aimin Zhou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-21T06:03:05+00:00",
      "link": "https://arxiv.org/pdf/2601.14686v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.16249v2",
      "title": "Ordering-based Causal Discovery via Generalized Score Matching",
      "abstract": "Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.",
      "authors": [
        "Vy Vo",
        "He Zhao",
        "Trung Le",
        "Edwin V. Bonilla",
        "Dinh Phung"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22T18:08:31+00:00",
      "link": "https://arxiv.org/pdf/2601.16249v2",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.20772v1",
      "title": "COMET-SG1: Lightweight Autoregressive Regressor for Edge and Embedded AI",
      "abstract": "COMET-SG1 is a lightweight, stability-oriented autoregressive regression model designed for time-series prediction on edge and embedded AI systems. Unlike recurrent neural networks or transformer-based sequence models, COMET-SG1 operates through linear behavior-space encoding, memory-anchored transition estimation, and deterministic state updates. This structure prioritizes bounded long-horizon behavior under fully autoregressive inference, a critical requirement for edge deployment where prediction errors accumulate over time. Experiments on non-stationary synthetic time-series data demonstrate that COMET-SG1 achieves competitive short-horizon accuracy while exhibiting significantly reduced long-horizon drift compared to MLP, LSTM, and k-nearest neighbor baselines. With a compact parameter footprint and operations compatible with fixed-point arithmetic, COMET-SG1 provides a practical and interpretable approach for stable autoregressive prediction in edge and embedded AI applications.",
      "authors": [
        "Shakhyar Gogoi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-28T16:59:56+00:00",
      "link": "https://arxiv.org/pdf/2601.20772v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.05537v1",
      "title": "Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts",
      "abstract": "Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) could help, naively applying it clashes with structural imbalance and risks expert collapse. We propose a Heterogeneous-aware Orthogonal Prototype Experts framework named HOPE, a plug-and-play replacement for the standard prediction head. HOPE uses learnable prototype-based routing to assign instances to experts by similarity, letting expert usage follow the natural long-tail distribution, and adds expert orthogonalization to encourage diversity and prevent collapse. Experiments on four real datasets show consistent gains across SOTA HGNN backbones with minimal overhead.",
      "authors": [
        "Wei Zhou",
        "Hong Huang",
        "Ruize Shi",
        "Bang Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-09T05:23:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05537v1",
      "tags": [
        "keyword:SR-LNS",
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.00931v1",
      "title": "Continuous-Utility Direct Preference Optimization",
      "abstract": "Large language model reasoning is often treated as a monolithic capability, relying on binary preference supervision that fails to capture partial progress or fine-grained reasoning quality. We introduce Continuous Utility Direct Preference Optimization (CU-DPO), a framework that aligns models to a portfolio of prompt-based cognitive strategies by replacing binary labels with continuous scores that capture fine-grained reasoning quality. We prove that learning with K strategies yields a Theta(K log K) improvement in sample complexity over binary preferences, and that DPO converges to the entropy-regularized utility-maximizing policy. To exploit this signal, we propose a two-stage training pipeline: (i) strategy selection, which optimizes the model to choose the best strategy for a given problem via best-vs-all comparisons, and (ii) execution refinement, which trains the model to correctly execute the selected strategy using margin-stratified pairs. On mathematical reasoning benchmarks, CU-DPO improves strategy selection accuracy from 35-46 percent to 68-78 percent across seven base models, yielding consistent downstream reasoning gains of up to 6.6 points on in-distribution datasets with effective transfer to out-of-distribution tasks.",
      "authors": [
        "Muhammad Ahmed Mohsin",
        "Muhammad Umer",
        "Ahsan Bilal",
        "Zihao He",
        "Muhammad Usman Rafique",
        "Asad Aali",
        "Muhammad Ali Jamshed",
        "John M. Cioffi",
        "Emily Fox"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-31T23:15:32+00:00",
      "link": "https://arxiv.org/pdf/2602.00931v1",
      "tags": [
        "keyword:SR-LNS"
      ]
    },
    {
      "id": "2601.21227v1",
      "title": "Jellyfish exist",
      "abstract": "We show the existence of infinitely many geometrically distinct homothetic expanders (jellyfish) for the elastic flow, epicyclic shrinkers for the curve diffusion flow, and epicyclic expanders for the ideal flow.",
      "authors": [
        "Ben Andrews",
        "Glen Wheeler"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG",
        "math.AP"
      ],
      "published": "2026-01-29T03:41:24+00:00",
      "link": "https://arxiv.org/pdf/2601.21227v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07564v1",
      "title": "Inhomogeneous almost symmetric submanifolds",
      "abstract": "We completely describe inhomogeneous properly embedded almost symmetric submanifolds of Euclidean space as certain unions of parallel symmetric submanifolds of the ambient Euclidean space.",
      "authors": [
        "Claudio Gorodski",
        "Carlos Olmos"
      ],
      "primary_category": "math.DG",
      "categories": [
        "math.DG"
      ],
      "published": "2026-01-12T14:20:54+00:00",
      "link": "https://arxiv.org/pdf/2601.07564v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13938v1",
      "title": "IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization",
      "abstract": "As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a \"diverge-then-converge\" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.",
      "authors": [
        "Heyang Zhou",
        "JiaJia Chen",
        "Xiaolu Chen",
        "Jie Bao",
        "Zhen Chen",
        "Yong Liao"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-20T13:13:39+00:00",
      "link": "https://arxiv.org/pdf/2601.13938v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05786v1",
      "title": "Selecting Hyperparameters for Tree-Boosting",
      "abstract": "Tree-boosting is a widely used machine learning technique for tabular data. However, its out-of-sample accuracy is critically dependent on multiple hyperparameters. In this article, we empirically compare several popular methods for hyperparameter optimization for tree-boosting including random grid search, the tree-structured Parzen estimator (TPE), Gaussian-process-based Bayesian optimization (GP-BO), Hyperband, the sequential model-based algorithm configuration (SMAC) method, and deterministic full grid search using $59$ regression and classification data sets. We find that the SMAC method clearly outperforms all the other considered methods. We further observe that (i) a relatively large number of trials larger than $100$ is required for accurate tuning, (ii) using default values for hyperparameters yields very inaccurate models, (iii) all considered hyperparameters can have a material effect on the accuracy of tree-boosting, i.e., there is no small set of hyperparameters that is more important than others, and (iv) choosing the number of boosting iterations using early stopping yields more accurate results compared to including it in the search space for regression tasks.",
      "authors": [
        "Floris Jan Koster",
        "Fabio Sigrist"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ],
      "published": "2026-02-05T15:44:42+00:00",
      "link": "https://arxiv.org/pdf/2602.05786v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.11443v1",
      "title": "Predict the Retrieval! Test time adaptation for Retrieval Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for enhancing large language models' question-answering capabilities through the integration of external knowledge. However, when adapting RAG systems to specialized domains, challenges arise from distribution shifts, resulting in suboptimal generalization performance. In this work, we propose TTARAG, a test-time adaptation method that dynamically updates the language model's parameters during inference to improve RAG system performance in specialized domains. Our method introduces a simple yet effective approach where the model learns to predict retrieved content, enabling automatic parameter adjustment to the target domain. Through extensive experiments across six specialized domains, we demonstrate that TTARAG achieves substantial performance improvements over baseline RAG systems. Code available at https://github.com/sunxin000/TTARAG.",
      "authors": [
        "Xin Sun",
        "Zhongqi Chen",
        "Qiang Liu",
        "Shu Wu",
        "Bowen Song",
        "Weiqiang Wang",
        "Zilei Wang",
        "Liang Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-16T17:07:01+00:00",
      "link": "https://arxiv.org/pdf/2601.11443v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22584v1",
      "title": "Scalable Fair Influence Blocking Maximization via Approximately Monotonic Submodular Optimization",
      "abstract": "Influence Blocking Maximization (IBM) aims to select a positive seed set to suppress the spread of negative influence. However, existing IBM methods focus solely on maximizing blocking effectiveness, overlooking fairness across communities. To address this issue, we formalize fairness in IBM and justify Demographic Parity (DP) as a notion that is particularly well aligned with its semantics. Yet enforcing DP is computationally challenging: prior work typically formulates DP as a Linear Programming (LP) problem and relies on costly solvers, rendering them impractical for large-scale networks. In this paper, we propose a DP-aware objective while maintaining an approximately monotonic submodular structure, enabling efficient optimization with theoretical guarantees. We integrate this objective with blocking effectiveness through a tunable scalarization, yielding a principled fairness-effectiveness trade-offs. Building on this structure, we develop CELF-R, an accelerated seed selection algorithm that exploits approximate submodularity to eliminate redundant evaluations and naturally supports Pareto front construction. Extensive experiments demonstrate that CELF-R consistently outperforms state-of-the-art baselines, achieving a $(1-1/e-ψ)$-approximate solution while maintaining high efficiency.",
      "authors": [
        "Qiangpeng Fang",
        "Jilong Shi",
        "Xiaobin Rui",
        "Jian Zhang",
        "Zhixiao Wang"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS"
      ],
      "published": "2026-01-30T05:27:47+00:00",
      "link": "https://arxiv.org/pdf/2601.22584v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21208v1",
      "title": "When should I search more: Adaptive Complex Query Optimization with Reinforcement Learning",
      "abstract": "Query optimization is a crucial component for the efficacy of Retrieval-Augmented Generation (RAG) systems. While reinforcement learning (RL)-based agentic and reasoning methods have recently emerged as a promising direction on query optimization, most existing approaches focus on the expansion and abstraction of a single query. However, complex user queries are prevalent in real-world scenarios, often requiring multiple parallel and sequential search strategies to handle disambiguation and decomposition. Directly applying RL to these complex cases introduces significant hurdles. Determining the optimal number of sub-queries and effectively re-ranking and merging retrieved documents vastly expands the search space and complicates reward design, frequently leading to training instability. To address these challenges, we propose a novel RL framework called Adaptive Complex Query Optimization (ACQO). Our framework is designed to adaptively determine when and how to expand the search process. It features two core components: an Adaptive Query Reformulation (AQR) module that dynamically decides when to decompose a query into multiple sub-queries, and a Rank-Score Fusion (RSF) module that ensures robust result aggregation and provides stable reward signals for the learning agent. To mitigate training instabilities, we adopt a Curriculum Reinforcement Learning (CRL) approach, which stabilizes the training process by progressively introducing more challenging queries through a two-stage strategy. Our comprehensive experiments demonstrate that ACQO achieves state-of-the-art performance on three complex query benchmarks, significantly outperforming established baselines. The framework also showcases improved computational efficiency and broad compatibility with different retrieval architectures, establishing it as a powerful and generalizable solution for next-generation RAG systems.",
      "authors": [
        "Wei Wen",
        "Sihang Deng",
        "Tianjun Wei",
        "Keyu Chen",
        "Ruizhi Qiao",
        "Xing Sun"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-01-29T03:16:53+00:00",
      "link": "https://arxiv.org/pdf/2601.21208v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.18664v2",
      "title": "S$^2$GR: Stepwise Semantic-Guided Reasoning in Latent Space for Generative Recommendation",
      "abstract": "Generative Recommendation (GR) has emerged as a transformative paradigm with its end-to-end generation advantages. However, existing GR methods primarily focus on direct Semantic ID (SID) generation from interaction sequences, failing to activate deeper reasoning capabilities analogous to those in large language models and thus limiting performance potential. We identify two critical limitations in current reasoning-enhanced GR approaches: (1) Strict sequential separation between reasoning and generation steps creates imbalanced computational focus across hierarchical SID codes, degrading quality for SID codes; (2) Generated reasoning vectors lack interpretable semantics, while reasoning paths suffer from unverifiable supervision. In this paper, we propose stepwise semantic-guided reasoning in latent space (S$^2$GR), a novel reasoning enhanced GR framework. First, we establish a robust semantic foundation via codebook optimization, integrating item co-occurrence relationship to capture behavioral patterns, and load balancing and uniformity objectives that maximize codebook utilization while reinforcing coarse-to-fine semantic hierarchies. Our core innovation introduces the stepwise reasoning mechanism inserting thinking tokens before each SID generation step, where each token explicitly represents coarse-grained semantics supervised via contrastive learning against ground-truth codebook cluster distributions ensuring physically grounded reasoning paths and balanced computational focus across all SID codes. Extensive experiments demonstrate the superiority of S$^2$GR, and online A/B test confirms efficacy on large-scale industrial short video platform.",
      "authors": [
        "Zihao Guo",
        "Jian Wang",
        "Ruxin Zhou",
        "Youhua Liu",
        "Jiawei Guo",
        "Jun Zhao",
        "Xiaoxiao Xu",
        "Yongqi Liu",
        "Kaiqiao Zhan"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-26T16:40:37+00:00",
      "link": "https://arxiv.org/pdf/2601.18664v2",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21853v1",
      "title": "LEMUR: Learned Multi-Vector Retrieval",
      "abstract": "Multi-vector representations generated by late interaction models, such as ColBERT, enable superior retrieval quality compared to single-vector representations in information retrieval applications. In multi-vector retrieval systems, both queries and documents are encoded using one embedding for each token, and similarity between queries and documents is measured by the MaxSim similarity measure. However, the improved recall of multi-vector retrieval comes at the expense of significantly increased latency. This necessitates designing efficient approximate nearest neighbor search (ANNS) algorithms for multi-vector search. In this work, we introduce LEMUR, a simple-yet-efficient framework for multi-vector similarity search. LEMUR consists of two consecutive problem reductions: We first formulate multi-vector similarity search as a supervised learning problem that can be solved using a one-hidden-layer neural network. Second, we reduce inference under this model to single-vector similarity search in its latent space, which enables the use of existing single-vector ANNS methods for speeding up retrieval. In addition to performance evaluation on ColBERTv2 embeddings, we evaluate LEMUR on embeddings generated by modern multi-vector text models and multi-vector visual document retrieval models. LEMUR is an order of magnitude faster than earlier multi-vector similarity search methods.",
      "authors": [
        "Elias Jääsaari",
        "Ville Hyvönen",
        "Teemu Roos"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-29T15:26:32+00:00",
      "link": "https://arxiv.org/pdf/2601.21853v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09684v1",
      "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection",
      "abstract": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",
      "authors": [
        "Ziyu Yang",
        "Guibin Chen",
        "Yuxin Yang",
        "Aoxiong Zeng",
        "Xiangquan Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-14T18:36:22+00:00",
      "link": "https://arxiv.org/pdf/2601.09684v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.23114v2",
      "title": "To See Far, Look Close: Evolutionary Forecasting for Long-term Time Series",
      "abstract": "The prevailing Direct Forecasting (DF) paradigm dominates Long-term Time Series Forecasting (LTSF) by forcing models to predict the entire future horizon in a single forward pass. While efficient, this rigid coupling of output and evaluation horizons necessitates computationally prohibitive re-training for every target horizon. In this work, we uncover a counter-intuitive optimization anomaly: models trained on short horizons-when coupled with our proposed Evolutionary Forecasting (EF) paradigm-significantly outperform those trained directly on long horizons. We attribute this success to the mitigation of a fundamental optimization pathology inherent in DF, where conflicting gradients from distant futures cripple the learning of local dynamics. We establish EF as a unified generative framework, proving that DF is merely a degenerate special case of EF. Extensive experiments demonstrate that a singular EF model surpasses task-specific DF ensembles across standard benchmarks and exhibits robust asymptotic stability in extreme extrapolation. This work propels a paradigm shift in LTSF: moving from passive Static Mapping to autonomous Evolutionary Reasoning.",
      "authors": [
        "Jiaming Ma",
        "Siyuan Mu",
        "Ruilin Tang",
        "Haofeng Ma",
        "Qihe Huang",
        "Zhengyang Zhou",
        "Pengkun Wang",
        "Binwu Wang",
        "Yang Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-30T16:02:27+00:00",
      "link": "https://arxiv.org/pdf/2601.23114v2",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.04352v1",
      "title": "Mosaic Learning: A Framework for Decentralized Learning with Model Fragmentation",
      "abstract": "Decentralized learning (DL) enables collaborative machine learning (ML) without a central server, making it suitable for settings where training data cannot be centrally hosted. We introduce Mosaic Learning, a DL framework that decomposes models into fragments and disseminates them independently across the network. Fragmentation reduces redundant communication across correlated parameters and enables more diverse information propagation without increasing communication cost. We theoretically show that Mosaic Learning (i) shows state-of-the-art worst-case convergence rate, and (ii) leverages parameter correlation in an ML model, improving contraction by reducing the highest eigenvalue of a simplified system. We empirically evaluate Mosaic Learning on four learning tasks and observe up to 12 percentage points higher node-level test accuracy compared to epidemic learning (EL), a state-of-the-art baseline. In summary, Mosaic Learning improves DL performance without sacrificing its utility or efficiency, and positions itself as a new DL standard.",
      "authors": [
        "Sayan Biswas",
        "Davide Frey",
        "Romaric Gaudel",
        "Nirupam Gupta",
        "Anne-Marie Kermarrec",
        "Dimitri Lerévérend",
        "Rafael Pires",
        "Rishi Sharma",
        "François Taïani",
        "Martijn de Vos"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-04T09:22:05+00:00",
      "link": "https://arxiv.org/pdf/2602.04352v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.22961v1",
      "title": "Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion",
      "abstract": "Supervised machine learning algorithms play a crucial role in optical quality control within industrial production. These approaches require representative datasets for effective model training. However, while non-defective components are frequent, defective parts are rare in production, resulting in highly imbalanced datasets that adversely impact model performance. Existing strategies to address this challenge, such as specialized loss functions or traditional data augmentation techniques, have limitations, including the need for careful hyperparameter tuning or the alteration of only simple image features. Therefore, this work explores the potential of generative artificial intelligence (GenAI) as an alternative method for expanding limited datasets and enhancing supervised machine learning performance. Specifically, we investigate Stable Diffusion and CycleGAN as image generation models, focusing on the segmentation of combine harvester components in thermal images for subsequent defect detection. Our results demonstrate that dataset expansion using Stable Diffusion yields the most significant improvement, enhancing segmentation performance by 4.6 %, resulting in a Mean Intersection over Union (Mean IoU) of 84.6 %.",
      "authors": [
        "Dennis Sprute",
        "Hanna Senke",
        "Holger Flatt"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-30T13:24:08+00:00",
      "link": "https://arxiv.org/pdf/2601.22961v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.20627v1",
      "title": "DIVERSE: Disagreement-Inducing Vector Evolution for Rashomon Set Exploration",
      "abstract": "We propose DIVERSE, a framework for systematically exploring the Rashomon set of deep neural networks, the collection of models that match a reference model's accuracy while differing in their predictive behavior. DIVERSE augments a pretrained model with Feature-wise Linear Modulation (FiLM) layers and uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to search a latent modulation space, generating diverse model variants without retraining or gradient access. Across MNIST, PneumoniaMNIST, and CIFAR-10, DIVERSE uncovers multiple high-performing yet functionally distinct models. Our experiments show that DIVERSE offers a competitive and efficient exploration of the Rashomon set, making it feasible to construct diverse sets that maintain robustness and performance while supporting well-balanced model multiplicity. While retraining remains the baseline to generate Rashomon sets, DIVERSE achieves comparable diversity at reduced computational cost.",
      "authors": [
        "Gilles Eerlings",
        "Brent Zoomers",
        "Jori Liesenborgs",
        "Gustavo Rovelo Ruiz",
        "Kris Luyten"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-28T14:02:28+00:00",
      "link": "https://arxiv.org/pdf/2601.20627v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.20646v1",
      "title": "TGSBM: Transformer-Guided Stochastic Block Model for Link Prediction",
      "abstract": "Link prediction is a cornerstone of the Web ecosystem, powering applications from recommendation and search to knowledge graph completion and collaboration forecasting. However, large-scale networks present unique challenges: they contain hundreds of thousands of nodes and edges with heterogeneous and overlapping community structures that evolve over time. Existing approaches face notable limitations: traditional graph neural networks struggle to capture global structural dependencies, while recent graph transformers achieve strong performance but incur quadratic complexity and lack interpretable latent structure. We propose \\textbf{TGSBM} (Transformer-Guided Stochastic Block Model), a framework that integrates the principled generative structure of Overlapping Stochastic Block Models with the representational power of sparse Graph Transformers. TGSBM comprises three main components: (i) \\emph{expander-augmented sparse attention} that enables near-linear complexity and efficient global mixing, (ii) a \\emph{neural variational encoder} that infers structured posteriors over community memberships and strengths, and (iii) a \\emph{neural edge decoder} that reconstructs links via OSBM's generative process, preserving interpretability. Experiments across diverse benchmarks demonstrate competitive performance (mean rank 1.6 under HeaRT protocol), superior scalability (up to $6\\times$ faster training), and interpretable community structures. These results position TGSBM as a practical approach that strikes a balance between accuracy, efficiency, and transparency for large-scale link prediction.",
      "authors": [
        "Zhejian Yang",
        "Songwei Zhao",
        "Zilin Zhao",
        "Hechang Chen"
      ],
      "primary_category": "cs.SI",
      "categories": [
        "cs.SI",
        "cs.IR"
      ],
      "published": "2026-01-28T14:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.20646v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.19535v1",
      "title": "LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG",
      "abstract": "Most conventional Retrieval-Augmented Generation (RAG) pipelines rely on relevance-based retrieval, which often misaligns with utility -- that is, whether the retrieved passages actually improve the quality of the generated text specific to a downstream task such as question answering or query-based summarization. The limitations of existing utility-driven retrieval approaches for RAG are that, firstly, they are resource-intensive typically requiring query encoding, and that secondly, they do not involve listwise ranking loss during training. The latter limitation is particularly critical, as the relative order between documents directly affects generation in RAG. To address this gap, we propose Lightweight Utility-driven Reranking for Efficient RAG (LURE-RAG), a framework that augments any black-box retriever with an efficient LambdaMART-based reranker. Unlike prior methods, LURE-RAG trains the reranker with a listwise ranking loss guided by LLM utility, thereby directly optimizing the ordering of retrieved documents. Experiments on two standard datasets demonstrate that LURE-RAG achieves competitive performance, reaching 97-98% of the state-of-the-art dense neural baseline, while remaining efficient in both training and inference. Moreover, its dense variant, UR-RAG, significantly outperforms the best existing baseline by up to 3%.",
      "authors": [
        "Manish Chandra",
        "Debasis Ganguly",
        "Iadh Ounis"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-27T12:26:31+00:00",
      "link": "https://arxiv.org/pdf/2601.19535v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.00805v1",
      "title": "Optimizing Retrieval Components for a Shared Backbone via Component-Wise Multi-Stage Training",
      "abstract": "Recent advances in embedding-based retrieval have enabled dense retrievers to serve as core infrastructure in many industrial systems, where a single retrieval backbone is often shared across multiple downstream applications. In such settings, retrieval quality directly constrains system performance and extensibility, while coupling model selection, deployment, and rollback decisions across applications.   In this paper, we present empirical findings and a system-level solution for optimizing retrieval components deployed as a shared backbone in production legal retrieval systems. We adopt a multi-stage optimization framework for dense retrievers and rerankers, and show that different retrieval components exhibit stage-dependent trade-offs. These observations motivate a component-wise, mixed-stage configuration rather than relying on a single uniformly optimal checkpoint. The resulting backbone is validated through end-to-end evaluation and deployed as a shared retrieval service supporting multiple industrial applications.",
      "authors": [
        "Yunhan Li",
        "Mingjie Xie",
        "Zihan Gong",
        "Zeyang Shi",
        "Gengshen Wu",
        "Min Yang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-31T16:29:32+00:00",
      "link": "https://arxiv.org/pdf/2602.00805v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.20397v1",
      "title": "FedRD: Reducing Divergences for Generalized Federated Learning via Heterogeneity-aware Parameter Guidance",
      "abstract": "Heterogeneous federated learning (HFL) aims to ensure effective and privacy-preserving collaboration among different entities. As newly joined clients require significant adjustments and additional training to align with the existing system, the problem of generalizing federated learning models to unseen clients under heterogeneous data has become progressively crucial. Consequently, we highlight two unsolved challenging issues in federated domain generalization: Optimization Divergence and Performance Divergence. To tackle the above challenges, we propose FedRD, a novel heterogeneity-aware federated learning algorithm that collaboratively utilizes parameter-guided global generalization aggregation and local debiased classification to reduce divergences, aiming to obtain an optimal global model for participating and unseen clients. Extensive experiments on public multi-domain datasets demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.",
      "authors": [
        "Kaile Wang",
        "Jiannong Cao",
        "Yu Yang",
        "Xiaoyin Li",
        "Mingjin Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-28T09:03:06+00:00",
      "link": "https://arxiv.org/pdf/2601.20397v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.09304v1",
      "title": "Single-Round Clustered Federated Learning via Data Collaboration Analysis for Non-IID Data",
      "abstract": "Federated Learning (FL) enables distributed learning across multiple clients without sharing raw data. When statistical heterogeneity across clients is severe, Clustered Federated Learning (CFL) can improve performance by grouping similar clients and training cluster-wise models. However, most CFL approaches rely on multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight constraints on communication rounds. We propose Data Collaboration-based Clustered Federated Learning (DC-CFL), a single-round framework that completes both client clustering and cluster-wise learning, using only the information shared in DC analysis. DC-CFL quantifies inter-client similarity via total variation distance between label distributions, estimates clusters using hierarchical clustering, and performs cluster-wise learning via DC analysis. Experiments on multiple open datasets under representative non-IID conditions show that DC-CFL achieves accuracy comparable to multi-round baselines while requiring only one communication round. These results indicate that DC-CFL is a practical alternative for collaborative AI model development when multiple communication rounds are impractical.",
      "authors": [
        "Sota Sugawara",
        "Yuji Kawamata",
        "Akihiro Toyoda",
        "Tomoru Nakayama",
        "Yukihiko Okada"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-14T09:14:44+00:00",
      "link": "https://arxiv.org/pdf/2601.09304v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.05848v1",
      "title": "DARWIN: Dynamic Agentically Rewriting Self-Improving Network",
      "abstract": "DARWIN is an evolutionary GPT model, utilizing a genetic-algorithm like optimization structure with several independent GPT agents being trained individually using unique training code. Each iteration, the GPT models are prompted to modify the training code of one another in an attempt to improve their performance in a mutation-like manner, and the best GPT agents are then benchmarked and selected for the next iteration by genetic algorithm. For demonstration purposes and due to budget and time constraints, OpenAI API is used to prompt training code improvements and the nanoGPT framework is used as the training code. DARWIN also utilizes persistent JSON-based memory files to track previous reasoning and changes to code to correlate with improvement to model performance. and a bidirectional interface for HITL intervention allowing the model to request upgrades such as additional datasets, training scripts, and restructuring of file hierarchies. In experiments, DARWIN achieved a 1.26 percent improvement in model FLOPS utilization (MFU) and a 2.07 percent improvement to perplexity in 5 iterations of training over baseline configurations, demonstrating promising capabilities as a foundation for scaling evolutionary GPT training.",
      "authors": [
        "Henry Jiang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-02-05T16:35:46+00:00",
      "link": "https://arxiv.org/pdf/2602.05848v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.18251v1",
      "title": "GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction",
      "abstract": "Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.",
      "authors": [
        "Kesha Ou",
        "Zhen Tian",
        "Wayne Xin Zhao",
        "Hongyu Lu",
        "Ji-Rong Wen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-26T08:15:04+00:00",
      "link": "https://arxiv.org/pdf/2601.18251v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21355v1",
      "title": "Decentralized Learning with Dynamically Refined Edge Weights: A Data-Dependent Framework",
      "abstract": "This paper aims to accelerate decentralized optimization by strategically designing the edge weights used in the agent-to-agent message exchanges. We propose a Dynamic Directed Decentralized Gradient (D3GD) framework and show that the proposed data-dependent framework is a practical alternative to the classical directed DGD (Di-DGD) algorithm for learning on directed graphs. To obtain a strategy for edge weights refinement, we derive a design function inspired by the cost-to-go function in a new convergence analysis for Di-DGD. This results in a data-dependent dynamical design for the edge weights. A fully decentralized version of D3GD is developed such that each agent refines its communication strategy using only neighbor's information. Numerical experiments show that D3GD accelerates convergence towards stationary solution by 30-40\\% over Di-DGD, and learns edge weights that adapt to data similarity.",
      "authors": [
        "Rongxing Du",
        "Hoi-To Wai"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-29T07:30:08+00:00",
      "link": "https://arxiv.org/pdf/2601.21355v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.17567v1",
      "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation",
      "abstract": "Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.",
      "authors": [
        "Zijing Hui",
        "Wenhan Lyu",
        "Shusen Wang",
        "Li Chen",
        "Chu Wang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-24T19:37:11+00:00",
      "link": "https://arxiv.org/pdf/2601.17567v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07055v1",
      "title": "Dr. Zero: Self-Evolving Search Agents without Training Data",
      "abstract": "As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.",
      "authors": [
        "Zhenrui Yue",
        "Kartikeya Upasani",
        "Xianjun Yang",
        "Suyu Ge",
        "Shaoliang Nie",
        "Yuning Mao",
        "Zhe Liu",
        "Dong Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-11T20:27:55+00:00",
      "link": "https://arxiv.org/pdf/2601.07055v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21061v1",
      "title": "Signal from Structure: Exploiting Submodular Upper Bounds in Generative Flow Networks",
      "abstract": "Generative Flow Networks (GFlowNets; GFNs) are a class of generative models that learn to sample compositional objects proportionally to their a priori unknown value, their reward. We focus on the case where the reward has a specified, actionable structure, namely that it is submodular. We show submodularity can be harnessed to retrieve upper bounds on the reward of compositional objects that have not yet been observed. We provide in-depth analyses of the probability of such bounds occurring, as well as how many unobserved compositional objects can be covered by a bound. Following the Optimism in the Face of Uncertainty principle, we then introduce SUBo-GFN, which uses the submodular upper bounds to train a GFN. We show that SUBo-GFN generates orders of magnitude more training data than classical GFNs for the same number of queries to the reward function. We demonstrate the effectiveness of SUBo-GFN in terms of distribution matching and high-quality candidate generation on synthetic and real-world submodular tasks.",
      "authors": [
        "Alexandre Larouche",
        "Audrey Durand"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-28T21:34:01+00:00",
      "link": "https://arxiv.org/pdf/2601.21061v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02636v1",
      "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
      "abstract": "Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.",
      "authors": [
        "Ziyang Huang",
        "Haolin Ren",
        "Xiaowei Yuan",
        "Jiawei Wang",
        "Zhongtao Jiang",
        "Kun Xu",
        "Shizhu He",
        "Jun Zhao",
        "Kang Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2026-02-02T18:32:48+00:00",
      "link": "https://arxiv.org/pdf/2602.02636v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.05465v1",
      "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering",
      "abstract": "Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.",
      "authors": [
        "Yu Liu",
        "Wenxiao Zhang",
        "Cong Cao",
        "Wenxuan Lu",
        "Fangfang Yuan",
        "Diandian Guo",
        "Kun Peng",
        "Qiang Sun",
        "Kaiyan Zhang",
        "Yanbing Liu",
        "Jin B. Hong",
        "Bowen Zhou",
        "Zhiyuan Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-09T01:38:38+00:00",
      "link": "https://arxiv.org/pdf/2601.05465v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.04153v1",
      "title": "Pruning for Generalization: A Transfer-Oriented Spatiotemporal Graph Framework",
      "abstract": "Multivariate time series forecasting in graph-structured domains is critical for real-world applications, yet existing spatiotemporal models often suffer from performance degradation under data scarcity and cross-domain shifts. We address these challenges through the lens of structure-aware context selection. We propose TL-GPSTGN, a transfer-oriented spatiotemporal framework that enhances sample efficiency and out-of-distribution generalization by selectively pruning non-optimized graph context. Specifically, our method employs information-theoretic and correlation-based criteria to extract structurally informative subgraphs and features, resulting in a compact, semantically grounded representation. This optimized context is subsequently integrated into a spatiotemporal convolutional architecture to capture complex multivariate dynamics. Evaluations on large-scale traffic benchmarks demonstrate that TL-GPSTGN consistently outperforms baselines in low-data transfer scenarios. Our findings suggest that explicit context pruning serves as a powerful inductive bias for improving the robustness of graph-based forecasting models.",
      "authors": [
        "Zihao Jing",
        "Yuxi Long",
        "Ganlin Feng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-04T02:41:29+00:00",
      "link": "https://arxiv.org/pdf/2602.04153v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.10657v2",
      "title": "PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution",
      "abstract": "Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent's context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT.",
      "authors": [
        "Minghao Yan",
        "Bo Peng",
        "Benjamin Coleman",
        "Ziqi Chen",
        "Zhouhang Xie",
        "Shuo Chen",
        "Zhankui He",
        "Noveen Sachdeva",
        "Isabella Ye",
        "Weili Wang",
        "Chi Wang",
        "Ed H. Chi",
        "Fernando Pereira",
        "Wang-Cheng Kang",
        "Derek Zhiyuan Cheng",
        "Beidou Wang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-01-15T18:25:23+00:00",
      "link": "https://arxiv.org/pdf/2601.10657v2",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.03690v1",
      "title": "LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization",
      "abstract": "We consider small-data, large-scale decision problems in which a firm must make many operational decisions simultaneously (e.g., across a large product portfolio) while observing only a few, potentially noisy, data points per instance. Inspired by the success of large language models (LLMs), we propose a pretrain-then-finetune approach built on a designed Transformer model to address this challenge. The model is first pretrained on large-scale, domain-informed synthetic data that encode managerial knowledge and structural features of the decision environment, and is then fine-tuned on real observations. This new pipeline offers two complementary advantages: pretraining injects domain knowledge into the learning process and enables the training of high-capacity models using abundant synthetic data, while finetuning adapts the pretrained model to the operational environment and improves alignment with the true data-generating regime. While we have leveraged the Transformer's state-of-the-art representational capacity, particularly its attention mechanism, to efficiently extract cross-task structure, our approach is not an off-the-shelf application. Instead, it relies on problem-specific architectural design and a tailored training procedure to match the decision setting. Theoretically, we develop the first comprehensive error analysis regarding Transformer learning in relevant contexts, establishing nonasymptotic guarantees that validate the method's effectiveness. Critically, our analysis reveals how pretraining and fine-tuning jointly determine performance, with the dominant contribution governed by whichever is more favorable. In particular, finetuning exhibits an economies-of-scale effect, whereby transfer learning becomes increasingly effective as the number of instances grows.",
      "authors": [
        "Zishi Zhang",
        "Jinhui Han",
        "Ming Hu",
        "Yijie Peng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03T16:08:33+00:00",
      "link": "https://arxiv.org/pdf/2602.03690v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.08528v1",
      "title": "SVFusion: A CPU-GPU Co-Processing Architecture for Large-Scale Real-Time Vector Search",
      "abstract": "Approximate Nearest Neighbor Search (ANNS) underpins modern applications such as information retrieval and recommendation. With the rapid growth of vector data, efficient indexing for real-time vector search has become rudimentary. Existing CPU-based solutions support updates but suffer from low throughput, while GPU-accelerated systems deliver high performance but face challenges with dynamic updates and limited GPU memory, resulting in a critical performance gap for continuous, large-scale vector search requiring both accuracy and speed. In this paper, we present SVFusion, a GPU-CPU-disk collaborative framework for real-time vector search that bridges sophisticated GPU computation with online updates. SVFusion leverages a hierarchical vector index architecture that employs CPU-GPU co-processing, along with a workload-aware vector caching mechanism to maximize the efficiency of limited GPU memory. It further enhances performance through real-time coordination with CUDA multi-stream optimization and adaptive resource management, along with concurrency control that ensures data consistency under interleaved queries and updates. Empirical results demonstrate that SVFusion achieves significant improvements in query latency and throughput, exhibiting a 20.9x higher throughput on average and 1.3x to 50.7x lower latency compared to baseline methods, while maintaining high recall for large-scale datasets under various streaming workloads.",
      "authors": [
        "Yuchen Peng",
        "Dingyu Yang",
        "Zhongle Xie",
        "Ji Sun",
        "Lidan Shou",
        "Ke Chen",
        "Gang Chen"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-13T13:12:07+00:00",
      "link": "https://arxiv.org/pdf/2601.08528v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.01331v1",
      "title": "A-MapReduce: Executing Wide Search via Agentic MapReduce",
      "abstract": "Contemporary large language model (LLM)-based multi-agent systems exhibit systematic advantages in deep research tasks, which emphasize iterative, vertically structured information seeking. However, when confronted with wide search tasks characterized by large-scale, breadth-oriented retrieval, existing agentic frameworks, primarily designed around sequential, vertically structured reasoning, remain stuck in expansive search objectives and inefficient long-horizon execution. To bridge this gap, we propose A-MapReduce, a MapReduce paradigm-inspired multi-agent execution framework that recasts wide search as a horizontally structured retrieval problem. Concretely, A-MapReduce implements parallel processing of massive retrieval targets through task-adaptive decomposition and structured result aggregation. Meanwhile, it leverages experiential memory to drive the continual evolution of query-conditioned task allocation and recomposition, enabling progressive improvement in large-scale wide-search regimes. Extensive experiments on five agentic benchmarks demonstrate that A-MapReduce is (i) high-performing, achieving state-of-the-art performance on WideSearch and DeepWideSearch, and delivering 5.11% - 17.50% average Item F1 improvements compared with strong baselines with OpenAI o3 or Gemini 2.5 Pro backbones; (ii) cost-effective and efficient, delivering superior cost-performance trade-offs and reducing running time by 45.8\\% compared to representative multi-agent baselines. The code is available at https://github.com/mingju-c/AMapReduce.",
      "authors": [
        "Mingju Chen",
        "Guibin Zhang",
        "Heng Chang",
        "Yuchen Guo",
        "Shiji Zhou"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.CL"
      ],
      "published": "2026-02-01T16:53:29+00:00",
      "link": "https://arxiv.org/pdf/2602.01331v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.13013v1",
      "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads",
      "abstract": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",
      "authors": [
        "Xiaohui Zhao",
        "Xinjian Zhao",
        "Jiahui Zhang",
        "Guoyu Liu",
        "Houzhi Wang",
        "Shu Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-19T12:47:31+00:00",
      "link": "https://arxiv.org/pdf/2601.13013v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.11161v1",
      "title": "GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling",
      "abstract": "Unsupervised domain adaptation tackles the problem that domain shifts between training and test data impair the performance of neural networks in many real-world applications. Thereby, in realistic scenarios, the source data may no longer be available during adaptation, and the label space of the target domain may differ from the source label space. This setting, known as source-free universal domain adaptation (SF-UniDA), has recently gained attention, but all existing approaches only assume a single domain shift from source to target. In this work, we present the first study on continual SF-UniDA, where the model must adapt sequentially to a stream of multiple different unlabeled target domains. Building upon our previous methods for online SF-UniDA, we combine their key ideas by integrating Gaussian mixture model-based pseudo-labeling within a mean teacher framework for improved stability over long adaptation sequences. Additionally, we introduce consistency losses for further robustness. The resulting method GMM-COMET provides a strong first baseline for continual SF-UniDA and is the only approach in our experiments to consistently improve upon the source-only model across all evaluated scenarios. Our code is available at https://github.com/pascalschlachter/GMM-COMET.",
      "authors": [
        "Pascal Schlachter",
        "Bin Yang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-16T10:23:19+00:00",
      "link": "https://arxiv.org/pdf/2601.11161v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.21452v1",
      "title": "SAGE: Sequence-level Adaptive Gradient Evolution for Generative Recommendation",
      "abstract": "While works such as OneRec have validated the scaling laws of Large Language Models (LLMs) in recommender systems, they rely on a cumbersome separate vocabulary. This dependency prevents the model architecture from reusing native LLM vocabularies, resulting in high maintenance costs and poor scalability. In response, we aim to efficiently reuse open-source LLM architectures without constructing a separate tokenization vocabulary. Furthermore, we identify that the optimization strategy of OneRec Gradient Bounded Policy Optimization (GBPO),suffers from a \"Symmetric Conservatism\" problem: its static gradient boundaries structurally suppress the update momentum required for cold-start items and fail to prevent diversity collapse in high-noise environments.To address this issue, we propose SAGE (Sequence-level Adaptive Gradient Evolution), a unified optimization framework tailored for list-wise generative recommendation. SAGE introduces two key innovations:(1) Sequence-level Signal Decoupling: By combining a geometric mean importance ratio with decoupled multi-objective advantages, we eliminate token-level variance and resolve the \"Reward Collapse\" problem. (2) Asymmetric Adaptive Dynamics: We construct a dynamic gradient manifold that applies a \"Boost Factor\" to high-potential cold start items to achieve super-linear updates and employs an \"Entropy Aware Penalty\" to break information cocoons. Theoretical analysis and empirical results demonstrate that SAGE effectively unblocks cold-start traffic and sustains recommendation diversity, all while retaining the numerical stability of GBPO.",
      "authors": [
        "Yu Xie",
        "Xing Kai Ren",
        "Ying Qi",
        "Hu Yao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-29T09:30:13+00:00",
      "link": "https://arxiv.org/pdf/2601.21452v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07048v3",
      "title": "GPU-Accelerated ANNS: Quantized for Speed, Built for Change",
      "abstract": "Approximate nearest neighbor search (ANNS) is a core problem in machine learning and information retrieval applications. GPUs offer a promising path to high-performance ANNS: they provide massive parallelism for distance computations, are readily available, and can co-locate with downstream applications.   Despite these advantages, current GPU-accelerated ANNS systems face three key limitations. First, real-world applications operate on evolving datasets that require fast batch updates, yet most GPU indices must be rebuilt from scratch when new data arrives. Second, high-dimensional vectors strain memory bandwidth, but current GPU systems lack efficient quantization techniques that reduce data movement without introducing costly random memory accesses. Third, the data-dependent memory accesses inherent to greedy search make overlapping compute and memory difficult, leading to reduced performance.   We present Jasper, a GPU-native ANNS system with both high query throughput and updatability. Jasper builds on the Vamana graph index and overcomes existing bottlenecks via three contributions: (1) a CUDA batch-parallel construction algorithm that enables lock-free streaming insertions, (2) a GPU-efficient implementation of RaBitQ quantization that reduces memory footprint up to 8x without the random access penalties, and (3) an optimized greedy search kernel that increases compute utilization, resulting in better latency hiding and higher throughput.   Our evaluation across five datasets shows that Jasper achieves up to 1.93x higher query throughput than CAGRA and achieves up to 80% peak utilization as measured by the roofline model. Jasper's construction scales efficiently and constructs indices an average of 2.4x faster than CAGRA while providing updatability that CAGRA lacks. Compared to BANG, the previous fastest GPU Vamana implementation, Jasper delivers 19-131x faster queries.",
      "authors": [
        "Hunter McCoy",
        "Zikun Wang",
        "Prashant Pandey"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "published": "2026-01-11T19:51:54+00:00",
      "link": "https://arxiv.org/pdf/2601.07048v3",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2602.02961v1",
      "title": "Generative Engine Optimization: A VLM and Agent Framework for Pinterest Acquisition Growth",
      "abstract": "Large Language Models are fundamentally reshaping content discovery through AI-native search systems such as ChatGPT, Gemini, and Claude. Unlike traditional search engines that match keywords to documents, these systems infer user intent, synthesize multimodal evidence, and generate contextual answers directly on the search page, introducing a paradigm shift from Search Engine Optimization (SEO) to Generative Engine Optimization (GEO). For visual content platforms hosting billions of assets, this poses an acute challenge: individual images lack the semantic depth and authority signals that generative search prioritizes, risking disintermediation as user needs are satisfied in-place without site visits.   We present Pinterest GEO, a production-scale framework that pioneers reverse search design: rather than generating generic image captions describing what content is, we fine-tune Vision-Language Models (VLMs) to predict what users would actually search for, augmented this with AI agents that mine real-time internet trends to capture emerging search demand. These VLM-generated queries then drive construction of semantically coherent Collection Pages via multimodal embeddings, creating indexable aggregations optimized for generative retrieval. Finally, we employ hybrid VLM and two-tower ANN architectures to build authority-aware interlinking structures that propagate signals across billions of visual assets. Deployed at scale across billions of images and tens of millions of collections, GEO delivers 20\\% organic traffic growth contributing to multi-million monthly active user (MAU) growth, demonstrating a principled pathway for visual platforms to thrive in the generative search era.",
      "authors": [
        "Faye Zhang",
        "Qianyu Cheng",
        "Jasmine Wan",
        "Vishwakarma Singh",
        "Jinfeng Rao",
        "Kofi Boakye"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-03T00:58:50+00:00",
      "link": "https://arxiv.org/pdf/2602.02961v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.10176v2",
      "title": "CC-OR-Net: A Unified Framework for LTV Prediction through Structural Decoupling",
      "abstract": "Customer Lifetime Value (LTV) prediction, a central problem in modern marketing, is characterized by a unique zero-inflated and long-tail data distribution. This distribution presents two fundamental challenges: (1) the vast majority of low-to-medium value users numerically overwhelm the small but critically important segment of high-value \"whale\" users, and (2) significant value heterogeneity exists even within the low-to-medium value user base. Common approaches either rely on rigid statistical assumptions or attempt to decouple ranking and regression using ordered buckets; however, they often enforce ordinality through loss-based constraints rather than inherent architectural design, failing to balance global accuracy with high-value precision. To address this gap, we propose \\textbf{C}onditional \\textbf{C}ascaded \\textbf{O}rdinal-\\textbf{R}esidual Networks \\textbf{(CC-OR-Net)}, a novel unified framework that achieves a more robust decoupling through \\textbf{structural decomposition}, where ranking is architecturally guaranteed. CC-OR-Net integrates three specialized components: a \\textit{structural ordinal decomposition module} for robust ranking, an \\textit{intra-bucket residual module} for fine-grained regression, and a \\textit{targeted high-value augmentation module} for precision on top-tier users. Evaluated on real-world datasets with over 300M users, CC-OR-Net achieves a superior trade-off across all key business metrics, outperforming state-of-the-art methods in creating a holistic and commercially valuable LTV prediction solution.",
      "authors": [
        "Mingyu Zhao",
        "Haoran Bai",
        "Yu Tian",
        "Bing Zhu",
        "Hengliang Luo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-15T08:35:17+00:00",
      "link": "https://arxiv.org/pdf/2601.10176v2",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.16858v1",
      "title": "Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation",
      "abstract": "The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).",
      "authors": [
        "Mahe Chen",
        "Xiaoxuan Wang",
        "Kaiwen Chen",
        "Nick Koudas"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-23T16:06:18+00:00",
      "link": "https://arxiv.org/pdf/2601.16858v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.07125v1",
      "title": "ReinPool: Reinforcement Learning Pooling Multi-Vector Embeddings for Retrieval System",
      "abstract": "Multi-vector embedding models have emerged as a powerful paradigm for document retrieval, preserving fine-grained visual and textual details through token-level representations. However, this expressiveness comes at a staggering cost: storing embeddings for every token inflates index sizes by over $1000\\times$ compared to single-vector approaches, severely limiting scalability. We introduce \\textbf{ReinPool}, a reinforcement learning framework that learns to dynamically filter and pool multi-vector embeddings into compact, retrieval-optimized representations. By training with an inverse retrieval objective and NDCG-based rewards, ReinPool identifies and retains only the most discriminative vectors without requiring manual importance annotations. On the Vidore V2 benchmark across three vision-language embedding models, ReinPool compresses multi-vector representations by $746$--$1249\\times$ into single vectors while recovering 76--81\\% of full multi-vector retrieval performance. Compared to static mean pooling baselines, ReinPool achieves 22--33\\% absolute NDCG@3 improvement, demonstrating that learned selection significantly outperforms heuristic aggregation.",
      "authors": [
        "Sungguk Cha",
        "DongWook Kim",
        "Mintae Kim",
        "Youngsub Han",
        "Byoung-Ki Jeon",
        "Sangyeob Lee"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-12T01:37:21+00:00",
      "link": "https://arxiv.org/pdf/2601.07125v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.23238v1",
      "title": "How well do generative models solve inverse problems? A benchmark study",
      "abstract": "Generative learning generates high dimensional data based on low dimensional conditions, also called prompts. Therefore, generative learning algorithms are eligible for solving (Bayesian) inverse problems. In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a prior sampled with the Markov Chain Monte Carlo method with three state of the art generative learning models, namely conditional Generative Adversarial Networks, Invertible Neural Networks and Conditional Flow Matching. We apply them to a problem of gas turbine combustor design where we map six independent design parameters to three performance labels. We propose several metrics for the evaluation of this inverse design approaches and measure the accuracy of the labels of the generated designs along with the diversity. We also study the performance as a function of the training dataset size. Our benchmark has a clear winner, as Conditional Flow Matching consistently outperforms all competing approaches.",
      "authors": [
        "Patrick Krüger",
        "Patrick Materne",
        "Werner Krebs",
        "Hanno Gottschalk"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-30T18:06:50+00:00",
      "link": "https://arxiv.org/pdf/2601.23238v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.11311v1",
      "title": "FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular Learning",
      "abstract": "Tabular data high-stakes critical decision-making in domains such as finance, healthcare, and scientific discovery. Yet, learning effectively from tabular data in few-shot settings, where labeled examples are scarce, remains a fundamental challenge. Traditional tree-based methods often falter in these regimes due to their reliance on statistical purity metrics, which become unstable and prone to overfitting with limited supervision. At the same time, direct applications of large language models (LLMs) often overlook its inherent structure, leading to suboptimal performance. To overcome these limitations, we propose FORESTLLM, a novel framework that unifies the structural inductive biases of decision forests with the semantic reasoning capabilities of LLMs. Crucially, FORESTLLM leverages the LLM only during training, treating it as an offline model designer that encodes rich, contextual knowledge into a lightweight, interpretable forest model, eliminating the need for LLM inference at test time. Our method is two-fold. First, we introduce a semantic splitting criterion in which the LLM evaluates candidate partitions based on their coherence over both labeled and unlabeled data, enabling the induction of more robust and generalizable tree structures under few-shot supervision. Second, we propose a one-time in-context inference mechanism for leaf node stabilization, where the LLM distills the decision path and its supporting examples into a concise, deterministic prediction, replacing noisy empirical estimates with semantically informed outputs. Across a diverse suite of few-shot classification and regression benchmarks, FORESTLLM achieves state-of-the-art performance.",
      "authors": [
        "Zhihan Yang",
        "Jiaqi Wei",
        "Xiang Zhang",
        "Haoyu Dong",
        "Yiwen Wang",
        "Xiaoke Guo",
        "Pengkun Zhang",
        "Yiwei Xu",
        "Chenyu You"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-16T14:08:51+00:00",
      "link": "https://arxiv.org/pdf/2601.11311v1",
      "tags": [
        "query:SR-LNS"
      ]
    },
    {
      "id": "2601.19833v1",
      "title": "A Multi-directional Meta-Learning Framework for Class-Generalizable Anomaly Detection",
      "abstract": "In this paper, we address the problem of class-generalizable anomaly detection, where the objective is to develop a unified model by focusing our learning on the available normal data and a small amount of anomaly data in order to detect the completely unseen anomalies, also referred to as the out-of-distribution (OOD) classes. Adding to this challenge is the fact that the anomaly data is rare and costly to label. To achieve this, we propose a multidirectional meta-learning algorithm -- at the inner level, the model aims to learn the manifold of the normal data (representation); at the outer level, the model is meta-tuned with a few anomaly samples to maximize the softmax confidence margin between the normal and anomaly samples (decision surface calibration), treating normals as in-distribution (ID) and anomalies as out-of-distribution (OOD). By iteratively repeating this process over multiple episodes of predominantly normal and a small number of anomaly samples, we realize a multidirectional meta-learning framework. This two-level optimization, enhanced by multidirectional training, enables stronger generalization to unseen anomaly classes.",
      "authors": [
        "Padmaksha Roy",
        "Lamine Mili",
        "Almuatazbellah Boker"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-27T17:39:11+00:00",
      "link": "https://arxiv.org/pdf/2601.19833v1",
      "tags": [
        "query:SR-LNS"
      ]
    }
  ],
  "queries": [
    {
      "type": "intent_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Deep learning for symbolic regression",
      "sim_scores": {
        "2601.05894v1": {
          "score": 0.01639344262295082,
          "rank": 1
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Recent advances and state-of-the-art methods in symbolic regression",
      "sim_scores": {
        "2601.16139v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.05704v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.05684v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.10028v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.21539v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.20152v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.08184v2": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.00266v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.16581v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.08614v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.15092v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.13266v2": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.00429v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.00754v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.16071v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.05119v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.01104v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.17969v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.08111v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.00116v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.11782v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.05557v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.04378v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.01499v2": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.14917v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.06785v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.11615v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.10262v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.15252v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.09548v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.13124v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.08474v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.17800v2": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.17250v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.14355v2": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.12351v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.00280v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.16626v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.19331v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2602.05841v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.04531v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2602.00233v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.07630v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.17832v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.17169v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.21156v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.16105v2": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.03860v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.00578v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.17539v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.07639v2": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.20122v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.02131v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.14920v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.11133v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.07511v2": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.08092v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.02997v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.14803v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.14453v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.09102v2": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.17742v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.02876v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.06841v2": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.17345v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.01471v2": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.18138v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.12427v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2602.01112v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.08704v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2602.01178v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.21871v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.15138v2": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2602.04654v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.03739v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01014v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.00278v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.14095v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.16765v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.13794v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.22072v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.15243v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.01001v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.08399v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.15905v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.22287v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2602.01080v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.16607v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.10895v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.09517v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.21958v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.09509v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.18153v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2602.04283v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.09472v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2602.00963v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2602.03642v2": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.12016v2": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.07000v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.09510v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR",
      "paper_tag": "query:SR",
      "query_text": "Symbolic regression methods and applications",
      "sim_scores": {
        "2602.08270v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.05894v1": {
          "score": 0.016129032258064516,
          "rank": 2
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR-LNS",
      "paper_tag": "query:SR-LNS",
      "query_text": "adaptive large neighborhood search for mathematical expression discovery",
      "sim_scores": {
        "2601.21227v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.07564v1": {
          "score": 0.016129032258064516,
          "rank": 2
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR-LNS",
      "paper_tag": "query:SR-LNS",
      "query_text": "hybrid genetic programming and large neighborhood search for regression",
      "sim_scores": {
        "2602.05371v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.18846v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.13465v3": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.01475v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.15552v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.00488v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.02311v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.17408v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.03258v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.00580v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.21759v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.02057v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.05358v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02143v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.07782v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.21513v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.13938v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.22944v2": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.05537v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.05786v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.08403v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.19477v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.11443v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.08216v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.09515v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.04536v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.12681v2": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.22584v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.03357v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.09692v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.14991v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.01711v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.21208v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.07281v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.18664v2": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.19266v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.21853v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.22563v2": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.14686v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.12400v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.12078v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.09684v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.22538v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.14446v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.00576v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.03608v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.23114v2": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.19395v2": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.04352v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.04066v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.22961v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.01186v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.20627v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.20646v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.19535v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.05930v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2602.00805v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.20397v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.15127v2": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.09304v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2602.05848v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.06352v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.18251v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.10995v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.22298v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.03641v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.21355v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.17567v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.13922v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.02382v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.07055v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2602.01237v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.17257v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.21061v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.02636v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.05465v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.04153v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.10657v2": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2602.03690v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.08528v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.01331v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.13013v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.05036v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.11161v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.03506v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.11883v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.08621v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.21452v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.07048v3": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.10581v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.08991v2": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2602.02961v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.10176v2": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.16858v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.07125v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.23238v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2602.03329v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.11311v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.19833v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.02015v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR-LNS",
      "paper_tag": "query:SR-LNS",
      "query_text": "state-of-the-art symbolic regression using metaheuristic search",
      "sim_scores": {
        "2602.05704v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.00429v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.15092v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.16581v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.08614v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.16139v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.05684v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.05119v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.00266v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.10028v2": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.13266v2": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.21539v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.00754v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.08184v2": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.20152v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.00116v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.11782v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.01104v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.08111v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.05557v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.17969v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.14917v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.04378v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.15252v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.16071v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.13124v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.11615v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.17250v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.12351v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.17800v2": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.19331v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.01499v2": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.08474v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.07630v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.06785v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.02131v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.04531v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.09548v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.17742v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.16105v2": {
          "score": 0.01,
          "rank": 40
        },
        "2601.14355v2": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2602.00280v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.10262v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.14803v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.17169v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.16626v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.17832v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.21156v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.00233v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.01471v2": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.11133v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.09102v2": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.05841v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.17539v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.18138v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.07511v2": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.07639v2": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.00578v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.08092v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.12427v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.06841v2": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2602.02876v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.14453v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2602.03860v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.08704v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.01001v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2602.02997v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.20122v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.15138v2": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.04654v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2602.01178v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.14095v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.14920v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.21871v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.00278v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01112v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.17345v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2602.03739v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.15243v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.16607v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.01080v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.08399v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.01014v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.22072v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.00963v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.16765v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2602.04283v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.10895v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.13794v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.15905v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.07000v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.22287v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.21958v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.18153v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.09509v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.09510v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.09517v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.12016v2": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.09472v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.03642v2": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR-RL",
      "paper_tag": "query:SR-RL",
      "query_text": "how to use policy gradient to optimize mathematical expressions",
      "sim_scores": {
        "2602.05119v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.05704v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.16581v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.13266v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.04378v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.15092v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.11782v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.17969v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.00754v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.00429v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.08111v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.13124v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.05684v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.08184v2": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.15252v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.05557v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.17250v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.20152v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.19331v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.17800v2": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.10028v2": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.17832v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.08614v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.16139v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.21539v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.14355v2": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.00266v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.00116v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.16071v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.17169v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.16607v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.08474v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.06785v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.12351v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.01499v2": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.04531v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.09548v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.01014v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.00280v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.16105v2": {
          "score": 0.01,
          "rank": 40
        },
        "2602.05841v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.11133v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.12427v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2602.01112v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.00578v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.17539v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.07630v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.03739v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.06841v2": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.02131v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2602.01471v2": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.00233v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.21156v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2602.01178v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.17742v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.02997v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.07511v2": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.08092v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.14803v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.07639v2": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.15138v2": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.20122v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.21871v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2602.01104v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.01080v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.04654v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.15905v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.14917v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.18138v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.14453v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.09102v2": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.10262v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.02876v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2602.03860v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.08704v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.10895v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.04283v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.14920v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.22072v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.07000v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.11615v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.16626v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.09517v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.15243v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.13794v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.17345v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2602.00278v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2602.01001v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.21958v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2602.01782v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.22049v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.22287v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2602.00963v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.16765v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.01398v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.09510v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.08399v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.14095v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.09472v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.09509v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "intent_query",
      "tag": "SR-RL",
      "paper_tag": "query:SR-RL",
      "query_text": "state-of-the-art reinforcement learning methods for symbolic regression",
      "sim_scores": {
        "2601.14693v1": {
          "score": 0.03278688524590164,
          "rank": 1
        },
        "2601.20071v2": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.20714v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.07118v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.20585v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.19720v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.05890v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.05999v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.02978v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.05379v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.03816v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.08107v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.13642v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.08136v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.09236v2": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.08726v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.11217v2": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.20116v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.08271v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.03171v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.18952v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.19452v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.18907v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.02098v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.01260v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.20193v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.02924v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.13284v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.21924v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.22823v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.01460v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.04181v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.16399v2": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2602.03201v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.04599v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.23075v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.21845v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.22211v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.05494v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.19284v2": {
          "score": 0.01,
          "rank": 40
        },
        "2601.18533v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.18107v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.22350v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.08646v3": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.03073v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.20802v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.03301v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.02150v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.05323v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.23010v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.21391v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.05776v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.00587v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.18626v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.21301v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.16403v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.22491v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.02722v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.21476v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.22891v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.17454v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.15761v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.00031v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.09083v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.02488v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.07164v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.18142v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.18479v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.15363v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.07524v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2602.01705v2": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.23058v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.01511v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2602.02900v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.02847v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.18795v2": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.01606v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.22900v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.11401v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.22496v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.12008v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.22044v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.18751v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.05933v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.02555v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2602.04417v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.05870v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2602.05863v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.14234v2": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2602.03876v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.10079v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.06336v2": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.21477v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2602.03309v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.14957v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.19707v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2602.05019v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2602.00921v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2602.05183v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.05630v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Genetic Programming",
      "sim_scores": {
        "2602.07310v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.14485v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.15070v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.15717v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.07659v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.01510v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.09772v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.15738v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.08885v3": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.10891v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.03840v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.04529v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.00843v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.00755v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2602.17082v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.08657v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.13864v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.10740v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.13410v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.14480v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2602.04901v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.12274v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.11487v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.08884v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.06820v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.01209v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.20693v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.00429v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.13407v2": {
          "score": 0.011235955056179775,
          "rank": 29
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Genetic programming for symbolic model discovery",
      "sim_scores": {
        "2602.04066v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.22203v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.03506v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.22688v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.02382v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.09381v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.22642v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.02143v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.02311v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.23085v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.10581v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.09446v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.20909v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.18383v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.11683v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.18846v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.01237v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.05539v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.07782v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.04892v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.10740v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.02623v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.22010v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.16199v2": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.15756v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.19094v2": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.12842v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.18091v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.02313v2": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.22617v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.23236v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.09692v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.13465v3": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.07525v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.05523v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.00092v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.09093v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.21096v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.13922v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.07180v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.01070v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.15127v2": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.05048v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.09473v2": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.14971v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.05930v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.22977v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.05307v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.18771v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.10995v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2602.05182v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.21882v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.01626v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.18204v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.07794v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.03006v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.22563v2": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.06019v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.11340v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2602.01475v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2602.05353v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.18949v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.16530v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.08517v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.01171v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.01711v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.13387v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2602.03695v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.22997v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.13969v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.09281v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.11124v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.14446v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.06352v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.09195v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.07477v2": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.02834v2": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2602.02010v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2602.02909v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2602.02138v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.07641v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.05705v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.05798v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.03772v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.01848v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.18734v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.22040v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.17426v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.20055v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.22269v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.15158v3": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.10101v2": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.19847v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.07593v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.03550v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.14349v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.08058v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.06779v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.12986v2": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.21571v2": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Reinforcement Learning",
      "sim_scores": {
        "2602.02710v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.13949v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.07948v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.16543v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.07719v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.18419v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.18953v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.16475v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.07821v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.06960v2": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.01260v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.12099v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.08244v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.12886v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.23058v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.21912v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.18533v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.21312v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.20802v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.22149v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2602.10894v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.20688v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.13284v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.05578v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.12146v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.17275v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.14697v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.06603v2": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.14338v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.06440v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.03048v2": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.03048v3": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.00400v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2602.14468v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.11455v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.04879v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.17038v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.02192v3": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.02192v2": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.18150v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.03352v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2602.00759v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.06107v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2602.15245v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.10019v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.09207v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.01388v2": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.13953v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.10539v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.01156v1": {
          "score": 0.00909090909090909,
          "rank": 50
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Reinforcement learning based symbolic regression",
      "sim_scores": {
        "2601.14693v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.20071v2": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.20585v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.05999v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.02978v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.20714v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.03816v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.07118v2": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.04181v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.19720v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.05890v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.09236v2": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.23075v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.22350v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.22823v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.05379v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.20116v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.13284v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.19452v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.08271v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.08107v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.08726v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.18952v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.21301v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.08136v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.05494v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.18907v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.02098v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.03171v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.18107v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.22211v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.00031v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.21845v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.13642v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.18626v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.05323v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.04599v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.16399v2": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.15014v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2602.01260v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.22891v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.09083v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.18533v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.11217v2": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.21476v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.20802v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.21391v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.14234v2": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.03301v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.03201v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.21924v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.15761v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.02150v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2602.02847v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2602.00587v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.03309v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2602.03073v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.07164v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2602.01705v2": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.22496v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2602.04417v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.23010v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.05863v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.22491v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.08646v3": {
          "score": 0.008,
          "rank": 65
        },
        "2602.01606v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.06336v2": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.05870v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2602.02722v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.00629v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2602.01460v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.22044v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.02708v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.18795v2": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.07408v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.05776v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.22595v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2602.05019v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.23058v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2602.05281v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.02900v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.19612v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.10079v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.05630v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.02555v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.20193v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2602.02924v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.11401v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.07524v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2602.02488v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.18751v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2602.03876v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.16403v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.19707v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.05933v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2602.01511v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.22900v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2602.00921v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.15363v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.15141v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Symbolic Regression",
      "sim_scores": {
        "2601.14693v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.08270v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.08885v3": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.15169v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.20637v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.13021v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.03506v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.00031v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.07727v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.17082v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.01510v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.22328v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.21789v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02311v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.19477v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.16852v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.12259v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.08733v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.07834v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.12870v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.14288v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.16166v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.01149v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.02886v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.10576v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.12109v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.07651v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.05894v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.10379v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.12979v2": {
          "score": 0.011111111111111112,
          "rank": 30
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR",
      "paper_tag": "keyword:SR",
      "query_text": "Symbolic regression methods and applications",
      "sim_scores": {
        "2602.05704v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.16139v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.05119v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.13266v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.20152v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.08184v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.10028v2": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.00754v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.08614v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.05684v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.21539v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.01104v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.15092v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.00266v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.16581v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.00429v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.08111v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.16071v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.00116v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.17969v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.11782v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.15252v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.05557v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.04378v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.01499v2": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.09548v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.13124v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.14917v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.11615v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.08474v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.10262v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.14355v2": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.12351v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.17250v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.17800v2": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.19331v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.17832v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.00233v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.04531v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.21156v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.06785v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.16626v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.00578v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2602.00280v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.05841v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.11133v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.16105v2": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.09102v2": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.07630v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.01471v2": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.17169v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.07511v2": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.02876v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.14803v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2602.03860v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.14920v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.17539v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.08092v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.07639v2": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.17742v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.12427v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2602.02997v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.18138v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.20122v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.02131v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.04654v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.15138v2": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.21871v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2602.01178v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.01112v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.14453v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.06841v2": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.00278v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.08704v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.03739v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01080v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.16765v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.17345v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.14095v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.22072v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.01001v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.13794v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.15243v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.01014v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.16607v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.22287v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.09517v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.09472v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.09510v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.15905v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.08399v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.07000v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.18153v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.10895v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.09509v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2602.00963v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2602.04283v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2602.01398v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.12016v2": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.01782v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "ALNS",
      "sim_scores": {
        "2601.12151v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.11414v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.17214v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.10495v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.12956v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.13827v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.22052v2": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.19201v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.20691v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.11010v1": {
          "score": 0.014285714285714285,
          "rank": 10
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "adaptive large neighborhood search for symbolic regression",
      "sim_scores": {
        "2601.07372v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.03539v2": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.13953v2": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.03290v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.11616v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.00987v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.12023v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.11420v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.14173v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.05225v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.21707v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.17112v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.02319v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.21835v2": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2602.04272v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.16842v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.05266v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.16200v2": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.04936v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.12957v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.16945v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.02759v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.20442v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.01412v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.12703v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.02201v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.19092v2": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.11491v2": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.20528v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.00387v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.20043v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.17188v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.00913v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.21623v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.03394v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.02920v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.08067v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.04490v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.01105v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2602.02753v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.00816v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.19551v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.18264v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.19016v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.16636v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.19250v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.21287v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.12442v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.07325v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.07892v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.12700v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.01956v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.01587v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.12121v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.11135v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.03134v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.18728v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.14013v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2602.05549v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.20254v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.22610v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.17646v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.07261v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.16038v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.12637v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.23252v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.21662v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2602.01075v2": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.22327v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.04767v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.20480v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.10248v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.00161v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.22825v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.00901v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.18619v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.09981v2": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2602.00547v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.12219v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.07074v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.09253v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2602.01667v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.01490v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.22760v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.17260v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.13712v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.17180v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.12865v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.23182v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.18524v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.12566v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2602.02944v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2602.04523v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.13645v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.01042v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.11464v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.12220v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.06599v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.19257v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.19026v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "large neighborhood search",
      "sim_scores": {
        "2601.11414v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.08253v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.11010v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.22052v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.12055v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.17899v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.05358v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.05358v2": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.08616v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.11047v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.17495v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.07948v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.13969v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.08621v1": {
          "score": 0.013513513513513514,
          "rank": 14
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "large neighborhood search (LNS) optimization",
      "sim_scores": {
        "2601.08535v2": {
          "score": 0.01639344262295082,
          "rank": 1
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "local search",
      "sim_scores": {
        "2602.05675v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.01475v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.06318v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.07948v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.11883v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.16156v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.14212v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.11841v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.04745v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.12005v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.13266v2": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.12465v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.13046v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.01209v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.11144v3": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.08952v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.08253v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.22075v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.04248v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.11389v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.19041v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.13532v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.12040v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.18005v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.09424v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.08473v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.13494v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.16473v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.10159v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.14162v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.14985v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.08501v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.06566v2": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.07621v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.23023v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.02623v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.15921v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.06269v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.16819v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.08084v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.02486v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.12667v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.21481v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.22369v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.00667v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.23232v2": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.08495v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.05371v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.02999v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.07465v1": {
          "score": 0.00909090909090909,
          "rank": 50
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "local search heuristics in symbolic regression",
      "sim_scores": {
        "2602.03506v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.13465v3": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.05371v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.01475v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.22538v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.00580v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.07782v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.03258v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.02623v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.00488v2": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.08403v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.02311v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.19477v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.15552v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.18846v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.05930v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.23085v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.23208v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.01711v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.09166v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2602.01070v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.07281v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.08621v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.22944v2": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.01485v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.12400v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.15423v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.18771v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.19395v2": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.03357v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.02382v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.09381v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.14615v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2602.03304v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.12842v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.02015v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.19094v2": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.12027v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.05539v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.08216v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.05358v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.15127v2": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.02080v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.14991v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.22977v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.11883v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.21200v2": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.17309v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.22899v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.18253v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.21513v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.22688v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.04906v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.15158v3": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2602.02057v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.02143v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.23207v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.04941v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.08991v2": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.21731v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.21929v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.22617v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.18917v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.22274v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.03329v1": {
          "score": 0.008,
          "rank": 65
        },
        "2602.03647v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.22010v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.05647v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.21608v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.01237v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.18608v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.22323v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.12681v2": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2602.03719v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.23236v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.18383v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.05036v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.13387v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.09515v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.21615v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.02162v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.20970v2": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.09550v2": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.20014v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.17408v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.21759v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.15871v2": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.15124v2": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.09692v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.21684v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2602.03608v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.14686v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.16249v2": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.20772v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.02909v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.22336v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.14971v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.05537v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2602.04536v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.00931v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "symbolic regression",
      "sim_scores": {
        "2601.14693v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.08270v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.08885v3": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.15169v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.20637v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.13021v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.03506v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.00031v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.07727v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.17082v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.01510v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.22328v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.21789v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02311v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.19477v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.16852v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.12259v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.08733v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.07834v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.12870v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.14288v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.16166v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.01149v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.02886v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.10576v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.12109v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.07651v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.05894v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.10379v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.12979v2": {
          "score": 0.011111111111111112,
          "rank": 30
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-LNS",
      "paper_tag": "keyword:SR-LNS",
      "query_text": "symbolic regression algorithms and methods",
      "sim_scores": {
        "2602.05704v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.16139v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.05119v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.13266v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.08614v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.10028v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.20152v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.08184v2": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.00754v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.21539v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.15092v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.05684v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.01104v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.00266v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.08111v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.16581v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.00429v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.00116v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.16071v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.17969v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.11782v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.15252v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.05557v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.04378v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.01499v2": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.11615v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.09548v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.14917v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.13124v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.10262v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.12351v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.17800v2": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.08474v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.06785v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.00233v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.14355v2": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.04531v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.16626v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.19331v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.17250v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.17832v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.16105v2": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.00280v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.07630v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.17169v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.00578v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.11133v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.21156v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.05841v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.14803v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.09102v2": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.02876v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2602.01471v2": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.07511v2": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2602.02131v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.17742v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2602.02997v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2602.03860v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.14920v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.07639v2": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.18138v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.08092v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.04654v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.20122v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.14453v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.17539v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.12427v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.15138v2": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.21871v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.06841v2": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2602.01112v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2602.00278v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.01178v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.14095v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.03739v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01080v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.16765v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.08704v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.15243v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.22072v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.01001v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.13794v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.17345v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.16607v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.01014v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.08399v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.22287v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.09517v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.09472v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.09510v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.10895v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.18153v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.07000v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.15905v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.09509v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2602.01398v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.21958v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2602.00963v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2602.04283v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.12016v2": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "Transformer",
      "sim_scores": {
        "2602.08267v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.08857v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.06300v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.08695v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.12681v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.16450v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.10519v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.07070v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.14318v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.13224v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.14803v3": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.10876v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.05618v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.18274v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2602.16608v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.16914v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.07930v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.12571v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.08920v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.10434v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2602.16264v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.15509v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.09467v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.07677v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.21069v2": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.00856v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.14875v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.06597v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.13188v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.17307v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.05770v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.18385v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.12515v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.21942v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.20854v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2602.05896v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2602.05523v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.22081v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.17724v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.20796v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.06246v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2602.11145v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.13067v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.20116v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.14522v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2601.06365v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.12480v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.15348v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.11237v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.15158v3": {
          "score": 0.00909090909090909,
          "rank": 50
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "Transformer models for symbolic regression tasks",
      "sim_scores": {
        "2602.03506v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.02385v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.17257v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.05647v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.02834v2": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.05539v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.05371v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.21929v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.22257v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.23208v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.23236v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.03641v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.02015v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02162v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.18253v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.12681v2": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.19208v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.17533v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.09692v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.22538v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.21795v2": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.22336v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.17986v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.08991v2": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.21571v2": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.07782v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.02382v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.22966v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.15158v3": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.22593v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.23085v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2602.01237v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.05649v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2602.02311v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.21708v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.07281v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.14172v2": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.22852v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.22478v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2602.00576v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.13387v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.12039v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.14971v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.09381v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.03351v2": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.03422v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.04906v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.13588v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2602.02564v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.21369v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.13288v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.22298v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.10058v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2602.01711v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.22617v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.05807v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.12467v2": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.22040v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.05588v2": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.22944v2": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.13525v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.12051v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.14112v2": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2602.02551v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.10566v3": {
          "score": 0.008,
          "rank": 65
        },
        "2601.19613v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.22688v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2602.03945v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.14007v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.19266v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.22694v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.17408v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.00092v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.05877v2": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.17958v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.21759v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.19477v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2602.01217v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.12260v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2602.03980v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.17309v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2602.02592v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.04486v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.04941v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.01626v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.21986v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.07474v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.06352v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2602.01186v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.13922v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.21789v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.21513v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2601.09026v2": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.12078v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.18213v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.12711v1": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.13700v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.16979v2": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2602.04536v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.15423v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "automated equation discovery from data using RL",
      "sim_scores": {
        "2602.00987v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.21707v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.07372v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.02201v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.12220v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.03290v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.14059v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.19453v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.00547v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.05266v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.16038v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.03539v2": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.12442v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02759v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.07967v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.18728v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.04523v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.21623v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.04936v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.11616v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.19016v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.06535v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.17188v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.22327v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2601.14732v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.01075v2": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.13953v2": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.06289v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.22610v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.17112v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.19250v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.12700v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.11135v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.12703v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.11491v2": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.20043v1": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.13712v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2602.02780v2": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.15214v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.08584v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.07325v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.09253v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2602.05977v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2602.05225v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2602.02742v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.03394v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.20113v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.21662v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.16047v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.14173v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.19257v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2601.19259v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.16945v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.13195v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.17026v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.18524v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.12219v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.10667v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2601.16193v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2602.00913v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.17204v2": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2602.00756v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.05549v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2602.00660v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.12023v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.12957v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.10131v2": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.21964v2": {
          "score": 0.0078125,
          "rank": 68
        },
        "2602.04696v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2602.01667v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.21191v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.08073v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2601.14710v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.15333v2": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2602.03523v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2601.09693v2": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2602.02940v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.15430v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.19567v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.12859v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.02920v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.21835v2": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.18619v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.20254v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.18264v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.17981v2": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.22191v2": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.22312v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2602.04889v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.06916v2": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.10362v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.15279v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2602.00816v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2602.04734v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.04767v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.16200v2": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.20442v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.21601v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.14598v2": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.03875v2": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "comparison between genetic programming and RL-based symbolic regression",
      "sim_scores": {
        "2602.00429v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.05704v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.15092v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2601.11782v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.16581v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.00266v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.05684v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.05119v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.08614v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.13266v2": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.17969v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.10028v2": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.00116v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.21539v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.05557v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.00754v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.16139v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.08184v2": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.15252v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.08474v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.13124v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.17800v2": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.20152v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.16071v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.01499v2": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.08111v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.14917v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.04378v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.11615v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.17250v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.01104v1": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.09548v1": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2601.10262v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2601.19331v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2601.12351v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.14355v2": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.07630v1": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.17742v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2602.04531v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2601.21156v1": {
          "score": 0.01,
          "rank": 40
        },
        "2601.06841v2": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.17169v1": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.17832v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.07639v2": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.08092v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.01471v2": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2601.16626v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2602.01112v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.06785v1": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2602.02131v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2602.01178v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.00280v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.12427v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2602.05841v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2601.15138v2": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2602.03739v1": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2601.07511v2": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.16105v2": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2602.02997v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.14803v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2602.02876v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2602.00578v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2601.20122v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.21871v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2601.16607v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.17539v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2601.14453v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2601.11133v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2601.18138v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.15905v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.14920v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2602.03860v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.00233v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2601.09102v2": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.16765v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01014v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.15243v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.13794v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.17345v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2601.08399v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2601.12016v2": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.22287v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2601.14095v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2602.04654v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2601.09509v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2602.01001v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2602.00278v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2601.18153v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.08704v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2601.22072v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2602.01080v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.07000v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2602.01782v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2602.04283v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2602.00963v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.13921v2": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.09517v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.22049v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.09472v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2601.16729v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "equation discovery",
      "sim_scores": {
        "2602.12259v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.13513v2": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.13021v2": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.10576v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2602.07970v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.22328v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.04114v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2601.20637v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.14779v2": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.04907v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.05632v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.04498v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.04498v2": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.07733v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.19223v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2602.11849v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.10632v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2601.19838v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.14961v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.19091v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.10038v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.09093v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2601.12320v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.07939v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.08269v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.17493v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.04806v2": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2602.04806v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.16852v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2602.14105v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2602.16551v1": {
          "score": 0.01098901098901099,
          "rank": 31
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "reinforcement learning for mathematical expression discovery",
      "sim_scores": {
        "2601.13953v2": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2601.07372v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2601.21623v1": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.03539v2": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.15214v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2601.21601v1": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2601.16038v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.03290v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2602.01075v2": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2601.17188v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2601.14710v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2602.02201v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2602.04696v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2601.09693v2": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.20043v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.17112v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2601.12442v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.02780v2": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2601.06002v2": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2601.11616v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.14173v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2601.22610v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.02686v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2601.08073v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.05977v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2601.17260v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2601.22327v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.09981v2": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2602.02940v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.12023v1": {
          "score": 0.011111111111111112,
          "rank": 30
        },
        "2601.16200v2": {
          "score": 0.01098901098901099,
          "rank": 31
        },
        "2601.15333v2": {
          "score": 0.010869565217391304,
          "rank": 32
        },
        "2602.01587v1": {
          "score": 0.010752688172043012,
          "rank": 33
        },
        "2602.05266v1": {
          "score": 0.010638297872340425,
          "rank": 34
        },
        "2602.00913v1": {
          "score": 0.010526315789473684,
          "rank": 35
        },
        "2601.10131v2": {
          "score": 0.010416666666666666,
          "rank": 36
        },
        "2601.21835v2": {
          "score": 0.010309278350515464,
          "rank": 37
        },
        "2601.21191v1": {
          "score": 0.01020408163265306,
          "rank": 38
        },
        "2601.09253v1": {
          "score": 0.010101010101010102,
          "rank": 39
        },
        "2602.02759v1": {
          "score": 0.01,
          "rank": 40
        },
        "2602.02920v1": {
          "score": 0.009900990099009901,
          "rank": 41
        },
        "2601.19092v2": {
          "score": 0.00980392156862745,
          "rank": 42
        },
        "2601.06300v1": {
          "score": 0.009708737864077669,
          "rank": 43
        },
        "2601.12700v1": {
          "score": 0.009615384615384616,
          "rank": 44
        },
        "2601.22408v1": {
          "score": 0.009523809523809525,
          "rank": 45
        },
        "2602.05549v1": {
          "score": 0.009433962264150943,
          "rank": 46
        },
        "2602.01956v1": {
          "score": 0.009345794392523364,
          "rank": 47
        },
        "2601.12219v1": {
          "score": 0.009259259259259259,
          "rank": 48
        },
        "2601.21964v2": {
          "score": 0.009174311926605505,
          "rank": 49
        },
        "2601.06599v1": {
          "score": 0.00909090909090909,
          "rank": 50
        },
        "2601.22760v1": {
          "score": 0.009009009009009009,
          "rank": 51
        },
        "2602.00944v1": {
          "score": 0.008928571428571428,
          "rank": 52
        },
        "2601.10157v1": {
          "score": 0.008849557522123894,
          "rank": 53
        },
        "2601.21662v1": {
          "score": 0.008771929824561403,
          "rank": 54
        },
        "2602.01105v1": {
          "score": 0.008695652173913044,
          "rank": 55
        },
        "2601.11491v2": {
          "score": 0.008620689655172414,
          "rank": 56
        },
        "2602.03134v1": {
          "score": 0.008547008547008548,
          "rank": 57
        },
        "2601.08584v1": {
          "score": 0.00847457627118644,
          "rank": 58
        },
        "2602.01667v1": {
          "score": 0.008403361344537815,
          "rank": 59
        },
        "2601.19259v1": {
          "score": 0.008333333333333333,
          "rank": 60
        },
        "2601.19257v1": {
          "score": 0.008264462809917356,
          "rank": 61
        },
        "2601.14732v1": {
          "score": 0.00819672131147541,
          "rank": 62
        },
        "2602.02742v1": {
          "score": 0.008130081300813009,
          "rank": 63
        },
        "2601.10667v1": {
          "score": 0.008064516129032258,
          "rank": 64
        },
        "2602.03096v1": {
          "score": 0.008,
          "rank": 65
        },
        "2601.19551v1": {
          "score": 0.007936507936507936,
          "rank": 66
        },
        "2602.00547v1": {
          "score": 0.007874015748031496,
          "rank": 67
        },
        "2602.05479v1": {
          "score": 0.0078125,
          "rank": 68
        },
        "2602.03394v1": {
          "score": 0.007751937984496124,
          "rank": 69
        },
        "2601.21678v1": {
          "score": 0.007692307692307693,
          "rank": 70
        },
        "2601.16945v1": {
          "score": 0.007633587786259542,
          "rank": 71
        },
        "2601.15890v1": {
          "score": 0.007575757575757576,
          "rank": 72
        },
        "2602.04936v1": {
          "score": 0.007518796992481203,
          "rank": 73
        },
        "2602.00987v1": {
          "score": 0.007462686567164179,
          "rank": 74
        },
        "2601.22382v1": {
          "score": 0.007407407407407408,
          "rank": 75
        },
        "2602.01042v1": {
          "score": 0.007352941176470588,
          "rank": 76
        },
        "2601.07261v1": {
          "score": 0.0072992700729927005,
          "rank": 77
        },
        "2601.07892v1": {
          "score": 0.007246376811594203,
          "rank": 78
        },
        "2601.19232v1": {
          "score": 0.007194244604316547,
          "rank": 79
        },
        "2602.04916v1": {
          "score": 0.007142857142857143,
          "rank": 80
        },
        "2602.04489v1": {
          "score": 0.0070921985815602835,
          "rank": 81
        },
        "2601.10254v1": {
          "score": 0.007042253521126761,
          "rank": 82
        },
        "2602.00161v1": {
          "score": 0.006993006993006993,
          "rank": 83
        },
        "2601.23182v1": {
          "score": 0.006944444444444444,
          "rank": 84
        },
        "2602.00663v1": {
          "score": 0.006896551724137931,
          "rank": 85
        },
        "2601.21287v1": {
          "score": 0.00684931506849315,
          "rank": 86
        },
        "2601.11135v1": {
          "score": 0.006802721088435374,
          "rank": 87
        },
        "2602.00461v1": {
          "score": 0.006756756756756757,
          "rank": 88
        },
        "2601.12220v1": {
          "score": 0.006711409395973154,
          "rank": 89
        },
        "2602.01200v1": {
          "score": 0.006666666666666667,
          "rank": 90
        },
        "2601.11028v1": {
          "score": 0.006622516556291391,
          "rank": 91
        },
        "2601.16086v1": {
          "score": 0.006578947368421052,
          "rank": 92
        },
        "2602.01216v1": {
          "score": 0.006535947712418301,
          "rank": 93
        },
        "2601.23212v1": {
          "score": 0.006493506493506494,
          "rank": 94
        },
        "2601.09285v1": {
          "score": 0.0064516129032258064,
          "rank": 95
        },
        "2601.05605v2": {
          "score": 0.00641025641025641,
          "rank": 96
        },
        "2601.12703v1": {
          "score": 0.006369426751592357,
          "rank": 97
        },
        "2601.13927v1": {
          "score": 0.006329113924050633,
          "rank": 98
        },
        "2601.19016v1": {
          "score": 0.006289308176100629,
          "rank": 99
        },
        "2602.04272v1": {
          "score": 0.00625,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "SR-RL",
      "paper_tag": "keyword:SR-RL",
      "query_text": "symbolic regression",
      "sim_scores": {
        "2601.14693v1": {
          "score": 0.01639344262295082,
          "rank": 1
        },
        "2602.08270v1": {
          "score": 0.016129032258064516,
          "rank": 2
        },
        "2602.08885v3": {
          "score": 0.015873015873015872,
          "rank": 3
        },
        "2602.15169v1": {
          "score": 0.015625,
          "rank": 4
        },
        "2601.20637v1": {
          "score": 0.015384615384615385,
          "rank": 5
        },
        "2602.13021v2": {
          "score": 0.015151515151515152,
          "rank": 6
        },
        "2602.03506v1": {
          "score": 0.014925373134328358,
          "rank": 7
        },
        "2602.00031v1": {
          "score": 0.014705882352941176,
          "rank": 8
        },
        "2601.07727v1": {
          "score": 0.014492753623188406,
          "rank": 9
        },
        "2602.17082v1": {
          "score": 0.014285714285714285,
          "rank": 10
        },
        "2602.01510v1": {
          "score": 0.014084507042253521,
          "rank": 11
        },
        "2601.22328v1": {
          "score": 0.013888888888888888,
          "rank": 12
        },
        "2601.21789v1": {
          "score": 0.0136986301369863,
          "rank": 13
        },
        "2602.02311v1": {
          "score": 0.013513513513513514,
          "rank": 14
        },
        "2601.19477v1": {
          "score": 0.013333333333333334,
          "rank": 15
        },
        "2601.16852v1": {
          "score": 0.013157894736842105,
          "rank": 16
        },
        "2602.12259v1": {
          "score": 0.012987012987012988,
          "rank": 17
        },
        "2602.08733v1": {
          "score": 0.01282051282051282,
          "rank": 18
        },
        "2602.07834v1": {
          "score": 0.012658227848101266,
          "rank": 19
        },
        "2602.12870v1": {
          "score": 0.0125,
          "rank": 20
        },
        "2601.14288v1": {
          "score": 0.012345679012345678,
          "rank": 21
        },
        "2602.16166v1": {
          "score": 0.012195121951219513,
          "rank": 22
        },
        "2602.01149v1": {
          "score": 0.012048192771084338,
          "rank": 23
        },
        "2602.02886v1": {
          "score": 0.011904761904761904,
          "rank": 24
        },
        "2602.10576v1": {
          "score": 0.011764705882352941,
          "rank": 25
        },
        "2602.12109v1": {
          "score": 0.011627906976744186,
          "rank": 26
        },
        "2602.07651v1": {
          "score": 0.011494252873563218,
          "rank": 27
        },
        "2601.05894v1": {
          "score": 0.011363636363636364,
          "rank": 28
        },
        "2601.10379v1": {
          "score": 0.011235955056179775,
          "rank": 29
        },
        "2601.12979v2": {
          "score": 0.011111111111111112,
          "rank": 30
        }
      }
    }
  ]
}