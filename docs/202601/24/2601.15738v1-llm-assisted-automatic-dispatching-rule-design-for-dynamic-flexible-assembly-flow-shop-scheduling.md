# LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling
# 大语言模型辅助的动态柔性装配流水车间调度自动派工规则设计

**Authors**: Junhao Qiu, Haoyang Zhuang, Fei Liu, Jianjun Liu, Qingfu Zhang \
**Date**: 2026-01-22 \
**PDF**: https://arxiv.org/pdf/2601.15738v1 \
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 10.0 \
**Evidence**: LLM辅助的调度启发式算法自动设计 \
**TLDR**: 开发了一种LLM辅助方法，用于自动设计复杂调度问题的派工规则。

---

## Abstract
Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.

## 摘要
动态多产品交付

---

## 论文详细总结（自动生成）

这是一份关于论文《LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling》的结构化深入总结：

### 1. 论文的核心问题与整体含义
*   **研究背景**：在个性化定制生产环境下，制造系统正从大规模生产转向小批量定制。柔性装配流水车间调度（FAFSP）涉及零件加工与产品装配的复杂供应关系。
*   **核心挑战**：
    1.  **双重配套约束**：订单交付取决于其中最晚完成的产品，而产品完成又取决于其所有零件的加工，这种多级时间耦合在动态环境下（如订单随机到达）极难协调。
    2.  **传统方法局限**：遗传编程（GP）等自动化启发式设计方法依赖固定的符号集，难以捕捉动态不确定性的语义信息；深度强化学习（DRL）则高度依赖预定义的规则集。
*   **研究动机**：利用大语言模型（LLM）强大的代码生成与逻辑推理能力，自动设计能够感知动态特征并处理多级耦合约束的集成调度规则。

### 2. 论文提出的方法论：LLM4DRD 框架
该框架通过 LLM 驱动的演化搜索，自动生成并优化动态派工规则（PDRs）。
*   **核心思想**：建立一个“双专家”闭环机制，由算法专家（LLM-A）负责生成代码，调度专家（LLM-S）负责定性分析与反馈，结合定量仿真评估实现规则的持续演化。
*   **关键技术细节**：
    1.  **异构图建模**：将加工、装配和交付决策统一建模为异构图上的有向边排序问题，消除多级供应冲突。
    2.  **精英知识引导初始化**：不从零开始，而是提取经典规则（如 EDD）的逻辑作为初始 Prompt，引导 LLM 生成高质量的初始种群。
    3.  **双专家机制**：
        *   **LLM-A (Algorithm Expert)**：根据 Prompt 执行交叉（优势融合、探索性交叉）和变异（定向优化、参数微调）操作生成 Python 代码。
        *   **LLM-S (Scheduling Expert)**：分析规则在仿真中的表现，指出逻辑缺陷（如忽视了瓶颈延迟），并给出改进建议。
    4.  **混合评估策略**：结合定量的“平均延迟”指标和 LLM-S 的定性语义评估，为演化提供多维度导航。
    5.  **特征拟合演化**：将订单、机器、弧（Arc）三个维度的 9 类动态特征（如利用率、到期时间、剩余加工量等）输入规则函数，使规则能自适应系统状态。

### 3. 实验设计
*   **数据集与场景**：
    *   **工业实例**：基于中国某家电制造商的真实订单结构、资源配置和动态到达分布。
    *   **合成实例**：通过泊松过程模拟订单到达，设置不同的负载因子（$\mu$）和柔性因子（$\phi$）。
*   **Benchmark（基准）**：
    *   **传统 AHD 方法**：遗传编程（GP）、基因表达式编程（GEP）。
    *   **LLM 驱动方法**：EOH、FunSearch、MCTS-AHD、ReEvo、RandSample。
    *   **经典规则**：EDD 以及 FIFO、SPT、MOPNR 等 9 种组合规则。
*   **对比维度**：训练集表现、测试集泛化性、不同负载下的鲁棒性、收敛效率。

### 4. 资源与算力
*   **硬件环境**：Intel Core i5-12600KF CPU。
*   **模型使用**：主要使用 **GPT-4o-mini** 作为核心引擎。
*   **对比模型**：实验中对比了 Qwen-2-72B、Claude-3.5-Sonnet、DeepSeek-Chat 等模型的代码准确率与成本效益。
*   **算力说明**：文中未提及 GPU 训练，因为该方法属于基于 LLM API 的推理与演化，主要算力消耗在 LLM 的 Token 生成和本地调度仿真器的运行上。

### 5. 实验数量与充分性
*   **实验规模**：
    *   **基础对比**：20 个代表性工业实例（10 个训练，10 个测试）。
    *   **鲁棒性测试**：构建了 **24 种不同工况场景**（涵盖不同机器规模、柔性、订单量、负载强度），共计 **480 个测试实例**。
    *   **消融实验**：针对动态特征、精英初始化、双专家机制等 5 个核心模块进行了独立验证。
*   **充分性评价**：实验设计非常充分。不仅对比了最先进的 LLM-AHD 框架，还通过大规模的工况组合验证了规则的泛化能力，确保了结果的客观性。

### 6. 主要结论与发现
*   **性能卓越**：LLM4DRD 生成的规则在平均延迟指标上比现有最强 LLM 方法提升了 **3.17% - 12.39%**。
*   **极强鲁棒性**：在 480 个变工况实例中，性能比第二名高出 **11.10%**，尤其在高负载和频繁扰动下优势更明显。
*   **收敛性**：相比 GP 或随机采样，LLM4DRD 能够利用 LLM-S 的语义反馈突破局部最优，在演化后期仍能发现更优规则。
*   **可解释性**：LLM 生成的代码逻辑清晰，能够自动整合“预测加工时间”和“历史性能因子”等高级调度逻辑。

### 7. 优点（亮点）
*   **语义导航**：引入 LLM-S 作为调度专家，将“为什么这个规则不好”转化为“如何改进”的自然语言指令，解决了数值优化中缺乏方向感的问题。
*   **冷启动优化**：通过精英知识引导，避免了 LLM 在搜索初期的盲目性，显著加快了收敛速度。
*   **端到端自动化**：从特征感知到代码实现完全自动化，生成的 Python 函数可直接部署于生产系统。

### 8. 不足与局限
*   **API 依赖与成本**：虽然使用了 GPT-4o-mini 降低成本，但大规模演化仍依赖商业 API，且存在网络延迟和隐私风险。
*   **扰动类型单一**：主要考虑了订单随机到达，未深入探讨机器故障（Breakdowns）或运输资源受限等更复杂的并发扰动。
*   **多目标平衡**：目前主要优化目标是“平均延迟”，对于能耗、成本、机器均衡等多目标调度的权衡尚待加强。

（完）
