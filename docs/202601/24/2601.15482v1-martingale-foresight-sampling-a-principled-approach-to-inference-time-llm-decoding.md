# Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding
# 鞅前瞻采样：一种基于原理的大语言模型推理时解码方法

**Authors**: Huayu Li, ZhengXiao He, Siyuan Tian, Jinghao Wen, Ao Li \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15482v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 原则性的搜索空间剪枝与解码 \
**TLDR**: 提出鞅前瞻采样，用原则性框架取代LLM解码中的临时启发式机制。

---

## Abstract
Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

## 摘要
大语言模型（LLMs）中标准的自回归解码本质上是短视的，由于其逐标记（token-by-token）的生成过程，往往无法找到全局最优的推理路径。虽然前瞻采样等推理时策略试图通过模拟未来步骤来

---

## 速览摘要（自动生成）

**问题**：传统的自回归解码存在短视问题，且现有的前瞻采样方法
