# Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling
# 动态柔性作业车间调度中遗传规划演化调度规则的泛化能力研究

**Authors**: Luyao Zhu, Fangfang Zhang, Yi Mei, Mengjie Zhang \
**Date**: 2026-01-22 \
**PDF**: https://arxiv.org/pdf/2601.15717v1 \
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 9.0 \
**Evidence**: 使用遗传编程自动进化调度规则 \
**TLDR**: 研究通过遗传编程自动进化的调度规则在复杂组合优化问题中的泛化能力。

---

## Abstract
Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.

## 摘要
动态柔性作业

---

## 论文详细总结（自动生成）

这篇论文对遗传规划（Genetic Programming, GP）演化的调度规则在动态柔性作业车间调度（DFJSS）中的泛化能力进行了系统深入的研究。以下是详细总结：

### 1. 论文的核心问题与整体含义
*   **研究动机**：DFJSS 是一个复杂的组合优化问题，涉及机器分配和工序排序。虽然 GP 已被广泛用于自动生成调度规则，但现有研究大多在相同类型（仅随机种子不同）的实例上进行训练和测试。
*   **核心问题**：GP 演化的规则在面对未见的、具有不同结构特征（如不同规模、不同参数、不同数据分布）的 DFJSS 实例时，其泛化能力（Generalisation Ability）究竟如何？
*   **背景**：在实际生产中，车间环境是动态且异构的，理解规则的跨类型泛化性对于工业应用至关重要。

### 2. 论文提出的方法论
*   **核心思想**：通过在一种类型的 DFJSS 实例上训练 GP 模型，并在多种不同属性的实例上进行交叉测试，系统评估性能衰减情况，并探究背后的机理。
*   **关键技术细节**：
    *   **多树表示法**：每个 GP 个体包含两棵树，一棵用于**路由规则**（机器分配），一棵用于**排序规则**（工序选择）。
    *   **目标函数**：最小化平均加权误期时间（Mean Weighted Tardiness, $WT_{mean}$）。
    *   **决策点分析**：引入“决策点分布”概念，通过机器工作量（Workload）等特征的分布重叠率（Overlap Ratio）来量化不同实例之间的相似性。
*   **算法流程**：训练阶段通过进化产生最优规则对；测试阶段将该规则对应用于具有不同机器数、作业数、利用率、交货期因子或批次大小的测试集。

### 3. 实验设计
*   **场景设置**：
    1.  **问题规模**：改变机器数量（2-50）和作业数量（100-10000）。
    2.  **车间参数**：改变系统利用率（0.50-0.99）、交货期紧迫度（Due Date Factor, 1.0-4.0）和批次大小（单件到巨大批次）。
    3.  **参数分布**：使用指数分布、伽马分布、对数正态分布、正态分布和均匀分布生成数据。
*   **Benchmark（基准）**：以“同类型训练与测试”的结果作为性能基准（即训练集和测试集特征完全一致时的表现）。
*   **对比方式**：采用 Wilcoxon 秩和检验（显著性水平 0.05）对比跨类型测试与基准性能的差异。

### 4. 资源与算力
*   **算力说明**：论文**未明确说明**具体的硬件型号（如 GPU/CPU 类型）或训练时长。
*   **实验参数**：提到了 GP 的超参数设置：种群大小 500，进化 100 代，每组实验独立运行 30 次以确保统计意义。

### 5. 实验数量与充分性
*   **实验规模**：论文涵盖了三大维度（规模、参数、分布）的数十种组合，每种组合均进行了 30 次独立重复实验。
*   **充分性与客观性**：实验设计非常全面，不仅观察了性能变化，还通过相关性分析（Pearson 和 Spearman 系数）验证了决策点分布与泛化性能之间的联系。使用了统计检验确保结论的可靠性，实验设计客观公平。

### 6. 论文的主要结论与发现
*   **规模影响**：在机器数固定时，在**大作业量**实例上训练的规则能很好地泛化到小作业量实例；但机器数量改变会显著降低泛化性。
*   **参数敏感性**：利用率、交货期因子和批次大小的改变均会导致性能下降。只有当训练和测试环境的参数**高度相似**时，泛化表现才较好。
*   **分布决定论**：参数分布（如从均匀分布变为正态分布）对泛化能力影响极大，跨分布泛化通常表现糟糕。
*   **底层机理**：泛化能力的强弱取决于训练与测试实例中**决策点分布的相似度**。分布重叠率越高，泛化性能越强。

### 7. 优点
*   **系统性强**：这是首个针对 DFJSS 领域 GP 规则泛化能力的全面实验研究，填补了文献空白。
*   **理论深度**：不仅停留在“性能下降”的表面，还通过决策点分布重叠率解释了“为什么下降”，为未来设计更具泛化性的算法提供了理论依据。
*   **实用价值**：发现“大规模训练可覆盖小规模”的规律，对工业界如何选择训练样本具有指导意义。

### 8. 不足与局限
*   **目标单一**：实验仅针对最小化平均加权误期时间，未探讨多目标调度下的泛化性。
*   **方法局限**：研究主要揭示了现有 GP 方法的局限性（泛化能力有限），但未在本文中提出显著提升泛化性的新算法（如元学习或终身学习机制）。
*   **特征依赖**：结论可能受到所选终端集（特征集）的影响，不同特征组合对泛化性的贡献未做消融研究。

（完）
