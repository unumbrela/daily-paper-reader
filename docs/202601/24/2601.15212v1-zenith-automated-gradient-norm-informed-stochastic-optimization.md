# ZENITH: Automated Gradient Norm Informed Stochastic Optimization
# ZENITH：自动化梯度范数告知的随机优化

**Authors**: Dhrubo Saha \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15212v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 7.0 \
**Evidence**: 学习率的自动演化 \
**TLDR**: 引入了 ZENITH，一种利用梯度范数历史自动调整学习率的优化器。

---

## Abstract
Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

## 摘要
训练深度计算机视觉模型需要对学习率（LR）调度进行人工监督或超参数调优。虽然现有的自适应优化器可以自动调度学习率，但它们往往面临计算和内存开销大、与正则化不兼容以及学习率选择次优等问题。在这项工作中，我们引入了 ZENITH（Zero-overhead Evolution using Norm-Informed Training History，基于范数告知训练历史的零开销演化）优化器，它利用梯度范数的时间演化来调整学习率。涵盖 6 种 CNN 架构和 6 个基准测试的图像分类实验表明，与基准方法相比，ZENITH 在更短的实际运行时间内实现了更高的测试准确率。在使用 R-CNN 系列模型在 MS COCO 数据集上进行的目标检测、关键点检测和实例分割任务中，它也取得了更优的平均精度均值（mAP）。此外，它与正则化的兼容性使其能够实现更佳的泛化性能。

---

## 速览摘要（自动生成）

**问题**：深度学习模型训练依赖繁琐的学习率手动调节，且现有自适应优化
