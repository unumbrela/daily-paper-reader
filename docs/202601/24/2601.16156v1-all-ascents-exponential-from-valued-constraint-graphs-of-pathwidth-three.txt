Title: All ascents exponential from valued constraint graphs of pathwidth three

URL Source: https://arxiv.org/pdf/2601.16156v1

Published Time: Fri, 23 Jan 2026 02:03:53 GMT

Number of Pages: 18

Markdown Content:
# All ascents exponential from valued constraint graphs of pathwidth three 

## Artem Kaznatcheev 1,2 and Willemijn Volgering 1,3 1Department of Mathematics, Utrecht University 

> 2

## Department of Information and Computing Sciences, Utrecht University 

> 3

## Department of Physics, Utrecht University 22 January 2026 

Abstract 

Many combinatorial optimization problems can be formulated as finding as assignment that maximized some pseudo-Boolean function (that we call the fitness function). Strict local search starts with some assignment and follows some update rule to proceed to an adjacent assignment of strictly higher fitness. This means that strict local search algorithms follow ascents in the fitness landscape of the pseudo-Boolean function. The complexity of the pseudo-Boolean function (and the fitness landscapes that it represents) can be parameterized by properties of the valued constraint satisfaction problem (VCSP) that encodes the pseudo-Boolean function. We focus on properties of the constraint graphs of the VCSP, with the intuition that spare graphs are less complex than dense ones. Specifically, we argue that pathwidth is the natural sparsity parameter for understanding limits on the power of strict local search. We show that prior constructions of sparse VCSPs where all ascents are exponentially long had pathwidth greater than or equal to four. We improve this this with our controlled doubling construction: a valued constraint satisfaction problem of pathwidth three where all ascents are exponentially long from a designated initial assignment. From this, we conclude that all strict local search algorithms can be forced to take an exponential number of steps even on simple valued constraint graphs of pathwidth three. 

# 1 Introduction 

Many combinatorial optimization problems can be formulated as finding an assignment x ∈{0, 1}d that maximizes some pseudo-Boolean function f : {0, 1}d → Z [4, 25] that we will call the 

fitness function . Often, assignments that are ‘similar’ yield similar fitness, so it becomes natural to introduce an adjacency structure based on just the assignments themselves, independent of the particular fitness function. The simplest such structure is to call two assignments adjacent 

if they differ at a single bit. A fitness landscape is such a pair of pseudo-Boolean function and assignment adjacency structure [34, 19, 20]. Local search heuristics are popular methods for navigating such fitness landscapes [32, 1]. Local search starts with some assignment and follows some update rule to proceed to an adjacent assignment until it eventually finds a good one. We say the method is a strict local search if each update step increases the fitness of the assignment. Such a method stops at some local peak x∗

such that every assignment y adjacent to x∗ has the same or lower fitness ( f (y) ≤ f (x∗)). The 1

> arXiv:2601.16156v1 [cs.DM] 22 Jan 2026

resulting sequence x0, x 1, . . . , x T = x∗ of step-wise adjacent assignments of increasing fitness is an ascent in the fitness landscape f [21, 33, 22]. There are two common modes of failure for local search. One well-known mode of failure is getting stuck in a local peak that is not the global peak. A less well-known mode of failure is taking exponentially long to find any (local) peak – even in cases where the peak is unique. Johnson, Papadimitriou, and Yannakakis [17] introduced the complexity class of polynomial-local search (PLS) to encode the problem of finding any local peak (not just the global one) and thus study this second mode of failure for both local and non-local algorithms. Under this coarse-grained complexity, it is not hard to see that fitness landscapes are PLS-complete even if we restrict to f that are at most quadratic [26, 31, 9, 5]. This means that (unless FP = PLS; which is something that most researchers do not believe to be likely) finding any local optimum in a general quadratic fitness landscapes is computationally intractable for any polynomial-time algorithm, regardless of whether it relies on local search or not. We want to build a more nuanced notion of complexity that both teaches us about the structure of easy vs hard fitness landscapes and that is specific to local search algorithms. 

## 1.1 Representing fitness landscapes by valued constraint graphs 

Our first step toward a more nuanced notion of complexity than broad PLS-completeness is to look at subclasses of pseudo-Boolean functions limited by some relevant parameter. We can find these parameters by rewriting an arbitrary pseudo-Boolean function f by its polynomial: 

f (x) = X

> S∈S

C(S) Y

> i∈S

xi (1) where S ⊆ 2[d] is a set of scopes and C : S → Z is a constraint weight function . The pair 

C = ( S, C ) is the instance of a valued constraint satisfaction problem (VCSP) that represents 

f [20]. We will often overload the notation of a VCSP-instance C to also double as the repre-sented pseudo-Boolean function with C(x) = f (x). For a general pseudo-Boolean function, the corresponding S will be exponentially large in d. So if we want d to be the ‘size’ parameter for our complexity measures then it makes sense to restrict to subclasses of pseudo-Boolean func-tions that are implemented by sets S that contain only a polynomial number of scopes. This can be done by, for example, limiting the arity of scopes to at most a constant k (i.e., |S| ≤ k

for S ∈ S ). We will be especially interested in pseudo-Boolean functions that are affine (i.e., at most unary scopes: |S| ≤ 1), quadratic (i.e., at most binary scopes: |S| ≤ 2), and cubic (i.e., at most ternary scopes: |S| ≤ 3). We will define the constraint graph of f as the hypergraph with vertexes [ d] and hyper-edges given by S. Often, we will label the hyper-edge S by the weight 

C(S) of the constraint with corresponding scope. For example: 1

−12

−3312 4 (2) will encode the pseudo-Boolean function C(x1x2x3) = −x1 − 3x2 + x3 + 2 x1x2 + 4 x2x3. We will overload the VCSP-instance C to also refer to this weighted (hyper)graph – the valued constraint graph. This allows us to measure the ‘simplicity’ of a pseudo-Boolean function through the (hyper)graph parameters of the corresponding VCSP’s constraint graph. We are especially interested in measures of simplicity like maximum degree and pathwidth. Given a set of variable indexes V (i.e., vertices) and set of scopes S (i.e., hyperedges), a path decomposition of ( V, S) is a sequence of sets (called bins) P = {X1, X 2, . . . , X p} where Xr ⊆ V

for r ∈ [p] with the following three properties: 21. Every vertex v ∈ V is in at least one bin Xr .2. For every hyperedge S ∈ S there exists an r ∈ [p] such that S ⊆ Xr .3. For every vertex v ∈ V , if v ∈ Xr ∩ Xs then v ∈ Xℓ for all ℓ such that r ≤ ℓ ≤ s.The width of a path decomposition is defined as one less than the size of the largest bin (i.e., max r∈[p] |Xr |− 1). The pathwidth of ( V, S) is the minimum possible width of a path decomposition of ( V, S). Pathwidth is a more restrictive variant of the general concept of treewidth . Since paths are a kind of tree, treewidth( V, S) ≤ pathwidth( V, S). One of the common ways to certify that a graph cannot have low treewidth is to find a large clique as a minor of the graph. Specficially, if ( V, S) has a Km minor then m ≤ treewidth( V, S) ≤ pathwidth( V, S). For more details about pathwidth (and treewidth) and their uses in parameterized complexity, see Cygan et al. [8]. 

## 1.2 Strict local search algorithms and the structure of ascents 

We focus on pathwidth as our parameter of sparsity because it illuminates limits on the power of local search versus non-local algorithms. Specifically, there exist non-local algorithms for finding a (global) optimum in VCSP-instances of bounded treewidth [3, 6]. This means that VCSPs of bounded treewidth are not PLS-complete (unless FP = PLS). But this tractability by non-local methods does not mean that finding a local peak in bounded treewidth VCSPs is tractable for local search. Thus, our second step toward a more nuanced notion of complexity is to restrict the set of potential algorithms to just (certain kinds of) strict local search algorithms. The efficiency of this restricted class of algorithms can then be measured by the length of ascents – a structural property of fitness landscapes. We will build up this notion and review existing results by considering a sequence of three questions. The first question to consider: is there any strict local search algorithm that fails on a specific subclass of fitness landscapes? Or the dual question: are there subclasses of fitness landscapes where all strict local search algorithms will find a peak in polynomial time? Under our definitions, this is equivalent to a structural property of fitness landscapes: it is asking when a fitness landscape will have an exponential ascent versus when can we guarantee all ascents are of polynomial length? For the primaly question, there are historic constructions like the Klee and Minty [24] d-cube where an ascent visits all 2 d assignments on the way to the peak – but these constructions cannot be represented by sparse VCSPs [7, 2]. For the dual question, the obvious partial answer is affine pseudo-Boolean functions, also knows as smooth fitness landscapes. On smooth landscapes, each variable has a preferred assignment independent of the assignments to the other d − 1 variables. As such, all ascents have length at most d. This class of all ascents short can be pushed further to include some quadratic pseudo-Boolean functions. For example, Kaznatcheev, Cohen, and Jeavons [20] showed that if a constraint graph is tree-structured then all ascents have length at most  d+1 2

. They also showed that this result cannot be further improved by constructing families of fitness landscapes represented by a sparse VCSP with constraint graphs of maximum degree 3 and pathwidth 2 that have exponentially long ascents. But both the Klee and Minty [24] and Kaznatcheev, Cohen, and Jeavons [20] constructions are easily solved by some strict local search methods like greedy local search. So, the second question to consider: does a particular frequently-used strict local search algorithm, like greedy local search, fail to be efficient on a specific subclass of fitness landscapes? Or under our definitions, when will fitness landscapes have an exponential steepest (rather than any) ascent? Here again, there is a number of historic results that have exponentially long steepest ascents in pseudo-Boolean functions that are not represented by sparse VCSPs [16, 11, 19]. Similar results also exist for other popular strict local search methods like random improving 3step [27, 14] or random facet [12, 23]. Recently, there was a series of improvements using similar techniques to construct sparse VCSPs that are hard for greedy local search. The first result in the series showed a construction of pathwidth 7 [7], which was improved to pathwidth 4 [21], and finally to the best possible result of pathwidth 2 (and maximum degree 3) [33, 22]. Kaznatcheev and Vazquez Alferez [23] also noted that the much older Haken and Luby [13] exponential steepest ascent construction has pathwidth 3, although Haken and Luby [13] never studied the pathwidth of their own construction. Finally, Kaznatcheev and Vazquez Alferez [23] answered the dual question of finding class of landscapes (in their case: conditionally-smooth) where many, but not all, local search methods find a peak in polynomial time. This brings us to the final question to consider, and the focus of this paper: on what fitness landscapes do all strict local search algorithms fail? Under our definitions, we express this as a structural property of fitness landscapes: when will a family of fitness landscapes have all ascents exponential from some designated initial assignment? Since quadratic pseudo-Boolean functions are PLS-complete under tight PLS-reductions, we know that there are some families of fitness landscapes and initial assignments such that all ascents are exponentially long [26, 31, 9, 5]. But the instances that we get through these reductions could have dense constraint graphs. There are also historic examples, like Horn, Goldberg, and Deb [15]’s recursive construction of a family of fitness landscapes with all ascents exponential from a designated initial assignment. But Cohen et al. [7] proved that any VCSP realizing this recursive construction has to be dense. As with the case of long steepest ascent, there has been recent progress on all ascents long from sparse VCSPs. But this progress has focused on bounded degree rather than pathwidth for sparseness and Max-Cut rather than general VCSPs for representations. Max-Cut is the restricted class of pseudo-Boolean functions that have the form: 

f (x) = X

> ij ∈E(G)

wij (xi(1 − xj ) + (1 − xi)xj ) (3) where E(G) are the edges of a graph with weights wij . Clearly, Eq. (3) can be rewritten as a binary Boolean VCSP-instance with the same constraint graph (thus, same maximum degree). On the one hand, Poljak [30] showed that if max degree of Max-Cut constraint graph is less than or equal to three then all ascents are short (similarly for general binary Boolean VCSPs, but only of degree less than or equal to two; Theorem 5.2 in [18]). On the other hand, Els¨ asser and Tscheuschner [10] showed that Max-Cut in constraint graphs of max degree five is PLS-complete under tight reductions. The remaining case of Max-Cut of degree four as PLS-complete or not is an open problem, but Monien and Tscheuschner [29] have provided an explicit construction of a family of Max-Cut instances of degree four where all ascents are exponential from a designated initial assignment. Very recently, Michel and Scott [28] have provided a much simpler Max-Cut construction of degree four with all ascents exponential from a designated initial assignment. 

## 1.3 Our contribution 

Given that max degree as a complexity parameter jumps abruptly from easy to PLS-complete, we believe that bounded pathwidth is a more interesting parameter for illuminating limits on the power of strict local search versus non-local algorithms. In Section 2, after reviewing the prior degree four Max-Cut constructions by Monien and Tscheuschner [29] and Michel and Scott [28], we show that they both have a K5 minor and thus pathwidth ≥ 4 (Theorems 1 and 2). In Section 3, we provide a new construction of a VCSP with pathwidth three (Theorem 3). In Section 4, we prove that this construction has an initial assignment from which all ascents are exponentially long (Theorem 4). Finally, in Section 5, we conjecture that there does not exist any pathwidth two example with all ascents long. 4C0             

> D0
> C1
> C2
> C3C4
> C5
> C6C7C8C9C10 C12 C13
> A6B6
> D10
> E10
> F10
> G10 G11
> A12 B12
> D12
> F12
> G12
> D13
> F13
> F14
> E14

if i < n 

if i < n 

if i = n

Figure 1: Gadget CMT  

> k

of Monien and Tscheuschner construction [29] ( CMT ) with constraint weights omitted. Dotted edges and vertices illustrate connections to neighboring gadgets. Node labels refer to grid position in layout of Figure 5 of [29]: letters for rows, numbers for columns. 

# 2 Pathwidth of prior Max-Cut constructions 

Both the prior Monien and Tscheuschner [29] and Michel and Scott [28] constructions with all ascents long are build as a chain of gadgets. This relates nicely to the definition of pathwidth. We can use the the pathwidth of a single gadget to find the pathwidth of the total construction. When the path decomposition of the gadgets is chosen in such way that the decomposition of gadget k directly connected to the decomposition of gadget k − 1, this defines a path decom-position of the total construction. So, the pathwidth of the total construction is equal to the maximum pathwidth of a single gadget with the restriction that the first bin of the gadget’s path-decomposition must contain the variables indexes that overlap with the prior gadget and the last bin of the gadget’s path-decomposition must contain the variables indexes that overlap with the next gadget. 

## 2.1 Monien and Tscheuschener construction 

The Max-Cut construction of Monien and Tscheuschener [29] is build on n + 1 gadgets CMT .There are n gadgets CMT  

> k

for k = 1 , . . . , n − 1 the same. The gadget with k = n has an edge between (0 , C 13) and (0 , D 13) The gadget CMT  

> k

is depicted in Fig. 1, where we neglected the constraints for clarity. The gadgets are connected by two edges with scopes (( k, C 13) , (k +1 , C 0)) and (( k, D 13) , (k+1 , D 0)). The total construction CMT  

> n, ≤m

is defined by the chain CMT 0 CMT 1 · · · C MT  

> m

.The construction is build such that the flips in gadget k result in twice as many flips in gadget k − 1. After the flip of C13 in the gadget CM T k the variables in this gadget are fixed until all variables in the gadgets CM T i for i > k are done. Then the variable D13 flips and triggers variables in CM T k to flip ending with a flip of C13. Again this will fix the variables in CM T k until all variables in the gadgets CM T i for i > k are done. The variable D13 will flip again and trigger another ascent in CM T k . This ends with a flip of C10 which finishes the ascent of CM T n, ≤k.5This construction has at least pathwidth of at least 4, since we can find a K5 minor. 

Proposition 1. The Monien and Tscheuschner [29] construction (Fig. 1) has treewidth (CMT ) = 4 ≤ pathwidth (CMT ) ≤ 5.Proof. To show that treewidth is four, we will show both sides of the inequality. Then we give the path decomposition to show that pathwidth( CMT ) ≤ 5. 

treewidth (CMT ) ≤ 4: The tree decomposition consists of a main path {X1, X 2, . . . , X 17 } with a single branch to Xℓ at the tenth node. The elements of the main path are given by: X1 =

{C0, C 1, C 2, C 3, D 0}, X2 = {C3, 4C, 5C, 6C, D 0}, X3 = {A6, B 6, C 3, C 6, D 0}, X4 =

{C3, C 6, C 7, C 8, D 0}, X5 = {C3, C 6, C 8, C 10 , D 0}, X6 = {C3, C 6, C 8, C 9, C 10 }, X7 =

{C3, C 6, C 8, C 10 , E 14 }, X8 = {C3, C 6, C 10 , E 14 , G 12 }, X9 = {C3, C 10 , E 14 , F 10 , G 12 },

X10 = {C10 , D 10 , E 14 , F 10 , G 12 }, X11 = {C10 , C 12 , E 14 , F 10 , G 12 },

X12 = {C12 , E 14 , F 10 , G 10 , G 12 }, X13 = {C12 , E 14 , G 10 , G 11 , G 12 },

X14 = {C12 , D 12 , E 14 , F 12 , G 12 }, X15 = {C12 , E 14 , F 12 , F 13 , F 14 },

X16 = {A12 , B 12 , C 12 , C 13 , F 12 }, X17 = {C13 , D 13 , F 12 }. The branch at the tenth node is given by Xℓ = {D10 , E 10 , E 14 , F 10 , G 12 }

treewidth (CMT ) ≥ 4: Contracting {C0, D 0, C 1, C 2, C 3, C 4, C 5, C 6, B 6, 6A},

{C10 , C 9, D 10 , E 10 }, {F 10 , G 10 , G 11 }, {C7, C 8, E 14 , D 13 , C 13 },

{G12 , F 12 , F 13 , F 14 , D 12 , C 12 , B 12 , A 12 } results in a K5 minor. 

pathwidth (CMT ) ≤ 5: path decomposition: {C0, C 1, C 2, C 3, C 4D0}, {C3, 4C, 5C, 6C, D 0, F 10 },

{A6, B 6, C 6, C 10 , D 0, F 10 }, {C6, C 7, C 8, C 9, C 10 , F 10 }, {C6, C 8, C 10 , E 14 , F 10 , G 12 },

{C10 , E 14 , F 10 , G 10 , G 11 , G 12 }, {C10 , E 14 , F 10 , G 10 , G 11 , G 12 },

{C10 , D 10 , E 10 , E 14 , F 10 , G 12 }, {C10 , E 14 , F 12 , F 13 , F 14 , G 12 },

{C10 , C 12 , D 12 , D 13 , F 12 }, {A12 , B 12 , C 12 , C 13 , D 13 }

## 2.2 Michel and Scott construction 

The Max-Cut construction of Michel and Scott [28] is build on 8 n + 4 variables. It is recursively constructed on n gadgets CMS  

> k

on 8 variables Vk = {(k, 1) , . . . , (k, 8) }, two variables are added as a bases and two variables are added to the final gadget. Each gadget has eight unary constraints and 13 binary constraints as shown in Fig. 2. There are seven binary constraints within the gadget with scopes {(k, i ), (k, i + 1) for all i = 1 , . . . , 7. The other six binary constraints connect the gadget to the adjacent gadgets with scopes {(k, i ), (k − 1, 1) } for i = 2 , 4, 6 and {(k + 1 , 8) , (k, i )}

for i = 3 , 5, 7. The initial gadget CMS 0 consists of two variables x0,1 and x0,8 and an edge between them. The final gadget CM T n+1 consists of two variables xn+1 ,1 and xn+,2 with scope 

{(n + 1 , 1) , (n + 1 , 2) }. This gadget is connected to CMS  

> n

via the scope {(n + 1 , 1) , (n, 1) }. The total construction CMS  

> ≤n

is given by CMS 

> n+1

CMS  

> n

· · · C MS 1 CMS 0 . We translated the constraint weights to a binary boolean VSCP as shown in Fig. 2. The construction is build such that the flips in gadget k, result in three times as many flips in gadget k − 1. There is only a single ascent starting from the initial assignment xMS  

> start

=01(10101010) n10, which has exponential length. We consider the flips in a gadget CMS  

> k

. First the variables ( k, 1) and ( k, 2) are flipped. Then the variables in gadget CMS  

> k

are fixed until all flips for variables in gadgets CMS  

> i

with i < k are done. Now variables ( k, 3) and ( k, 4) flip, after which the variables in CMS  

> k

are fixed again until all flips for variables in gadgets CMS  

> i

with i < k are done. This leads to the flips of variables ( k, 5) and ( k, 6). Once again the variables in CMS  

> k

are fixed until all flips for variables in gadgets CMS  

> i

with i < k are done. Finally, the variables ( k, 7) and ( k, 8) will flip, which finishes the ascent of the gadget CM S k . Similar, arguments hold when 6k − 1, 8               

> k−1,1
> k+ 1 ,2
> k+ 1 ,4
> k+ 1 ,6
> k+ 1 ,3
> k+ 1 ,5
> k+ 1 ,7

k, 1

15 · 8k

k, 2

13 · 8k

k, 3

10 · 8k + 1 

k, 4

7 · 8k

k, 5

6 · 8k − 1

k, 6

5 · 8k

k, 7

2 · 8k + 1 

k, 8

8k + 1 

−14 · 8k

−10 · 8k

−10 · 8k

−6 · 8k

−6 · 8k

−2 · 8k

−2 · 8k

−2 · 8k

> 2 · 8k
> −2 · 8k

−2

2

−2

−2 · 8k+1 

> 2 · 8k+1
> −2 · 8k+1

−2

2

−2

Figure 2: Gadget CMS  

> k

of Michel and Scott construction [28]: the weights of unary constraints are next to their variables and the weights of binary constraints are on the edges that specify their scope. The dotted edges and vertices illustrate the connection to the neighboring gadgets. 7starting form the assignment xMS  

> start

= 10(01010101) n01, which has exponential length. When adding a gadget CMS 

> k+1

, the length of the ascent will be three times as long as the current ascent. So, indeed the ascent has exponential length. Michel and Scott [28] were not focused on the pathwidth of their construction. We show that the construction CMT has pathwidth four. 

Proposition 2. Michel and Scott [28] construction ( CMT ; Fig. 2) has pathwidth (CMT ) = 4 .Proof. To show that pathwidth is four, we will show both sides of the inequality. 

pathwidth (CMS ) ≤ 4: Path decomposition: {(k − 1, 1) , (k − 1, 8) , (k, 6) , (k, 4) , (k, 5) }, {(k −

1, 1) , (k − 1, 8) , (k, 6) , (k, 4) , (k, 3) }, {(k − 1, 1) , (k − 1, 8) , (k, 6) , (k, 7) , (k, 3) },

{(k − 1, 1) , (k, 2) , (k, 4) , (k, 3) }, {(k, 1) , (k, 8) , (k, 2) , (k, 7) }

pathwidth (CMS ) ≥ 4: K5 is a minor: contracted nodes {(k − 1, 1) }, {(k − 1, 8) },

{(k, 1) , (k, 2) , (k, 3) }, {(k, 4) , (k, 5) }, and {(k, 6) , (k, 7) , (k, 8) }.

# 3 Pathwidth three construction 

Now we construct a VCSP of pathwidth three that we call the controlled doubling construction .For each n, we construct a ternary Boolean VCSP instance CCD on 8 n variables as a chain of 

n gadgets connected by pairs of scopes. The full 8 n variables are grouped into n gadgets of 8 variables each: 

Vk = {(k, 1) , . . . , (k, 6) }

| {z }

> ‘doubling’ variables

∪ { (k, A ), (k, B )}

| {z }

> ‘control’ variables

(4) where the first six ‘doubling’ variables are essential for creating an exponential ascent and the subsequent two ‘control’ variables help us eliminate the short non-exponential ascents (see Sec-tion 4). The gadgets have all eight unary constraints, thirteen binary constraints and two ternary constraints shown in Fig. 4: 

• ‘doubling’ cycles on ( k, 1) , ..., (k, 6) with scopes {(k, 1) , (k, 2) }, {(k, 2) , (k, 3) }, {(k, 3) , (k, 6) },

{(k, 1) , (k, 4) }, {(k, 4) , (k, 5) }, {(k, 5) , (k, 6) };

• constraint between the ‘control’ variables ( k, A ), (k, B ) with scope {(k, A ), (k, B )};

• four connections between the ‘control’ and ‘doubling’ cycles with scopes {(k, 1) , (k, B )},

{(k, 2) , (k, B )}, {(k, 4) , (k, A )} and {(k, 4) , (k, B )};

• two ternary constraints with scopes {(k, 2) , (k, A ), (k, B )} and {(k, 4) , (k, A ), (k, B )}; and 

• two constraints connecting to adjacent gadgets with scopes {(k, 6) , (k−1, 1) }, and {(k, B ), (k+1, A )}.Based on this definition we can check that the controlled doubling construction ( CCD ) has path-width 3. 

Proposition 3. The controlled doubling construction (Fig. 4) has pathwidth 3.Proof. To show that the pathwidth is three, we will show both sides of the inequality. 

pathwidth (CCD ) ≤ 3: Path decomposition: {(k, 1) , (k, B ), (k, 2) , (k, 4) },

{(k, B ), (k, 2) , (k, 4) , (k, A )}, {(k, 2) , (k, 4) , (k, A ), (k, 3) }, {(k, 4) , (k, A ), (k, 3) , (k, 5) },

{(k, A ), (k, 3) , (k, 5) , (k, 6) }

8sk + 4 

> sk + 2
> sk−1
> z }| {
> sk + 6

sk + 4 

sk + 2 

−2

> sk
> mk+1

z }| {

2mk + 16 

> mk + 6
> mk + 6

mk + 4 

mk + 4 

> mk + 2
> −(mk + 2)

mk

−(sk + 4) 

−(sk + 2) 

mk = 2 k−1(8 n + 16) − 16 

sk = 8( n − k)

k, 1

> −(2 mk + 13)

k, 2

−(mk + 5) 

k, 4

−(mk + sk + 7) 

k, 3

−(mk + 3) 

k, 5

−1

k, 6

> −(mk + 1)

k, B 

−(sk + 3) 

k, A 

−(sk + 5)          

> k−1,1k+ 1 ,6
> k+ 1 , A k−1, B

Figure 3: A gadget CCD k of the controlled doubling construction with mk = 2 k−1(8 n + 16) − 16 and sk = 8( n − k). The constraints of the kth of n gadgets are shown: the weights of unary constraints are next to their variables, the weights of binary constraints are on the edges that specify their scope, the weights of ternary constraints are in the center of the shaded area that specify their scope. The dotted edges and vertices illustrate the connection to the neighboring gadgets. 

pathwidth (CCD ) ≥ 3: K4 is a minor: contracted node {(k, 1) }, {(k, A ), (k, 2) , (k, 3) }, {(k, B )},and {(k, 4) , (k, 5) , (k, 6) }.We define the constraints weight function C(x) on the scopes using parameters mk = 2 k−1(8 n+16) − 16 and sk = 8( n − k). First we define the constraints on the control variables in equations (5)-(13). Then we define the constraints on the doubling variables in equations (14)-(27). Finally, we define the ternary constraints in equation (28) and (29). They are shown on the constraint graph in Fig. 4. 

C(( k, B ), (k + 1 , A )) = sk (5) 

C(( k, 1) , (k, B )) = −2 (6) 9C(( k, B )) = −(|C(( k, B ), (k + 1 , A )) | + |C(( k, 1) , (k, B )| + 1) = −(sk + 3) (7) 

C(( k, 4) , (k, B )) = |C(( k, B )) | − 1 = sk + 2 (8) 

C(( k, 4) , (k, A )) = |C(( k, 4) , (k, B )) | = sk + 2 (9) 

C(( k, A ), (k, B )) = |C(( k, B )) | + 1 = sk + 4 (10) 

C(( k, 2) , (k, B )) = |C(( k, B )) | + 1 = sk + 4 (11) 

C(( k, A )) = −(|C(( k, A ), (k, B )) | + 1) = −(sk + 5) (12) 

C(( k − 1, B ), (k, A )) = |C(A)| + 1 = sk + 6 (13) 

C(( k, 6) , (k − 1, 1)) = mk (14) 

C(( k, 6)) = −(|C(( k, 6) , (k − 1, 1)) | + 1) = −(mk + 1) (15) 

C(( k, 3) , (k, 6)) = |C(( k, 6)) | + 1 = mk + 2 (16) 

C(( k, 5) , (k, 6)) = −| C(( k, 3) , (k, 6)) | = −(mk + 2) (17) 

C(( k, 3)) = −(|C(( k, 3) , (k, 6)) | + 1) = −(mk + 3) (18) 

C(( k, 2) , (k, 3)) = |C(( k, 3)) | + 1 = mk + 4 (19) 

C(( k, 2)) = −(|C(( k, 2) , (k, 3)) | + 1) = −(mk + 5) (20) 

C(( k, 1) , (k, 2)) = |C(( k, 2)) | + 1 = mk + 6 (21) 

C(( k, 5)) = −1 (22) 

C(( k, 4) , (k, 5)) = |C(( k, 5)) + C(( k, 5) , (k, 6)) | + 1 = mk + 4 (23) 

C(( k, 4)) = −(|C(( k, 4) , (k, 5)) + C(( k, 4) , (k, A )) | + 1) = −(mk + sk + 7) (24) 

C(( k, 1) , (k, 4)) = |C(( k, 4)) + C(( k, 4) , (k, A )) | + 1 = mk + 6 (25) 

C(( k, 1)) = −(|C(( k, 1) , (k, 2)) + C(( k, 1) , (k, 4)) | + 1) = −(2 mk + 13) (26) 

C(( k + 1 , 6) , (k, 1)) = |C(( k, 1) + C(( k, 1) , (k, B )) | + 1 = 2 mk + 16 

| {z }

> mk+1

(27) 

C(( k, 2) , (k, A ), (k, B )) = −| C(( k, A ), (k, B )) | = −(sk + 4) (28) 

C(( k, 4) , (k, A ), (k, B )) = −| C(( k, 4) , (k, B )) | = −(sk + 2) (29) The weights are assigned, such that all the unary constraints are negative. Furthermore, the magnitude of each ’doubling’ variable unary constraint is greater than the binary constraint from that variable to a ’doubling’ variable in the gadget with higher second index. In the first gadget (k = 1) the constraint C((1 , 6) , (0 , 1)) and C((0 , B ), (1 , A )) are merged together in the constraint 

C((1 , 6) , (1 , A )) = m1 = s0 = 8 n. The first gadget is shown in Fig. 4 with the corresponding constraint weights. When considering a single gadget, we can define the unary weights of ( k, 1) and ( k, A ) using the states of ( k + 1 , 6) and ( k − 1, B ) respectively. To do this we define the modified unary constraints ˆC(k, 1) and ˆC(k, A ) as ˆC(( k, 1)) = C(( k, 1)) + C(( k + 1 , 6) , (k, 1)) = mk + 3 (30) ˆC(( k, A )) = C(( k, A )) + C(( k − 1, B ), (k, A )) = 1 (31) The unary weight of ( k, 1) is then given by C(( k, 1)) as in (26) if x(k+1 ,6) = 0 and by ˆC(( k, 1)) as in (30) if x(k+1 ,6) = 1. Similar, the unary weight of ( k, A ) is given by C(( k, A )) as in (12) if 

x(k−1,B ) = 0 and by ˆC(( k, 1)) as in (31) if x(k−1,B ) = 1. Using this we denote the k’th gadget of 10 8n − 4

> 8n − 6
> m1=s0

z}|{ 

8n

8n + 4 

8n − 6

−2

> s1
> z }| {
> 8n − 8
> m2

z }| {

16 n + 16 

> 8n + 6
> 8n + 6

8n + 4 

8n + 4 

> 8n + 2
> −(8 n + 2)

−(8 n − 4) 

−(8 n − 6) 

m1 = 8 ns0 = 8 n

1, 1

> −(16 n + 13)

1, 2

−(8 n + 5) 

1, 4

−(16 n − 1) 

1, 3

−(8 n + 3) 

1, 5

−1

1, 6

> −(8 n + 1)

1, B 

−(8 n − 5) 

1, A 

−(8 n − 3)  

> 2,6
> 2, A

Figure 4: The first gadget ( CCD  

> 1

) of the controlled doubling construction with m1 = s0 = 8 n.The constraints of the first gadget are shown: the weights of unary constraints are next to their variables, the weights of binary constraints are on the edges that specify their scope, the weights of ternary constraints are in the center of the shaded area that specify their scope. The dotted edge and vertices illustrate the connection to the second gadget. the controlled doubling construction by CP,Q n,k , where P and Q correspond to the assignment of respectively x(k+1 ,6) and x(k−1,B ). So, when x(k+1 ,6) = 0 and x(k−1,B ) = 0 we have C0,0

> n,k

; when 

x(k+1 ,6) = 1 and x(k−1,B ) = 0 we have C1,0

> n,k

; when x(k+1 ,6) = 0 and x(k−1,B ) = 1 we have C0,1

> n,k

;and when x(k+1 ,6) = 1 and x(k−1,B ) = 1 we have C1,1

> n,k

.Using this notation we define two VCSP-instances for the controlled doubling construction: 

C1,0 

> n, ≤m

and C0,0 

> n, ≤m

on 8 m variables. We construct the instance C1,0 

> n, ≤m

as a path of m gadgets 

C1,0

> n,m

, C0,0

> n,m −1

, . . . , C0,0

> n, 2

, C0,0 

> n, 1

and the instance C0,0 

> n, ≤m

as a path of m gadgets C0,0

> n,m

, C0,0

> n,m −1

, . . . , C0,0

> n, 2

,

C0,0

> n, 1

. Note that only the first gadget is different: C1,0 

> n,m

vs C0,0

> n,m

. The only difference between these gadget is the unary constraint on ( m, 1). In Section 4 we will show that both instances have all ascents exponential. We will see that C0,1 

> n, ≤m

and C1,1 

> n, ≤m

come across, when following the ascent. The defined gadgets C0,0

> n,k

, C1,0

> n,k

, C0,1 

> n,k

and C1,1 

> n,k

all have different local peaks. The local peaks of the gadgets are listed in Table 1. The columns correspond to the variables of the k’th gadget. 11 The columns are structured in three block types: A block containing the columns P and Q,representing the state of the gadgets to the left and the right respectively; A block containing the variables labeled by numbers, corresponding to the doubling variables; And a block containing the variables labeled by A and B, corresponding to the controlling variables. The rows are structured based on the assignment of the variables P and Q and correspond to the assignment of the local peaks of the corresponding gadget. Since all unary constraints are negative, the all zero assignment is a local peak of C0,0

> n,k

. Note that in the case where P = 1, there is a local peak where the assignment of x(k,B ) can be either 0 or 1. This depends on the assignment of 

x(k+1 ,A ): when the assignment x(k+1 ,A ) is one, the assignment x(k,B ) is one as well and when the assignment x(k+1 ,A ) is zero, the assignment x(k,B ) is zero as well. However, as we will see in Section 4, we choose the initial assignments such that x(k+1 ,A ) will follow the assignment of 

x(k,B ).P Q 1 2 3 4 5 6 A B0 0 0 0 0 0 0 0 0 00 1 1 0 0 1 0 10 1 0 0 0 0 0 0 1 10 1 1 0 0 1 1 11 0 1 1 1 0 0 1 0 0/1 1 1 1 1 1 0 0 11 1 1 0 0 1 1 0 1 0/1 1 1 1 1 1 0 1 0Table 1: Peaks of gadget k as shown in Figure 4. The columns corresponds to the variable of the k’th gadget. The columns are structured in three block types. The block with columns 

P and Q correspond to state of the gadgets to the left and right respectively. The blocks with variables labeled by numbers, correspond to the doubling variables. The blocks with variables labeled by A and B, correspond to the controlling variables. The rows are structured based on the assignment of neighboring gadgets, i.e. the assignment of the variables P and Q. The rows correspond to the assignment of a fitness peak based on the assignments of variables P and Q.A positive change in fitness is marked in green. 

# 4 All ascents exponential 

Theorem 4. Consider the VCSP-instances C1,0 

> n, ≤m

and C0,0 

> n, ≤m

of the controlled doubling con-struction from Section 3. In the fitness landscape of C1,0

> n, ≤m

, there is only one ascent from the initial assignment x1,0 

> start ,≤m

:= 0 8m – this ascent ends at the peak x1,0 

> end ,≤m

:= 111110 01 0 8( m−1) ;and in the fitness landscape of C0,0

> n, ≤m

, there is only one ascent ascent from the initial assignment 

x0,0

> start ,≤m

(= x1,0

> end ,≤m

) – this ascent ends at the peak x0,0

> end ,≤m

(= x1,0

> start ,≤m

). Both of these ascents have length Tm = 10(2 m − 1) .

To show that all ascents are exponential, we will recursively analyze the ascents in our two fitness landscapes C1,0 

> n, ≤m

and C0,0

> n, ≤m

. As we recall from Section 3, C1,0 

> n, ≤m

and C0,0 

> n, ≤m

are landscapes that differ in a single unary. This is what will allow our recursion. The flips in the landscape spanned by Vm will trigger twice as many flips in the landscape spanned by Vm−1. For example, as we move through the landscape of C1,0

> n, ≤m

, we will end up recursively entering the landscapes of C1,0 

> n, ≤m−1

and C0,0

> n, ≤m−1

. The control variables with indexes ( m, A ) and ( m, B ) will keep the 12 variables with indexes in Vm fixed until all flips for variables with indexes in V≤m−1 are done. We will be able to repeat this recursions because the designated starting point x1,0start ,≤m of the ascent in C1,0 

> n, ≤m

is the same as the end of the ascent x0,0end ,≤m in C0,0

> n, ≤m

, and vice versa. We will show that this is the only ascent from our designated starting point, and thus we will show that all ascents from our designated starting point are exponential. Specifically, we will show that it takes an exponential number of steps to go from the assignment x1,0start ,≤m := 0 8m to the peak 

x1,0end ,≤m := 111110 01 0 8( m−1) in the fitness landscape implemented by C1,0

> n, ≤m

. We will then use the fitness landscape of C0,0 

> n, ≤m

to ”reverse” this ascent: in the fitness landscape implemented by 

C0,0 

> n, ≤m

it take a large number of steps to go from the assignment x0,0start ,≤m := 111110 01 0 8( m−1) (= 

x1,0end ,≤m) to the peak x0,0end ,≤m := 0 8m(= x1,0start ,≤m). We will prove that by induction on the number of gadgets m, that there exist only one ascent and that this ascent is exponentially long. 

Proof. We will prove that all ascents are exponentially long by induction on the number of gadgets m. The inductive hypothesis states that there is: 1. single ascent starting from x1,0start ,≤m−1 := 0 8( m−1) in C1,0 

> n, ≤m−1

to x1,0end ,≤m−1 := 111110 01 0 8( m−2) ,and 2. single ascent starting from x0,0start ,≤m−1 := 111110 01 0 8( m−2) in C0,0 

> n, ≤m−1

to x0,0end ,≤m−1 := 08m−1

with both ascents having length Tm−1. From the inductive hypothesis we will show that by adding a gadget C1,0 

> n, ≤m

to C0,0 

> n, ≤m−1

there is a single ascent staring from x1,0start ,≤m := 0 8m and similar for adding a gadget C0,0 

> n, ≤m

to C0,0 

> n, ≤m−1

starting from x0,0start ,≤m := 111110 01 0 8( m−1) . We will show that both ascent have length Tm = 10(2 m − 1). In Table 2 the ascent of the k’th gadget is shown. The columns correspond to the variables of the k’th gadget. The columns are structured in three block types: A block containing the columns P = x(k+1 ,6) and Q = x(k−1,B ), representing the state of the gadgets to the left and the right respectively; A block containing the variables labeled by numbers, corresponding to the doubling variables; And a block containing the variables labeled by A and B, corresponding to the controlling variables. The rows are structured based on the assignment of the variables P

and Q. The top three row blocks in Table 2 show the ascent starting from x1,0start ,k = 0 8 in C1,0 

> n,k

to 

x1,0end ,k = 11111001 The final three row blocks show the ascent starting from x0,0start ,k = 11111001 in C0,0 

> n, ≤m

to x0,0end ,k = 0 8. The left table shows the assignment in each step of the ascent. The right table shows for each step in the ascent the change in fitness when flipping the variable in the corresponding column. When the change in fitness is positive it is marked in green and the variable can be flipped in the next step of the ascent. Note that in each step there is at most one variable that can flip to increase fitness. This means that there is a unique ascent. 13 P Q  1 2 3 4 5 6 A B1 0  0 0 0 0 0 0 0 0

> 1 0 0 0 0 0 0 01 1 0 0 0 0 0 01 1 1 0 0 0 0 01 1 1 0 0 1 0 01 1  1 1 1 0 0 1 0 01 1 1 0 0 1 1 01 1 1 1 0 1 1 01 1 1 1 1 1 1 01 1 1 1 1 0 1 01 0  1 1 1 1 1 0 1 01 1 1 1 1 0 0 01 1 1 1 1 0 0 1
> 0 0  1 1 1 1 1 0 0 1
> 0 1 1 1 1 0 0 10 1 1 0 1 0 0 10 1 1 0 0 0 0 10 1 1 0 0 1 0 10 1  0 1 1 0 0 1 0 10 1 1 0 0 1 1 10 0 1 0 0 1 1 10 0 0 0 0 1 1 10 0 0 0 0 0 1 10 0  0 0 0 0 0 0 1 10 0 0 0 0 0 0 10 0 0 0 0 0 0 0
> 1 2 3 4 5 6 A B3 −(mk + 5)  −(mk +3)  −(mk + sk + 7)  -1  −(mk +1)  −(sk + 5)  −(sk + 3)
> −3 1 −(mk +3)  −(sk + 1)  -1  −(mk +1)  −(sk + 5)  −(sk + 5)
> −(mk + 9)  −1 1 −(sk + 1)  -1  −(mk +1)  −(sk + 5)  −1
> −(mk + 9)  −(mk + 5)  −1 −(sk + 1)  -1  1 −(sk + 5)  −1
> −(mk + 9)  −(mk + 5)  −(mk +3)  −(sk + 1)  −(mk +3)  −1 −(sk + 5)  −1
> −(mk + 9)  −(mk + 5)  −(mk +3)  −(sk + 1)  −(mk +3)  −(mk +1)  1 −1
> −(mk + 9)  −(mk + 5)  −(mk +3)  1 −(mk +3)  −(mk +1)  −1 −1
> −(2 mk +15)  −(mk + 5)  −(mk +3)  −1 1 −(mk +1)  −(sk + 3)  −1
> −(2 mk +15)  −(mk + 5)  −(mk +3)  −(mk + 5)  −1 1 −(sk + 3)  −1
> −(2 mk +15)  −(mk + 5)  −1 −(mk + 5)  −(mk +3)  −1 −(sk + 3)  −1
> −(2 mk +15)  −(mk + 5)  −1 −(mk + 5)  −(mk +3)  −(mk +1)  3 −1
> −(2 mk +15)  −(mk + 5)  −1 −(mk − sk + 3)  −(mk +3)  −(mk +1)  −3 sk + 1
> −(2 mk +13)  −(mk + sk + 9)  −1 −(mk + 5)  −(mk +3)  −(mk +1)  −(sk + 5)  −(sk + 1) 3 −(mk + sk + 9)  −1 −(mk + 5)  −(mk +3)  −(mk +1)  −(sk + 5)  −(2 sk +1)
> −3 −(sk + 3)  −1 1 −(mk +3)  −(mk +1)  −(sk + 5)  −(2 sk +3)
> −(mk + 9)  −(sk + 3)  −1 −1 1 −(mk +1)  −(sk + 5)  −(sk + 1)
> −(mk + 9)  −(sk + 3)  −1 −(mk + 5)  −1 1 −(sk + 5)  −(sk + 1)
> −(mk + 9)  −(sk + 3)  −(mk +3)  −(mk + 5)  −(mk +3)  −1 −(sk + 5)  −(sk + 1)
> −(mk + 9)  −(sk + 3)  −(mk +3)  −(mk + 5)  −(mk +3)  −(mk +1)  1 −(sk + 1)
> −(mk + 9)  1 −(mk +3)  −(mk + 5)  −(mk +3)  −(mk +1)  −1 −(sk + 1)
> −(2 mk +15)  −1 1 −(mk + 5)  −(mk +3)  −(mk +1)  −(sk + 5)  −(sk + 1)
> −(2 mk +15)  −(mk + 5)  −1 −(mk + 5)  −(mk +3)  1 −(sk + 5)  −(sk + 1)
> −(2 mk +15)  −(mk + 5)  −(mk +3)  −(mk + 5)  −1 −1 −(sk + 5)  −(sk + 1)
> −(2 mk +15)  −(mk + 5)  −(mk +3)  −(mk + 5)  −1 −(mk +1)  1 −(sk + 1)
> −(2 mk +15)  −(mk − sk + 1)  −(mk +3)  −(mk + 5)  −1 −(mk +1)  −1 3
> −(2 mk +15)  −(mk + 5)  −(mk +3)  −(mk + sk + 7)  −1 −(mk +1)  −(sk + 5)  −3
> Table 2:  Important ascents in the gadget  CCD k as shown in Figure 4.  The columns corresponds to the variable of the  k’th gadget. The columns are structured in three block types. The block with columns  P and  Q correspond to state of the gadgets to the left and right respectively. The blocks with variables labeled by numbers, correspond to the doubling variables. The blocks with variables labeled by  A and  B, correspond to the controlling variables.  In the left three blocks the rows correspond to an assignment of the variables. The right two blocks show the change in fitness ∆ C when the assignment of the variable in the corresponding column is changed, while keeping the other variables fixed in the assignment in the left part.  The rows are structured based on the assignment of neighboring gadgets, i.e. the assignment of the variables  P and  Q. A positive change in fitness is marked in green. The variable that will flip in the ascent is underlined and the variable that has been flipped with respect to the previous assignment is bolded.

14 We consider the ascent in the fitness landscape of C1,0 

> n, ≤m

starting from the peak 0 8m of the landscape C0,0

> n, ≤m

. The first four steps will take place in the gadget C1,0

> n,m

:000000 00 x0,0end ,≤m−1 → 10000 00 x0,0end ,≤m−1 → 110000 00 x0,0end ,≤m−1

→ 11 1000 00 x0,0end ,≤m−1 → 11100 1 00 x1,0start ,≤m−1. (32) where the variable that can flip is underlined and the variable that has been flipped is bolded. For each step there is only a single variable that can change its assignment to increase fitness, as shown in the first row block of Table 2. In the final step the assignment of x(m, 6) is changed from 0 to 1. By doing this, we change the landscape from C0,0 

> n, ≤m−1

to C1,0

> n, ≤m−1

. In this landscape 

x0,0end ,≤m−1 = x1,0start ,≤m−1 is not a peak, hence it is underlined. This makes that the variables in 

Vm−1 take over the ascent: 111001 00 x1,0start ,≤m−1    

> Tm−1steps of V≤m−1in the landscape of C1,0
> n, ≤m−1

−−−−−−−−−−−−−−−−−−−−−−→ 111001 00 x1,0end ,≤m−1. (33) In the final step variable x(m−1,B ) has changed from 0 to 1. This changes the landscape from 

C1,0 

> n, ≤m

to C1,1

> n, ≤m

. In this landscape 111001 00 is not a peak (see Table 1). The following four steps are taken: 111001 00 x1,0end ,≤m−1 → 111001 10 x1,0end ,≤m−1 → 111 101 10 x1,0end ,≤m−1

→ 1111 11 10 x1,0end ,≤m−1 → 11111 0 10 x0,0start ,≤m−1. (34) Again, there is only one variable that can change its assignment to increase fitness. This is shown in the second block of Table 2. In the last step variable x(m, 6) flipped back from 1 to 0, changing the landscape of from C1,0 

> n, ≤m−1

to C0,0

> n, ≤m−1

. So x1,0end ,≤m−1 = x0,0start ,≤m−1 is no longer a peak on 

V≤m−1. The variables in Vm−1 take over the ascent: 111110 10 x0,0start ,≤m−1    

> Tm−1steps of V≤m−1in the landscape of C1,0
> n, ≤m−1

−−−−−−−−−−−−−−−−−−−−−−→ 111110 10 x0,0end ,≤m−1. (35) In the last step the variable x(m−1,B ) changed back from 1 to 0. This change the landscape back from C1,1 

> n, ≤m

to C1,0

> n, ≤m

. In this landscape x1,1start ,m = 111110 10 is no longer a peak. The ascent finished by taking two more steps: 111110 10 x0,0end ,≤m−1 → 111110 10 x0,0end ,≤m−1 → 111110 0 1 x0,0end ,≤m−1

| {z }

> x1,0end ,≤m

. (36) Again these are the only possible steps that can be taken, based on Table 2. Similarly, the ascent in the landscape of C0,0 

> n, ≤m

starting from x1,0start ,≤m = 111110 01 0 8( m−1) ,the peak of the landscape C1,0

> n, ≤m

, has the following steps: 111110 01 x0,0end ,≤m−1 → 011110 01 x0,0end ,≤m−1 → 011 010 01 x0,0end ,≤m−1

→ 0110 00 01 x0,0end ,≤m−1 → 01100 1 01 x1,0start ,≤m−1 (37) 011001 01 x1,0start ,≤m−1    

> Tm−1steps of V≤m−1in the landscape of C1,0
> n, ≤m−1

−−−−−−−−−−−−−−−−−−−−−−→ 011001 01 x1,0end ,≤m−1. (38) 15 011001 01 x1,0end ,≤m−1 → 011001 11 x1,0end ,≤m−1 → 001001 11 x1,0end ,≤m−1

→ 00 0001 11 x1,0end ,≤m−1 → 00000 0 11 x0,0start ,≤m−1 (39) 000000 11 x0,0start ,≤m−1    

> Tm−1steps of V≤m−1in the landscape of C0,0
> n, ≤m−1

−−−−−−−−−−−−−−−−−−−−−−→ 000000 11 x0,0end ,≤m−1 (40) 000000 11 x0,0end ,≤m−1 → 000000 01 x∗ 

> 0,0

→ 000000 0 0 x0,0end ,≤m−1

| {z }

> x0,0end ,≤m

(41) The ascent in C1,0 

> n, ≤m

starting from x0,0start ,≤m and the ascent in C0,0 

> n, ≤m

starting from x1,0start ,≤m both have length Tm = 10 + 2 Tm−1. With T1 = 10, we obtain Tm = 10(2 m − 1). 

# 5 Discussion 

Local search is a popular and versatile method that is often applied in combinatorial optimiza-tion [32, 1]. But its power is limited compared to the design space of all possible algorithms. In this paper, we have built toward understanding these limits. As such, we have focused on problems that can solved efficiently by non-local methods: VCSPs of bounded pathwidth [3, 6]. We build a VCSP of pathwidth three where every ascent is exponentially long from a designated initial assignment. From this, we conclude that all strict local search algorithms can be forced to take an exponential number of steps even on simple VCSPs of pathwidth three. Our controlled doubling construction is based on taking Kaznatcheev and Vazquez Alferez [22]’s chain of gadgets that has a long steepest ascent (where steepness is used to select which gadget will ‘activate’) and adding a control system that forces only one gadget to be able to ‘activate’ at any given time. This effectively converts the steepest ascent into the only ascent, thus making all ascents exponential from the designated initial assignment. Intuitively, this approach creates two ‘channels’ of ‘information flow’ through the VCSP-instance. For the right channel, we see from CCD k+1 to CCD k the ‘doubling’ flow from Kaznatcheev and Vazquez Alferez [22], which is captured by the exponentially increasing weights of mk. For the left channel, we see from CCD k−1 to CCD k the ‘control’ flow, which is captured by the linearly decreasing weights of sk. This keeps only a single gadget at a time capable of flips (whereas for Kaznatcheev and Vazquez Alferez [22], many gadgets could have flips but the stepness selected the flips to be in the correct gadget). Since the right channel requires pathwidth two and the left channel requires adding an extra node to each bin in the path-decomposition, the resulting construction ends up with pathwidth three. Currently, our result leaves only treewidth two as an open question for all ascents long: is there a Boolean VCSP of treewidth two with all ascents exponential from some designed initial assignment? We believe that the answer to this question is ‘no’. We do not think that our controlled doubling construction can be significantly improved. Stated precisely as a formal conjecture: 

Conjecture 5. There exists a polynomial p such that given any treewidth two Boolean VCSP-instances on d variables, there exists an ascent of length p(d) or less from any initial assignment. 

Since Kaznatcheev, Cohen, and Jeavons [20] showed that any tree-structured Boolean VCSP has at most a quadratic ascent, we know that having some ascent exponential requires bins of size 3 in the constraint graph’s tree-decomposition. But these long ascents, seem to always requires flips to occur in specific order of bins of the tree-decomposition. To block flips in the ‘wrong’ bins and thus block the short ascents, we think that an extra variable will need to be added to each bin that can potentially be ‘wrong’. That is why we expect long ascents to not be possible without bins of size four and thus treewidth greater than or equal to three. 16 References 

[1] E. Aarts and J. K. Lenstra, eds. Local Search in Combinatorial Optimization . Princeton, NJ, USA: Princeton University Press, 2003. [2] T. Batman. “Arity of polynomials for equivalence classes of pseudo-Boolean functions”. Bachelor’s Thesis. Utrecht University, 2025. [3] U. Bertel` e and F. Brioschi. “On non-serial dynamic programming”. In: Journal of Combi-natorial Theory, Series A 14.2 (1973), pp. 137–148. issn : 0097-3165. doi : https://doi. org/10.1016/0097-3165(73)90016-2 .[4] E. Boros and P. L. Hammer. “Pseudo-boolean optimization”. In: Discrete applied mathe-matics 123.1-3 (2002), pp. 155–225. [5] M. Borzechowski. “The complexity class Polynomial Local Search (PLS) and PLS-complete problems”. Bachelor’s Thesis. Freie Universitat Berlin, 2016. [6] C. Carbonnel, M. Romero, and S. ˇZivn´ y. “The Complexity of General-Valued Constraint Satisfaction Problems Seen from the Other Side”. In: SIAM Journal on Computing 51.1 (2022), pp. 19–69. doi : 10.1137/19M1250121 .[7] D. A. Cohen, M. C. Cooper, A. Kaznatcheev, and M. Wallace. “Steepest ascent can be exponential in bounded treewidth problems”. In: Operations Research Letters 48 (3 2020), pp. 217–224. [8] M. Cygan, F. V. Fomin, L. Kowalik, D. Lokshtanov, D. Marx, M. Pilipczuk, M. Pilipczuk, and S. Saurabh. Parameterized algorithms . Springer International Publishing, 2015. doi :

10.1007/978-3-319-21275-3 .[9] D. Dumrauf and B. Monien. “On the PLS-complexity of maximum constraint assignment”. In: Theoretical Computer Science 469 (2013), pp. 24–52. [10] R. Els¨ asser and T. Tscheuschner. “Settling the complexity of local max-cut (almost) completely”. In: International Colloquium on Automata, Languages, and Programming .Springer. 2011, pp. 171–182. [11] M. Emamy-K. “The worst case behavior of a greedy algorithm for a class of pseudo-boolean functions”. In: Discrete Applied Mathematics 23.3 (1989), pp. 285–287. [12] B. G¨ artner. “The Random-Facet simplex algorithm on combinatorial cubes”. In: Random Structures & Algorithms 20.3 (2002), pp. 353–381. [13] A. Haken and M. Luby. “Steepest descent can take exponential time for symmetric con-nection networks”. In: Complex Syst. 2.2 (Apr. 1988), pp. 191–196. issn : 0891-2513. url :

http://www.complex-systems.com/abstracts/v02%5C_i02%5C_a03.html .[14] T. D. Hansen and U. Zwick. “Random-edge is slower than random-facet on abstract cubes”. In: Leibniz International Proceedings in Informatics 55 (2016), pp. 51–1. [15] J. Horn, D. E. Goldberg, and K. Deb. “Long path problems”. In: International Conference on Parallel Problem Solving from Nature . Springer. 1994, pp. 149–158. [16] R. G. Jeroslow. “The simplex algorithm with the pivot rule of maximizing criterion im-provement”. In: Discrete Mathematics 4.4 (1973), pp. 367–377. [17] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis. “How easy is local search?” In: 

Journal of Computer and System Sciences 37.1 (1988), pp. 79–100. issn : 0022-0000. [18] A. Kaznatcheev. “Algorithmic Biology of Evolution and Ecology”. PhD thesis. University of Oxford, 2020. 17 [19] A. Kaznatcheev. “Computational complexity as an ultimate constraint on evolution”. In: 

Genetics 212.1 (2019), pp. 245–265. [20] A. Kaznatcheev, D. A. Cohen, and P. Jeavons. “Representing fitness landscapes by val-ued constraints to understand the complexity of local search”. In: Journal of Artificial Intelligence Research 69 (2020), pp. 1077–1102. [21] A. Kaznatcheev and M. van Marle. “Exponential Steepest Ascent from Valued Constraint Graphs of Pathwidth Four”. In: 30th International Conference on Principles and Practice of Constraint Programming (CP 2024) . 2024, 17:1–17:16. [22] A. Kaznatcheev and S. Vazquez Alferez. “Greed Is Slow on Sparse Graphs of Oriented Valued Constraints”. In: 31st International Conference on Principles and Practice of Con-straint Programming (CP 2025) . Ed. by M. G. de la Banda. Vol. 340. Leibniz Interna-tional Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl – Leibniz-Zentrum f¨ ur Informatik, 2025, 18:1–18:13. isbn : 978-3-95977-380-5. doi : 10.4230/LIPIcs. CP.2025.18 .[23] A. Kaznatcheev and S. Vazquez Alferez. When is local search both effective and efficient? 

2026. doi : 10 . 48550 / arXiv . 2410 . 02634 . arXiv: 2410 . 02634 [cs.DS] . url : https : //arxiv.org/abs/2410.02634 .[24] V. Klee and G. J. Minty. “How good is the simplex algorithm”. In: Inequalities 3.3 (1972), pp. 159–175. [25] G. Kochenberger, J.-K. Hao, F. Glover, M. Lewis, Z. L¨ u, H. Wang, and Y. Wang. “The unconstrained binary quadratic programming problem: a survey”. In: Journal of Combi-natorial Optimization 28.1 (2014), pp. 58–81. [26] M. W. Krentel. “On Finding and Verifying Locally Optimal Solutions”. In: SIAM Journal on Computing 19.4 (1990), pp. 742–749. [27] J. Matousek and T. Szabo. “RANDOM EDGE can be exponential on abstract cubes.” In: 

Advances in Mathematics 204 (1 2006), pp. 262–277. [28] L. Michel and A. Scott. Superpolynomial smoothed complexity of 3-FLIP in Local Max-Cut .2024. arXiv: 2310.19594 [cs.DS] . url : https://arxiv.org/abs/2310.19594 .[29] B. Monien and T. Tscheuschner. “On the Power of Nodes of Degree Four in the Local Max-Cut Problem”. In: Algorithms and Complexity . Ed. by T. Calamoneri and J. Diaz. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp. 264–275. [30] S. Poljak. “Integer linear programs and local search for max-cut”. In: SIAM Journal on Computing 24.4 (1995), pp. 822–839. [31] A. A. Sch¨ affer and M. Yannakakis. “Simple local search problems that are hard to solve”. In: SIAM Journal on Computing 20.1 (1991), pp. 56–87. [32] T. St¨ utzle. “Local search algorithms for combinatorial problems: Analysis, Improvements, and New Applications”. PhD thesis. TU Darmstadt, 1998. [33] M. van Marle. “Complexity of Greedy Local Search for Constraint Satisfaction”. Master’s Thesis. Utrecht University, 2025. [34] S. Wright. “The roles of mutation, inbreeding, crossbreeding, and selection in evolution”. In: Proc. of the 6th International Congress on Genetics . 1932, pp. 355–366. 18