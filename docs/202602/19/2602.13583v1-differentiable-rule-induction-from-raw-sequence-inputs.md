---
title: Differentiable Rule Induction from Raw Sequence Inputs
authors: "Kun Gao, Katsumi Inoue, Yongzhi Cao, Hanpin Wang, Feng Yang"
date: 2026-02-14
pdf: "https://arxiv.org/pdf/2602.13583v1"
tags: ["query:sr"]
score: 7.0
evidence: 可微规则归纳与神经符号集成
tldr: 本研究针对可微归纳逻辑程序设计（ILP）在处理原始非符号化数据时存在的“显式标签泄漏”难题，提出了一种创新的端到端框架。该框架通过集成自监督可微聚类模型与新型可微ILP模型，实现了在无需输入特征标签监督的情况下，直接从时间序列和图像等原始序列数据中诱导逻辑规则。实验证明，该方法能够精准提取具有高度可解释性和泛化能力的规则，有效弥合了深度学习与符号推理之间的鸿沟。
motivation: 现有的可微ILP模型通常依赖符号化数据集，在直接处理原始数据时面临无法在无监督情况下将连续输入映射为符号变量的挑战。
method: 提出一种将自监督可微聚类与新型可微ILP模型相结合的方法，实现从原始数据到逻辑规则的端到端诱导。
result: 在时间序列和图像数据集上的实验表明，该方法能够直观且精确地学习到具有泛化性的逻辑规则。
conclusion: 该研究成功解决了从原始输入进行规则归纳时的标签泄漏问题，显著提升了规则学习模型在处理非结构化数据时的实用性和解释性。
---

## Abstract
Rule learning-based models are widely used in highly interpretable scenarios due to their transparent structures. Inductive logic programming (ILP), a form of machine learning, induces rules from facts while maintaining interpretability. Differentiable ILP models enhance this process by leveraging neural networks to improve robustness and scalability. However, most differentiable ILP methods rely on symbolic datasets, facing challenges when learning directly from raw data. Specifically, they struggle with explicit label leakage: The inability to map continuous inputs to symbolic variables without explicit supervision of input feature labels. In this work, we address this issue by integrating a self-supervised differentiable clustering model with a novel differentiable ILP model, enabling rule learning from raw data without explicit label leakage. The learned rules effectively describe raw data through its features. We demonstrate that our method intuitively and precisely learns generalized rules from time series and image data.