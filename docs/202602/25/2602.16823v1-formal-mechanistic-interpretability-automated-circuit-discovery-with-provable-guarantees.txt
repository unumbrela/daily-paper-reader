Title: Formal Mechanistic Interpretability: Automated Circuit Discovery with Provable Guarantees

URL Source: https://arxiv.org/pdf/2602.16823v1

Published Time: Fri, 20 Feb 2026 01:08:04 GMT

Number of Pages: 42

Markdown Content:
Published as a conference paper at ICLR 2026 

# FORMAL MECHANISTIC INTERPRETABILITY :AUTOMATED CIRCUIT DISCOVERY WITH PROVABLE 

# GUARANTEES 

Itamar Hadad 1, Guy Katz 1, Shahaf Bassan 1

School of Computer Science and Engineering, The Hebrew University of Jerusalem 1

itamar.hadad@mail.huji.ac.il, g.katz@mail.huji.ac.il ,

shahaf.bassan@mail.huji.ac.il 

## ABSTRACT 

Automated circuit discovery is a central tool in mechanistic interpretability for identifying the internal components of neural networks responsible for specific behaviors. While prior methods have made significant progress, they typically depend on heuristics or approximations and do not offer provable guarantees over continuous input domains for the resulting circuits. In this work, we leverage recent advances in neural network verification to propose a suite of automated algorithms that yield circuits with provable guarantees . We focus on three types of guarantees: (i) input domain robustness , ensuring the circuit agrees with the model across a continuous input region; (ii) robust patching , certifying circuit alignment under continuous patching perturbations; and (3) minimality , formalizing and capturing a wide array of various notions of succinctness. Interestingly, we uncover a diverse set of novel theoretical connections among these three families of guarantees, with critical implications for the convergence of our algorithms. Finally, we conduct experiments with state-of-the-art verifiers on various vision models, showing that our algorithms yield circuits with substantially stronger robustness guarantees than standard circuit discovery methods — establishing a principled foundation for provable circuit discovery. 

## 1 INTRODUCTION 

The rapid rise of neural networks, driven by transformative architectures such as Transformers, has reshaped both theory and applications. Alongside this revolution, interpretability has become a central research direction (Zhang et al., 2021; Räuker et al., 2023); and more recently, efforts have focused on mechanistic interpretability (MI), which aims to reverse-engineer neural networks into human-understandable components and functional modules (Olah et al., 2020; Olah, 2022; Zhao et al., 2024). MI offers fine-grained interpretability that serves various purposes, including transparency, trustworthiness, safety, and other applications (Bereska & Gavves, 2024; Zhou et al., 2025). A central open challenge in MI is circuit discovery (Olah et al., 2020), which seeks to identify subgraphs within neural networks, called circuits , that drive specific model behaviors. Recent works propose varied approaches (Wang et al., 2023; Conmy et al., 2023; Rajaram et al., 2024), differing by domain (text vs. vision), patching methods (zero, mean, sampling), and the balance between manual and automated steps. However, despite substantial progress, most current circuit discovery algorithms remain heuristic or approximate, without rigorous guarantees of circuit faithfulness, particularly under continuous perturbation domains (Adolfi et al., 2025; Miller et al., 2024; Méloux et al., 2025). This limitation is concerning: even small perturbations can break circuit faithfulness, and since circuit discovery is tied to safety considerations (Bereska & Gavves, 2024), such guarantees are essential. 

Our Contributions. To address these concerns, we introduce a novel algorithmic framework that builds on recent and exciting advances in the emerging field of neural network verification (Wang et al., 2021; Zhou et al., 2024; Brix et al., 2024; Kotha et al., 2023; Ferrari et al., 2022), enabling the derivation of circuits with provable guarantees across continuous domains of interest. 1

> arXiv:2602.16823v1 [cs.LG] 18 Feb 2026

Published as a conference paper at ICLR 2026 1.1 THEORETICAL CONTRIBUTIONS 

• We formalize a set of novel provable guarantees for circuit discovery that hold strictly over 

entire continuous domains . These include: (i) input-domain robustness , ensuring circuits remain faithful across continuous input regions; (ii) patching-domain robustness , addressing criticisms of sampling-based ablation; and (iii) a broad family of minimality guarantees ,extending earlier notions to include quasi -, local -, subset -, and cardinal -minimality. • We present novel theoretical proofs that reveal strong connections between these three families of guarantees. At the core is the circuit monotonicity property, which underpins min-imality guarantees for optimization algorithms and clarifies the conditions under which they hold. We also establish a crucial duality between circuits and small “blocking” subgraphs, enabling the efficient discovery of circuits with much stronger minimality guarantees. 1.2 EMPIRICAL CONTRIBUTIONS 

• We propose a framework for encoding both input- and patching-robustness guarantees in neural networks and their circuits, using a technical siamese encoding of the network with its associated circuit or patching-domain, which enables certifying the desired properties. • We introduce a set of novel automated algorithms that preserve the invariants of the robust-ness guarantees and prove that each converges to circuits meeting our various minimality criteria. These algorithms enable a trade-off between computational cost and the degree of minimality achieved in the resulting circuits. • We conduct extensive experiments with α–β-CROWN, the state-of-the-art in neural network verification, to derive circuits with input, patching, and minimality guarantees. These are evaluated on standard neural vision models commonly used in the neural network verification literature. Compared to sampling-based approaches, our framework certifies robustness, whereas even infinitesimal perturbations break the faithfulness of sampling-based circuits. Overall, we believe these contributions mark a significant step forward in establishing both theoretical and empirical foundations for circuit discovery with provable guarantees, paving the way for a wide range of future research directions. 

## 2 PRELIMINARIES 

2.1 NOTATION 

Let fG : Rn → Rd denote a neural network, with G := ⟨V, E ⟩ representing its computation graph. The precise structure of G — that is, what each node and edge correspond to (e.g., neurons, attention heads, positional embeddings, convolution filters) — is determined both by the network’s architecture and by the level of granularity chosen by the user. A circuit C is defined as a subgraph C ⊆ G,consisting of components hypothesized to drive the model’s behavior on a task. Each such circuit naturally induces a function fC : Rn → Rd, obtained by restricting fG to the components in C.In circuit discovery, the complement C := G \ C is often fixed to constant activations, a practice known as patching , with variants such as zero-patching or mean-patching. Let fG have L ∈ N

layers with activation spaces Vi for i ∈ [L], and let X ⊆ Rn be an input domain. For x ∈ X ,denote the activations at layer i as hi(x) ∈ Vi, and the reachable activation space as HG(X ) = 

{(h1(x), . . . , h L(x)) : x ∈ X } ⊆ V1 × · · · × VL. We write HC (X ) for the partial reachable activation space over C. For a partial activation assignment α ∈ H C (X ), we write fC (x | C = α) to denote inference through fC (x), constructed from the components of C, while fixing the activations of C to the values in α.2.2 NEURAL NETWORK VERIFICATION 

Consider a generic neural network fG with arbitrary element-wise nonlinear activations. Many tools exist to formally verify properties of such networks, with adversarial robustness being the most studied (Brix et al., 2024). Formally, the neural network verification problem can be stated as follows: 2Published as a conference paper at ICLR 2026 

Neural Network Verification (Problem Statement) :

Input : A neural network model fG, for which y := fG(x), with an input specification ψin (x), and an unsafe output specification ψout (y).

Output : No , if there exists some x ∈ Rn such that ψin (x) and ψout (y) both hold, and Yes otherwise. A variety of off-the-shelf neural network verifiers have been developed (Brix et al., 2024). When the input constraints ψin (x), output constraints ψout (y), and model fG are piecewise-linear (e.g., ReLU activations), the verification problem can be solved exactly (Katz et al., 2017). In practice, it is often relaxed for efficiency, and the output is enclosed within bounds that account for approximation errors. 

## 3 PROVABLE GUARANTEES FOR CIRCUIT DISCOVERY 

3.1 INPUT DOMAIN GUARANTEES 

In this subsection, we introduce the first set of guarantees that our algorithms are designed to satisfy — specifically, provable robustness against input perturbations. A central challenge when evaluating a circuit’s faithfulness is that, even if it matches the model at one point or a finite set of points, small input perturbations can quickly break this agreement. To overcome this limitation, our first definition considers circuits that are not only faithful to the model on a discrete set of points but are also provably robust across an entire infinite continuous set of inputs. 

Definition 1 (Input-robust circuit) . Given a neural network fG and a union of continuous domains 

Z ⊆ Rn (e.g., a union of ℓp-balls of radius ϵp around a set of discrete points {xj }kj=1 ), we say that a subgraph C ⊆ G is an input-robust circuit with respect to ⟨fG, Z⟩ , a fixed patching vector α applied to the complement set C := G \ C, and a tolerance level δ ∈ R+, if and only if: 

∀z ∈ Z := 

> k

[

> j=1

Bpϵp (xj ). ∥fC (z | C = α) − fG(z)) ∥p ≤ δ, s.t. Bpϵp (xj ) := {zj ∈ Rn | ∥ zj − xj ∥p ≤ ϵp}

(1) z1      

> z2
> f(G⊔C′)(z|C′=α)
> Concatenated logits
> Model G
> Circuit C
> Input

Figure 1: Illustration of the Siamese encoding for certifying the guarantee in Def. 1. 

Certifying circuit input robustness via verification. 

Neural network verification properties are typically encoded over a single model fG, while the circuit input robustness property (Def. 1) requires evaluating both the model graph G and a circuit C ⊆ G. To address this, we introduce a novel method to certify the property in Def. 1 using a siamese encoding of the network fG. Specifically, we duplicate the circuit 

C′ := C and “stack” it with G to form a combined model G ⊔ C′ with a shared input layer. This induces a function f(G⊔C′) : Rn → R2d. The activations of the non-circuit components in the duplicate, C′ := 

G \ C′, are fixed to a constant α, so for any z ∈ Rn

inference is f(G⊔C′)(z | C′ = α), enabling direct certification of Def. 1 over the combined model. The input constraint ψin (x) bounds x within Z, while the output constraint ψout (y) bounds the distance measure between the logits of C′ and G. Further details of this encoding appear in Appendix E. 3.2 PATCHING DOMAIN GUARANTEES 

A central challenge in circuit discovery lies in deciding how to assign values to the complementary activations of a circuit — a process known as patching . The goal of patching is to replace these values to isolate the circuit’s contribution. Prior work has examined several approaches, including zero-patching, which has been criticized as arbitrary since such values may be out-of-distribution if unseen during training (Conmy et al., 2023; Wang et al., 2023). Other strategies include mean-value patching (Wang et al., 2023) and sampling from discrete input distributions (Conmy et al., 2023). Yet, these methods still rely on evaluating complementary activations over a discrete set of sampled inputs, which may fail to generalize in continuous domains: even small perturbations in the 3Published as a conference paper at ICLR 2026 patching scheme can undermine a circuit’s faithfulness. By analogy to input -robustness, we introduce 

patching -robustness: the requirement that a circuit preserve its faithfulness across an entire provable range of feasible perturbations to the complementary activations over a continuous input domain. 

Definition 2 (Patching-robust circuit) . Given a neural network fG, a continuous input domain 

Z ⊆ Rn,and a reference set of inputs {xj }kj=1 ⊆ X , we say that C ⊆ G is a patching-robust circuit 

with respect to ⟨fG, Z⟩ and a tolerance level δ ∈ R+, iff for every xj in {xj }kj=1 :

∀α ∈ H C (Z). ∥fC (xj | C = α) − fG(xj )∥p ≤ δ (2) z1       

> z2
> x1
> x2
> Input
> f(G⊔C′)
> (x)∣∣C′=HC(z))
> Logits
> Model G
> Circuit C

Figure 2: Illustration of the Siamese encoding for certifying the guarantee in Def. 2. Gray neurons denote non-circuit units whose activa-tions are patched with those of the full model. 

Certifying circuit patching robustness via verifi-cation. Analogous to input robustness, we introduce here a novel method to certify the property in Def 2, using a siamese encoding of fG. Concretely, we du-plicate the circuit C′ := C and “stack” it with G,but now G and C′ have disjoint input domains, yield-ing f(G⊔C′) : R2n → Rd. We connect C′ and G

by fixing the activations of C′ to those attained by 

HC (z) when evaluating fG(z). Thus, inference for 

(x, z) ∈ R2n is given by f(G⊔C′)(x | C′ = HC (z)) .We then set input constraints to bound z within Z,and output constraints to limit the distance ∥·∥ p be-tween the logits of C′ and G. Further details appear in Appendix F. We remark that input robustness and patching robustness can also be certified simultane-ously within a single verification query by extending the siamese encoding (see Appendix G). 

## 4 FROM CIRCUITS TO MINIMAL CIRCUITS 

A common convention in the literature is that smaller circuits (i.e., lower circuit size) are generally considered more interpretable than larger ones (Mueller et al., 2025; Adolfi et al., 2025; Chowdhary et al., 2025; Wang et al., 2023; Bhaskar et al., 2024; Shi et al., 2024; Conmy et al., 2023). This makes minimality an important additional guarantee (Adolfi et al., 2025; Chowdhary et al., 2025; Shi et al., 2024; Mueller et al., 2025). While many works have pursued minimal circuits, recent studies highlight that “minimality” itself can take different forms (Adolfi et al., 2025), ranging from the weak notion of quasi -minimality to the strong notion of cardinal -minimality. In this work, we extend this spectrum to four main forms and provide rigorous proofs linking them to different optimization algorithms. 4.1 MINIMALITY GUARANTEES v1 = x2                  

> v2=x1
> v3=x1
> v4=x1⊕x2
> v5=x1⊕x2
> v6=x2⊕x2(= 0)
> x1
> x2
> ⊕y

Figure 3: A toy Boolean circuit. In this subsection, we introduce four central notions of minimality. Since minimality must be defined rel-ative to what qualifies as a “valid” or faithful circuit, we begin by specifying a general faithfulness pred-icate , Φ( C, G ). Given a circuit C ⊆ G within the computation graph G of a model fG, Φ( C, G ) re-turns True if C is faithful under some condition of interest, and False otherwise. Instances of Φ may include standard sampling-based measures used in circuit discovery, such as requiring the mean-squared error or KL-divergence between C and G to remain below a threshold τ (Conmy et al., 2023). Alterna-tively, Φ can reflect our provable measures that hold across continuous domains (Section 3), e.g., defining 

Φ( C, G ) to require input and/or patching robustness. Consider, for example, a toy Boolean circuit pre-sented in Fig. 3 as a running example. For sim-plicity, we assume that each node in the circuit corresponds to a component of the model. 4Published as a conference paper at ICLR 2026 The network takes inputs (x1, x 2) ∈ { 0, 1}2, whose outputs are aggregated by XOR, yielding 

fG(x1, x 2) = v1 ⊕ v2 ⊕ · · · ⊕ v6 = x2, since 

fG(x1, x 2) := x2 ⊕ x1 ⊕ x1 ⊕ (x1 ⊕x2) ⊕ (x1 ⊕x2) ⊕ (x2 ⊕x2)= x2 ⊕ (x1 ⊕x1)

| {z }

> =0

⊕ [( x1 ⊕x2) ⊕ (x1 ⊕x2)] 

| {z }

> =0

⊕ (x2 ⊕x2)

| {z }

> =0

= x2.

For simplicity, we set the faithfulness predicate to consider the very strong condition of strict equality between the circuit and the model for every boolean input. In other words, for all x1 and x2 in 

{0, 1}2, it holds that Φ( C, G ) := fC (x1, x 2) = fG(x1, x 2) = x2. A more detailed description of this example appears in Appendix C.3. We begin with the weakest form of minimality and proceed step by step until we reach the strongest. The first notion, quasi -minimality, introduced by (Adolfi et al., 2025), defines C as a subset that includes a “breaking point”: some component that, when removed, breaks the circuit’s faithfulness: 

Definition 3 (Quasi-Minimal Circuit) . Given G, a quasi-minimal circuit C ⊆ G concerning Φ, is a circuit for which Φ( C, G ) holds (“ C is faithful”), and there exists some element (i.e., node/edge) i in 

C for which Φ( C \ { i}, G ) is false. 

In our running example C = {v1, . . . , v 5} is quasi-minimal: it satisfies v1 ⊕ · · · ⊕ v5 = fG, but removing some essential node (e.g., v1) breaks this equality. However, we observe that the quasi -minimality notion of (Adolfi et al., 2025) can be strengthened: instead of requiring a single breaking point, one can demand that every component serves as one. Following conventions in the optimization literature, we refer to this stronger notion as local minimality. 

Definition 4 (Locally-Minimal Circuit) . Given G, a locally-minimal circuit C ⊆ G concerning Φ, is a circuit for which Φ( C, G ) holds, and for any element i in C, Φ( C \ { i}, G ) is false. 

In our example, C = {v1, v 2, v 3} is locally minimal, as the predicate holds for {v1, v 2, v 3}, but does not hold for {v1, v 2}, {v1, v 2}, and {v2, v 3}. However, while local-minimality is stronger than quasi-minimality, it still has a limitation. Although removing any single component from the circuit C breaks it, removing multiple components may still leave C valid, giving a misleading sense of minimality. For instance, in our locally minimal circuit C = {v1, v 2, v 3}, observe that while removing any single component (i.e., v1, v2, or v3) breaks faithfulness, removing the pair {v2, v 3}

(i.e., keeping only v1) nonetheless results in a faithful circuit. To address this, we define a stronger notion: subset-minimality , which requires every subset of components to be a breaking point. 

Definition 5 (Subset-Minimal Circuit) . Given G, a subset-minimal circuit C ⊆ G concerning Φ, is a circuit for which Φ( C, G ) holds true, and for any subgraph S ⊊ C, Φ( C \ S, G ) is false. 

In the running example, C = {v2, v 4} is a subset-minimal circuit, as v2 ⊕ v4 = x1 ⊕ (x1 ⊕ x2) = x2,since every strict subset ( {v2}, {v4}) fails to compute fG. We note that even this significantly stronger notion of subset-minimality does not necessarily yield subsets of the absolute lowest cardinality. To address this limitation, the final notion introduces the strongest form: a cardinally-minimal circuit, which corresponds to the global optimum of minimality. 

Definition 6 (Cardinally-Minimal Circuit) . Given G, a cardinally-minimal circuit C ⊆ G concerning 

Φ is a circuit for which Φ( C, G ) is true, and has the lowest cardinality |C| (i.e., there is no circuit 

C′ ⊆ G for which Φ( C′, G ) is true and |C′| < |C|). 

Here, {v1} is cardinally minimal, since v1 = x2 is functionally equivalent to fG and no smaller faithful circuit exists. 4.2 ALGORITHMS FOR LOCAL AND QUASI MINIMAL CIRCUITS 

In this subsection, we present optimization algorithms for discovering circuits with provable guar-antees. Building on prior circuit discovery frameworks, we show how modifying or validating optimization objectives changes the resulting guarantees. We also establish theoretical links between objectives based on continuous robustness guarantees and different notions of minimality. We begin with a standard greedy algorithm (Algorithm 1): 5Published as a conference paper at ICLR 2026 

Algorithm 1 Greedy Circuit Discovery Iterative Search  

> 1:

Input Model fG, circuit faithfulness predicate Φ 

> 2:

C ← G under some given element ordering (e.g., reverse topological sort)  

> 3:

for all i ∈ C do  

> 4:

if Φ( C \ { i}, G ) then  

> 5:

C ← C \ { i} 

> 6:

end if  

> 7:

end for  

> 8:

return C

Algorithm 1 describes a standard greedy procedure that starts from the full model graph G and itera-tively removes components as long as the faithfulness predicate holds. While this structure underlies many circuit discovery methods, we also consider an exhaustive variant, given as Algorithm 3 in Appendix C, which repeatedly iterates over the remaining components and attempts further removals, stopping only when every single component is critical. This guarantees the following: 

Proposition 1. Given any model fG and faithfulness predicate Φ, Algorithm 1 visits a quasi-minimal 

circuit and Algorithm 3 converges to a locally-minimal circuit C, both with respect to Φ.

We note that each evaluation of Φ( C \ { i}, G ) may be costly, depending on the predicate Φ (e.g., certifying input or patching robustness). To mitigate this, one may use a lighter notion of minimality — the quasi -minimal circuits of (Adolfi et al., 2025) — which require only a logarithmic, rather than linear, number of invocations. For completeness, we formally present and extend their binary-search procedure, provided as Algorithm 4 in Appendix C. Algorithm 4 follows a procedure similar to Algorithm 1, but employs a binary rather than iterative search. As a result, it yields a weaker notion of minimal circuits, while requiring fewer queries. We can therefore establish the following proposition: 

Proposition 2. While Algorithm 4 converges to a quasi-minimal circuit using O(log |G|) evaluations of Φ( C, G ) (Adolfi et al., 2025), Algorithm 1 visits a quasi-minimal circuit with O(|G|) evaluations, and Algorithm 3 converges to a locally-minimal circuit using O(|G|2) evaluations. 

Finally, we note that Algorithms 1, 3 and 4 converge only to relatively “weak” forms of minimality. Even the stronger local-minimality guarantee of Algorithm 3 can fall short: while every single-element removal C \ { i} breaks faithfulness, removing two elements simultaneously, C \ { i, j }, may still yield a faithful circuit. This undermines C’s “minimality” and shows that neither algorithm ensures the stronger notion of subset -minimality. 

Proposition 3. There exist infinitely many configurations of fG, and Φ, for which Algorithms 1, 3 and 4 do not converge to a subset-minimal circuit C concerning Φ.

4.3 THE CIRCUIT MONOTONICITY PROPERTY AND ITS IMPACT ON MINIMALITY 

To address the issue of algorithms converging to “bad” local minima, we identify a key property of the faithfulness predicate Φ with crucial implications for stronger minimal subsets — monotonicity :

Definition 7. We say that a circuit faithfulness predicate Φ is monotonic iff for any C ⊆ C′ ⊆ G it holds that if Φ( C, G ) is true, then Φ( C′, G ) is true. 

Intuitively, monotonicity means that once Φ( C, G ) holds for a circuit C (i.e., it is “faithful”), it will keep holding as elements are added. In other words, enlarging the circuit never breaks faithfulness. This property is essential for Algorithm 1, as it underpins the stronger minimality guarantee: 

Proposition 4. If Φ is monotonic, then for any model fG, Algorithm 1 converges to a subset-minimal circuit C concerning Φ.

The condition of monotonicity. Interestingly, we establish a novel connection between the guarantees on the input and patching domains outlined in Section 3 and the monotonic behavior of Φ:

Proposition 5. Let Φ( C, G ) denote validating whether C is input-robust concerning ⟨fG, Z⟩ (Def. 1), and simultaneously patching-robust concerning ⟨fG, Z′⟩ (Def. 2). Then if Z ⊆ Z ′ and HG(Z′) is closed under concatenation, Φ is monotonic. 

6Published as a conference paper at ICLR 2026 Intuitively, Proposition 5 shows that if the patching domain Z′ subsumes the input domain Z, and the activation space HG(Z′) is closed under concatenation, i.e., concatenating any two partial activations remains within HG(Z′) — then the faithfulness predicate Φ is monotonic. This introduces a new class of evaluation conditions that are monotonic by construction, yielding stronger minimal circuits. 

Proposition 6. If the condition Φ( C, G ) is set to validating whether C is input-robust concerning 

⟨fG, Z⟩ (Def. 1), and also patching-robust with respect to ⟨fG, Z′⟩ (Def. 2), then if Z ⊆ Z ′ and 

HG(Z′) is closed under concatenation, Algorithm 1 converges to a subset-minimal circuit. 

4.4 FROM SUBSET -M INIMAL CIRCUITS TO CARDINALLY -M INIMAL CIRCUITS 

Although the monotonicity of Φ provides a stronger guarantee of subset-minimality, it still does not ensure convergence to the globally minimal circuit (i.e., a cardinally -minimal circuit). A naive approach to obtain such circuits is to enumerate all C ⊆ G, verify Φ( C, G ), and choose the one with the lowest cardinality |C|, but this quickly becomes intractable even for modestly sized graphs. 

Exploiting circuit blocking-set duality for efficient approximation of cardinally-minimal circuits. 

In this subsection, we leverage the idea that neural networks often contain small “circuit blocking-sets” — subgraphs C′ ⊆ G whose altered activations break the faithfulness of any circuit C that excludes them. We prove a duality between circuits (under monotone faithfulness predicates) and these blocking-sets, enabling a new algorithmic construction that approximates — and sometimes exactly recovers — cardinally minimal circuits far more efficiently than naive search. Formally, for 

fG and Φ, a circuit blocking-set is any C′ ⊆ G such that Φ( C \ C′, G ) fails for all C ⊆ G. This yields a duality grounded in a minimum-hitting-set (MHS) relation between circuits and blocking-sets: 

Proposition 7. Given some model fG, and a monotonic predicate Φ, the MHS of all circuit blocking-sets concerning Φ is a cardinally minimal circuit C for which Φ( C, G ) is true. Moreover, the MHS of all circuits C ⊆ G for which Φ( C, G ) is true, is a cardinally minimal blocking-set w.r.t Φ.

The definition of MHS, a classic NP-Complete problem is given in Appendix B.7. This duality is powerful because, despite NP-completeness, MHS can often be solved efficiently in practice with modern solvers such as MILP or MaxSAT (Ignatiev et al., 2019a). Hence, similar dualities have already been central to formal reasoning and provable explainability methods (Bacchus & Katsirelos, 2015; Ignatiev et al., 2019c; Bassan & Katz, 2023; Liffiton et al., 2016). With this duality theorem in hand, we can design an algorithm that often computes (or approximates) cardinally minimal circuits: 

Algorithm 2 Cardinally Minimal Circuit Approximation using MHS duality  

> 1:

Input model fG, faithfulness predicate Φ, tmax ∈ [|G|] 

> 2:

BlockingSets ← ∅  

> 3:

for t ← 1 to tmax do  

> 4:

Ct ← { S ⊆ G, ∀U ⊆ BlockingSets : |S| = t, U ̸ ⊆ S} 

> 5:

for all S ∈ C t do ▷ parallelization  

> 6:

if ¬Φ( G \ S, G ) then  

> 7:

BlockingSets ← BlockingSets ∪ S 

> 8:

end if  

> 9:

end for  

> 10:

C ← MHS (BlockingSets ) 

> 11:

if Φ( C, G ) then return C 

> 12:

end if  

> 13:

end for 

Algorithm 2 leverages Proposition 7 by iterating over blocking-sets in parallel and computing each set’s MHS to obtain a circuit C. This establishes a lower bound on the cardinally minimal circuit and, through successive refinements, converges to the minimal one. While the number of blocking-set subsets may be excessive in the worst case, in practice their size is often tractable (see Section 5) yielding a low tmax and enabling more efficient — or closely approximate — computation of cardinally minimal circuits. This is formalized in the following claim: 7Published as a conference paper at ICLR 2026 

Proposition 8. Given a model fG, and a monotonic predicate Φ, Algorithm 2 computes a subset C

whose size is a lower bound to the cardinally minimal circuit for which Φ( C, G ) is true. For a large enough tmax value, the algorithm converges exactly to the cardinally minimal circuit. 

## 5 EXPERIMENTAL EVALUATION 

Experimental setup. We evaluate our method on standard benchmarks from the neural network verification literature (Brix et al., 2024; 2023): (i) MNIST, (ii) CIFAR-10, (iii) GTSRB, and (iv) Tax-iNet (a real-world dataset used in verification-based input-explainability studies (Wu et al., 2023a; Bassan et al., 2025a)) . For neural network verification, we use the state-of-the-art α, β -CROWN verifier (Bak et al., 2021; Müller et al., 2022a; Brix et al., 2024); for MHS we use RC2 (Ignatiev et al., 2019a). For consistency, we evaluate our results on model architectures from prior verification studies, particularly the neural network verification competition (VNN-COMP) (Brix et al., 2024); full architectural details appear in Appendix D. To balance circuit discovery difficulty and human interpretability, we chose the circuit granularity level to be neurons for MNIST and convolutional filters for CIFAR-10, GTSRB, and TaxiNet. Both provable and sampling-based variants use the standard logit-difference metric (Conmy et al., 2023). Further details are in Appendices E, F and G. 5.1 CIRCUIT DISCOVERY WITH INPUT -R OBUSTNESS GUARANTEES 

We begin by evaluating the continuous input robustness guarantees of our method. We compare two variants of Algorithm 1: (i) a standard sampling-based approach, where faithfulness is assessed by applying the logit-difference predicate with tolerance δ on sampled inputs, and (ii) a provable 

approach, which, via the siamese encoding of Section 3.1, certifies that the logit difference always remains below δ throughout the continuous input domain. For both methods, we report circuit size and robustness over the continuous input neighborhood across 100 batches (one circuit per batch). We set the input neighborhood using ϵp values aligned with VNN-COMP (Brix et al., 2024) (with variations in Appendix E) and adopt zero-patching in both settings. Results (Table 1) show that the provable method is slower, due to solving certification queries, yet achieves 100% robustness with 

comparable circuit sizes , whereas the sampling-based baseline attains substantially lower robustness. An illustrative example appears in Figure 4. Table 1: Circuit results from Algorithm 1, where Φ is defined either by bounding logit differences under input sampling or by verifying the bound using the siamese encoding.                                                        

> Dataset Sampling-based Circuit Discovery Provably Input-Robust Circuit Discovery
> Time (s) Size ( |C|)Robustness (%) Time (s) Size ( |C|)Robustness (%) CIFAR-10 0.23 ±0.52 16.47 ±9.08 46.5 ±5.02970.85 ±874 .23 19.18 ±10 .16 100.0 ±0.0
> MNIST 0.31 ±0.89 12.56 ±2.30 19.2 ±4.0611.93 ±97 .14 15.84 ±2.33 100.0 ±0.0
> GTSRB 0.11 ±0.33 28.91 ±4.69 27.6 ±4.0991.08 ±162 .91 29.59 ±4.45 100.0 ±0.0
> TaxiNet 0.01 ±0.00 5.77 ±0.80 9.5 ±3.0180.00 ±40 .39 6.82 ±0.46 100.0 ±0.0

5.2 CIRCUIT DISCOVERY WITH PATCHING -R OBUSTNESS GUARANTEES 

Table 2: Circuit results from Algorithm 1, where Φ is defined either by bounding logit differences under zero patching, mean patching, or by verifying the bound using the siamese encoding.                                                                                 

> Dataset Zero Patching Mean Patching Provably Patching-Robust Patching
> Time (s) Size ( |C|)Rob. (%) Time (s) Size ( |C|)Rob. (%) Time (s) Size ( |C|)Rob. (%) CIFAR-10 0.1 ±0.3 65.1 ±3.046.4 ±6.00.0 ±0.064.1 ±3.633.3 ±5.75408.5 ±1091 .065.6 ±1.6100.0
> MNIST 0.1 ±0.320.0 ±1.558.0 ±5.30.0 ±0.019.2 ±1.855.7 ±5.3714.9 ±207 .117.0 ±2.3100.0
> GTSRB 0.3 ±0.932.6 ±4.238.0 ±4.40.0 ±0.033.4 ±4.240.5 ±4.52907.2 ±721 .734.3 ±4.1100.0
> TaxiNet 0.0 ±0.15.8 ±0.857.1 ±5.00.0 ±0.15.4 ±0.763.3 ±4.9175.7 ±52 .75.4 ±0.6100.0

To assess patching robustness, we study three variants of Algorithm 1 enforcing a bounded logit difference under different patching schemes: (i) zero-patching, (ii) mean-patching, and (iii) a certified 8Published as a conference paper at ICLR 2026 f0 

f1 f2 

> f3
> f4
> f5
> f6
> f7
> f9
> f10
> f11
> f12
> f14

f0 

f1 f2  

> f3
> f4
> f5
> f6
> f7
> f11
> f12
> f13
> f14
> f15
> Conv1
> f9
> f8
> f13
> f10
> f8
> f15
> Block 1
> Conv2

f0 

f1 f2 

> f3
> f4
> f5
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f15

f0 

f1 f2  

> f3
> f4
> f5
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f15
> Conv1 Conv2
> Deer
> Conv1

f3 

f4 

f5 

f6 

f7 

f1 

f0 

FC 

> Block 2

+

f2  +

f0 

f1 f2 

> f3
> f4
> f5
> f6 f7
> f9
> f10
> f11
> f12
> f14

f0 

f1 f2  

> f3
> f4
> f5 f6
> f7
> f11
> f12
> f14
> f15
> Conv1
> f13
> f9
> f8
> f13
> f10
> f8
> f15
> Conv2

f0 

f1 f2 

> f3
> f4
> f5
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f15

f0 

f1 f2  

> f3
> f4
> f5
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13 f14
> f15
> Conv1 Conv2

Provably-

robust 

> Bird
> Conv1

f3 

f4 

f5 

f6 

f7 

f1 

f0 

+

f2  +

Sam pling-

based  

> Block 1 Block 2

FC   

> +=
> +=

Figure 4: Examples of ResNet circuits at the filter level on CIFAR-10. Filters are numbered within each layer, with non-circuit filters in gray and residual connections shown as dashed lines. We compare circuits from the sampling-based discovery and the provably robust variant, highlighting components unique to the provable circuit in green. variant that, using a siamese encoding (Section 3.2), verifies the bound uniformly over a continuous patching domain. Circuits found with zero or mean patching are then evaluated under the same continuous-domain criterion as the certified setting. Results appear in Table 2. Circuits found under standard patching (zero/mean) are sensitive to changes in the patching domain and yield low robustness, whereas the verified method certifies this property and achieves 100% robustness. Despite the higher computational cost (due to the reliance on verification), the provable method delivers much stronger robustness at comparable circuit sizes. 5.3 EXPLORING DIFFERENT MINIMALITY GUARANTEES OF CIRCUIT DISCOVERY 

We experiment with the minimality guarantees from Sec. 4 and their connection to the robustness and patching guarantees of Sec. 3. For the Φ predicate, we certify both input- and patching robustness using a double-siamese encoding (Sec. 3.2), with environments Z ⊆ Z ′, and run Alg. 1, 2, 4. Alg. 2 is run with tmax = 3 , restricting the contrastive blocking-set enumeration to sets of size at most three. Our experiments show that MHS size consistently lower-bounds circuit size, with no circuit falling 

below its MHS. In some runs, Alg. 1 circuits meet the bound exactly, and some MHS circuits are certified as faithful (i.e., satisfying both input and patching robustness), as shown in Fig. 5a. We also note the efficiency–circuit size trade-off in Figure 5b: the quasi-minimal (Alg. 4) procedure terminates fastest but plateaus at larger sizes with weaker minimality; the iterative search (Alg. 1) achieves smaller sizes (stronger minimality) at higher runtime; and the MHS (Alg. 2) loop is slowest yet progressively approaches a cardinally minimal (optimal) circuit size. 

## 6 RELATED WORK 

Circuit discovery. Our work joins recent efforts on circuit discovery in MI (Olah et al., 2020; Elhage et al., 2021; Dunefsky et al., 2024), particularly those advancing automated algorithms (Conmy et al., 2023; Hsu et al., 2024). Other relevant avenues include metrics for circuit faithfulness (Marks et al., 2025; Hanna et al., 2024), differing patching strategies (Jafari et al., 2025; Syed et al., 2024; Haklay et al., 2025; Miller et al., 2024; Zhang & Nanda, 2024), minimality criteria (Chowdhary et al., 2025; Wang et al., 2023), and applications (Yao et al., 2024; Sharkey et al., 2025). 

Theoretical investigations of MI. Several recent directions have examined other theoretical aspects of MI, often linked to circuit discovery. These include framing MI within a broader causal abstraction framework (Geiger et al., 2025; 2024), connecting it to distributed alignment search (DAS) (Wu 9Published as a conference paper at ICLR 2026 2 4 6 8 10 

> MHS Size
> 0
> 5
> 10
> 15
> 20
> 25
> 30
> Circuit Size
> Binary Search (Quasi-Min.)
> Iterative Search
> Faithful MHS Circuit
> MHS equality line (y=x)

(a) Circuit size against MHS size 0 60 120 180 240 300 360 420 480 540 600  

> Elapsed Time (seconds)
> 0
> 5
> 10
> 15
> 20
> 25
> 30
> 35
> Circuit Size
> MHS
> Iterative Search
> Binary Search (Quasi)

(b) Circuit size over time 

Figure 5: (a) Circuit size vs. MHS of blocking sets size, with the dashed equality line y=x as the lower bound. (b) Convergence of circuit size over the first 10 minutes; shaded region shows deviation. et al., 2023b; Sun et al., 2025); analyzing learned circuit logic through abstract interpretation from program analysis (Palumbo et al., 2025), proof theory (Miller et al., 2024; Wu et al., 2025), statistical identification (Méloux et al., 2025), and complexity theory (Adolfi et al., 2025). 

Neural network verification and formal explainability. Our certification of robustness guarantees (input and patching) builds on the rapid progress of neural network verification (Brix et al., 2024; Wang et al., 2021; Zhou et al., 2024; Chiu et al., 2025; Müller et al., 2021; Singh et al., 2019). These advances have also been applied to certifying provable guarantees for input-based explainability 

notions (Wu et al., 2023a; Bassan et al., 2025a; Izza et al., 2024; Audemard et al., 2022b; La Malfa et al., 2021) (often termed formal explainable AI (Marques-Silva & Ignatiev, 2022)). Our work is the first to employ neural network verification based strategies for circuit discovery in mechanistic interpretability. 

## 7 LIMITATIONS AND FUTURE WORK 

A limitation of our framework, shared by all methods offering robustness guarantees over continuous domains, is its reliance on neural network verification queries. While current verification techniques remain limited for state-of-the-art models, they are advancing rapidly in scalability (Brix et al., 2024; Wang et al., 2021; Zhou et al., 2024). Our framework provides a novel integration of such tools to mechanistic interpretability , enabling circuit discovery with provable guarantees. Hence, as verification methods continue to scale, so will the reach of our approach, as our extensive experiments are grounded in α-β-CROWN, the current leading verifier, and evaluated on standard benchmarks from the annual NN verification competition. Moreover, our novel theoretical results, covering guarantees over input domains, patching domains, and minimality, lay strong groundwork for future research on provable circuit discovery, including probabilistic and statistical forms of guarantees. 

## 8 CONCLUSION 

We introduce a framework for discovering circuits with provable guarantees, covering both (i) con-tinuous input -domain robustness, (ii) continuous patching -domain robustness, and (iii) multiple forms of minimality . Central to our approach is the notion of circuit monotonicity , which reveals deep theoretical connections between input, patching, and minimality guarantees, and underpins the convergence of circuit discovery algorithms. Our experiments, which leverage recent advancements in neural network verification, confirm that our framework delivers substantially stronger guarantees than standard sampling-based approaches commonly used in circuit discovery. By bridging circuit discovery with neural network verification, this work takes a novel step toward designing safer, more reliable circuits , and lays new theoretical and algorithmic foundations for future research in provable circuit discovery. 10 Published as a conference paper at ICLR 2026 

## ACKNOWLEDGMENTS 

This work was partially funded by the European Union (ERC, VeriDeL, 101112713). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. This research was additionally supported by a grant from the Israeli Science Foundation (grant number 558/24). 

## REFERENCES 

Federico Adolfi, Martina Vilas, and Todd Wareham. The Computational Complexity of Circuit Discovery for Inner Interpretability. In Proc. 13th Int. Conf. on Learning Representations (ICLR) ,2025. Guy Amir, Shahaf Bassan, and Guy Katz. Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation. In Proc. 27th European Conf. on Artifical Intelligence (ECAI) ,2024. Alaa Anani, Tobias Lorenz, Mario Fritz, and Bernt Schiele. Pixel-level Certified Explanations via Randomized Smoothing. In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025. M. Arenas, P. Barceló, M. Romero, and B. Subercaseaux. On Computing Probabilistic Explanations for Decision Trees. In Proc. 36th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 28695–28707, 2022. Marcelo Arenas, Daniel Baez, Pablo Barceló, Jorge Pérez, and Bernardo Subercaseaux. Foundations of Symbolic Languages for Model Interpretability. In Proc. 35th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 11690–11701, 2021. G. Audemard, S. Bellart, L. Bounia, F. Koriche, J. Lagniez, and P. Marquis. On the Computa-tional Intelligibility of Boolean Classifiers. In Proc. 18th Int. Conf. on Principles of Knowledge Representation and Reasoning (KR) , pp. 74–86, 2021. Gilles Audemard, Steve Bellart, Louenas Bounia, Frédéric Koriche, Jean-Marie Lagniez, and Pierre Marquis. On Preferred Abductive Explanations for Decision Trees and Random Forests. In Proc. 31st Int. Joint Conf. on Artificial Intelligence (IJCAI) , pp. 643–650, 2022a. Gilles Audemard, Steve Bellart, Louenas Bounia, Frédéric Koriche, Jean-Marie Lagniez, and Pierre Marquis. Trading Complexity for Sparsity in Random Forest Explanations. In Proc. of the 36th AAAI Conf. on Artificial Intelligence , number 5, pp. 5461–5469, 2022b. Gilles Audemard, Jean-Marie Lagniez, Pierre Marquis, and Nicolas Szczepanski. Computing Abductive Explanations for Boosted Trees. In Proc. 26th Int. Conf. on Artificial Intelligence and Statistics (AISTATS) , pp. 4699–4711, 2023. Steve Azzolin, Sagar Malhotra, Andrea Passerini, and Stefano Teso. Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective. In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025. Fahiem Bacchus and George Katsirelos. Using Minimal Correction Sets to More Efficiently Compute Minimal Unsatisfiable Sets. In Proc. 27th Int. Conf. on Computer Aided Verification (CAV) , pp. 70–86. Springer, 2015. Stanley Bak, Changliu Liu, and Taylor Johnson. The Second International Verification of Neural Networks Competition (VNN-COMP 2021): Summary and Results. 2021. Technical Report. 

https://arXiv:2109.00498 .P. Barceló, M. Monet, J. Pérez, and B. Subercaseaux. Model Interpretability through the Lens of Computational Complexity. In Proc. 34th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 15487–15498, 2020. 11 Published as a conference paper at ICLR 2026 S. Bassan and G. Katz. Towards Formal XAI: Formally Approximate Minimal Explanations of Neural Networks. In Proc. 29th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems (TACAS) , pp. 187–207, 2023. S. Bassan, G. Amir, and G. Katz. Local vs. Global Interpretability: A Computational Complexity Perspective. In Proc. 41st Int. Conf. on Machine Learning (ICML) , 2024. S. Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Matthias Althoff, and Guy Katz. Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations. In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025a. Shahaf Bassan, Guy Amir, Davide Corsi, Idan Refaeli, and Guy Katz. Formally Explaining Neural Networks Within Reactive Systems. In Proc. 23rd Int. Conf. on Formal Methods in Computer-Aided Design (FMCAD) , pp. 1–13, 2023. Shahaf Bassan, Guy Amir, Meirav Zehavi, and Guy Katz. What makes an Ensemble (Un) Inter-pretable? In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025b. Shahaf Bassan, Ron Eliav, and Shlomit Gur. Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons. In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025c. Shahaf Bassan, Shlomit Gur, Sergey Zeltyn, Konstantinos Mavrogiorgos, Ron Eliav, and Dimosthenis Kyriazis. Self-Explaining Neural Networks for Business Process Monitoring. 2025d. Technical Report. https://arXiv:2503.18067 .Shahaf Bassan, Michal Moshkovitz, and Guy Katz. Additive Models Explained: A Computational Complexity Approach. In Proc. 39th Conf. on Neural Information Processing Systems (NeurIPS) ,2025e. Shahaf Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Volkan ¸ Sahin, Jan Kretinsky, Matthias Althoff, and Guy Katz. Provably Explaining Neural Additive Models. In Proc. 14th Int. Conf. on Learning Representations (ICLR) , 2026a. Shahaf Bassan, Xuanxiang Huang, and Guy Katz. Unifying Formal Explanations: A Complexity-Theoretic Perspective. In Proc. 14th Int. Conf. on Learning Representations (ICLR) , 2026b. Leonard Bereska and Efstratios Gavves. Mechanistic Interpretability for AI Safety—A Review. 

Transactions on Machine Learning Research (TMLR) , 2024. Adithya Bhaskar, Alexander Wettig, Dan Friedman, and Danqi Chen. Finding Transformer Circuits with Edge Pruning. In Proc. 38th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 18506–18534, 2024. Guy Blanc, Jane Lange, and Li-Yang Tan. Provably Efficient, Succinct, and Precise Explanations. In 

Proc. 35th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 6129–6141, 2021. Guy Blanc, Caleb Koch, Jane Lange, and Li-Yang Tan. A Query-Optimal Algorithm for Finding Counterfactuals. In Proc. 39th Int. Conf. on Machine Learning (ICML) , pp. 2075–2090, 2022. Ryma Boumazouza, Fahima Cheikh-Alili, Bertrand Mazure, and Karim Tabia. ASTERYX: A model-Agnostic SaT-basEd appRoach for SYmbolic and Score-Based EXplanations. In Proc. 30th ACM Int. Conf. on Information & Knowledge Management (CIKM) , pp. 120–129, 2021. Ryma Boumazouza, Raya Elsaleh, Melanie Ducoffe, Shahaf Bassan, and Guy Katz. FAME: For-mal Abstract Minimal Explanation for Neural Networks. In Proc. 14th Int. Conf. on Learning Representations (ICLR) , 2026. Louenas Bounia. Enhancing the Intelligibility of Boolean Decision Trees with Concise and Reliable Probabilistic Explanations. In Proc. 20th Int. Conf. on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU) , pp. 205–218, 2024. Louenas Bounia. Using Submodular Optimization to Approximate Minimum-Size Abductive Path Explanations for Tree-Based Models. In Proc. 41st Conf. on Uncertainty in Artificial Intelligence (UAI) , 2025. 12 Published as a conference paper at ICLR 2026 Christopher Brix, Mark Niklas Müller, Stanley Bak, Taylor T Johnson, and Changliu Liu. First Three Years of the International Verification of Neural Networks Competition (VNN-COMP). Int. Journal on Software Tools for Technology Transfer (STTT) , 25(3):329–339, 2023. Christopher Brix, Stanley Bak, Taylor T Johnson, and Haoze Wu. The Fifth International Verification of Neural Networks Competition (VNN-COMP 2024): Summary and Results. 2024. Technical Report. https://arXiv:2412.19985 .Hong-Ming Chiu, Hao Chen, Huan Zhang, and Richard Y Zhang. SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming. In 

Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025. Pratim Chowdhary, Peter Chin, and Deepernab Chakrabarty. K-MSHC: Unmasking Minimally Sufficient Head Circuits in Large Language Models with Experiments on Syntactic Classification Tasks. 2025. Technical Report. https://arxiv.org/abs/2505.12268 .Arthur Conmy, Augustine Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adrià Garriga-Alonso. Towards Automated Circuit Discovery for Mechanistic Interpretability. In Proc. 37th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 16318–16352, 2023. A. Darwiche and A. Hirth. On the Reasons Behind Decisions. In Proc. 24th European Conf. on Artificial Intelligence (ECAI) , pp. 712–720, 2020. Adnan Darwiche. Logic for Explainable AI. In Proc. 38th ACM/IEEE Symposium on Logic in Computer Science (LICS) , pp. 1–11, 2023. Adnan Darwiche and Chunxi Ji. On the Computation of Necessary and Sufficient Explanations. In 

Proc. 36th AAAI Conf. on Artificial Intelligence , pp. 5582–5591, 2022. Alessandro De Palma, Greta Dolcetti, and Caterina Urban. Faster Verified Explanations for Neural Networks. 2025. Technical Report. https://arXiv:2512.00164 .Jacob Dunefsky, Philippe Chlenski, and Neel Nanda. Transcoders Find Interpretable LLM Feature Circuits. Proc. 38th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 24375–24410, 2024. Ruediger Ehlers. Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks. In Proc. 15th Int. Symposium on Automated Technology for Verification and Analysis (ATVA) , pp. 269–286. Springer, 2017. Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, et al. A Mathematical Framework for Transformer Circuits. Transformer Circuits Thread , 1(1):12, 2021. Thomas Fel, Mélanie Ducoffe, David Vigouroux, Rémi Cadène, Mikael Capelle, Claire Nicodème, and Thomas Serre. Don’t Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis. In Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 16153–16163, 2023. Claudio Ferrari, Mark Niklas Mueller, Nikola Jovanovi´ c, and Martin Vechev. Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound. In Proc. 10th Int. Conf. on Learning Representations (ICLR) , 2022. Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev. AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation. In Proc. 39th IEEE Symposium on Security and Privacy (S&P) , pp. 3–18, 2018. Atticus Geiger, Zhengxuan Wu, Christopher Potts, Thomas Icard, and Noah Goodman. Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations. In 

Proc. 3rd Conf. on Causal Learning and Reasoning (CleaR) , pp. 160–187, 2024. Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, et al. Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability. Journal of Machine Learning Research (JMLR) , 26(83):1–64, 2025. 13 Published as a conference paper at ICLR 2026 Chuqin Geng, Nham Le, Xiaojie Xu, Zhaoyue Wang, Arie Gurfinkel, and Xujie Si. Towards Reliable Neural Specifications. In Proc. 40th Int. Conf. on Machine Learning (ICML) , pp. 11196–11212, 2023. Chuqin Geng, Zhaoyue Wang, Haolin Ye, and Xujie Si. Learning Minimal Neural Specifications. 2024. Technical Report. https://arXiv:2404.04662 .Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, and Yonatan Belinkov. Position-Aware Automatic Circuit Discovery. In Proc. 63rd Annual Meeting of the Association for Computational Linguistics (ACL) , pp. 2792–2817, 2025. Michael Hanna, Sandro Pezzelle, and Yonatan Belinkov. Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms. In Proc. 1st Conf. on Language Modeling (COLM) , 2024. Ouns El Harzli, Bernardo Cuenca Grau, and Ian Horrocks. Cardinality-Minimal Explanations for Monotonic Neural Networks. In Proc. 32nd Joint Conf. on Artificial Intelligence (IJCAI) , pp. 3677–3685, 2023. Aliyah R Hsu, Georgia Zhou, Yeshwanth Cherapanamjeri, Yaxuan Huang, Anobel Odisho, Peter R Carroll, and Bin Yu. Efficient Automated Circuit Discovery in Transformers using Contextual Decomposition. In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2024. Alexey Ignatiev, António Morgado, and Joao Marques-Silva. RC2: An Efficient MaxSAT Solver. 

Journal on Satisfiability, Boolean Modelling and Computation (JSAT) , 11(1):53–64, 2019a. Alexey Ignatiev, Nina Narodytska, and Joao Marques-Silva. Abduction-Based Explanations for Machine Learning Models. In Proc. 33rd AAAI Conf. on Artificial Intelligence , pp. 1511–1519, 2019b. Alexey Ignatiev, Nina Narodytska, and Joao Marques-Silva. On Relating Explanations and Ad-versarial Examples. Proc. 33rd Conf. on Neural Information Processing Systems (NeurIPS) ,2019c. Alexey Ignatiev, Yacine Izza, Peter J Stuckey, and Joao Marques-Silva. Using MaxSAT for Efficient Explanations of Tree Ensembles. In Proc. 36th AAAI Conf. on Artificial Intelligence , pp. 3776– 3785, 2022. Yacine Izza, Xuanxiang Huang, Alexey Ignatiev, Nina Narodytska, Martin Cooper, and Joao Marques-Silva. On Computing Probabilistic Abductive Explanations. Int. Journal of Approximate Reasoning (IJAR) , 159:108939, 2023. Yacine Izza, Xuanxiang Huang, Antonio Morgado, Jordi Planes, Alexey Ignatiev, and Joao Marques-Silva. Distance-Restricted Explanations: Theoretical Underpinnings & Efficient implementation. In Proc. 21st Int. Conf. on Principles of Knowledge Representation and Reasoning (KR) , pp. 475–486, 2024. Farnoush Rezaei Jafari, Oliver Eberle, Ashkan Khakzar, and Neel Nanda. RelP: Faithful and Efficient Circuit Discovery via Relevance Patching. 2025. Technical Report. https://arXiv: 2508.21258 .Helen Jin, Anton Xue, Weiqiu You, Surbhi Goel, and Eric Wong. Probabilistic Stability Guarantees for Feature Attributions. 2025. Technical Report. https://arXiv:2504.13787 .Kyle D Julian, Ritchie Lee, and Mykel J Kochenderfer. Validation of Image-based Neural Net-work Controllers through Adaptive Stress Testing. In Proc. 23rd IEEE Int. Conf. on Intelligent Transportation Systems (ITSC) , pp. 1–7, 2020. Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In Proc. 29th Int. Conf. on Computer Aided Verification (CAV) , pp. 97–117, 2017. 14 Published as a conference paper at ICLR 2026 Guy Katz, Derek A Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus, Rachel Lim, Parth Shah, Shantanu Thakoor, Haoze Wu, Aleksandar Zelji´ c, et al. The Marabou Framework for Verification and Analysis of Deep Neural Networks. In Proc. 31st Int. Conf. on Computer Aided Verification (CAV) , pp. 443–452, 2019. Suhas Kotha, Christopher Brix, J Zico Kolter, Krishnamurthy Dvijotham, and Huan Zhang. Provably Bounding Neural Network Preimages. In Proc. 37th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 80270–80290, 2023. Alex Krizhevsky and Geoffrey Hinton. Learning Multiple Layers of Features From Tiny Images, 2009. Technical Report. https://www.cs.toronto.edu/~kriz/ learning-features-2009-TR.pdf .Emanuele La Malfa, Agnieszka Zbrzezny, Rhiannon Michelmore, Nicola Paoletti, and Marta Kwiatkowska. On Guaranteed Optimal Robust Explanations for NLP Models. In Proc. Int. Joint Conf. on Artificial Intelligence (IJCAI) , pp. 2658–2665, 2021. Faezeh Labbaf, Tomáš Kolárik, Martin Blicha, Grigory Fedyukovich, Michael Wand, and Natasha Sharygina. Space Explanations of Neural Network Classification. In Proc. 37th Int. Conf. on Computer Aided Verification (CAV) , pp. 287–303, 2025. Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-Based Learning Applied to Document Recognition. Proc. of the IEEE , 86(11):2278–2324, 1998. Mark H Liffiton, Alessandro Previti, Ammar Malik, and Joao Marques-Silva. Fast, Flexible MUS Enumeration. Constraints , 21(2):223–250, 2016. Emanuele La Malfa, Agnieszka Zbrzezny, Rhiannon Michelmore, Nicola Paoletti, and Marta Kwiatkowska. On Guaranteed Optimal Robust Explanations for NLP Models. In Proc. Int. Joint Conf. on Artificial Intelligence (IJCAI) , 2021. Samuel Marks, Can Rager, Eric J Michaud, Yonatan Belinkov, David Bau, and Aaron Mueller. Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models. In 

Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025. J. Marques-Silva, T. Gerspacher, M. Cooper, A. Ignatiev, and N. Narodytska. Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay. In Proc. 34th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 20590–20600, 2020. Joao Marques-Silva and Alexey Ignatiev. Delivering Trustworthy AI through Formal XAI. In Proc. 36th AAAI Conf. on Artificial Intelligence , pp. 12342–12350, 2022. Joao Marques-Silva and Alexey Ignatiev. No Silver Bullet: Interpretable ML Models Must be Explained. Frontiers in Artificial Intelligence , 6:1128212, 2023. Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev, and Nina Narodytska. Explanations for Monotonic Classifiers. In Proc. Int. Conf. on Machine Learning (ICML) , pp. 7469–7479, 2021. Reda Marzouk and Colin De La Higuera. On the Tractability of SHAP Explanations under Markovian Distributions. In Proc. 41st Int. Conf. on Machine Learning (ICML) , pp. 34961–34986, 2024. Reda Marzouk, Shahaf Bassan, and Guy Katz. SHAP Meets Tensor Networks: Provably Tractable Explanations with Parallelism. In Proc. 39th Conf. on Neural Information Processing Systems (NeurIPS) , 2025a. Reda Marzouk, Shahaf Bassan, Guy Katz, and De la Higuera. On the Computational Tractability of the (Many) Shapley Values. In Proc. 28th Int. Conf. on Artificial Intelligence and Statistics (AISTATS) , pp. 3691–3699. PMLR, 2025b. Maxime Méloux, Silviu Maniu, François Portet, and Maxime Peyrard. Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable? In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025. 15 Published as a conference paper at ICLR 2026 Joseph Miller, Bilal Chughtai, and William Saunders. Transformer Circuit Evaluation Metrics Are Not Robust. In Proc. 1st Conf. on Language Modeling (COLM) , 2024. Aaron Mueller, Atticus Geiger, Sarah Wiegreffe, Dana Arad, Iván Arcuschin, Adam Belfki, Yik Siu Chan, Jaden Fried Fiotto-Kaufman, Tal Haklay, Michael Hanna, et al. MIB: A Mechanistic Interpretability Benchmark. In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025. Christoph Müller, François Serre, Gagandeep Singh, Markus Püschel, and Martin Vechev. Scaling Polyhedral Neural Network Verification on GPUs. In Proc. 4th Conf. on Machine Learning and Systems (MLSys) , pp. 733–746, 2021. Mark Niklas Müller, Christopher Brix, Stanley Bak, Changliu Liu, and Taylor T Johnson. The Third International Verification of Neural Networks Competition (VNN-COMP 2022): Summary and Results. 2022a. Technical Report. https://arXiv.org/abs/2212.10376 .Mark Niklas Müller, Gleb Makarchuk, Gagandeep Singh, Markus Püschel, and Martin Vechev. PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approxima-tions. Proc. 6th ACM on Programming Languages (POPL) , pp. 1–33, 2022b. Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress Measures for Grokking via Mechanistic Interpretability. In Proc. 11th Int. Conf. on Learning Representations (ICLR) , 2023. Chris Olah. Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases. 

Transformer Circuits Thread , 2022. Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. Zoom In: An Introduction to Circuits. Distill , 2020. Nils Palumbo, Ravi Mangal, Zifan Wang, Saranya Vijayakumar, Corina S. Pasareanu, and Somesh Jha. Validating Mechanistic Interpretations: An Axiomatic Approach. In Proc. 42nd Int. Conf. on Machine Learning (ICML) , 2025. Achyuta Rajaram, Neil Chowdhury, Antonio Torralba, Jacob Andreas, and Sarah Schwettmann. Automatic Discovery of Visual Circuits. 2024. Technical Report. https://arxiv.org/abs/ 2404.14349 .Tilman Räuker, Anson Ho, Stephen Casper, and Dylan Hadfield-Menell. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. In Proc. 1st IEEE Int. Conf. on Secure and Trustworthy Machine Learning (SaTML) , pp. 464–483, 2023. Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. In Proc. 16th IEEE Int. Conf. on Computer Vision (ICCV) , pp. 618–626, 2017. Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, et al. Open Problems in Mechanistic Interpretability. Transactions on Machine Learning Research (TMLR) , 2025. Claudia Shi, Nicolas Beltran Velez, Achille Nazaret, Carolina Zheng, Adrià Garriga-Alonso, Andrew Jesson, Maggie Makar, and David Blei. Hypothesis Testing the Circuit Hypothesis in LLMs. In 

Proc. 38th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 94539–94567, 2024. Zhouxing Shi, Qirui Jin, Zico Kolter, Suman Jana, Cho-Jui Hsieh, and Huan Zhang. Neural Network Verification with Branch-and-Bound for General Nonlinearities. In Proc. 31th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems (TACAS) , pp. 315–335, 2025. A. Shih, A. Choi, and A. Darwiche. A Symbolic Approach to Explaining Bayesian Network Classifiers. In Proc. 27th Int. Joint Conf. on Artificial Intelligence (IJCAI) , pp. 5103–5111, 2018. Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin Vechev. An Abstract Domain for Certifying Neural Networks. In Proc. 3rd ACM on Programming Languages (POPL) , pp. 1–30, 2019. 16 Published as a conference paper at ICLR 2026 Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, and Daniela Cancila. Formal Abductive Latent Explanations for Prototype-Based Networks. 2025. Technical Report. https://arXiv.org/abs/2511.16588 .Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. The German Traffic Sign Recognition Benchmark: A Multi-class Classification Competition. In Proc. 24th Int. Joint Conf. on Neural Networks (IJCNN) , pp. 1453–1460, 2011. Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D’Oosterlinck, Christopher Potts, Michael Sklar, and Atticus Geiger. HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks. In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025. Aaquib Syed, Can Rager, and Arthur Conmy. Attribution Patching Outperforms Automated Circuit Discovery. In Proc. 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP , pp. 407–416, 2024. Vincent Tjeng, Kai Y Xiao, and Russ Tedrake. Evaluating Robustness of Neural Networks with Mixed Integer Programming. In Proc. 5th Int. Conf. on Learning Representations (ICLR) , 2017. Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small. In Proc. 11th Int. Conf. on Learning Representations (ICLR) , 2023. Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter. Beta-crown: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification. In Proc. 35th Conf. on Neural Information Processing Systems (NeurIPS) ,pp. 29909–29921, 2021. Haoze Wu, Omri Isac, Aleksandar Zelji´ c, Teruhiro Tagomori, Matthew Daggitt, Wen Kokke, Idan Refaeli, Guy Amir, Kyle Julian, Shahaf Bassan, et al. Marabou 2.0: A Versatile Formal Analyzer of Neural Networks. In Proc. 36th Int. Conf. on Computer Aided Verification (CAV) , pp. 249–264, 2024. Min Wu, Haoze Wu, and Clark Barrett. VeriX: Towards Verified Explainability of Deep Neural Networks. In Proc. 37th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 22247– 22268, 2023a. Wilson Wu, Louis Jaburi, Jason Gross, et al. Towards a Unified and Verified Understanding of Group-Operation Networks. In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025. Zhengxuan Wu, Atticus Geiger, Thomas Icard, Christopher Potts, and Noah Goodman. Interpretability at Scale: Identifying Causal Mechanisms in Alpaca. In Proc. 37th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 78205–78226, 2023b. Anton Xue, Rajeev Alur, and Eric Wong. Stability Guarantees for Feature Attributions with Multi-plicative Smoothing. In Proc. 37th Conf. on Neural Information Processing Systems (NeurIPS) ,pp. 62388–62413, 2023. Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, and Huajun Chen. Knowledge Circuits in Pretrained Transformers. In Proc. 38th Conf. on Neural Information Processing Systems (NeurIPS) , pp. 118571–118602, 2024. Jinqiang Yu, Alexey Ignatiev, Peter Stuckey, Nina Narodytska, and Joao Marques-Silva. Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations. In Proc. 37th AAAI Conf. on Artificial Intelligence , pp. 4123–4131, 2023. Fred Zhang and Neel Nanda. Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. In Proc. 12th Int. Conf. on Learning Representations (ICLR) , 2024. Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient Neural Network Robustness Certification with General Activation Functions. In Proc. 32th Conf. on Neural Information Processing Systems (NeurIPS) , 2018. 17 Published as a conference paper at ICLR 2026 Yu Zhang, Peter Tiˇ no, Aleš Leonardis, and Ke Tang. A Survey on Neural Network Interpretability. 

IEEE Transactions on Emerging Topics in Computational Intelligence , 5(5):726–742, 2021. Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du. Explainability for Large Language Models: A Survey. ACM Transactions on Intelligent Systems and Technology , 15(2):1–38, 2024. Duo Zhou, Christopher Brix, Grani A Hanasusanto, and Huan Zhang. Scalable Neural Network Veri-fication with Branch-and-Bound Inferred Cutting Planes. Proc. 38th Conf. on Neural Information Processing Systems (NeurIPS) , 37:29324–29353, 2024. Zhenhong Zhou, Haiyang Yu, Xinghua Zhang, Rongwu Xu, Fei Huang, Kun Wang, Yang Liu, Junfeng Fang, and Yongbin Li. On the Role of Attention Heads in Large Language Model Safety. In Proc. 13th Int. Conf. on Learning Representations (ICLR) , 2025. 18 Published as a conference paper at ICLR 2026 

# Appendix 

The appendix collects proofs, model specifications, and supplementary experimental results that support the main paper. 

Appendix A contains additional background on neural network verification, circuit discovery, and patching. 

Appendix B contains the complete proofs of all propositions. 

Appendix C provides the pseudocode for the greedy quasi-minimality algorithm, together with a more detailed explanation of the toy example illustrating the minimality notion. 

Appendix D provides specifications of the datasets and architectures used. 

Appendix E provides additional details on the input-robustness experiment’s methodology, verifica-tion setup, and evaluation. 

Appendix F provides additional details on the patching-robustness experiment’s methodology, verification setup, and evaluation. 

Appendix G provides details on the minimality evaluation experiment’s methodology, verification setup, and evaluation. 

Appendix H provides the LLM usage discolsure. 

## A ADDITIONAL BACKGROUND ON NEURAL NETWORK VERIFICATION ,CIRCUIT DISCOVERY , AND FORMAL XAI 

Neural Network Verification. Neural network verification provides formal guarantees about the behavior of a neural network fG over a continuous input region. Classic SMT/MILP-based approaches (Katz et al., 2017; Wu et al., 2024; Katz et al., 2019; Tjeng et al., 2017; Ehlers, 2017) encode ReLU networks and specifications as logical or mixed-integer constraints and offer exact guarantees, but scale only to small–medium models. Abstract-interpretation methods (Singh et al., 2019; Gehr et al., 2018; Ferrari et al., 2022; Müller et al., 2022b) propagate over-approximations layer by layer, giving fast but incomplete robustness certificates. A major advance came from linear-relaxation–based bound propagation, notably CROWN (Zhang et al., 2018) and follow-ups (Wang et al., 2021; Chiu et al., 2025; Zhou et al., 2024; Shi et al., 2025), which compute tight dual-based linear bounds and serve either as scalable incomplete verifiers or as strong relaxations inside exact search. Modern branch-and-bound (BaB) frameworks leverage these relaxations to achieve complete 

verification at scale, with α-β-CROWN and related variants now dominating VNN-COMP (Brix et al., 2024) and handling million-parameter models. Recent progress includes tighter relaxations (e.g., SDP hybrids (Chiu et al., 2025)), cutting planes (Zhou et al., 2024), and support for non-ReLU nonlinearities (Shi et al., 2025). Verification today routinely certifies robustness for moderately large CNNs and ResNets, though major challenges remain for transformers, complex architectures, and richer temporal or relational specifications. 

Circuit discovery and patching. An important step in circuit discovery is patching , which seeks to isolate the computational role of a hypothesized circuit by intervening on the activations outside it. In a typical setup, the model is run on a base input, and activations at selected non-circuit nodes are replaced — either with fixed baseline values (e.g., zero or mean activation) or with activations taken from a counterfactual input. If the model’s output remains unchanged, the circuit is understood to be sufficient for the behavior; if it changes, this reveals a dependency on the patched components. Numerous patching protocols have been proposed, including activation replacement, path patching, and attention/head interventions (Jafari et al., 2025; Syed et al., 2024; Haklay et al., 2025; Miller et al., 2024; Zhang & Nanda, 2024; Nanda et al., 2023), all aiming to identify model components whose behavior is necessary or sufficient for a target computation. To the best of our knowledge, our method is the first to provably certify the stability of circuits under families of such patching interventions. 

Formal XAI. Our work is also related to the line of research known as formal explainable AI 

(formal XAI) (Marques-Silva & Ignatiev, 2022), which studies input-based explanations with formal guarantees (Yu et al., 2023; Darwiche & Ji, 2022; Darwiche, 2023; Shih et al., 2018; Azzolin et al., 2025; Audemard et al., 2021). Since generating explanations with formal guarantees is often computationally intractable (Adolfi et al., 2025; Barceló et al., 2020; Arenas et al., 2021; Bassan et al., 2026b; Marzouk et al., 2025a;b; Marzouk & De La Higuera, 2024; Amir et al., 2024; Bassan et al., 19 Published as a conference paper at ICLR 2026 2024; Blanc et al., 2021; 2022), much of this literature has focused on simpler model classes (Marques-Silva & Ignatiev, 2023), including decision trees (Bounia, 2025; Arenas et al., 2022; Bounia, 2024), linear models (Marques-Silva et al., 2020), additive models (Bassan et al., 2025e; 2026a), monotonic models (Marques-Silva et al., 2021; Harzli et al., 2023), and tree ensembles (Audemard et al., 2023; 2022a; Ignatiev et al., 2022; Bassan et al., 2025b; Boumazouza et al., 2021). Closer to our setting, several works have extended these guarantees to neural networks (Malfa et al., 2021; Bassan et al., 2023; Wu et al., 2023a; Bassan et al., 2025a; Boumazouza et al., 2026; Labbaf et al., 2025; De Palma et al., 2025; Fel et al., 2023; Soria et al., 2025). A central concept in formal explainability is that of a sufficient reason (Darwiche & Hirth, 2020; Bassan et al., 2025c;d; Barceló et al., 2020), also referred to as an abductive explanation (Ignatiev et al., 2019b; Izza et al., 2023). These notions are closely related to stability-based feature attribution frameworks (Xue et al., 2023; Jin et al., 2025; Anani et al., 2025). Informally, a sufficient reason resembles a circuit in that fixing it preserves the model’s prediction. Various minimality notions have been studied in this context, including subset-minimal explanations (Ignatiev et al., 2019b), as well as cardinally-minimal explanations that are computed via a similar minimal hitting set (MHS) duality (Ignatiev et al., 2019b; Bassan & Katz, 2023) that was studied here. However, our work addresses a fundamentally different task: discovering circuits rather than input subsets. Moving from subsets of features to subcomponents of the model introduces several new challenges, including dual encodings of the model for certification, the need to handle patching operations, and the loss of monotonicity under certain patching schemes, which complicates convergence to minimal circuits. To the best of our knowledge, this is the first work to leverage ideas from formal explainability within mechanistic interpretability, and in particular for the task of circuit discovery. Lastly, another partially relevant line of work has incorporated neural network verification to activation-pattern specifications (NAPs) (Geng et al., 2023), which encode active/inactive neuron states and induce input regions beyond local perturbation balls. Recent work (Geng et al., 2024) fur-ther aims to learn minimal NAPs by removing redundant neuron states while preserving correctness. These also differ from our circuits which compute actual subgraphs of neural networks. 

## B PROOFS OF MAIN RESULTS 

This appendix presents the proofs of the main propositions stated in the main paper. B.1 PROOF OF PROPOSITION 1

Proposition 1. Given any model fG and faithfulness predicate Φ, Algorithm 1 visits a quasi-minimal 

circuit and Algorithm 3 converges to a locally-minimal circuit C, both with respect to Φ.Proof. We must establish three points: (i) Faithfulness: The final circuit C returned by Algorithms 1 and 3 is indeed faithful, i.e., the predicate Φ( C, G ) holds true. (ii) Algorithm 1 visits a quasi-minimal circuit during its execution, i.e., there exists an iteration t where the corresponding circuit Ct contains a component i such that Φ( Ct \ { i}, G ) is false. (iii) Algorithm 3 achieves local minimality: In the returned circuit C, removing any single component i ∈ C breaks faithfulness; that is, for every i ∈ C,

Φ( C \ { i}, G ) is false. In the first part of the proof, both Algorithms 1 and 3 start with C ← G. Since the full model graph 

G is, by definition, faithful, Φ( G, G ) holds true. At each step, the algorithms check Φ( C \ { i}, G )

for the current component i and update C ← C \ { i} only if this predicate remains true. Hence, the invariant is preserved throughout the execution, and the final circuit C still satisfies Φ( C, G ).For the second part, we prove that Algorithm 1 visits a quasi-minimal circuit during its execution. We assume that the empty circuit is unfaithful, i.e., ¬Φ( ∅, G ). Let Ct denote the circuit maintained by the algorithm at iteration t. Since the algorithm maintains the invariant Φ( Ct, G ) and removes components only when faithfulness is preserved, it cannot reach the empty circuit. Hence, not all components can be removed while maintaining Φ. Therefore, there exists a first iteration t at which the algorithm considers some component i ∈ Ct and does not remove it because Φ( Ct \ { i}, G )

is false. Thus, Ct contains a component whose removal violates faithfulness and is, by definition, quasi-minimal with respect to Φ. This establishes that Algorithm 1 visits a quasi-minimal circuit during its execution. 20 Published as a conference paper at ICLR 2026 For the third part of the proof, note that Algorithm 3 continues to iterate over the circuit components until a full pass occurs with no further changes to the circuit C. This termination condition implies that for any remaining i ∈ C, the predicate Φ( C \ { i}, G ) must have been false during the final iteration. Otherwise, if Φ( C \ { i}, G ) were true for any i ∈ C, the component would have been removed, and the algorithm would have proceeded to another iteration. Therefore, upon termination, every i ∈ C is essential for maintaining the faithfulness predicate, establishing that C is locally minimal with respect to Φ. This completes the proof. B.2 PROOF OF PROPOSITION 2

Proposition 2. While Algorithm 4 converges to a quasi-minimal circuit and performs O(log |G|)

evaluations of Φ( C, G ) (Adolfi et al., 2025), Algorithm 1 visits a quasi-minimal circuit and performs 

O(|G|) such evaluations, and Algorithm 3 converges to a locally-minimal circuit and performs 

O(|G|2) evaluations. Proof. We provide the proof for each algorithm: 

(Algorithm 1) . By Proposition 1, Algorithm 1 visits a quasi-minimal circuit during its execution. Observe that the algorithm 1 processes each component of G individually and exactly once. Since it tests Φ upon the removal of each of these |G| components, the procedure carries out O(|G|) predicate evaluations in total. 

(Algorithm 3) . By Proposition 1, Algorithm 3 converges to a locally minimal circuit. For the runtime analysis, observe that Algorithm 3 processes each component of G and continues to do so until convergence. In each pass, it tests the predicate Φ upon the removal of every remaining component. In the worst case, when only a single component is removed in each pass, the total number of predicate evaluations is |G| + ( |G| − 1) + ( |G| − 2) + · · · + 1 = O(|G|2). Thus, the procedure performs 

O(|G|2) evaluations of Φ( C, G ) in total. 

(Algorithm 4) .The quasi-minimality algorithm 4 and its runtime were established in Adolfi et al. (2025). For completeness, we restate the argument regarding the number of evaluations: the algorithm halves the candidate index range at each step, requiring at most ⌈log |G|⌉ predicate evaluations before termination. Thus, its complexity is O(log |G|).B.3 PROOF OF PROPOSITION 3

Proposition 3. There exist infinitely-many number of configurations of fG, and Φ, for which Algo-rithms 1, 3 and 4 do not converge to a subset-minimal circuit C concerning Φ.Proof. Consider a small nonlinear counterexample network fG : R → R, with underlying structure 

G and node set VG := {v1, v 2, v 3, v 4}. The network is defined over a one-dimensional input x, with three hidden nodes v1, v 2, v 3 and an output node v4.Consider a one-dimensional input x, three hidden units v1, v 2, v 3, and an output neuron v4:

v1(x) := ReLU( x), v2(x) := ReLU( x), v3(x) := x, v4(u, v, w ) := u − v + w (3) Therefore, the following holds: 

fG(x) := v4

 v1(x), v 2(x), v 3(x) = v1(x) − v2(x) + v3(x) = x (4) For any subset C ⊆ { v1, v 2, v 3}, define fC by applying zero-patching to all hidden units outside C.We take the faithfulness predicate to be strong equality , i.e., corresponding to δ = 0 and ϵp given by the ℓ∞ norm over the domain [0 , 1] . In particular: 

Φ( C, G ) ⇐⇒ ∀ x ∈ [0 , 1] , fC (x) = fG(x) (5) 21 Published as a conference paper at ICLR 2026 

Iterative (Algorithms 1 and 3 ). We consider the standard traversal order over these components from end to start (i.e., reverse topological order): (v4, v 3, v 2, v 1). We note that removing v4 (i.e., zero-patching it) directly breaks faithfulness. Moreover, no other single-component removal preserves 

Φ: removing any hidden unit breaks the equality. 

fG\{ v3}(x) = ReLU( x) − ReLU( x) = 0 ̸ = x for x > 0,fG\{ v2}(x) = ReLU( x) + x̸ = x for x > 0,fG\{ v1}(x) = −ReLU( x) + x̸ = x for x > 0

(6) Hence, Algorithm 1 and Algorithm 3 halt at C = G (locally minimal). Yet a strict subset is faithful: removing the pair {v1, v 2} yields fG\{ v1,v 2}(x) = v3(x) = x, so Φ( G \ { v1, v 2}, G ) holds. Therefore, G is not subset-minimal. 

Quasi (Algorithm 4). With a valid order (v1, v 3, v 2, v 4), Algorithm 4 first tests the prefix removal 

{v1, v 3}, leaving fG(x) = −ReLU( x)̸ = x, then tests {v1}, leaving fG(x) = −ReLU( x) + x̸ = x;it never considers the pair {v1, v 2} and so returns C = G, which is not subset-minimal, as we previously showed in Equation 6. Since this holds for every m ∈ N, we obtain infinitely many configurations where both algorithms fail to return a subset-minimal circuit. 

Infinite family. For any m ≥ 1, add pairs (pi, q i) with pi(x) = qi(x) = ReLU( x) and set 

gv (x) = v3(x) + 

> m

X

> i=1

 pi(x) − qi(x).

Then fG(x) = x on [0 , 1] , any single removal (of v3, some pj , or some qj ) breaks equality, but removing a whole pair {pj , q j } preserves it. Under the ordering (p1, . . . , p m, v 3, q 1, . . . , q m, v 4), the iterative greedy Algorithms 1 and 3 and the quasi-minimal Algorithm 4 both return G. Thus, there are infinitely many such configurations. B.4 PROOF OF PROPOSITION 4

Proposition 4. If Φ is monotonic, then for any model fG, Algorithm 1 converges to a subset-minimal circuit C concerning Φ.Proof. By definition, establishing subset-minimality of the circuit C requires showing: (i) that C is faithful, i.e., Φ( C, G ) holds, and (ii) that no proper subgraph C′ ⊆ C also satisfies Φ( C′, G ).For the first part of the proof, we follow the same faithfulness-preservation argument used in the proof of Proposition 1. Algorithm 1 begins with the full model G, which is initially faithful to itself (Φ( G, G ) holds). It then iterates through components in a fixed order (e.g., reverse topological order). At each step, the algorithm maintains a current circuit Ct; a component i is removed only if its removal preserves faithfulness, i.e., if Φ( Ct \ { i}, G ) holds. Consequently, faithfulness is maintained as a loop invariant throughout the execution. In particular, upon termination, the resulting circuit C

satisfies Φ( C, G ).For the second part of the proof, assume towards contradiction that there exists some C′ ⊊ C for which it holds that Φ( C′, G ) is true. Now, pick any c⋆ ∈ C \ C′. Let Ct be the circuit at iteration t

where this iteration marks the step over which the algorithm has evaluated whether to add c⋆ to the circuit. Because c⋆ is present in the final returned circuit C, then by induction it was not removed at step t when considered, and hence it must hold that Φ( Ct \ { c⋆}, G ) is false. On the other hand, we have the following inclusions: 

C′ ⊆ C \ { c⋆} ⊆ Ct \ { c⋆}. (7) And so by the very definition of the monotonicity of C with respect to Φ, we obtain that: 

Φ( C′, G ) =⇒ Φ( Ct \ { c⋆}, G ) (8) 22 Published as a conference paper at ICLR 2026 This contradicts the fact that we have derived that Φ( Ct \ { c⋆}, G ) must be false from the algorithm’s progression. Hence, we have obtained that for any subset C′ ⊊ C it holds that Φ( C′, G ) is false, and hence C is subset-minimal with respect to Φ.B.5 PROOF OF PROPOSITION 5

Proposition 5. Let Φ( C, G ) denote validating whether C is input-robust concerning ⟨fG, Z⟩ (Def. 1), and simultaneously patching-robust concerning ⟨fG, Z′⟩ (Def. 2). Then if Z ⊆ Z ′, and HG(Z′) is closed under concatenation, Φ is monotonic. Proof. We begin by formally stating the condition of an activation space being closed under concate-nation: 

Definition 1. We say that an activation space HG(Z) of some model fG and domain Z ⊆ Rn

is closed under concatenation iff for any two partial activations α, α ′, where α ∈ H C (Z) is an activation over the circuit C ⊆ G, and α′ ∈ H C′ (Z) is an activation over the circuit C′ ⊆ G, then it holds that α ∪ α′ ∈ H C∪C′ (Z).

Now, let there be some C ⊆ C′ ⊆ G, for which C′ := C ⊔ { c′

> 1

, . . . , c ′

> t

}. We assume that the predicate Φ is defined as validating whether some circuit C is input-robust concerning ⟨fG, Z⟩ , and also patching-robust with respect to ⟨fG, Z′⟩. In other words, this implies that Φ( C, G ) holds if and only if: 

∀z ∈ Z := 

> k

[

> j=1

Bpϵp (xj ), ∀α ∈ H C (Z′) : fC (z | C = α) − fG(z) p ≤ δ (9) We note that the following notation is equivalent to the following: 

max   

> z∈Z ,α ∈H C(Z′)

fC (z | C = α) − fG(z) p ≤ δ ⇐⇒ 

max  

> z∈Z ,z′∈Z ′

fC (z | C = HC (z′)) − fG(z) p ≤ δ (10) where we use the notation HC (z′) to denote the specific activation over C when computing fG(z′)

for some z′ ∈ Rn.Since our goal is to prove that Φ is monotonic, it suffices to show that C′ also satisfies the above conditions. An equivalent formulation is to verify the condition for any C′ := C ⊔ { c′

> i

}, i.e., for supersets that differ from C by a single element rather than an arbitrary subset. This is valid because adding subsets inductively, one element at a time, is equivalent to adding the entire subset at once. We therefore proceed under this formulation and assume, for contradiction, that the conditions fail to hold for C′. In other words, we assume the following: 

∃z ∈ Z , ∃α ∈ H C′ (Z′) : fC′ (z | C′ = α) − fG(z) p > δ ⇐⇒ 

max   

> z∈Z ,α ∈H C′(Z′)

fC′ (z | C′ = α) − fG(z) p > δ ⇐⇒ 

max  

> z∈Z ,z′∈Z ′

fC′ (z | C′ = HC′ (z′)) − fG(z) p > δ 

(11) This is also equivalent to stating that: 

max  

> z∈Z ,z′∈Z ′

fC⊔{ c′

> i}

(z | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′)) − fG(z) p

> δ (12) Let us denote by S ⊆ R the set of all values that are feasible to obtain by fC (z | C = HC (z′)) and by S ⊆ R all values that are feasible by fC (z | C′ = HC′ (z′)) . More precisely: 23 Published as a conference paper at ICLR 2026 

S := {fC (z | C = HC (z′)) : z ∈ Z , z′ ∈ Z ′}, ∧ S′ := {fC′ (z | C′ = HC′ (z′)) : z ∈ Z , z′ ∈ Z ′}

(13) For finalizing the proof of the proposition, we will make use of the following Lemma: 

Lemma 1. Given the predefined fG, the circuits C ⊆ C′ ⊆ G, and the aforementioned notations of 

S and S′, then it holds that S′ ⊆ S.Proof. We first note that by definition: 

S′ := {fC′ (z | C′ = HC′ (z′)) : z ∈ Z , z′ ∈ Z ′} =

{fC⊔{ c′

> i}

(z | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′)) : z ∈ Z , z′ ∈ Z ′} (14) We also note that for any z ∈ Rn it holds, by definition, that: 

fC (z | C = HC (z′)) = f∅(z | C = HC (z′), C = HC (z)) (15) The notation f∅(z | C = HC (z′), C = HC (z)) simply means that we fix the activations of C to 

HC (z) and those of C to HC (z′). From the same manipulation of notation, we can get that: 

fC⊔{ c′

> i}

(z | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′)) = 

f∅(z | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′), C ⊔ { i} = HC⊔{ c′

> i}

(z)) = 

f∅(z | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′), C = HC (z), {c′

> i

} = Hc′ 

> i

(z)) = 

f∅(z | C \ { c′

> i

} = HC\{ c′

> i}

(z′), C = HC (z), {c′

> i

} = Hc′ 

> i

(z)) 

(16) To prove that S′ ⊆ S, let us take some z0, z′ 

> 0

∈ Z . We will now prove that for any such choice of 

z0, z′ 

> 0

then the following holds: 

fC′ (z0 | C′ = HC′ (z′

> 0

)) ⊆ S (17) Since z′ 

> 0

∈ Z ′, z0 ∈ Z ⊆ Z ′, and HG(Z′) is closed under concatenation, then by definition it holds that fixing the activations of C \ { c′

> i

} to HC\{ c′

> i}

(z′

> 0

) ∈ H C\{ c′

> i}

(Z′) and those of {c′

> i

} to 

H{c′

> i}

(z0) ∈ H {c′

> i}

(Z′) yields an activation α ∈ H C\{ c′

> i}∪{ c′
> i}

(Z′) = HC (Z′).Hence, we arrive at: 

fC′ (z0 | C′ = HC′ (z′

> 0

)) = 

fC⊔{ c′

> i}

(z0 | C ⊔ { c′

> i

} = HC⊔{ c′

> i}

(z′

> 0

)) = 

f∅(z0 | C \ { c′

> i

} = HC\{ c′

> i}

(z′

> 0

), C = HC (z0), {c′

> i

} = Hc′ 

> i

(z0)) = 

f∅(z0 | C = α, C = HC (z0)) 

(18) Since we have shown that α ∈ H C (Z′) and since HC (z0) ∈ H C (Z) then we have that: 

fC′ (z0 | C′ = HC′ (z′

> 0

)) = 

f∅(z0 | C = α, C = HC (z0)) ∈{fC (z | C = HC (z′)) : z ∈ Z , z′ ∈ Z ′} = S

(19) This establishes that S′ ⊆ S, and hence concludes the proof of the lemma. Now to finalize the proof of the proposition, we recall that we have shown that the following holds (and can now rewrite this expression given our new definition of S): 24 Published as a conference paper at ICLR 2026 

max  

> z∈Z ,z′∈Z ′

fC (z | C = HC (z′)) − fG(z) p ≤ δ ⇐⇒ 

max  

> z∈Z ,y∈S

∥ y − fG(z) ∥p ≤ δ (20) We have also assumed towards contradiction that the following holds, and we can similarly further rewrite this term given our new definition of S′:

max  

> z∈Z ,z′∈Z ′

fC′ (z | C′ = HC′ (z′)) − fG(z) p > δ ⇐⇒ 

max  

> z∈Z ,y∈S′

∥ y − fG(z) ∥p > δ (21) However, since we have proven in Lemma 1 that S′ ⊆ S then we know that: 

max  

> z∈Z ,y∈S

∥ y − fG(z) ∥p ≥ max  

> z∈Z ,y∈S′

∥ y − fG(z) ∥p (22) which stands in contradiction to equations 20 and 21, hence implying the monotonicity of Φ, and concluding the proof of the proposition. B.6 PROOF OF PROPOSITION 6

Proposition 6. If the condition Φ( C, G ) is set to validating whether C is input-robust concerning 

⟨fG, Z⟩ (Def. 1), and also patching-robust with respect to ⟨fG, Z′⟩ (Def. 2), then if Z ⊆ Z ′ and 

HG(Z′) is closed under concatenation, Algorithm 1 converges to a subset-minimal circuit. Proof. The claim follows directly from Propositions 4 and 5. Since Z ⊆ Z ′, Proposition 5 implies that 

Φ( C, G ) is monotonic . By Proposition 4, it follows that Algorithm 1 converges to a subset-minimal 

circuit C with respect to Φ.B.7 PROOF OF PROPOSITION 7

Proposition 7. Given some model fG, and a monotonic predicate Φ, the MHS of all circuit blocking-sets concerning Φ is a cardinally minimal circuit C for which Φ( C, G ) is true. Moreover, the MHS of all circuits C ⊆ G for which Φ( C, G ) is true, is a cardinally minimal blocking-set w.r.t Φ.Proof. Prior to the proof of Proposition 7, which establishes the connection between Minimum Hitting Sets (MHS) and cardinal minimality, we first recall the definition of MHS: 

Definition 2 (Minimum Hitting Set (MHS)) . Given a collection S of sets over a universe U , a hitting set H ⊆ U for S is a set such that 

∀S ∈ S , H ∩ S̸ = ∅.

A hitting set H is called minimal if no subset of H is a hitting set, and minimum if it has the smallest possible cardinality among all hitting sets. 

We also show the following equivalence concerning the set of blocking sets. 

Lemma 2. Under a monotone predicate Φ, the set of circuit blocking sets with respect to G coincides exactly with the sets whose removal breaks faithfulness of the full model, i.e., C′ ⊆ G is a blocking set if and only if ¬Φ( G \ C′, G ).Proof. We prove both directions, starting with ⇒. Let C′ be a blocking set. By the definition of a blocking set (Section 4.4), Φ( C \ C′, G ) fails for all C ⊆ G, trivially including C = G. Therefore, 

¬Φ( G \ C′, G ). For the reverse direction ⇐, consider a set C′ ⊆ G whose removal from G, breaks the faithfulness of the full model G, namely ¬Φ( G \ C′, G ). Assume toward a contradiction that C′

25 Published as a conference paper at ICLR 2026 is not a blocking set. Then there exists some C ⊆ G for which Φ( C \ C′, G ) holds. By monotonicity of Φ, since C ⊆ G, we have Φ( C \ C′, G ) ⇒ Φ( G \ C′, G ), contradicting our assumption. This completes the proof, establishing that under monotonicity, the blocking sets are exactly the sets whose removal breaks faithfulness of the full model G.We now move to prove that the MHS of blocking-sets is a cardinally minimal faithful circuit. Let C

be a minimum hitting set (MHS) of the set of blocking-sets B.We now move to prove Proposition 7, establishing that the minimum hitting set (MHS) of the blocking sets is a cardinally minimal faithful circuit. Let B denote the set of blocking sets, which by Lemma 2, under the monotonicity assumption, coincides with the sets whose removal breaks faithfulness of the full model G. Let C be a minimum hitting set of B.Assume towards contradiction that ¬Φ( C, G ). Set B⋆ := G \ C. Then Φ( G \ B⋆, G ) = Φ( C, G )

is false, so B⋆ ∈ B . Yet by definition C ∩ B⋆ = ∅, contradicting that C hits every set in B. Hence 

Φ( C, G ) holds. We now move forward to prove minimality. Assume there exists C′ ⊆ G with Φ( C′, G ) and 

|C′| < |C|. We claim C′ is also a hitting set of B, contradicting the minimality of C as an MHS. Indeed, if some B ∈ B satisfied C′ ∩ B = ∅, then C′ ⊆ G \ B, and by monotonicity of Φ we would have Φ( G \ B, G ), contradicting B ∈ B . Hence C′ hits all of B, contradicting that C is an MHS. For the second part of the proof, let C := { C ⊆ G : Φ( C, G ) } and let B be a minimum hitting set of C. Assume towards contradiction that it is not, namely Φ( G \ B, G ) holds. Then C⋆ := G \ B is a faithful circuit, implying C⋆ ∈ C . Yet by definition C⋆ ∩ B = ∅, contradicting that B hits every set in C.Finally, assume towards contradiction that there exists a blocking-set B′ with |B′| ≤ | B|. Let C ∈ C .If C ∩ B′ = ∅, then C ⊆ G \ B′, and by monotonicity of Φ, we obtain that Φ( G \ B′, G ) holds, contradicting B′ being a blocking-set. Hence, C ∩ B′̸ = ∅, so B′ is a hitting set of C. But since 

|B′| ≤ | B|, this contradicts the minimality of B as an MHS. Therefore, B is cardinally minimal among blocking-sets. B.8 PROOF OF PROPOSITION 8

Proposition 8. Given a model fG, and a monotonic predicate Φ, Algorithm 2 computes a subset C

whose size is a lower bound to the cardinally minimal circuit for which Φ( C, G ) is true. For a large enough tmax value, the algorithm converges exactly to the cardinally minimal circuit. Proof. We begin with the proof for the part on the lower bound to cardinally minimal circuit size. Let 

C be the output of Algorithm 2 for some tmax . By definition, C is the MHS of the set of blocking-sets accumulated by the algorithm, denoted Btmax .Assume towards contradiction that |C| is not a lower bound for the size of a cardinally minimal circuit. This would imply the existence of a faithful circuit C′ with Φ( C′, G ) and |C′| ≤ | C|. From the minimality of C as a hitting set, it follows that C′ is not a hitting set. Hence, there exists some 

B ∈ B tmax such that C′ ∩ B = ∅. This implies C′ ⊆ G \ B, and by monotonicity of Φ we obtain 

Φ( G \ B, G ), contradicting B being a blocking-set. We now continue to the second part of the proof regarding the convergence to cardinally minimal for large enough tmax . For tmax = |G|, the algorithm iterates over all possible blocking-sets. Hence, the resulting output C is the MHS of all circuit blocking-sets, and by Proposition 7 we conclude that C

is a cardinally minimal circuit. 26 Published as a conference paper at ICLR 2026 

## C MINIMALITY GUARANTEES : A LGORITHMS AND ILLUSTRATIONS 

C.1 GREEDY EXHAUSTIVE ITERATIVE CIRCUIT DISCOVERY 

We present here an algorithm for exhaustively and repeatedly iterating over the circuit components, removing any component whose deletion does not violate faithfulness, until no further removals are possible (Algorithm 3). 

Algorithm 3 Greedy Exhaustive Circuit Discovery  

> 1:

Input Model fG, circuit faithfulness predicate Φ 

> 2:

C ← G under some given element ordering (e.g., reverse topological sort)  

> 3:

changed ← true  

> 4:

while changed do  

> 5:

changed ← false  

> 6:

for all i ∈ C do  

> 7:

if Φ( C \ { i}, G ) then  

> 8:

C ← C \ { i} 

> 9:

changed ← true  

> 10:

end if  

> 11:

end for  

> 12:

end while  

> 13:

return C

C.2 GREEDY CIRCUIT DISCOVERY BINARY SEARCH FOR QUASI -M INIMAL CIRCUITS 

We formalize the binary search procedure introduced in (Adolfi et al., 2025) in Algorithm 4. 

Algorithm 4 Greedy Circuit Discovery Binary Search  

> 1:

Input: Model fG, circuit faithfulness predicate Φ with Φ( G, G ) ∧ ¬ Φ( ∅, G ) 

> 2:

C ← G, low ← 0, high ← | G| 

> 3:

while high − low > 1 do  

> 4:

mid ← ⌊ (low + high )/2⌋ 

> 5:

Cmid ← G \ G[1 : mid ] 

> 6:

if Φ( Cmid , G ) then  

> 7:

low ← mid; C ← Cmid  

> 8:

else  

> 9:

high ← mid  

> 10:

end if  

> 11:

end while  

> 12:

return C

C.3 TOY EXAMPLE : M INIMALITY NOTIONS 

To illustrate the distinctions between the four minimality notions introduced in Definitions 3,4,5,6 (Section 4), we construct a simple Boolean toy network. For simplicity, we illustrate the different minimality notions using a Boolean circuit with XOR gates. While this abstraction makes the example easier to follow, it is without loss of generality, since Boolean gates can be equivalently expressed with ReLU activations. (Specifically, the XOR gate satisfies 

x1 ⊕ x2 = ReLU( x1 − x2) + ReLU( x2 − x1),

as for x1, x 2 ∈ { 0, 1} both terms vanish when x1 = x2, and exactly one equals 1 when x1̸ = x2). We emphasize that this encoding is not part of the computation graph, which can be defined indepen-dently. Accordingly, our toy boolean circuit (Fig. 6) can be viewed as a small feed-forward ReLU 27 Published as a conference paper at ICLR 2026 network. Despite its small size, this network cleanly separates the notions of cardinal , subset , local ,and quasi -minimal circuits.                    

> v1=x2
> v2=x1
> v3=x1
> v4=x1⊕x2
> v5=x1⊕x2
> v6=x2⊕x2(= 0)
> x1
> x2

⊕ y

Figure 6: Boolean toy network with XOR aggregation: y = v1 ⊕ v2 ⊕ v3 ⊕ v4 ⊕ v5. With v1 = x2,

v2 = v3 = x1, v4 = v5 = x1 ⊕ x2, and v6 = x2 ⊕ x2 = 0 the full model computes fG(x1, x 2) = x2.

Explanation. For clarity and simplicity, we define a Boolean network G which takes inputs in 

(x1, x 2) ∈ { 0, 1}2. The network G is composed of six components, whose vertex set is denoted 

VG = {v1, v 2, v 3, v 4, v 5, v 6}, aggregated by XOR (Fig. 6): 

y = v1 ⊕v2 ⊕v3 ⊕v4 ⊕v5 ⊕v6, with v1 = x2, v 2 = v3 = x1, v 4 = v5 = x1 ⊕x2, v 6 = x2 ⊕x2

The full network computes fG(x1, x 2) = x2, since 

fG(x1, x 2) = x2 ⊕ x1 ⊕ x1 ⊕ (x1 ⊕x2) ⊕ (x1 ⊕x2) ⊕ (x2 ⊕x2)= x2 ⊕ (x1 ⊕x1)

| {z }

> =0

⊕ [( x1 ⊕x2) ⊕ (x1 ⊕x2)] 

| {z }

> =0

⊕ (x2 ⊕x2)

| {z }

> =0

= x2.

We pick the faithfulness predicate to be 

Φ( C, G ) := fC (x1, x 2) = fG(x1, x 2) = x2 ∀(x1, x 2),

i.e., C is faithful if it computes the same output as G on all inputs. This single construction cleanly separates the four minimality notions: For each circuit C, we verify that it satisfies fC (x1, x 2) = x2 and state why it meets (or fails) the corresponding minimality condition. • Cardinal-minimal: Ccard = {v1}. It computes fCcard = v1 = x2 = fG. No circuit with fewer components can be faithful. • Subset-minimal: Csub = {v2, v 4}. The computation is 

v2 ⊕ v4 = x1 ⊕ (x1 ⊕ x2) = x2.

Removing any component breaks correctness: {v2} = x1̸ = x2 and {v4} = x1 ⊕ x2̸ = x2.• Local-minimal: Cloc = {v1, v 2, v 3}. It computes 

v1 ⊕ v2 ⊕ v3 = x2 ⊕ x1 ⊕ x1 = x2.

Removing any single component breaks correctness: {v1, v 2} = x2 ⊕ x1̸ = x2, {v1, v 3} =

x2 ⊕ x1̸ = x2, {v2, v 3} = x1 ⊕ x1 = 0 ̸ = x2. However, removing two components may still leave a correct singleton (e.g. {v1}), so it is not subset-minimal. • Quasi-minimal: Cquasi = {v1, v 2, v 3, v 4, v 5}. It computes 

v1 ⊕ v2 ⊕ v3 ⊕ v4 ⊕ v5 = x2.

The circuit contains a single essential component ( v1), while the remaining ones can be removed in various combinations without changing the output (e.g., v2 ⊕ v3 = 0 and 

v4 ⊕ v5 = 0 ). Hence it is faithful but not minimal under any stricter notion. 28 Published as a conference paper at ICLR 2026 

## D BENCHMARKS , M ODELS AND ARCHITECTURAL SPECIFICATIONS 

We evaluate our methods on four standard benchmarks in neural network verification: three classifi-cation benchmarks (CIFAR-10 (Krizhevsky & Hinton, 2009), GTSRB (Stallkamp et al., 2011), and MNIST (Lecun et al., 1998)) and one regression benchmark, TaxiNet (Julian et al., 2020). For each benchmark, we perform circuit discovery at the natural level of granularity for the model: convolutional filters (or channels ) in CNNs and neurons in the fully connected network. The number of components at each granularity is summarized in Table 3. Table 3: Granularity and number of components considered for circuit discovery across the benchmark models.                

> Dataset Model Examined Granularity # Components
> MNIST FC Neurons 31 GTSRB CNN Filters 48 CIFAR-10 ResNet Filters 72 TaxiNet CNN Filters 8

Data Selection. For the input and patching robustness experiments (Appendices E, F), we con-structed at least 100 batches per benchmark, sampled from the test set using only correctly predicted inputs (or low-error inputs in the regression case). In classification tasks, each batch contained k = 3 

samples from a single class, evenly distributed across classes. In the regression task, batches of 

k = 3 were drawn from inputs with absolute error below 0.2, excluding large deviations relative to the model’s performance. Specifically, we sampled 100 batches for CIFAR-10 and MNIST (10 per class), 129 batches for GTSRB (3 per class across 43 classes), and 100 batches for the regression benchmark TaxiNet .For the minimality guarantees experiment (Subsection 5.3, Appendix G), we used 50 singleton batches ( k = 1 ), obtained by selecting one sample from each MNIST batch above, thereby preserving the even class distribution. D.1 CIFAR-10 For the CIFAR-10 benchmark Krizhevsky & Hinton (2009), we use the ResNet2b model, originating from the VNN-COMP neural network verification competition (Bak et al., 2021). This residual network consists of an initial convolutional layer, two residual blocks, and a dense classification head producing 10 output classes. In total, it comprises 72 filters (also referred to as channels ). 29 Published as a conference paper at ICLR 2026                                                                                                 

> Layer / Block Output Dim. Details
> Input 32 ×32 ×3CIFAR-10 image Conv1 16 ×16 ×83×3, stride 2
> Residual Block 1
> Conv1 8×8×16 3×3, stride 2 ReLU 8×8×16 non-linearity Conv2 8×8×16 3×3, stride 1 Skip connection 8×8×16 identity/projection Output 8×8×16 addition + ReLU
> Residual Block 2
> Conv1 8×8×16 3×3, stride 1 ReLU 8×8×16 non-linearity Conv2 8×8×16 3×3, stride 1 Skip connection 8×8×16 identity Output 8×8×16 addition + ReLU Flatten 1×2048 –Linear1 2048 →100 ReLU Linear2 100 →10 Output logits

Table 4: Full architecture of the ResNet2b model used in Bak et al. (2021) for the CIFAR-10 benchmark D.2 GTSRB The German Traffic Sign Recognition Benchmark (GTSRB) Stallkamp et al. (2011) is a large-scale image classification dataset containing more than 50,000 images of traffic signs across 43 classes, captured under varying lighting and weather conditions. We adopt the GTSRB-CNN model used in recent explainability studies (Bassan et al., 2025a). This architecture is a convolutional network with two convolutional layers using ReLU activations and average pooling, followed by two fully connected layers. It outputs logits over 43 traffic sign classes. In total, the GTSRB-CNN comprises 48 filters across its two convolutional layers (16 + 32).                                                     

> Layer Output Dim. Details
> Input 32 ×32 ×3GTSRB image Conv1 32 ×32 ×16 3×3, padding 1, ReLU AvgPool1 16 ×16 ×16 2×2
> Conv2 16 ×16 ×32 3×3, padding 1, ReLU AvgPool2 8×8×32 2×2
> Flatten 1×2048 –FC1 2048 →128 ReLU FC2 128 →43 Output logits

Table 5: Architecture of the GTSRB-CNN model used in (Bassan et al., 2025a). D.3 MNIST We use a simple, classic fully connected feedforward network for MNIST classification, which we trained given the simplicity of the task. The model achieves 95.20% accuracy on the test set. It consists of two hidden layers with ReLU activations of sizes 13 and 11, followed by a linear output layer, comprising 31 non-input neurons in total and 10,479 trainable parameters. 30 Published as a conference paper at ICLR 2026                   

> Layer Dimensions Activation
> Input 28 ×28 = 784 –Fully Connected (fc1) 784 →13 ReLU Fully Connected (fc2) 13 →11 ReLU Fully Connected (fc3) 11 →10 –

Table 6: Architecture of the fully connected MNIST network. The model has 31 hidden neurons in total, which we treat as the granularity for circuit discovery. D.4 TAXI NET 

The TaxiNet dataset (Julian et al., 2020) was developed by NASA for vision-based aircraft taxiing, and consists of synthetic runway images paired with continuous control targets. Unlike the classification benchmarks, TaxiNet is a regression task: the model predicts real-valued outputs corresponding to flight control variables. For our experiments, we adopt the TaxiNet CNN regression model introduced in the VeriX frame-work (Wu et al., 2023a) and subsequently used in other explainability studies (Bassan et al., 2025a). This convolutional network, comprising 8 filters, achieves a mean squared error (MSE) of 0.848244, and a root mean squared error (RMSE) of 0.921.                                         

> Layer Output Dim. Details
> Input 27 ×54 ×1TaxiNet image Conv1 27 ×54 ×43×3, padding 1, ReLU Conv2 27 ×54 ×43×3, padding 1, ReLU Flatten 1×5832 –FC1 5832 →20 ReLU FC2 20 →10 ReLU FC3 10 →1Regression output

Table 7: Architecture of the CNN regression model used for TaxiNet, following the VeriX frame-work (Wu et al., 2023a). 

## EXPERIMENTAL DETAILS 

## E INPUT ROBUSTNESS CERTIFICATION 

In this experiment, we evaluate the robustness of discovered circuits over a continuous input neighbor-hood Bpϵ (x), as established in Section 3.1. We compare two variants of the iterative circuit discovery procedure in Algorithm 1, which differ in their elimination criterion: 1. Sampling-based Circuit Discovery : directly evaluates the metric on the input batch at each step. 2. Provably Input-Robust Circuit Discovery : certifies that the metric holds across the entire input neighborhood (Def. 1). The procedure traverses network components sequentially, deciding at each step whether to retain or remove a component. As noted in Conmy et al. (2023), the traversal order influences the resulting circuit. Following their approach, we proceed from later fully-connected or convolutional layers toward earlier ones, ordering neurons or filters within each layer lexicographically. For consistency, we fix the patching scheme for all non-circuit components to zero-patching .31 Published as a conference paper at ICLR 2026 E.1 METHODOLOGY 

E.1.1 SIAMESE NETWORK FOR VERIFICATION 

To integrate circuit discovery with formal verification, we construct a Siamese Network , which pairs the full model with a candidate circuit, and outputs the concatenation of the two networks’ logits. This Siamese formulation provides the interface for the neural network verification used in two settings: • Provably Input-Robust Circuit Discovery: certify at each elimination step that the candi-date circuit satisfies the metric across the continuous input neighborhood, ensuring robust-ness is preserved. • Evaluation: verify after discovery (via either sampling- or provable-based methods) that the resulting circuit is robust over the same neighborhood. 

Output Metric. For consistency, all of our experiments employ the same output metric for both the sampling-based and provably input-robust discovery methods. We measure the difference in logits, requiring this difference to remain within a tolerance δ.In classification tasks over an input z, we focus on the logit of the gold-class, indexed by k, and require that the predictions of the circuit C and the full model G differ by at most δ:

|fG(z)[ k] − fC (z)[ k]| ≤ δ, 

where the absolute value denotes the ℓp-norm on the one-dimensional vector corresponding to the k-th entry. In the sampling-based method, it is evaluated on the sampled batch, whereas in the provable (siamese) setting, this criterion is certified over the concatenated logits of the siamese encoding. For instance, in a 10-class classification task, the verification constraint on the siamese network’s output is: 

| logits [:10] [k] − logits [10:] [k] | ≤ δ. 

where the first 10 entries correspond to the logits of the full model G and the second to those of the circuit C.In regression settings (e.g., TaxiNet), the same principle applies to the full output (a scalar-valued prediction), measuring the absolute difference between the model and the circuit. In both cases, this metric directly instantiates the norm metric used in the robustness definitions (Definitions 1, 2). 

Input Neighborhoods. In our setup, the neighborhood B∞ 

> ϵp

(x) is defined in the input space with respect to the L∞ norm. For fully connected models (e.g., MNIST), inputs are flattened into vectors and the perturbation ball is defined over this representation. For convolutional models (e.g., CIFAR-10, GTSRB, TaxiNet), inputs are multi-channel tensors, and the neighborhood is applied independently to each channel and spatial location. E.1.2 VERIFICATION AND EXPERIMENTAL SETUP (I NPUT ROBUSTNESS )Since sound-and-complete verification of piecewise linear activation networks against linear properties is NP-hard Katz et al. (2017), Some queries may not complete within the allotted time; in such cases, the outcome is reported as unknown . In practice, with the α, β -CROWN verifier, we limit each query to 45 seconds of Branch-and-bound time. For fairness, we report robustness statistics only on batches where the robustness check of the sampling-based method was determined (robust or non-robust, excluding timeouts) In the main paper results, the rate of timed-out instances was 1% on MNIST, 1.6% on GTSRB, 1% on CIFAR-10, and 5% on TaxiNet. Comparable rates were observed in the neighborhood size variations E.2.1 studies (on average, 0.5% for MNIST, 3% for CIFAR-10, and 2.7% for TaxiNet), and in the tolerance level variations δ E.2.2 (on average 8.6% for TaxiNet, 3.6% for MNIST). Experiments on MNIST, GTSRB, and CIFAR-10 were conducted on a unified hardware setup with a 48 GB NVIDIA L40S GPU paired with a 2-core, 16 GB CPU. For the TaxiNet model, we used only a 2-core, 36 GB CPU machine. 32 Published as a conference paper at ICLR 2026 E.2 ROBUSTNESS EVALUATION AND PARAMETER VARIATIONS 

We evaluate the robustness of circuits discovered by both methods over the neighborhood B∞ 

> ϵp

(x),using formal verification via the Siamese Network as described above. The parameter ϵp controls the neighborhood size: if too small, the resulting circuits are trivial; if too large, the perturbations become unrealistic and off-distribution. We choose ϵp values within ranges commonly used in prior verification work or empirically selected to balance circuit size and robustness. In addition, we vary both parameters, ϵp and δ, to analyze their effect. E.2.1 VARIATION OF INPUT NEIGHBORHOOD SIZE ϵp

We fix the tolerance δ and vary the input neighborhood size ϵp. For CIFAR-10 and MNIST, we use 

δ = 2 .0; for GTSRB, δ = 5 .0. For the TaxiNet regression model, we set δ = 0 .92 (the model’s root mean squared error, RMSE), reflecting its typical prediction scale (larger deviations would let the circuit drift more than the full model from the ground truth). Results are reported in Table 8. Rows highlighted in gray correspond to the results selected in the main paper.                                                                                                                                             

> Dataset ϵpSampling-based Circuit Discovery Provably Input-Robust Circuit Discovery
> Time (s) Size ( |C|)Robustness (%) Time (s) Size ( |C|)Robustness (%) MNIST ( δ=2 .0)
> 0.005 0.015 ±0.003 12.57 ±2.29 46.0 ±5.0677.36 ±183 .65 14.51 ±2.41 100.0 ±0.00.009 0.016 ±0.013 12.56 ±2.30 25.3 ±4.4663.60 ±181 .13 15.76 ±2.25 100.0 ±0.00.010 0.309 ±0.889 12.56 ±2.30 19.2 ±4.0611.93 ±97 .14 15.84 ±2.33 100.0 ±0.00.050 0.027 ±0.065 12.57 ±2.29 0.0 ±0.01700.05 ±562 .36 28.75 ±6.67 100.0 ±0.0
> TaxiNet ( δ=0 .92 )
> 0.001 0.040 ±0.146 5.76 ±0.77 62.2 ±4.9201.81 ±34 .16 6.07 ±0.71 100.0 ±0.00.005 0.010 ±0.002 5.77 ±0.80 9.5 ±3.0180.00 ±40 .39 6.82 ±0.46 100.0 ±0.00.010 0.010 ±0.002 5.78 ±0.79 2.0 ±1.4271.03 ±54 .23 7.91 ±0.32 100.0 ±0.0
> CIFAR-10 ( δ=2 .0)
> 0.007 0.035 ±0.001 16.70 ±9.48 73.7 ±4.42104.13 ±118 .95 17.96 ±9.90 100.0 ±0.00.012 0.116 ±0.367 16.91 ±9.12 58.1 ±5.12226.34 ±103 .71 18.88 ±9.21 100.0 ±0.00.015 0.228 ±0.517 16.47 ±9.08 46.5 ±5.02970.85 ±874 .23 19.18 ±10 .16 100.0 ±0.0
> GTSRB ( δ=5 .0)
> 0.001 0.111 ±0.329 28.91 ±4.69 27.6 ±4.0991.08 ±162 .91 29.59 ±4.45 100.0 ±0.0

Table 8: Effect of varying the input neighborhood size ϵp under a fixed tolerance δ. Reported values are means with standard deviations. For robustness (a binary variable), we report the standard error (SE). Bold values indicate robustness percentages. Rows highlighted in gray correspond to the results selected in the main paper. E.2.2 VARIATION OF TOLERANCE LEVEL δ

We vary the tolerance δ while fixing the input neighborhood size ϵp to the dataset-specific values used in the main paper (MNIST: ϵp=0 .01 , TaxiNet: ϵp=0 .005 ). Results are reported in Table 9. Rows corresponding to the main paper results are highlighted in gray.                                                                                                                                                         

> Dataset δSampling-based Circuit Discovery Provably Input-Robust Circuit Discovery
> Time (s) Size ( |C|)Robustness (%) Time (s) Size ( |C|)Robustness (%) MNIST ( ϵp=0 .01 )
> 0.50 0.083 ±0.329 19.72 ±1.50 15.6 ±3.8 460.14 ±36.59 22.02 ±2.52 100.0 ±0.0
> 2.00 0.309 ±0.889 12.56 ±2.29 19.2 ±4.0 611.93 ±97.14 15.84 ±2.33 100.0 ±0.0
> 3.00 0.013 ±0.001 9.44 ±1.92 34.0 ±4.7 577.41 ±35.84 12.27 ±2.52 100.0 ±0.0 TaxiNet ( ϵp=0 .005 )
> 0.50 0.038 ±0.115 6.84 ±0.86 32.1 ±5.2 93.08 ±22.75 7.75 ±0.46 100.0 ±0.0
> 0.70 0.008 ±0.001 6.15 ±0.81 14.8 ±3.8 114.51 ±23.95 7.31 ±0.53 100.0 ±0.0
> 0.92 0.010 ±0.002 5.77 ±0.80 9.5 ±3.0 180.00 ±40.39 6.82 ±0.46 100.0 ±0.0
> 1.00 0.009 ±0.002 5.57 ±0.82 9.5 ±3.0 142.62 ±24.77 6.66 ±0.52 100.0 ±0.0
> 1.20 0.009 ±0.001 5.43 ±0.96 6.1 ±2.4 155.03 ±26.34 6.32 ±0.59 100.0 ±0.0

Table 9: Variation on tolerance level δ, with input neighborhood size ϵ fixed to the dataset-specific values used in the main experiments. Reported values are means with standard deviations. For robustness (a binary variable), we report the standard error (SE). Rows highlighted in gray correspond to the results selected in the main paper. 33 Published as a conference paper at ICLR 2026 E.2.3 EVALUATION UNDER ALTERNATIVE OUTPUT METRICS 

To further assess the generality of our framework, we repeat the robustness evaluation using alternative output metrics beyond the default logit-difference criterion. Specifically, we consider two additional formulations: • Consistent winner class: Given some target class t ∈ [d], enforces that the winner class remains consistent over a specified region. This metric directly targets preservation of the predicted class across the input domain and is widely used in robustness verification studies. The criterion then enforces that: 

∀z ∈ Z , argmax 

> j

(fG(z)) (j) = argmax 

> j

(fC (x | C = α)( z)) (j) = t. 

To allow greater flexibility, we relax the requirement by permitting the predicted class to remain consistent under any change that stays within a tolerance δ ∈ R+ above the runner-up class. When 

δ = 0 , this reduces back to the original definition. To make this threshold more meanignful and interpretable, we set δ as a configurable fraction α ∈ (0 , 1] of the model’s original winner–runner gap on the unperturbed input. In our experiments, for simplicity, we enforce the consistency condition only between the winner and runner-up classes. • Abs-Max: Bounds the maximum absolute deviation across all output dimensions by a specified threshold. This criterion does not guarantee class invariance but constrains the overall output drift. Formally, we require: 

∀z ∈ Z , ∥fG(z) − fC (x | C = α)∥∞ ≤ δ, 

ensuring that no individual logit differs by more than δ.We evaluate both metrics, using the same discovery configurations and ϵp as in the main input-robustness experiments. For the logits-difference metric, we used the same δ as in our main experiment (Table 1). In the winner-runner setting, we set α = 0 .5 (preserving half the original margin), and for the abs-max criterion we used δ = 4 .0. Results are reported in Table 10, which compares the 

sampling-based and provable discovery methods under each metric.                                                      

> Dataset Metric Sampling-based Circuit Discovery Provably Input-Robust Circuit Discovery
> Time (s) Size ( |C|)Robustness (%) Time (s) Size ( |C|)Robustness (%) MNIST Logit-diff 0.31 ±0.89 12.56 ±2.30 19.2 ±4.0611.93 ±97 .14 15.84 ±2.33 100.0 ±0.0
> Winner–Runner 0.13 ±0.60 5.18 ±1.05 73.0 ±4.4638.57 ±20.94 12.04 ±5.79 100.0 ±0.0
> Abs-Max 0.014 ±0.012 25.55 ±2.90 6.0 ±2.4362.61 ±55.73 28.11 ±2.37 100.0 ±0.0

Table 10: Comparison of circuit discovery methods under alternative output metrics. Reported values are means with standard deviations. For robustness (a binary variable), we report the standard error (SE). All methods use the same configurations as in the main experiments. Across all metrics, the same overall trend is observed: the provable method consistently approaches 100% robustness while maintaining circuit sizes comparable to those of the sampling-based baseline, which attains substantially lower robustness. This consistency across different metrics suggests that the robustness of the provable approach is not tied to a particular output metric, but reflects a stable characteristic of the method. E.2.4 COVERAGE ANALYSIS OF PROVABLY -R OBUST VS . S AMPLING -B ASED CIRCUITS 

To better understand the relationship between the circuits identified by our provably-robust procedure and those produced by the sampling-based method, we conduct an explicit coverage analysis over several robustness radii ϵ ∈ { 0.005 , 0.007 , 0.01 , 0.02 , 0.03 , 0.04 , 0.05 } on the MNIST benchmark. All other settings, including tolerance and metric definitions, follow those used in the main experiment (as discussed in section E.1). We conduct these experiments on a 2-core CPU machine with 16 GB of RAM. For each perturbation radius ϵp, we examine the provably input-robust circuit Cp derived for that ra-dius and the sampling-based circuit Cs, each obtained over 100 different inputs (as in our experimental setup), resulting in 100 circuit pairs for every ϵp.34 Published as a conference paper at ICLR 2026 For these two circuits, we compute: (i) the size of the intersection, |Cp ∩ Cs|, (ii) the components unique to the provable circuit ( provable-only ), |Cp \ Cs|, and (iii) the components unique to the sampling-based circuit ( sampling-only ), |Cs \ Cp|.We average these quantities over the 100 circuit pairs and report their means and standard deviations. To summarize the overall similarity/discrepancy between Cp and Cs across ϵp, we additionally compute standard set-similarity measures: Intersection over Union (IoU), Dice coefficient, and two asymmetric coverage metrics (provable-over-sampling and sampling-over-provable). These aggregate trends are visualized in Fig. 7. To further highlight the non-overlapping components, Table 11 reports their counts and their percentages relative to the full network size. Because the sampling-based method does not enforce a robustness condition, its circuit size remains constant across ϵp, while the provable-based circuits naturally expand as ϵp increases in order to guarantee certified robustness. We indeed view that as the required robustness grows, the provably-robust circuits include additional components essential for certification. 0.01 0.02 0.03 0.04 0.05                 

> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Similarity / discrepancy
> IoU =|CpCs||Cp| + | Cs||CpCs|
> Dice =2| CpCs||Cp| + | Cs|
> |CpCs||Cs|(Provable over sampling)
> |CpCs||Cp|(Sampling over provable)
> Symmetric difference ratio =|CpCs||CpCs|

Figure 7: Comparison of similarity and coverage metrics between provably-robust and sampling-based circuits. We report symmetric measures (IoU, Dice), a symmetric difference ratio, and asymmetric coverage ratios ( provable over sampling , sampling over provable ) to illustrate both overlap and directional differences. As shown in Fig. 7, the provably robust circuits consistently recover the vast majority of units identified by the sampling-based method across all ϵp values, with especially high agreement for small perturbation radii (e.g., IoU and Dice ≈ 0.9 at ϵp = 0 .005 ). As ϵp increases, the overlap between the two circuits gradually decreases (IoU drops toward 0.5), indicating that the sampling-based circuits capture a smaller fraction of the provable-based ones under larger perturbations. 35 Published as a conference paper at ICLR 2026 

Dataset ϵp |Cp \ Cs| % of full net |Cs \ Cp| % of full net 

MNIST 0.005 2.64 7.76% 0.70 2.06% 0.007 3.32 9.76% 0.74 2.18% 0.010 4.10 12.06% 0.81 2.38% 0.020 6.24 18.35% 0.58 1.71% 0.030 7.73 22.74% 0.39 1.15% 0.040 10.94 32.18% 0.24 0.71% 0.050 16.11 47.38% 0.13 0.38% Table 11: Set differences between the provably-robust circuit Cp and the sampling-based circuit Cs.For each ϵp, we report (i) the number of units appearing only in the provably-robust circuit |Cp \ Cs|,(ii) the number appearing only in the sampling-based circuit |Cs \ Cp|, and (iii) the corresponding percentages relative to the full network size for that dataset. This reflects the fact that the provably-robust circuits expand to satisfy stronger robustness require-ments. This trend is also evident in Table 11: the difference Cp \ Cs grows steadily with ϵp, while 

Cs \ Cp remains small across all settings, and decreases further for larger perturbation radii - indicat-ing that the sampling-based method contributes few components that are not required by the provable, certified solution. E.2.5 RUNTIME TRADE -O FF ACROSS INPUT NEIGHBORHOOD SIZES 

We aim to further analyze the runtime trade-off of the provably-robust method. For each input-robustness radius ϵp, we run the method to obtain a corresponding provably robust circuit and report the mean circuit-size-over-time curves (with standard deviation shown as shaded regions) across these circuits for different input neighborhoods induced by increasing ϵp. We perform this analysis on the MNIST benchmark, using the same perturbation radii and experimental settings as in the coverage analysis in Appendix E.2.4. 0 500 1000 1500 2000 2500 

> Time (sec)
> 15
> 20
> 25
> 30
> 35
> Circuit Size
> Provably-robust Circuit Size Over Time (Mean ± Std)
> =0.005
> =0.007
> =0.01
> =0.02
> =0.03
> =0.04
> =0.05

Figure 8: Provable-robust circuit size over time on MNIST for different neighborhood radii ϵp.Shaded regions denote the standard deviation. In all cases, the curves start at the full network size at time 0 and then decrease monotonically as components are pruned, until the procedure terminates. Across the smaller and closely spaced ϵp

values, the curves exhibit a very similar trajectory: an initial almost-linear decrease during the first 

∼ 300 seconds, followed by a stabilization phase around ∼ 500 seconds. The standard deviation 36 Published as a conference paper at ICLR 2026 bands for these curves are also comparable. As expected, larger neighborhoods lead to larger final circuit sizes. For substantially larger neighborhoods (e.g., ϵp = 0 .03 -0.05 ), the behavior changes: the decrease is slower, stabilization occurs later, and the variability (standard deviation) is considerably higher. Moreover, for these larger and more widely spaced ϵp values, we observe a clear increase in overall runtime (as indicated by where the curves terminate), reflecting the added complexity of discovering robust certified circuits under broader perturbation regions. E.2.6 QUALITATIVE OBSERVATIONS OF THE DISCOVERED CIRCUITS 

While our method is centered on formal guarantees, and our evaluation therefore focuses on robustness and minimality, we also include a brief exploratory look at the circuits discovered by our provably robust procedure and by the sampling-based baseline. This examination is qualitative in nature and is intended only to provide an informal visual sense of how the two circuits behave. For this analysis, we consider several channel-level GTSRB circuits produced in the input-robustness experiments. Recall that for each batch (composed of samples from the same class) we executed both our provably robust discovery (under a given ϵ = 0 .001 neighborhood) and the sampling-based discovery, producing two circuits. In the examples below, we select pairs of circuits with comparable sizes, where the sampling-based circuit is empirically non-robust while the provably robust circuit is certified robust. We then analyze their behavior on a representative clean input from the batch and on its corresponding adversarial example (an ϵ = 0 .001 -bounded adversarial perturbation). To obtain a coarse semantic signal, we apply Grad-CAM (Selvaraju et al., 2017) to the last convolu-tional layer of (i) the full model, (ii) the provably robust circuit, and (iii) the sampling-based circuit. Grad-CAM produces a class-specific importance map by weighting spatial activations according to the globally averaged gradients of the target class logit. Formally, for class c,

α(c) 

> k

:= 1

HW 

X

> i,j

∂y c

∂A kij 

, CAM c(i, j ) := ReLU X

> k

α(c) 

> k

Akij 

!

.

Here, yc denotes the logit of the target class c (the true label in our case), Ak is the k-th activation map (i.e., the output of filter k) of spatial size H × W , and α(c) 

> k

is the Grad-CAM weight obtained by spatially averaging the gradients ∂y c/∂A kij . Multiplying these weights by the corresponding activation maps and summing over channels, as in CAM c, highlights the spatial regions that the model relies on most for predicting class c.We use this mechanism to compare the behavior of the discovered circuits with that of the full model. Following common practice in vision models, we apply Grad-CAM to the last convolutional layer of the GTSRB networks. For visualization, we compute, normalize, and upsample the resulting Grad-CAM maps. Figure 9 illustrates these maps for an illustrative GTSRB sample depicting a roundabout sign. While the sampling-based circuit is larger than the provably robust one (35 convolutional channels compared to 26), the latter exhibits a closer match to the full model in the final convolutional layer. As shown in Fig. 9b, the heatmaps of the full model on this sample align well with those of the provably robust circuit, whereas the sampling-based circuit shows a less aligned activation pattern, with some loss of emphasis on regions in the sign interior. In addition, despite the very small perturbation radius (which makes the clean and perturbed images visually almost indistinguishable; Fig. 9a), Fig. 9b shows that the sampling-based circuit shifts its attention between the two inputs, while the provably robust circuit exhibits essentially no variation. This may suggest that the provably robust circuit better maintains its focus under perturbations. These observations, though not central to our evaluation, provide an additional qualitative lens on how the discovered circuits operate. 37 Published as a conference paper at ICLR 2026 

> (a) Original input, and a perturbed input in the GTSRB dataset.
> (b) GradCAM computations at the last convolutional layer

Figure 9: Grad-CAM heatmaps comparison for a GTSRB input and its adversarial counterpart, shown at the last convolutional layer across three models (the full model, the provably robust circuit, and the sampling-based circuit). E.2.7 ADDITIONAL QUALITATIVE INTERPRETATION OF COMPONENT -L EVEL BEHAVIOR 

Another possible direction for qualitative analysis is to assign semantic interpretations to inner components and subgraphs. This may include examining their behaviour and inferring the causal pathways in which they participate. In the example shown in Figure 4, we consider a CIFAR-10 bird sample together with its adversarial perturbation (also displayed in Figure 10), and compare the two circuit variants extracted from the ResNet model: the sampling-based circuit and the provably robust one. As illustrated, several filter-level components are preserved in the provably robust circuit, enabling it to satisfy the robustness criterion under perturbations. To analyze the additional components, we focus on the first convolutional layer, as shown in Figure 4. While later-layer interactions could also be insightful, for simplicity and clarity, we restrict our attention to the first-layer filters applied to the perturbed bird image. As the figure illustrates, this layer contains three filters shared by both circuits and one additional filter present only in the provably-robust circuit. We next examine the clean and adversarial images and their corresponding normalized difference heatmap, presented in Figure 10 within the main paper. Although the perturbation at ϵ = 0 .015 

is visually almost indistinguishable from the clean input, visualizing their difference reveals that substantial portions of the perturbation concentrate in the lower part of the image, beneath the bird’s contour. 38 Published as a conference paper at ICLR 2026 

Figure 10: Clean input x, its perturbed version z ∈ Bpϵp (x) with ϵp = 0 .015 , and the corresponding difference heatmap.  

> (a) Shared filters across both circuits (b) Filter retained only in the provably-robust circuit

Figure 11: (a) Activation maps of the shared first-layer filters present in both the provably robust and sampling-based circuits. (b) Activation map of the additional first-layer filter included only in the provably robust circuit. Blue indicates negative activations; red indicates positive activations. White denotes neutral or near-zero values. To gain further insight, we inspect the activation maps of these filters on the perturbed input (Fig-ure 11). We examine the three filters shared by both circuits as well as the additional filter unique to the provably robust circuit. For each filter, we extract the signed activations (since this layer does not apply a ReLU), normalize them, and upsample them for visibility. The resulting sign-normalized maps display negative activations in blue and positive activations in red. Across the three shared filters, we observe in Figure 11a that, although they react to and capture aspects of the bird’s contour, all of them assign negative values to the lower region where the noise is concentrated. Filter 0 outputs strongly negative values in this area, while filters 2 and 7 produce values between negative and neutral, passing only a weak signal over that region. In contrast, the additional filter included appears only in the provably-robust circuit (Figure 11b) produces strong positive activations precisely over the lower, noise-affected region. It is the only filter in this layer to do so. This suggests that its inclusion, together with the other filters, may help enrich and stabilize the signal over the perturbed region of the input, potentially contributing to the circuit’s certified robustness under this perturbation. Such an illustrative view suggests a possible connection between the retained components and the circuit’s robustness. 

## F PATCHING ROBUSTNESS CERTIFICATION 

In this experiment, we evaluate the robustness of discovered circuits when non-circuit components are patched with feasible activations drawn from a continuous input range, rather than fixed constants, as defined in Section 3.2. Operationally, for any circuit C, we test whether perturbing non-circuit components within the range of activations induced by inputs z ∈ B ∞ 

> ϵp

(x) can cause a violation of some metric ∥·∥ p with tolerance δ. If no such violation exists, we declare C to be patching-robust 2. 39 Published as a conference paper at ICLR 2026 We compare three patching schemes within the iterative discovery framework (Algorithm 1): 1. Zero patching: sets all non-circuit components to zero. 2. Mean patching: replaces non-circuit components with their empirical means, estimated from 100 randomly selected training samples. 3. Provably robust patching: verifies robustness across the full range of feasible activations induced by a continuous input domain (Def. 2). F.1 METHODOLOGY 

F.1.1 PATCHING SIAMESE NETWORK FOR VERIFICATION 

As an interface for verifying patching robustness, we employ a Patching Siamese network with two branches: (i) a full-network patching branch , used to capture non-circuit activations for patching; and (ii) a circuit branch restricted to C, where every non-circuit component is replaced by the activation of its counterpart in the patching branch. This replacement is implemented through dedicated wiring that copies the required activations from the first branch to the second. We examine activations induced by inputs from a neighborhood around x: Z = B∞ 

> ϵp

(x). As outlined in Section 3.2, the siamese network is fed a concatenated input (x, z) (along the feature axis for MNIST and the channel axis for CNNs). Here, x is routed to the circuit branch and z to the patching branch. The verification domain is applied only to z, while x is held fixed. This setup simulates the circuit running on x, with its non-circuit activations replaced by those induced from z ∈ Z . We note that, for numerical stability on the verifier’s side, the circuit-branch input is enclosed in a negligible 

10 −5 L∞ ball. For the output criterion, the resulting circuit logits are verified against the logits of the full model, 

fG(x) (precomputed independently of the Siamese construction) under the logit-difference metric with tolerance δ. This guarantees that the patching-robustness property (Def. 2) holds. 

Input Neighborhoods. As in Section E.1.2, we define the neighborhood Z = B∞ 

> ϵp

(x) using the 

ℓ∞ norm. F.2 ROBUSTNESS EVALUATION AND PARAMETER VARIATIONS 

After discovery (using zero, mean, or provably robust patching), we verify the resulting circuits with the Patching Siamese Network over the same B∞ 

> ϵp

(x), reporting circuit size, runtime, and patching robustness. Since typical ϵp values in the literature target input perturbations, we use larger values for the patching domain to reflect the broader variability of internal activations while avoiding off-distribution regimes. We report results below for varying (ϵp, δ ) to assess their effects on robustness and size. F.2.1 VERIFICATION AND EXPERIMENTAL SETUP (P ATCHING ROBUSTNESS )We use the same hardware configuration as in the input-robustness study E.1.2. We set a Branch-and-bound timeout of 45 seconds for MNIST, GTSRB, and TaxiNet as in the input experiment. For CIFAR-10, iterative discovery queries in the provably robust method are limited to 45 seconds, while discovered circuit-robustness evaluations are allowed up to 120 seconds. Queries that do not complete within these limits are reported as unknown .As in the input robustness experiment E, for fairness, we exclude cases where the robustness check for zero or mean patching timed out from the reported robustness statistics. In our main results, the timeout rates were 12% for MNIST, 2% for TaxiNet, 6.2% for GTSRB, and 31% for CIFAR-10, while in the variations over ϵp ( F.2.2) they averaged 0.5% for TaxiNet and 8.8% for MNIST. Over the δ variation ( F.2.3), the average timeout rate was 1.5% on TaxiNet and 14% on MNIST. 40 Published as a conference paper at ICLR 2026 F.2.2 VARIATION OF PATCHING NEIGHBORHOOD SIZE ϵp

We fix the tolerance level δ and vary the patching neighborhood size ϵp. For CIFAR-10 we use δ=0 .1,for MNIST δ=0 .5, for TaxiNet δ=0 .92 , and for GTSRB δ=2 .0. Table 12 extends the main results with additional ϵp variations on the MNIST and TaxiNet benchmarks.                                                                                                                                                                                                                                            

> Dataset ϵpZero Patching Mean Patching Provably Patching-Robust Patching
> Time (s) Size ( |C|)Rob. (%) Time (s) Size ( |C|)Rob. (%) Time (s) Size ( |C|)Rob. (%) MNIST ( δ=0 .5)
> 0.005 0.054 ±0.182 19.87 ±1.55 87.0 ±3.40.013 ±0.001 19.19 ±1.87 93.0 ±2.6671.08 ±36 .86 11.32 ±2.56 100.0 ±0.00.009 0.013 ±0.000 19.92 ±1.51 65.9 ±5.00.013 ±0.001 19.13 ±1.88 64.8 ±5.0583.59 ±44 .99 16.75 ±2.26 100.0 ±0.0
> 0.010 0.060 ±0.322 19.96 ±1.50 58.0 ±5.30.016 ±0.003 19.16 ±1.84 55.7 ±5.3714.87 ±207 .08 17.03 ±2.30 100.0 ±0.00.050 0.015 ±0.005 19.76 ±1.50 1.2 ±1.20.015 ±0.003 19.09 ±1.81 1.2 ±1.2598.41 ±156 .96 23.20 ±1.17 100.0 ±0.0
> TaxiNet ( δ=0 .92 )
> 0.005 0.061 ±0.183 5.78 ±0.79 93.0 ±2.60.022 ±0.061 5.38 ±0.65 100.0 ±0.0220.67 ±57 .23 4.60 ±0.74 100.0 ±0.00.008 0.026 ±0.097 5.78 ±0.79 62.0 ±4.90.008 ±0.001 5.38 ±0.65 77.0 ±4.2168.99 ±44 .83 5.26 ±0.54 100.0 ±0.0
> 0.010 0.024 ±0.059 5.78 ±0.78 57.1 ±5.00.025 ±0.068 5.39 ±0.65 63.3 ±4.9175.73 ±52 .71 5.41 ±0.59 100.0 ±0.00.030 0.009 ±0.002 5.78 ±0.79 27.0 ±4.40.008 ±0.001 5.38 ±0.65 40.0 ±4.995.31 ±15 .54 6.04 ±0.20 100.0 ±0.00.050 0.024 ±0.058 5.77 ±0.78 0.0 ±0.00.012 ±0.032 5.37 ±0.65 0.0 ±0.089.37 ±17 .58 7.07 ±0.26 100.0 ±0.0
> CIFAR-10 ( δ=0 .1)
> 0.030 0.109 ±0.321 65.07 ±3.00 46.4 ±6.0 0.046 ±0.003 64.07 ±3.60 33.3 ±5.7 5408.51 ±1091.05 65.55 ±1.64 100.0 ±0.0 GTSRB ( δ=2 .0)
> 0.005 0.284 ±0.951 32.65 ±4.24 38.0 ±4.4 0.041 ±0.009 33.40 ±4.16 40.5 ±4.5 2907.17 ±721.67 34.34 ±4.07 100.0 ±0.0

Table 12: Variations on patching neighborhood size ϵp with fixed tolerance δ. Reported values are means with standard deviations (formatted as {mean ± std}). For robustness (a binary outcome), we report the mean robustness with its standard error (SE), and display robustness values in bold . Rows highlighted in gray correspond to the results selected in the main paper. F.2.3 VARIATION OF TOLERANCE TOLERANCE δ

We fix ϵp and examine various tolerance values. As in the main paper results, we use ϵp=0 .01 for MNIST and Taxinet and vary the tolerance δ. Results are reported in Table 13 

Dataset δ Zero Patching Mean Patching Provably Robust Patching 

Time (s) Size ( |C|) Rob. (%) Time (s) Size ( |C|) Rob. (%) Time (s) Size ( |C|) Rob. (%) MNIST ( ϵp=0 .01 )

0.25 0.142 ± 0.476 21.36 ± 1.87 48.6 ± 5.9 0.013 ± 0.000 21.22 ± 1.74 52.8 ± 5.9 523.67 ± 41.31 19.42 ± 2.01 100.0 ± 0.0 

0.50 0.060 ± 0.322 19.96 ± 1.50 58.0 ± 5.3 0.016 ± 0.003 19.16 ± 1.84 55.7 ± 5.3 714.87 ± 207.08 17.03 ± 2.30 100.0 ± 0.0 

1.00 0.013 ± 0.000 16.88 ± 1.85 61.2 ± 4.9 0.013 ± 0.001 16.11 ± 1.93 66.3 ± 4.8 690.42 ± 44.38 11.37 ± 2.64 100.0 ± 0.0 TaxiNet ( ϵp=0 .01 )

0.50 0.011 ± 0.003 6.86 ± 0.78 74.0 ± 4.4 0.010 ± 0.001 5.83 ± 0.40 80.0 ± 4.0 157.67 ± 33.68 6.00 ± 0.00 100.0 ± 0.0 

0.80 0.080 ± 0.210 6.04 ± 0.77 57.1 ± 5.0 0.010 ± 0.001 5.49 ± 0.54 61.2 ± 4.9 204.38 ± 40.04 5.68 ± 0.55 100.0 ± 0.0 

0.92 0.024 ±0.059 5.78 ±0.78 57.1 ±5.0 0.025 ±0.068 5.39 ±0.65 63.3 ±4.9 175.73 ±52 .71 5.41 ±0.59 100.0 ±0.01.20 0.011 ± 0.001 5.44 ± 0.96 46.9 ± 5.0 0.010 ± 0.003 5.20 ± 0.79 58.2 ± 5.0 246.14 ± 50.82 5.15 ± 0.51 100.0 ± 0.0 

Table 13: Variation of tolerance level δ with fixed patching neighborhood size ϵp = 0 .01 . Reported values are means with standard deviations (formatted as mean ± std). For robustness (a binary outcome), we report the mean robustness with its standard error (SE), and display robustness means in bold . Rows highlighted in gray correspond to the results selected in the main paper. 

## G EXPLORING CIRCUIT MINIMALITY GUARANTEES 

In this experiment, we examine circuits that must simultaneously satisfy both input-robustness (Def. 1) and patching-robustness (Def. 2), as introduced in Section 3.2. Specifically, we define Φ to require that circuits remain robust within the input neighborhood Z = B∞

ϵin (x), when non-circuit components are patched with values drawn from the patching neighborhood Z′ = B∞

ϵp (x).Thus, two domains are involved: one for inputs and one for obtaining activations used in patching. Here, ϵin and ϵp denote the radii of the respective L∞-balls. In our setup, we use ϵin = 0 .01 ,

ϵp = 0 .012 , and δ = 2 .0.G.1 VERIFYING SIMULTANEOUS INPUT - AND PATCHING -R OBUSTNESS WITH TRIPLED 

SIAMESE 

We certify simultaneous input- and patching-robustness using a tripled Siamese network with three branches, each evaluated on its designated domain: (i) a full-network patching branch , which 41 Published as a conference paper at ICLR 2026 processes inputs z′ ∈ B ∞ 

> ϵp

(x) to capture activations for use as patching values; (ii) the full network ,which processes inputs z ∈ B ∞ 

> ϵin

(x) to provide reference logits fG(z); and (iii) the circuit branch ,also evaluated on z ∈ B ∞ 

> ϵin

(x) but restricted to C, where non-circuit components are masked and instead receive transplanted activations from the patching branch. This special wiring enables the direct transfer of non-circuit activations, allowing the verifier to certify that the circuit logits fC (z) remain faithful to fG(z) across the input neighborhood B∞ 

> ϵin

(x)

under patching values induced by B∞ 

> ϵp

(x), thereby establishing the simultaneous input- and patching-robustness property. We evaluate three discovery strategies under this setting, all applied with the combined robustness predicate Φ defined above: 1. Iterative discovery: Algorithm 1. 2. Quasi-minimal search: Algorithm 4. 3. Blocking-sets MHS method: Algorithm 2, leveraging circuit blocking set duality to approximate cardinally minimal circuits. G.2 BLOCKING -SETS MHS METHOD : A NALYSIS AND EXPERIMENTAL DETAILS 

Experimental setup. We conduct experiments on the MNIST network (34 hidden neurons). Since contrastive subsets are enumerated in increasing order of size, the number of verification queries grows combinatorially. Even when restricted to subset sizes t ∈ { 1, 2, 3}, each batch requires thousands of verification calls. To keep computations tractable, we evaluate singletons ( k = 1 per batch) and enforce a 30-second timeout per query. In one rare case, the procedure produced an empty circuit (size 0), as Φ held vacuously under a particular choice of environments and metric, eliminating all components. This case was excluded from the reported results. 

Parallelism. Unlike iterative discovery, where elimination steps are sequentially dependent, the verification of contrastive subsets is independent. This independence allows full parallelization: we distribute verification queries across 14 workers, with runtime scaling nearly linearly with the number of workers. 

Properties. Under monotonic Φ, the MHS method yields either (i) a lower bound on the size of any cardinally minimal circuit, or (ii) when the hitting set itself satisfies Φ, a certified cardinally minimal circuit. Although more computationally expensive than iterative discovery, MHS provides strictly stronger guarantees: if the hitting set is valid, the result is provably cardinally minimal; otherwise, its size gives a tight lower bound that exposes whether iterative discovery reached cardinal minimality and quantifies any gap. 

## H DISCLOSURE : U SAGE OF LL MS 

An LLM was used solely as a writing assistant to correct grammar, fix typos, and enhance clarity. It played no role in generating research ideas, designing the study, analyzing data, or interpreting results; all of these tasks were carried out exclusively by the authors. 42