---
title: "On the Mechanism and Dynamics of Modular Addition: Fourier Features, Lottery Ticket, and Grokking"
title_zh: 论模加法的机制与动力学：傅里叶特征、彩票机制与顿悟
authors: "Jianliang He, Leda Wang, Siyu Chen, Zhuoran Yang"
date: 2026-02-18
pdf: "https://arxiv.org/pdf/2602.16849v1"
tags: ["query:sr"]
score: 6.0
evidence: 神经网络解决数学任务的机械解释
tldr: 本研究深入探讨了两层神经网络解决模加法任务的机制与动力学。通过提出包含相位对称与频率多样性的“多样化条件”，揭示了神经元如何通过多数投票机制消除噪声并形成全局解。研究利用梯度流分析证明了特征演化的“彩票机制”，并以此将“顿悟”（Grokking）现象重新定义为受权重衰减驱动的、从记忆到泛化的三阶段演化过程。
motivation: 旨在解决现有研究无法充分解释单个神经元的傅里叶特征如何协同构建模加法全局解的问题。
method: 通过形式化多样化条件并结合梯度流分析与ODE比较引理，对网络特征的耦合动力学进行严谨表征。
result: 证明了相位对称性允许网络通过多数投票抵消噪声，并揭示了初始频谱强度决定神经元频率竞争胜负的机制。
conclusion: 揭示了模加法的机械解释，并证明顿悟是记忆与两阶段泛化组成的动力学过程，由损失优化与权重衰减共同驱动。
---

## 摘要
我们对双层神经网络如何学习特征以解决模加法任务进行了全面分析。我们的工作为所学模型提供了完整的机制解释，并对其训练动力学给出了理论说明。虽然先前的研究已经发现单个神经元会学习单频傅里叶特征和相位对齐，但尚未充分解释这些特征如何组合成全局解。我们通过形式化在过度参数化训练过程中出现的“多样化条件”来弥补这一空白，该条件由两部分组成：相位对称性和频率多样化。我们证明了这些性质允许网络共同逼近模加法任务正确逻辑上的一个有缺陷的指示函数。虽然单个神经元会产生噪声信号，但相位对称性实现了一种多数投票机制来抵消噪声，从而使网络能够稳健地识别正确的和。此外，我们通过彩票机制解释了随机初始化下这些特征的出现。我们的梯度流分析证明了频率在每个神经元内部相互竞争，而“胜者”由其初始频谱幅度和相位对齐决定。从技术角度来看，我们对逐层相位耦合动力学进行了严格表征，并利用 ODE 比较引理形式化了竞争格局。最后，我们利用这些见解揭开了顿悟（grokking）的神秘面纱，将其表征为一个包含记忆以及随后两个泛化阶段的三阶段过程，这一过程由损失最小化与权重衰减之间的竞争所驱动。

## Abstract
We present a comprehensive analysis of how two-layer neural networks learn features to solve the modular addition task. Our work provides a full mechanistic interpretation of the learned model and a theoretical explanation of its training dynamics. While prior work has identified that individual neurons learn single-frequency Fourier features and phase alignment, it does not fully explain how these features combine into a global solution. We bridge this gap by formalizing a diversification condition that emerges during training when overparametrized, consisting of two parts: phase symmetry and frequency diversification. We prove that these properties allow the network to collectively approximate a flawed indicator function on the correct logic for the modular addition task. While individual neurons produce noisy signals, the phase symmetry enables a majority-voting scheme that cancels out noise, allowing the network to robustly identify the correct sum. Furthermore, we explain the emergence of these features under random initialization via a lottery ticket mechanism. Our gradient flow analysis proves that frequencies compete within each neuron, with the "winner" determined by its initial spectral magnitude and phase alignment. From a technical standpoint, we provide a rigorous characterization of the layer-wise phase coupling dynamics and formalize the competitive landscape using the ODE comparison lemma. Finally, we use these insights to demystify grokking, characterizing it as a three-stage process involving memorization followed by two generalization phases, driven by the competition between loss minimization and weight decay.