Title: Behavior Learning (BL): Learning Hierarchical Optimization Structures from Data

URL Source: https://arxiv.org/pdf/2602.20152v1

Published Time: Tue, 24 Feb 2026 03:12:09 GMT

Number of Pages: 50

Markdown Content:
International Conference on Learning Representations (ICLR) 2026 

# Behavior Learning (BL): 

# Learning Hierarchical Optimization Structures from Data 

Zhenyao Ma ∗

Xiamen University 

Yue Liang 

University of T¨ ubingen 

Dongxu Li 

Xi’an Jiaotong University 

# ABSTRACT 

Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and iden-tifiable optimization structures from data, ranging from single optimization prob-lems to hierarchical compositions. It unifies predictive performance, intrinsic in-terpretability, and identifiability, with broad applicability to scientific domains involving optimization. BL parameterizes a compositional utility function built from intrinsically interpretable modular blocks, which induces a data distribution for prediction and generation. Each block represents and can be written in sym-bolic form as a utility maximization problem (UMP), a foundational paradigm in behavioral science and a universal framework of optimization. BL supports archi-tectures ranging from a single UMP to hierarchical compositions, the latter mod-eling hierarchical optimization structures. Its smooth and monotone variant (IBL) guarantees identifiability. Theoretically, we establish the universal approximation property of BL, and analyze the M-estimation properties of IBL. Empirically, BL demonstrates strong predictive performance, intrinsic interpretability and scala-bility to high-dimensional data. Code: MoonYLiang/Behavior-Learning 

on GitHub; install via pip install blnetwork .Utility Maximization Problem (UMP) Environment  Behavior 

Human Behavior 

Behavior Learning   

> (c)
> (b)
> (a) (d)
> CompU
> Learning Scheme
> Data
> Learnable
> Learnable
> Learnable
> Each Block Learnable UMP
> BL (Single)

Single UMP 

UMP Composition  

> BL (Deep)
> BL (Shallow)
> Symbolic Form of
> Prediction Generation
> Intrinsic Interpretability
> Visualization
> 23
> 4

Interpretability & Inference 

Figure 1: Behavior Learning (BL). (a) Human behavior modeled as a UMP. (b) Learning scheme of BL, where CompU denotes the compositional utility function. (c) BL offers intrinsic interpretability (via symbolic form as a hierarchical optimization structure), identifiability, and inference capability. (d) Three architectural variants of BL, from single UMP to deep compositions. 

> ∗

Correspondence to: zhenyaoma@stu.xmu.edu.cn; Code contact: yue.liang@student.uni-tuebingen.de 

1

> arXiv:2602.20152v1 [cs.LG] 23 Feb 2026

International Conference on Learning Representations (ICLR) 2026 

# 1 INTRODUCTION 

Scientific research often grapples with phenomena that resist precise formalization (Anderson, 1972; Mitchell, 2009), including human and social domains (Simon, 1955; Arthur, 2009). Such phenom-ena are difficult to predict and even harder to falsify through theory alone. Interpretable machine learning (Interpretable ML) (Molnar, 2020), with its powerful approximation capabilities and built-in transparency, offers a promising alternative for modeling such phenomena. Yet a long-standing tension remains unresolved: model predictive performance and intrinsic interpretability often trade off—a challenge commonly known as the performance–interpretability trade-off (Arrieta et al., 2020). High-performing models such as deep neural networks (LeCun et al., 2015) typically lack transparency, while intrinsically interpretable models struggle to capture complex nonlinear patterns. Some efforts have been made to mitigate the performance–interpretability trade-off. For exam-ple, Hastie (2017); Alvarez Melis & Jaakkola (2018); Angelino et al. (2018); Nori et al. (2019); Koh et al. (2020); Agarwal et al. (2021); Kraus et al. (2024); Liu et al. (2024b); Plonsky et al. (2025) demonstrate varied strengths. However, two fundamental limitations remain, restricting their scientific applicability. (i) Insufficient alignment with scientific theories . Most approaches focus on extending existing machine learning methods to achieve interpretability, rather than de-veloping a scientifically grounded framework (e.g., based on optimization problems or differential equations). This often hinders alignment with scientific theories and limits the ability to extract scientific knowledge from learned models (Roscher et al., 2020; Bereska & Gavves, 2024; Longo et al., 2024). (ii) Non-uniqueness of interpretations . Most models are non-identifiable —their in-terpretations are not uniquely determined by observable predictions in a mathematical sense (Ran & Hu, 2017; M´ eloux et al., 2025). As a result, such models cannot support reliable estimation of ground-truth parameters (Newey & McFadden, 1994; Van der Vaart, 2000), and may even lack Pop-perian falsifiability (Popper, 2005), ultimately limiting their scientific credibility. These limitations naturally raise a key question: can we design an interpretable ML framework that mitigates the performance–interpretability trade-off while being scientifically grounded and identifiable? Inspired by behavioral science, we propose Behavior Learning (BL) : a general-purpose machine learning framework that learns interpretable and identifiable (hierarchical) optimization structures from data . It unifies high predictive performance, intrinsic interpretability, and identifiability, with broad applicability to scientific domains involving optimization. As illustrated in Figure 1, BL builds on one of the most fundamental paradigms in behavioral science—utility maximization—which posits that human behavior arises from solving a utility maximization problem (UMP) (Samuelson, 1948; Debreu, 1959; Mas-Colell et al., 1995). Motivated by this paradigm, BL learns interpretable optimization structures from data. It models responses ( y) as drawn from a probability distribution induced by a UMP or a composition of multiple interacting UMPs. This distribution is parameterized by a compositional utility function BL( x, y), constructed from intrinsically interpretable modular blocks B(x, y). Each block is a learnable penalty-based formulation that represents an optimization problem (UMP), which can be written in symbolic form and offers transparency comparable to linear regression. BL admits hierarchical structure , mainly in three architectural variants: BL(Single), defined by a single block; BL(Shallow), a moderately layered composition of blocks; and BL(Deep), a deep hier-archical composition of multiple blocks. The latter two model, and can be symbolically interpreted as, hierarchical optimization structures . All variants are trained end-to-end to induce a condi-tional Gibbs distribution for prediction and generation. By refining the penalty functions in each block into smooth and monotone forms, we develop Identifiable BL (IBL), the identifiable variant of BL. Under mild conditions, IBL guarantees unique intrinsic interpretability. This property ensures the scientific credibility of its explanations and further supports recovery of the ground-truth model under appropriate conditions. While motivated by behavioral science, BL is not domain-specific . It applies broadly to any scientific domain where observed outcomes arise as solutions to optimization problems—such as macroeco-nomics (Ramsey, 1928; Ljungqvist & Sargent, 2018), statistical physics (Gibbs, 1902; Landau & Lifshitz, 2013), or evolutionary biology (Wright et al., 1932; Fisher, 1999). This generality is sup-ported by a key theoretical insight (Theorem 2.2): any optimization problem can be equivalently written as a UMP. This makes BL a general-purpose modeling framework for data-driven inverse optimization (Ahuja & Orlin, 2001) across diverse scientific disciplines. 2International Conference on Learning Representations (ICLR) 2026 We study BL both theoretically and empirically. Theoretically, we show that both BL and IBL ad-mit universal approximation under mild assumptions (Section 2.2). For IBL, we further establish its M-estimation properties (Section 2.3), including identifiability, consistency, universal consistency, asymptotic normality, and asymptotic efficiency. Empirically, we evaluate BL across four tasks. Standard prediction tasks (Section 3.1) demonstrate its strong predictive performance. A qualitative case study (Section 3.2) illustrates its intrinsic interpretability. Prediction on high-dimensional in-puts (Section 3.3) further demonstrates its scalability to high-dimensional data. Further discussion and related work are provided in Section 5 and Section 6, respectively. We also provide guidance on how to scientifically explain BL(Deep) and architectural details in Section 4 and Section A, respec-tively. Overall, our key contributions are threefold. (i) We propose Behavior Learning (BL), a novel general-purpose machine learning framework inspired by behavioral science, which unifies high predictive performance, intrinsic interpretability, identifiability, and scalability. (ii) For scientific re-search, BL offers a scientifically grounded, interpretable, and identifiable machine learning approach for modeling complex phenomena that defy precise formalization. BL applies broadly to scientific disciplines involving optimization. (iii) At the paradigm level, BL learns from data the optimization structure of either a single optimization problem or a hierarchical composition of problems through distributional modeling, contributing a new methodology to data-driven inverse optimization. 

# 2 BEHAVIOR LEARNING (BL) 

2.1 UTILITY MAXIMIZATION PROBLEM (UMP) The modeling of human behavior, particularly in behavioral science and decision theory, often be-gins with the assumption that observed outcomes arise from a latent optimization process. A canon-ical formulation of this idea is the Utility Maximization Problem (UMP) (Mas-Colell et al., 1995), in which an agent selects actions y ∈ Y in response to contextual features x ∈ X by solving: 

max  

> y∈Y

U (x, y) s.t. C(x, y) ≤ 0, T (x, y) = 0 (1) Here, U (·) denotes a subjective utility function encoding the agent’s internal preferences or goals. The inequality constraint C(·) captures resource constraints, while the equality constraint T (·) en-codes either endogenous belief consistency or exogenous conservation laws. The UMP can be recast as a cost–benefit framework, where the agent trades off utility gains against constraint violations. Formally, under mild regularity conditions, it admits an unconstrained penalty reformulation at the level of local optimality (Han & Mangasarian, 1979), as formalized below. 

Theorem 2.1 (Local Exact Penalty Reformulation for UMP) . Let X ⊂ Rdx and Y ⊂ Rdy be nonempty compact sets, and let U : X × Y → R, C : X × Y → Rm, and T : X × Y → Rp be C1.Assume that for a given x ∈ X , the Han–Mangasarian constraint qualification holds at any strict local maximizer y⋆ of the UMP. Then there exist λ0 > 0, λ1 ∈ Rm

> ++

, and λ2 ∈ Rp 

> ++

such that y⋆ is a local maximizer of 

max  

> y∈Y

λ0 ϕ U (x, y) − λ⊤ 

> 1

ρ C(x, y) − λ⊤ 

> 2

ψ T (x, y). (2) 

Here ϕ : R → R is strictly increasing and C1, ρ(z) := max {z, 0}, and ψ(z) := |z|.

The proof is provided in Appendix B.1. This unconstrained reformulation offers greater tractability for both theoretical analysis and model training. While motivated by behavioral modeling, the UMP formulation is not domain-specific. It applies to any setting where observed outcomes are solutions to (explicit or latent) optimization problems. This is because any optimization problem can be equivalently formulated as a UMP. We state this in the following result, while the formal statement and proof are provided in Appendix B.1. 

Theorem 2.2 (Universality of UMP) . Any optimization problem of the form max y∈Y f (x, y) or 

min y∈Y f (x, y), subject to equality and inequality constraints, is equivalent to a UMP. 

3International Conference on Learning Representations (ICLR) 2026 2.2 BL A RCHITECTURE 

Figure 1(b–d) illustrates the architecture of BL. We consider samples (x, y) ∼ D , where x ∈ Rd

denotes contextual features and y is the response, represented as (ydisc , ycont ) ∈ Y disc × Rmc , cap-turing its hybrid structure. Responses are assumed to be stochastically generated by solving multiple interacting UMPs, each with a penalty-based formulation, which together compose a compositional utility function BL( x, y). On this basis, we model the data using a conditional Gibbs distribution (Gibbs, 1902) parameterized by BL Θ(x, y):

pτ (y | x; Θ) = exp  BL Θ(x, y)/τ 

Zτ (x; Θ) , Zτ (x; Θ) = 

Z

> Y

exp  BL Θ(x, y′)/τ  dy′ (3) Here the temperature parameter τ > 0 controls the randomness of the response. As τ → 0, the distribution in equation 3 converges to a Dirac measure supported on arg max y BL( x, y), thereby recovering the deterministic best response obtained by solving the composed UMPs. 

Model Structure of BL( x, y). To represent the composition of multiple UMPs, we build 

BL( x, y) by composing fundamental modular blocks B(x, y). Each block provides a penalty-based formulation of a single UMP, and together they yield the overall compositional utility function. Motivated by Theorem 2.1, we parameterize B(x, y) as 

B(x, y; θ) := λ⊤ 

> 0

ϕ UθU (x, y) − λ⊤ 

> 1

ρ CθC (x, y) − λ⊤ 

> 2

ψ TθT (x, y) (4) where θ := ( λ0, λ 1, λ 2, θ U , θ C , θ T ) denotes the complete set of learnable parameters. Following Theorem 2.1, ϕ is an increasing function; ρ penalizes inequality violations; and ψ captures symmet-ric deviations. Each block can be written as a well-defined UMP. We then compose BL( x, y) from multiple B-blocks through hierarchical composition to improve its representational power for optimization structures, yielding three main architectural variants, as illustrated in Figure 1(d). 1. BL(Single) applies a single instance of B(x, y) as defined in equation 4, without any additional layers. It can be viewed as learning a single UMP, and offers maximal interpretability. 2. BL(Shallow) uses B(x, y) as the fundamental modular block to construct a shallow net-work. It introduces one or two intermediate layers of computation. Each layer Bℓ

stacks multiple parallel Bℓ,i blocks to produce a vector in Rdℓ , i.e., Bℓ(x, y; θℓ) := [Bℓ, 1(x, y; θℓ, 1), . . . , Bℓ,d ℓ (x, y; θℓ,d ℓ )] ⊤. The output of Bℓ is directly fed into the next Bℓ+1 ,and only the final output is passed through a learnable affine transformation. 3. BL(Deep) extends the BL(Shallow) architecture to more than two layers, enabling richer hierar-chical compositions of UMPs while maintaining the same recursive structure. As before, only the final output is affine transformed. The overall structure of BL(Shallow) and BL(Deep) can be expressed in a unified form, where the shallow case corresponds to L ≤ 2 and the deep case to L > 2:

BL( x, y) := WL · BL

  · · · B2(B1(x, y)) · · ·  (5) 

Learning Objective. The response y may contain both discrete and continuous components. For discrete responses, we directly apply cross-entropy (Kullback & Leibler, 1951) on ydisc . For contin-uous responses, since the compositional utility function is analogous to an energy function (LeCun et al., 2006), we employ denoising score matching (Vincent, 2011) on ycont . The final objective combines the two with nonnegative weights γd, γ c:

L(θ) = γd E− log pτ (ydisc | x) + γc E ∇˜ycont log pτ (˜ ycont | x) + σ−2(˜ ycont − ycont ) 2 (6) 

Implementation Details. Here, we describe the key implementation choices for the general form of BL, taken as defaults unless otherwise noted. Further details are provided in Appendix A.3. • Function Instantiation. Following equation 4, we instantiate the function B(x, y) as 

B(x, y) = λ⊤ 

> 0

tanh  pu(x, y) − λ⊤ 

> 1

ReLU  pc(x, y) − λ⊤ 

> 2

pt(x, y) (7) 4International Conference on Learning Representations (ICLR) 2026 where pu, pc, pt are polynomial feature maps of bounded degree, providing interpretable rep-resentations of utility, inequality, and equality terms, respectively. The bounded tanh reflects the principle of diminishing marginal utility (Jevons, 2013), a commonly assumed principle in behavioral science, while ReLU and | · | introduce soft penalties for constraint violations. • Polynomial Maps. In BL(Single), the structure of polynomial maps is optional. In BL(Shallow) and BL(Deep), each B-block employs affine transformations as its polynomial maps, with higher-degree and interaction terms omitted by default for computational efficiency. • Skip Connections. For deep variants, skip connections can be optionally introduced to improve representational efficiency. More detailed architectural descriptions for this section are provided in Appendix A. 

Theoretical Guarantees. Under the given architecture, the BL framework has universal approxi-mation power: it can approximate any continuous conditional distribution arbitrarily well, provided that BL has sufficient capacity, as stated below. The proof is given in Appendix B.2. 

Theorem 2.3 (Universal Approximation of BL) . Let X ⊂ Rd and Y ⊂ Rm be compact sets, and let 

p⋆(y | x) be any continuous conditional density such that p⋆(y | x) > 0 for all (x, y) ∈ X × Y .Then for any τ > 0 and ε > 0, there exists a finite BL architecture (with depth and width depending on ε) and a parameter θ⋆ such that the Gibbs distribution in equation 3 satisfies 

sup 

> x∈X

KL  p⋆(· | x) ∥ pτ (· | x; θ⋆) < ε. (8) 

Interpretability. Alongside its expressive power, BL also exhibits strong intrinsic interpretability. • Each B-block can be expressed in symbolic form as an optimization problem (UMP): the tanh 

term defines the objective, the ReLU term corresponds to an inequality constraint, and the absolute-value term corresponds to an equality constraint. Thus, BL(Single) can be directly expressed as a symbolic UMP, whereas deeper architectures can be interpreted as compositions of UMPs, with each block retaining interpretability. • The polynomial basis ensures a level of transparency comparable to linear regression , as both objectives and constraints can be represented as linear combinations of polynomial features. It can further be visualized as a computational graph (Figure 7), in which each input’s influence on every B-block is traceable through compositional pathways. • BL(Deep) composes B-blocks in a layered manner, forming a hierarchical optimization struc-ture . Interpretation proceeds in a bottom-up fashion, where the relation between any two consec-utive layers can be viewed as aggregation or coarse-grained observation. Overall, the interpretive pathway is: raw input features → micro-level optimization blocks → macro-level aggregation or coarse-grained behavioral constructs → macro-level optimization systems . Section 4 provides a detailed description of this interpretation procedure. • BL also offers multiple architectural degrees of freedom that provide flexibility but simultane-ously affect the resulting interpretability. In deep variants, skip connections introduce cross-layer dependency structures that are modeled in statistical physics (Yang & Schoenholz, 2017). Replacing polynomial maps with affine transformations preserves the underlying optimization semantics but reduces symbolic granularity, yielding a more qualitative rather than symbolic interpretation of each block. • BL can be interpreted as a single UMP when the final layer contains only one B-block, since all lower-layer structures aggregate into a unified optimization problem. When the final layer contains multiple B-blocks, BL corresponds to a linear trade-off among multiple optimization problems. 2.3 IDENTIFIABLE BEHAVIOR LEARNING (IBL) Beyond prediction and interpretability, the BL framework supports a third fundamental goal: the identification of ground-truth parameters , which in turn endows BL with the capacity for scientifi-cally credible modeling. We refer to this setting as Identifiable Behavior Learning (IBL) . In the 5International Conference on Learning Representations (ICLR) 2026 Layer 1 

> Economic
> -sensitive
> Buyer
> Location
> -sensitive
> Buyer
> Represen
> tative
> Composit
> e Buyer
> Layer 2

Hierarchy of Needs  Hierarchical Social Organization  Renormalization in Physics 

> Location -
> Sensitive
> Buyer
> Economic -
> Sensitive
> Buyer
> Risk -
> Sensitive
> Buyer
> Zoning -
> Contrast
> Buyer
> Affordabilit
> y-Preferring
> Buyer
> Integrated
> Location –
> Economic
> Budget -
> Conflict
> Buyer
> Balanced
> Trade -off
> Buyer
> Represent
> ative
> Composite
> Buyer
> Utility
> Macro -level
> Preference
> Trade -offs
> Representative Agent
> Micro -level
> Primitive
> Preferences
> Environment
> Behavior
> Coarse
> Graining
> Coarse
> Graining
> Coarse
> Graining
> Features
> Utility
> Landscape

(d)  BL(Deep) Application: Hierarchical Optimization Systems in Science 

(b)  Interpreting BL[2,1] 

(a)  Interpreting BL(Single)  (c)  Interpreting BL(Deep) 

Figure 2: (a) Visualization and symbolic form of BL(Single) trained on the Boston Housing dataset, modeling the UMP ( max U s.t. C ≤ 0, T = 0 ) of a representative buyer in Boston housing (details in Section 3.2). Top: computational graphs of the polynomials inside the three penalty functions— tanh (preference), ReLU (budget), and | · | (belief). Each graph is respectively centered on tanh −1(U ), C, and T from left to right, with surrounding nodes representing input features. Directed edges (shown only if coefficient ≥ 0.3) indicate how each feature contributes to the corre-sponding term. Bottom: approximate symbolic formulation of the trained BL model as a UMP. (b) 

The BL[2,1] architecture. Layer 1 identifies two key micro-level preference types: the Economic-sensitive Buyer and the Location-sensitive Buyer . Layer 2 aggregates these two components into an effective representative buyer. (c) The BL(Deep) [5,3,1] architecture. Layer 1 recovers five distinct micro-level housing preference types. Layer 2 identifies three macro-level trade-off types captur-ing different ways these primitive preferences interact. Layer 3 aggregates them into the overall representative buyer. Table 10 provides detailed descriptions of each type. BL(Deep) provides a hierarchical explanation consistent with the coarse-graining principle (Kadanoff, 1966) in statistical physics, reconstructing the full micro-to-macro optimization hierarchy. In addition, the preference and trade-off patterns uncovered by BL(Deep) are well documented in the classical economics liter-ature (see Table 11). (d) BL can be applied to a broad class of hierarchical optimization structures in science, including hierarchical need structures, hierarchical social–organizational structures, and renormalization-style coarse-grained structures in physics. IBL setting, we define the modular block as 

Bid (x, y; θ) := λ⊤

0 ϕid  UθU (x, y) − λ⊤

1 ρid  CθC (x, y) − λ⊤

2 ψid  TθT (x, y) (9) Unlike BL, which uses general nonlinearities, the IBL architecture imposes stricter structural con-straints: ϕid and ρid are strictly increasing, while ψid is symmetric and strictly increasing in | · | . In addition, all three functions are C1. These properties ensure that each UMP block stays responsive 6International Conference on Learning Representations (ICLR) 2026 and adjusts smoothly to objectives and constraints. In practice, we instantiate equation 9 as 

Bid (x, y) = λ⊤ 

> 0

tanh  pu(x, y) − λ⊤ 

> 1

softplus  pc(x, y) − λ⊤

> 2

 pt(x, y)⊙2 (10) where (·)⊙2 denotes elementwise square. We design IBL in three architectural forms. Similar to BL, the IBL(Single) directly uses Bid (x, y) as the compositional utility function. The IBL(Shallow) and IBL(Deep) variants are defined recursively as 

IBL( x, y) := W◦ 

> L

· Bid 

> L

  · · · Bid 2

 Bid 1 (x, y) · · · , L ≥ 1 (11) where Bid  

> ℓ

stacks multiple parallel blocks Bid 

> ℓ,i

(x, y), and W◦ 

> L

is a learnable affine transformation without bias. All other design choices follow the BL setting. 

Theoretical Foundation. IBL admits favorable properties for ground-truth identification. We be-gin by establishing identifiability, which is fundamental for statistical inference. We first state our key assumption (see Assumption B.1 for details). 

Assumption 2.1. Let ¯Ψ denote the quotient space of atomic parameters. We assume that the map 

¯Ψ → RX ×Y , ¯ψ 7 → g ¯ψ , is injective , and that any finite set of distinct atoms is linearly indepen-dent . We further restrict attention to minimal representations with no duplicate atoms and a fixed canonical ordering. 

Theorem 2.4 (Identifiability of IBL) . Under Assumption B.1, the architectures IBL(Single), IBL(Shallow), and IBL(Deep) are identifiable in the parameter quotient space ¯Θ.

Theorem 2.5 (Loss Identifiability of IBL) . The IBL model is parameterized by θ ∈ Θ. Suppose Θ is compact. Then under Assumption B.1, the population loss L defined in equation 6 satisfies: 

• If γc > 0, it admits a unique minimizer in the quotient space ¯Θ;

• If γc = 0 , it admits a unique minimizer in the scale-invariant quotient space eΘ.

Theorems 2.4 and 2.5 together establish the identifiability of IBL. Theorem 2.4 shows that if two IBL models of the same structure induce the same compositional utility, then their parameters coincide up to an equivalence class. Theorem 2.5 further extends this result to loss-based identifiability. These results jointly imply that IBL admits a unique parameter estimate up to an equivalence class, and thus yields intrinsic interpretability that is unique up to the same class. Building on identifiability, Theorem 2.6 establishes the statistical consistency of IBL: under com-pactness of the parameter space, the learned parameters converge in probability to a minimizer of the population loss as the sample size n → ∞ . If the model is correctly specified, the estimator further 

converges to the ground-truth parameter, recovering the true underlying model , thereby endowing IBL with the potential to recover the ground-truth model. 

Theorem 2.6 (Consistency of IBL) . Let Ξ denote the relevant parameter quotient space: Ξ = ¯Θ

if γc > 0, and Ξ = eΘ if γc = 0 . Let ˆθn ∈ arg min θ∈Θ Mn(θ) denote the empirical minimizer, and let θ• ∈ arg min θ∈Θ M(θ) denote the population minimizer. Then under the conditions of Theorem B.5, ˆθnp

−→ θ• in Ξ, M(ˆθn) p

−→ M (θ•).

Moreover, if the model is correctly specified (i.e., the data distribution is realized by some θ⋆ ∈ Θ), then θ• = θ⋆ in Ξ, and thus ˆθnp

−→ θ⋆.

Correct specification is a strong and often unrealistic assumption. Fortunately, the IBL frame-work—like BL—also enjoys a universal approximation guarantee (Theorem B.6). Building on this result, we further establish the universal consistency of IBL: even under misspecification, IBL is capable of recovering the ground-truth model with sufficiently large sample sizes. 

Theorem 2.7 (Universal Consistency of IBL) . Under the conditions of Theorem B.7, for any admis-sible data-generating distribution p† satisfying the regularity assumptions of Theorem B.6, the IBL posterior sequence {pˆθn } satisfies 

sup 

> x∈X

KL  p†(· | x) ∥ pˆθn (· | x) p

−→ 0,

i.e., the learned conditional distributions {pˆθn } converge in KL to p† uniformly over x.

7International Conference on Learning Representations (ICLR) 2026 Specifically, this result implies that, even under model misspecification, the learned predictive dis-tribution pˆθn , parameterized by the IBL model, converges uniformly in KL to the true conditional distribution p†, provided that the capacity of the IBL architecture grows with the sample size n.We also establish the asymptotic normality of IBL estimators (Theorem B.9), showing that the parameter estimates converge in distribution to a normal law as the sample size increases. Further-more, under additional regularity conditions, the asymptotic variance attains the efficient informa-tion bound (Theorem B.10), demonstrating the statistical optimality of IBL. Formal statements and proofs of all theorems in this part are deferred to Appendix B.3. 

# 3 EXPERIMENTS 

In this section, we conduct four groups of experiments to systematically evaluate the capabilities of BL. Due to space constraints, details are provided in Appendix C. 3.1 STANDARD PREDICTION TASKS Performance Scores     

> On 10 datasets ×8 seeds
> AUC boxplot

Performance Ranks       

> On 10 datasets ×8 seeds
> Sorted by mean F1 -Macro rank

Performance Scores     

> On 10 datasets ×8 seeds
> F1 -Macro boxplot

Figure 3: Predictive performance of BL and baselines. Left/Middle: relative AUC and F1-Macro gains over DT, sorted by mean (excluding BL). Right: mean F1-Macro ranks ( ↓ better). BL achieves first-tier performance in both metrics. Its variants rank second and third in mean F1-Macro rank, with BL(Shallow) showing no statistically significant difference from state-of-the-art models. 

Is BL accurate enough for standard prediction tasks? In this part, we evaluate the predictive performance of BL on 10 datasets (Table 4), covering diverse sample sizes, feature dimensions, and scientific domains. For fair comparison, we consider two BL variants—BL(Single) and BL(Shallow)—and compare them against 10 baseline models (Table 5) drawn from five method-ological families: neural networks, tree-based models, gradient boosting methods, Bayesian meth-ods, and linear regressors. All methods share a unified preprocessing and tuning pipeline. 

Predictive Performance. Figure 3 shows that BL attains first-tier predictive performance overall, achieving the best results among intrinsically interpretable models. Notably, BL(Shallow) surpasses MLP, highlighting that BL delivers interpretability without sacrificing performance. 8International Conference on Learning Representations (ICLR) 2026 3.2 INTERPRETING BL: A C ASE STUDY 

How can BL be interpreted in practice? This part presents a case study using the Boston Housing 

dataset, where we train a supervised BL(Single) model with a degree-2 polynomial basis, a BL[2,1] model (i.e., a two-layer BL with two B-blocks in the first layer and one in the second layer), and a BL(Deep) model with a [5,3,1] architecture to predict median home values. We illustrate how the internal structure of BL can be interpreted as explicit optimization problems and their hier-archical versions, accompanied by complementary visualizations. Further details are provided in Appendix C.3 and C.5. 

Symbolic Form of BL(Single) as a UMP. As shown in Figure 2, the trained BL(Single) model can be interpreted as the UMP of a representative buyer in the Boston Housing market, comprising a single objective, inequality, and equality term. Each term is represented by an estimated quadratic polynomial. For parsimony, we extract approximate symbolic expressions by retaining only the monomials with the largest (2–5) absolute coefficients, while collecting the remaining terms (in-cluding constants) into a residual term ˜R. For example, the utility term can be written as: 

pu = −0.56 · P 2 − 0.6 · RM + 0 .57 · RM · P + ˜Ru ≈ (1 − P )(1 + P − RM) + ˜Ru

We similarly simplify the budget and belief terms to recover an approximate UMP for the buyer. The full symbolic form is illustrated at the bottom of Figure 2. 

Interpreting BL(Single) via Model Visualization. Visualizations of each term’s polynomial re-veal how features constitute the UMP. Three insights emerge from the visualizations in Figure 2. (i) Median housing price (MEDV) and average number of rooms (RM) are dominant across all terms—MEDV negatively affects utility in a near-quadratic form, while RM modulates its marginal effect. (ii) Proportion of lower-income residents (LSTAT) features prominently in the budget con-straint, reflecting implicit resource limitations. (iii) Crime rate (CRIM) appears only in the belief term, suggesting that buyers treat it as influencing others’ behavior rather than their own preferences. 

Figure 4: Interpreting deeper BL architectures as hierarchical structures of interacting agents. Each block B represents an interpretable agent solving its own UMP, while a layer corresponds to a set of heterogeneous agents operating in parallel. The next layer then aggregates and reallocates the neg-ative energies from the previous layer, thereby performing higher-level coordination across agents. This layered organization provides a natural compositional interpretation of deep BL: bottom-layer modules encode local objectives, while upper layers synthesize these into collective outcomes. Anal-ogous structures arise in biological and social systems—for example, in ant colonies, individual ants (first-layer agents) follow simple local rules, yet their collective behavior is coordinated through higher-level interactions (second-layer aggregation), yielding globally efficient resource allocation and task division. 9International Conference on Learning Representations (ICLR) 2026 

Interpreting BL(Deep). (1) Figure 2 (b) illustrates the optimization problems learned by the BL[2,1] model. Layer 1 identifies two micro-level preference types: an Economic-sensitive Buyer ,whose utility and constraint terms load primarily on ZN (Large-lot residential share) and LSTAT (Proportion of lower-income residents); and a Location-sensitive Buyer , driven mainly by CHAS (Charles River indicator) and RAD (Highway accessibility). Layer 2 aggregates these basic pref-erences, yielding an effective “representative buyer” that integrates the two preference types. (2) Figure 2 (c) presents the internal structure of the BL[5,3,1] model. In Layer 1, BL recovers five distinct micro-level preference types characterizing heterogeneous patterns in the housing market. Layer 2 identifies three macro-level representative agents, each capturing a different macro-level trade-off among the basic preferences. Layer 3 then aggregates these components into a single high-level mechanism, yielding the overall representative buyer. Table 10 provides detailed descrip-tions of each type. (3) Beyond interpretability, we find that each preference pattern and trade-off recovered by BL(Deep) aligns with established findings in the economics literature (see Table 11). This indicates that BL successfully reconstructs underlying scientific knowledge. 3.3 PREDICTION ON HIGH -D IMENSIONAL INPUTS 

Is BL scalable to high-dimensional inputs? We evaluate BL against the energy-based MLP (E-MLP) baseline across network depths d ∈ { 1, 2, 3}, with all models implemented without skip connections. Experiments are conducted on four datasets spanning both image and text domains, and are evaluated using six metrics : in-distribution accuracy, calibration metrics (ECE and NLL), and OOD robustness metrics (AUROC, AUPR, and FPR@95). For OOD evaluation, we adopt symmetric ID ↔OOD splits, using MNIST (LeCun et al., 2002) and Fashion-MNIST (Xiao et al., 2017) as one pair, and AG News and Yelp Polarity (Zhang et al., 2015) as another. E-MLP and BL are controlled to have comparable parameters. 

Scalability on High-Dimensional Inputs. Figure 5 and Table 1 present results for BL and E-MLP across network depths. On image datasets, the two models exhibit comparable in-distribution ac-curacy, while BL generally achieves stronger out-of-distribution detection performance on Fashion-MNIST at similar accuracy levels. On text datasets, BL consistently improves ID accuracy over E-MLP across depths. However, OOD detection behavior varies by dataset: BL outperforms E-MLP on Yelp, whereas E-MLP shows better OOD discrimination on AG News. BL also achieves better calibration metrics (ECE and NLL; Table 2). 

Downward Shift of the Pareto Frontier. Table 13 reports the parameter counts of BL and E-MLP across four tasks, and Tables 3 summarize their runtimes. The two models have highly comparable parameter sizes. Across datasets, BL exhibits slightly higher training time than E-MLP. Combining these results with their comparable predictive performance and the intrinsic interpretability of BL, in contrast with the black-box E-MLP, indicates that BL achieves a downward shift of the Pareto frontier. 3.4 CONSTRAINT ENFORCEMENT TEST : H IGH -D IMENSIONAL ENERGY CONSERVATION 

To evaluate whether the learnable penalty terms in BL are capable of enforcing near-hard constraints under finite temperature, we isolate the penalty mechanism and test it on a high-dimensional energy-conservation constraint. This diagnostic experiment removes the utility term and focuses solely on the penalty term, providing a characterization of how the penalty term controls constraint violations as a function of temperature τ and penalty scale λ.

Experiment setup. We sample x ∈ R64 i.i.d. from a standard Gaussian x ∼ N (0 , I 64 ) and define a pure penalty compositional utility 

T (x, y ) = ∥y∥2 − ∥ x∥2, BL (x, y ) = −λ T (x, y )2,

which plays the role of an energy-conservation residual and its quadratic penalty. We target the Gibbs distribution 

p(y | x) ∝ exp  BL (x, y )/τ 

10 International Conference on Learning Representations (ICLR) 2026 

Figure 5: Comparison of BL and E-MLP on image and text datasets; d de-notes model depth. Table 1: ID accuracy and OOD AUROC (%) on image and text datasets. BL and E-MLP are evaluated at depths 1–3 with matched parameter counts, both without skip connec-tions. Top-two per column are blue and red. 

Image Datasets Model MNIST Fashion-MNIST Accuracy OOD AUROC Accuracy OOD AUROC E-MLP (depth=1) 98.15 ± 0.07 88.72 ± 1.36 88.79 ± 0.29 90.57 ± 1.39 

BL (depth=1) 97.97 ± 0.18 91.17 ± 2.68 89.26 ± 0.22 91.89 ± 0.71 

E-MLP (depth=2) 98.11 ± 0.08 90.32 ± 1.74 88.88 ± 0.26 84.61 ± 2.56 

BL (depth=2) 98.05 ± 0.12 90.57 ± 2.49 88.96 ± 0.39 89.87 ± 2.48 

E-MLP (depth=3) 98.14 ± 0.11 87.76 ± 2.55 89.33 ± 0.25 83.13 ± 1.90 

BL (depth=3) 97.93 ± 0.27 92.92 ± 1.69 88.79 ± 0.25 89.24 ± 4.18 

Text Datasets Model AG News Yelp Accuracy OOD AUROC Accuracy OOD AUROC E-MLP (depth=1) 88.74 ± 0.26 59.24 ± 0.21 91.16 ± 0.02 57.60 ± 0.31 

BL (depth=1) 89.52 ± 0.16 66.18 ± 0.20 91.56 ± 0.04 57.06 ± 0.10 

E-MLP (depth=2) 89.29 ± 0.20 62.48 ± 0.76 91.32 ± 0.09 57.47 ± 0.21 

BL (depth=2) 89.22 ± 0.20 63.68 ± 0.46 91.39 ± 0.06 57.31 ± 0.27 

E-MLP (depth=3) 89.37 ± 0.21 66.82 ± 1.01 91.23 ± 0.07 57.36 ± 0.27 

BL (depth=3) 88.80 ± 0.18 64.44 ± 0.52 91.13 ± 0.09 57.16 ± 0.48 

Table 2: ECE and NLL on image and text datasets. BL and E-MLP are evaluated at depths 1–3 with matched parameter counts. Top-two per column are blue and red. 

Model MNIST Fashion-MNIST 

ECE NLL ECE NLL E-MLP (depth=1) 0.02 ± 0.00 0.20 ± 0.02 0.08 ± 0.00 0.74 ± 0.01 

BL (depth=1) 0.02 ± 0.00 0.26 ± 0.01 0.05 ± 0.00 0.36 ± 0.01 

E-MLP (depth=2) 0.02 ± 0.00 0.23 ± 0.02 0.09 ± 0.00 0.89 ± 0.03 

BL (depth=2) 0.02 ± 0.00 0.16 ± 0.01 0.07 ± 0.00 0.44 ± 0.01 

E-MLP (depth=3) 0.02 ± 0.00 0.16 ± 0.02 0.09 ± 0.00 0.85 ± 0.04 

BL (depth=3) 0.02 ± 0.00 0.13 ± 0.02 0.07 ± 0.00 0.49 ± 0.02 

Model AG News Yelp 

ECE NLL ECE NLL E-MLP (depth=1) 0.02 ± 0.00 0.40 ± 0.01 0.01 ± 0.00 0.24 ± 0.00 

BL (depth=1) 0.02 ± 0.00 0.31 ± 0.01 0.00 ± 0.00 0.20 ± 0.00 

E-MLP (depth=2) 0.02 ± 0.00 0.42 ± 0.01 0.00 ± 0.00 0.25 ± 0.00 

BL (depth=2) 0.06 ± 0.01 0.43 ± 0.03 0.02 ± 0.00 0.23 ± 0.01 

E-MLP (depth=3) 0.01 ± 0.00 0.41 ± 0.02 0.00 ± 0.00 0.25 ± 0.01 

BL (depth=3) 0.05 ± 0.01 0.39 ± 0.02 0.02 ± 0.00 0.22 ± 0.00 

Table 3: Training time (seconds) of BL vs. E-MLP on high-dimensional datasets (mean ± std). 

Model MNIST FashionMNIST AG News Yelp 

E-MLP (depth=1) 100.59 ± 0.29 73.57 ± 1.20 14.69 ± 0.40 179.37 ± 0.73 

BL (depth=1) 110.63 ± 3.34 96.52 ± 2.90 17.20 ± 0.06 181.07 ± 1.80 

E-MLP (depth=2) 102.64 ± 0.26 78.25 ± 0.28 15.76 ± 0.06 179.22 ± 0.66 

BL (depth=2) 122.85 ± 3.95 114.43 ± 3.72 21.78 ± 0.08 180.38 ± 1.44 

E-MLP (depth=3) 104.52 ± 0.30 85.57 ± 1.19 16.95 ± 0.05 178.99 ± 1.42 

BL (depth=3) 140.17 ± 4.42 130.03 ± 4.96 26.29 ± 0.24 180.36 ± 0.91 

11 International Conference on Learning Representations (ICLR) 2026 using overdamped Langevin dynamics with step size η = 10 −4:

yk+1 = yk + η ∇y BL (x, y k)/τ + p2ητ ξ k, ξk ∼ N (0 , I 64 ).

For each pair (λ, τ ) we run 512 parallel chains, each for 1500 Langevin steps (500 burn-in). We sweep over temperatures τ ∈ { 2.0, 1.0, 0.5, 0.25 , 0.1, 0.05 , 0.02 , 0.01 , 0.005 } at a fixed penalty λ =25 , and over penalty weights λ ∈ { 0, 1, 3, 10 , 30 , 100 , 200 , 500 } at a fixed temperature τ = 0 .05 .For each configuration we record the residual magnitude |T (x, y )| from the final state of every chain. We then report three summary statistics: (i) the mean violation E[|T (x, y )|], (ii) the 95 th percentile of |T (x, y )|, and (iii) the empirical probability of near-feasible samples. We declare a sample to satisfy the constraint approximately if 

|T (x, y )| ≤ εtol with εtol = 10 −1,

and estimate P (|T (x, y )| ≤ εtol ) across chains. This tolerance scale is chosen to be small relative to the typical unconstrained residuals, so that the near-feasible regime corresponds to a practically tight energy-conservation constraint. 

Figure 6: Constraint enforcement test of the BL penalty block on an energy-conservation constraint. The figure reports violation statistics |T (x, y )| when varying the temperature τ (left side of panel) and the penalty weight λ (right side of panel). 

Constraint enforcement. Figure 6 shows that BL achieves near-hard constraint enforcement un-der finite temperature and penalty scaling. Violations decrease substantially as τ decreases or λ

increases. At around λ = 25 and τ = 0 .01 , the 64-dimensional energy-conservation constraint is enforced within 10 −2 error. Curves remain mostly smooth and monotone in 64 dimensions, indicat-ing stable Langevin sampling and effective penalty enforcement. 

# 4 SCIENTIFIC EXPLANATION OF BL(D EEP )

BL(Deep) provides a form of interpretability that is consistent with hierarchical optimization struc-tures. In BL, each layer performs a coarse-graining of the optimization structure implemented by the layer below. An intuitive analogy is a corporate organizational hierarchy: lower-layer managers 12 International Conference on Learning Representations (ICLR) 2026 solve their own local optimization problems, while higher-layer managers aggregate and coordi-nate the outcomes of many such lower-layer problems to achieve broader organizational objectives. BL(Deep) follows the same principle—higher layers summarize, reorganize, and coordinate the so-lutions formed at lower layers. This perspective aligns with many scientific domains characterized by multi-level complexity, in-cluding (i) the formation of representative behavioral agents in behavioral sciences, and (ii) renor-malization in statistical physics, where fine-scale interactions are compressed into effective coarse-scale potentials. We describe the explanation procedure below. To build intuition, let us first consider a generic hier-archical optimization structure—this may refer to a multi-layer organizational structure composed of individual agents, or a multi-scale physical system composed of interacting particles. 

Step 1: Bottom-layer interpretation. 

Each bottom-layer block is an optimization problem that directly receives inputs from the environ-ment. These blocks correspond to micro-level behavioral mechanisms , such as the decision rules of individual agents performing environment-facing tasks in an organization, or the motion laws governing a single particle in statistical physics. Examining these bottom-layer blocks reveals the fundamental optimization principles followed by all units that directly interact with the environment. 

Step 2: Layer-wise coarse-graining and micro-to-macro aggregation. 

Blocks in the next layer aggregate the outputs of lower-layer optimization problems through a new optimization step, producing a coarse-grained behavioral summary . Each higher-level block repre-sents the effective optimization system that emerges from the interactions among many lower-level units, thereby capturing macro-level regularities distilled from micro-level mechanisms. This micro-to-macro transition is consistent with many well-established scientific principles, includ-ing: • (i) Aggregation and coordination : in hierarchical organizations, the outputs of lower-level agents are aggregated, reallocated, and coordinated by higher-level agents to achieve improved organizational objectives. • (ii) Coarse-grained observation : in hierarchical behavioral systems, individual agents are grouped into categories that share characteristic optimization patterns; in statistical physics, many particles collectively form systems whose coarse-grained behavior is governed by effective potentials induced by microscopic interactions. 

Step 3: Bottom-up reconstruction. 

A global explanation is obtained by tracing the hierarchy upward, following the model’s micro-to-macro abstraction path: raw input features → micro-level optimization blocks → macro-level aggregation and coordination or coarse-grained behavioral constructs → macro-level optimization system. At each layer, we inspect the characteristics of each block and its associated optimization objective, as well as how these optimization problems evolve across layers. This reveals how each higher layer aggregates, coordinates, or coarse-grains the outputs of the layer below. Together, these observations yield a compact multi-scale interpretation in which BL is understood as a hierarchical optimization structure. 

# 5 DISCUSSION 

In what follows, we discuss the limitations and future directions of Behavior Learning from the perspectives of theoretical foundations, architecture, and applications. 

Scalability of theoretical assumptions. The identifiability-related statistical theorems constitute the core theoretical pillars of IBL, ensuring uniqueness of the interpretability and supporting its scientific credibility. Although these results hold under mild conditions, their behavior in large-scale, highly over-parameterized architectures remains less well understood. This highlights the need for 13 International Conference on Learning Representations (ICLR) 2026 systematic investigations into the robustness, potential failure modes, and empirical boundaries of these guarantees when applied to modern large-scale learning systems. 

Choice of basis functions. Polynomial basis functions enhance expressivity while preserving symbolic interpretability in BL (Single). However, high-order polynomials may introduce optimiza-tion instability, exacerbate sensitivity to initialization and normalization, and complicate training dynamics. Future work may explore alternative basis families—such as trigonometric, spline-based, or neural basis functions—and develop conditioning or normalization strategies that improve nu-merical stability without sacrificing interpretability. 

Interpretable generative modeling. BL integrates several training techniques from energy-based models while retaining intrinsic interpretability, enabling interpretable generative modeling for vi-sion (e.g., image or video generation) and language (e.g., large language models). Extending BL to explicitly generative architectures in which outputs correspond directly to human-understandable and scientifically meaningful blocks represents a compelling direction. Such extensions could yield generative systems with greater transparency, controllability, and scientific credibility compared to traditional black-box models. 

Hybrid architectures for partial interpretability. A promising direction for future work is to develop hybrid architectures that integrate BL with black-box models in a principled way to achieve partial interpretability. Three avenues are particularly worth exploring: (i) Feature-level integra-tion. Black-box neural networks can serve as high-capacity feature extractors, while BL operates on the resulting learned representations to impose structured, optimization-based semantics. (ii) Decision-critical integration. BL blocks may be inserted specifically at high-risk or decision-critical components of the model, substantially reducing the interpretability and reliability risks associated with purely black-box architectures. (iii) Mechanism-level integration. Because BL provides an optimization-driven inductive bias aligned with many real-world mechanisms, selectively applying BL to the parts of the system where such inductive bias is essential may yield models that better cap-ture the underlying ground-truth processes while retaining the flexibility of deep networks, thereby improving generalization performance. 

BL for scientific and social-scientific modeling. BL represents data as a composition of opti-mization problems, closely resonating with modeling paradigms in the natural and social sciences. Its competitive performance, intrinsic interpretability, and statistical rigor position BL as a promis-ing framework for scientific machine learning. Future research may apply BL to domains such as statistical physics, evolutionary biology, computational neuroscience, and climate dynamics, as well as behavioral science, economics, sociology, and political science—particularly in settings involving complex, partially formalized, or cognitively meaningful structures. 

# 6 RELATED WORK 

6.1 INTERPRETABILITY 

Interpretability has become increasingly vital in machine learning (Lipton, 2018; Molnar, 2020), especially for scientific domains (Doshi-Velez & Kim, 2017; Roscher et al., 2020). Ensuring inter-pretability fosters transparency and reproducibility, and may further provide insights into underly-ing scientific principles. The ideal form of interpretability is intrinsic interpretability , in which a model’s structure or parameters are directly understandable to humans. However, intrinsic inter-pretability is challenging to achieve in some widely used high-capacity models such as deep neural networks (LeCun et al., 2015). This has motivated post-hoc interpretability methods (Ribeiro et al., 2016; Lundberg & Lee, 2017), which seek to explain a pre-trained black-box model. While more broadly applicable, such explanations are often considered less suitable for scientific research (Rudin, 2019), as they may compromise stability and faithfulness to the model’s decision process. 

Performance–Interpretability Trade-off. The limited intrinsic interpretability observed in high-capacity models has long been recognized as a central challenge. This is commonly framed as the performance–interpretability trade-off (Rudin, 2019; Arrieta et al., 2020), which posits a ten-sion between predictive performance and intrinsic interpretability. High-performing models such 14 International Conference on Learning Representations (ICLR) 2026 as deep neural networks often lack transparency, whereas intrinsically interpretable models strug-gle to capture complex nonlinear patterns. Several efforts have sought to mitigate the perfor-mance–interpretability trade-off, which can be broadly categorized into four groups. (i) Additive models. Classical GAMs (Hastie, 2017), modern GA2Ms/EBMs (Caruana et al., 2015; Nori et al., 2019), and neural variants such as NAM (Agarwal et al., 2021) and NODE-GAM (Chang et al., 2021) preserve interpretability by decomposing predictions into main effects and low-order interac-tions. (ii) Concept-based models. Concept Bottleneck Models (Koh et al., 2020), TCAV (Kim et al., 2018), and SENN (Alvarez Melis & Jaakkola, 2018) map inputs into human-interpretable latent concepts and use them as intermediate predictors. (iii) Rule- and score-based systems. SLIM (Us-tun & Rudin, 2016) and CORELS (Angelino et al., 2018) generate transparent scoring functions or rule lists with provable optimality guarantees. (iv) Shape-constrained networks. Deep Lattice Net-works (You et al., 2017) and related monotonic architectures impose monotonicity and calibration constraints to encode domain priors while retaining flexibility. 

Limitations in Scientifically Credible Modeling. The above approaches demonstrate strengths, yet two fundamental limitations restrict their applicability in scientific research. First, most methods are tool-centric modifications of machine learning architectures rather than frameworks grounded in scientific theory (e.g., optimization, dynamical systems, conservation laws). As recent surveys emphasize (Roscher et al., 2020; Karniadakis et al., 2021; Allen et al., 2023; Bereska & Gavves, 2024; Longo et al., 2024; Mersha et al., 2024), genuine scientific insight requires models linked to mechanistic principles, yet many interpretability techniques remain detached from such principles. Second, these approaches are typically non-identifiable (Ran & Hu, 2017; M´ eloux et al., 2025), meaning that multiple distinct parameterizations can explain the same data. This lack of unique-ness undermines their reliability for recovering ground-truth mechanisms and, in statistical terms, complicates consistency guarantees. As a result, the trained model may fail to converge to the true data-generating process as sample size increases (Newey & McFadden, 1994; Van der Vaart, 2000). 

Relation to BL. BL also mitigates the performance–interpretability trade-off. Unlike prior meth-ods, it is principle-driven and scientifically grounded, learning interpretable latent optimization structures directly from data. The framework applies broadly to domains where outcomes arise as solutions to (explicit or latent) optimization problems. It is also identifiable: its smooth and mono-tone variant, Identifiable Behavior Learning (IBL), guarantees identifiability under mild conditions, ensuring the scientific credibility of its explanations and supporting recovery of the ground-truth model under appropriate conditions. 6.2 DATA -D RIVEN INVERSE OPTIMIZATION 

Inverse optimization (IO) (Ahuja & Orlin, 2001; Chan et al., 2025) is a core paradigm for learning latent optimization problems from observed data. Traditional IO aims to construct objectives or constraints that exactly rationalize a small set of deterministic decisions. In contrast, data-driven IO (Keshavarz et al., 2011; Aswani et al., 2018) focuses on statistically recovering the underly-ing problem from large-scale, noisy observational data. Inverse optimal control (IOC) (Kalman, 1964; Freeman & Kokotovic, 1996) extends this paradigm to dynamic settings, seeking to infer sequential decision processes from expert trajectories. Within machine learning , inverse reinforce-ment learning (IRL) (Ng et al., 2000; Wulfmeier et al., 2015) and inverse constrained reinforcement learning (ICRL) (Malik et al., 2021; Liu et al., 2024a) are prominent instances of data-driven IOC: Typically, IRL assumes fixed constraints and learns a reward function, whereas ICRL reverses this role. Both require repeatedly solving for (near-)optimal policies and matching with expert demon-strations—incurring high computational cost. In the behavioral sciences , particularly economics, numerous studies can be viewed as instances of the data-driven IO paradigm. Foundational work (McFadden, 1972; Dubin & McFadden, 1984; Hanemann, 1984; Berry et al., 1993) and related stud-ies typically posits theoretically grounded, parametric utility maximization problems (UMPs) and estimates their structural parameters from observed behavior. 

Relation to BL. The BL framework also falls under the paradigm of data-driven inverse optimiza-tion but differs notably from prior related work in both machine learning and behavioral science. Compared with IRL and ICRL, BL does not rely on matching expert-demonstrated policies with the aim of improving task-specific performance. Instead, it is proposed as a general-purpose, scien-tifically grounded, and intrinsically interpretable framework that operates via low-cost end-to-end 15 International Conference on Learning Representations (ICLR) 2026 training with a hybrid CE–DSM objective. It jointly learns a utility functions and constraints—a direction that has received little attention in IRL and ICRL (Park et al., 2020; Jang et al., 2023; Liu & Zhu, 2024). Meanwhile, in behavioral science, related work typically formulates distinct utility maximization models under varying assumptions for specific decision contexts, and estimate their parameters accordingly. However, to the best of our knowledge, no existing work proposes a structure-free framework for learning UMPs that generalizes across contexts. BL fills this gap with a structure-free, data-driven approach that does not rely on fixed UMP structures. 6.3 ENERGY -BASED MODELS (EBM S)Energy-based models (EBMs) (LeCun et al., 2006) are a prominent data-driven IO scheme, rooted in the principle of energy minimization from statistical physics. They learn an energy function 

Eθ (x, y ) that parameterizes the compatibility between inputs and outputs, inducing a Gibbs distri-bution pθ (y | x) ∝ exp {− Eθ (x, y )} that favors outcomes corresponding to low-energy solutions. In practice, this energy function is almost always instantiated by high-capacity neural networks, en-dowing the learned landscape with strong expressive power but also a black-box nature. Training EBMs typically relies on objectives that circumvent the intractable partition function, with classi-cal approaches including contrastive divergence (Hinton, 2002), persistent contrastive divergence (Tieleman, 2008), and noise-contrastive estimation (Gutmann & Hyv¨ arinen, 2010). A particularly influential line of work is score matching (Hyv¨ arinen & Dayan, 2005) and its denoising variant (DSM) (Vincent, 2011), which have underpinned breakthroughs in score-based generative modeling (Song & Ermon, 2019; 2020) and laid the foundation for modern diffusion methods (Song et al., 2020). 

Relation to BL. BL and EBMs exhibit a principled correspondence: BL is grounded in behav-ioral science and rooted in utility maximization, while EBMs are grounded in statistical physics and based on energy minimization. BL adopts several training techniques common to EBMs, such as Gibbs distribution modeling and denoising score matching (DSM). However, the two frameworks differ substantially in model structure. EBMs primarily focus on generative quality and typically employ black-box neural networks to learn an opaque energy function with little regard for inter-pretability. In contrast, BL is built on the utility maximization problem (UMP) and its equivalence to penalty formulations, yielding a principled and scientifically grounded framework. Its architecture is composed of intrinsically interpretable blocks, each of which can be explicitly expressed in sym-bolic form as a UMP—a foundational paradigm in behavioral science and a universal optimization framework. These properties enable BL to jointly achieve high predictive performance, intrinsic interpretability, and identifiability, thereby supporting scientifically credible modeling that extends beyond mere generative capability. 

# 7 ACKNOWLEDGEMENTS 

We would like to thank Prof. Dr. Philipp Hennig, Shu Liu, and Prof. Dr. Sen Geng for their helpful discussions and valuable suggestions. We are also grateful to participants of the Xi’an Jiaotong University seminar for their constructive feedback. We acknowledge the public computational resources provided by the University of T¨ ubingen. Finally, we sincerely thank all anonymous reviewers for their insightful comments. In particular, we appreciate Reviewer sGAR for the highly constructive advice. The energy conservation constraint experiment was added following a suggestion from Reviewer sGAR. If any errors remain, they are solely our responsibility. 16 International Conference on Learning Representations (ICLR) 2026 

# REFERENCES 

Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana, and Geoffrey E Hinton. Neural additive models: Interpretable machine learning with neural nets. arXiv preprint arXiv:2004.13912 , 2020. Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich, Rich Caruana, and Geoffrey E Hinton. Neural additive models: Interpretable machine learning with neural nets. 

Advances in neural information processing systems , 34:4699–4711, 2021. Ravindra K Ahuja and James B Orlin. Inverse optimization. Operations research , 49(5):771–783, 2001. Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: A next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining , pp. 2623–2631, 2019. Genevera I Allen, Luqin Gan, and Lili Zheng. Interpretable machine learning for discovery: Statis-tical challenges and opportunities. Annual Review of Statistics and Its Application , 11, 2023. David Alvarez Melis and Tommi Jaakkola. Towards robust interpretability with self-explaining neural networks. Advances in neural information processing systems , 31, 2018. Philip W Anderson. More is different: broken symmetry and the nature of the hierarchical structure of science. Science , 177(4047):393–396, 1972. Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin. Learning certifiably optimal rule lists for categorical data. Journal of Machine Learning Research , 18(234): 1–78, 2018. Sercan ¨ O Arik and Tomas Pfister. Tabnet: Attentive interpretable tabular learning. In Proceedings of the AAAI conference on artificial intelligence , volume 35, pp. 6679–6687, 2021. Alejandro Barredo Arrieta, Natalia D´ ıaz-Rodr´ ıguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc´ ıa, Sergio Gil-L´ opez, Daniel Molina, Richard Benjamins, et al. Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges to-ward responsible ai. Information fusion , 58:82–115, 2020. W Brian Arthur. Complexity and the economy. In Handbook of Research on Complexity . Edward Elgar Publishing, 2009. Anil Aswani, Zuo-Jun Shen, and Auyon Siddiq. Inverse optimization with noisy data. Operations Research , 66(3):870–892, 2018. Santiago R Balseiro, Omar Besbes, and Gabriel Y Weintraub. Dynamic mechanism design with budget-constrained buyers under limited commitment. Operations Research , 67(3):711–730, 2019. Patrick Bayer, Fernando Ferreira, and Robert McMillan. A unified framework for measuring pref-erences for schools and neighborhoods. Journal of political economy , 115(4):588–638, 2007. Leonard Bereska and Efstratios Gavves. Mechanistic interpretability for ai safety–a review. arXiv preprint arXiv:2404.14082 , 2024. Steven T Berry, James A Levinsohn, and Ariel Pakes. Automobile prices in market equilibrium: Part i and ii, 1993. Sandra E Black. Do better schools matter? parental valuation of elementary education. The quarterly journal of economics , 114(2):577–599, 1999. Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. Intel-ligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In 

Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining , pp. 1721–1730, 2015. 17 International Conference on Learning Representations (ICLR) 2026 Timothy CY Chan, Rafid Mahmood, and Ian Yihang Zhu. Inverse optimization: Theory and appli-cations. Operations Research , 73(2):1046–1074, 2025. Chun-Hao Chang, Rich Caruana, and Anna Goldenberg. Node-gam: Neural generalized additive model for interpretable deep learning. arXiv preprint arXiv:2106.01613 , 2021. Kenneth Y Chay and Michael Greenstone. Does air quality matter? evidence from the housing market. Journal of political Economy , 113(2):376–424, 2005. Gerard Debreu. Theory of value: An axiomatic analysis of economic equilibrium , volume 17. Yale University Press, 1959. Finale Doshi-Velez and Been Kim. Towards a rigorous science of interpretable machine learning. 

arXiv preprint arXiv:1702.08608 , 2017. Jeffrey A Dubin and Daniel L McFadden. An econometric analysis of residential electric appliance holdings and consumption. Econometrica: Journal of the Econometric Society , pp. 345–362, 1984. Ronald Aylmer Fisher. The genetical theory of natural selection: a complete variorum edition .Oxford University Press, 1999. Randy A Freeman and Petar V Kokotovic. Inverse optimality in robust stabilization. SIAM journal on control and optimization , 34(4):1365–1391, 1996. Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson. Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances in Neural Information Processing Systems , 2018. Stephen Gibbons and Stephen Machin. Valuing rail access using transport innovations. Journal of urban Economics , 57(1):148–169, 2005. Josiah Willard Gibbs. Elementary principles in statistical mechanics: developed with especial ref-erence to the rational foundations of thermodynamics . C. Scribner’s sons, 1902. Edward L Glaeser and Joseph Gyourko. The impact of building restrictions on housing affordability. 

Federal Reserve Bank of New York, Economic Policy Review , 2002:1–19, 2002. Michael Gutmann and Aapo Hyv¨ arinen. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the thirteenth international conference on artificial intelligence and statistics , pp. 297–304. JMLR Workshop and Conference Proceedings, 2010. S-P Han and Olvi L Mangasarian. Exact penalty functions in nonlinear programming. Mathematical programming , 17(1):251–269, 1979. W Michael Hanemann. Discrete/continuous models of consumer demand. Econometrica: Journal of the Econometric Society , pp. 541–561, 1984. Trevor J Hastie. Generalized additive models. Statistical models in S , pp. 249–307, 2017. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-nition. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 770–778, 2016. Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural computation , 14(8):1771–1800, 2002. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 4700–4708, 2017. Aapo Hyv¨ arinen and Peter Dayan. Estimation of non-normalized statistical models by score match-ing. Journal of Machine Learning Research , 6(4), 2005. 18 International Conference on Learning Representations (ICLR) 2026 Jaehwi Jang, Minjae Song, and Daehyung Park. Inverse constraint learning and generalization by transferable reward decomposition. IEEE Robotics and Automation Letters , 9(1):279–286, 2023. William Jevons. The theory of political economy . Springer, 2013. Leo P Kadanoff. Scaling laws for ising models near t c. Physics Physique Fizika , 2(6):263, 1966. Rudolf Emil Kalman. When is a linear control system optimal? 1964. George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang. Physics-informed machine learning. Nature Reviews Physics , 3(6):422–440, 2021. Amr Kayid, Nicholas Frosst, and Geoffrey E Hinton. Neural additive models library, 2020. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems , 30, 2017. Arezou Keshavarz, Yang Wang, and Stephen Boyd. Imputing a convex objective function. In 2011 IEEE international symposium on intelligent control , pp. 613–619. IEEE, 2011. Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et al. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In International conference on machine learning , pp. 2668–2677. PMLR, 2018. Diederik P Kingma. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 ,2014. Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and Percy Liang. Concept bottleneck models. In International conference on machine learning , pp. 5338–5348. PMLR, 2020. Mathias Kraus, Daniel Tschernutter, Sven Weinzierl, and Patrick Zschech. Interpretable generalized additive neural networks. European Journal of Operational Research , 317(2):303–316, 2024. Solomon Kullback and Richard A Leibler. On information and sufficiency. The annals of mathe-matical statistics , 22(1):79–86, 1951. Lev Davidovich Landau and Evgenii Mikhailovich Lifshitz. Statistical Physics: Volume 5 , volume 5. Elsevier, 2013. Yann LeCun, L´ eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE , 86(11):2278–2324, 2002. Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, Fujie Huang, et al. A tutorial on energy-based learning. Predicting structured data , 1(0), 2006. Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature , 521(7553):436–444, 2015. Zachary C Lipton. The mythos of model interpretability: In machine learning, the concept of inter-pretability is both important and slippery. Queue , 16(3):31–57, 2018. Guiliang Liu, Sheng Xu, Shicheng Liu, Ashish Gaurav, Sriram Ganapathi Subramanian, and Pascal Poupart. A comprehensive survey on inverse constrained reinforcement learning: Definitions, progress and challenges. arXiv preprint arXiv:2409.07569 , 2024a. Shicheng Liu and Minghui Zhu. Meta inverse constrained reinforcement learning: Convergence guarantee and generalization analysis. International Conference on Learning Representations, 2024. Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljaˇ ci´ c, Thomas Y Hou, and Max Tegmark. Kan: Kolmogorov-arnold networks. arXiv preprint arXiv:2404.19756 , 2024b. 19 International Conference on Learning Representations (ICLR) 2026 Lars Ljungqvist and Thomas J Sargent. Recursive macroeconomic theory . MIT press, 2018. Luca Longo, Mario Brcic, Federico Cabitza, Jaesik Choi, Roberto Confalonieri, Javier Del Ser, Riccardo Guidotti, Yoichi Hayashi, Francisco Herrera, Andreas Holzinger, et al. Explainable artificial intelligence (xai) 2.0: A manifesto of open challenges and interdisciplinary research directions. Information Fusion , 106:102301, 2024. Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 , 2017. Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems , 30, 2017. Shehryar Malik, Usman Anwar, Alireza Aghasi, and Ali Ahmed. Inverse constrained reinforcement learning. In International conference on machine learning , pp. 7390–7399. PMLR, 2021. Andreu Mas-Colell, Michael Dennis Whinston, Jerry R Green, et al. Microeconomic theory , vol-ume 1. Oxford university press New York, 1995. Daniel McFadden. Conditional logit analysis of qualitative choice behavior. 1972. Daniel McFadden. Modelling the choice of residential location. 1977. Maxime M´ eloux, Silviu Maniu, Franc ¸ois Portet, and Maxime Peyrard. Everything, everywhere, all at once: Is mechanistic interpretability identifiable? arXiv preprint arXiv:2502.20914 , 2025. Melkamu Mersha, Khang Lam, Joseph Wood, Ali K Alshami, and Jugal Kalita. Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction. Neurocomputing ,599:128111, 2024. Melanie Mitchell. Complexity: A guided tour . Oxford university press, 2009. Christoph Molnar. Interpretable machine learning . Lulu. com, 2020. Whitney K Newey and Daniel McFadden. Large sample estimation and hypothesis testing. Hand-book of econometrics , 4:2111–2245, 1994. Andrew Y Ng, Stuart Russell, et al. Algorithms for inverse reinforcement learning. In Icml , vol-ume 1, pp. 2, 2000. Harsha Nori, Samuel Jenkins, Paul Koch, and Rich Caruana. Interpretml: A unified framework for machine learning interpretability. arXiv preprint arXiv:1909.09223 , 2019. Daehyung Park, Michael Noseworthy, Rohan Paul, Subhro Roy, and Nicholas Roy. Inferring task goals and constraints using bayesian nonparametric inverse reinforcement learning. In Conference on robot learning , pp. 1005–1014. PMLR, 2020. Ori Plonsky, Reut Apel, Eyal Ert, Moshe Tennenholtz, David Bourgin, Joshua C Peterson, Daniel Reichman, Thomas L Griffiths, Stuart J Russell, Even C Carter, et al. Predicting human decisions with behavioural theories and machine learning. Nature Human Behaviour , pp. 1–14, 2025. Karl Popper. The logic of scientific discovery . Routledge, 2005. Frank Plumpton Ramsey. A mathematical theory of saving. The economic journal , 38(152):543– 559, 1928. Zhi-Yong Ran and Bao-Gang Hu. Parameter identifiability in statistical machine learning: a review. 

Neural Computation , 29(5):1151–1203, 2017. Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ” why should i trust you?” explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining , pp. 1135–1144, 2016. Ribana Roscher, Bastian Bohn, Marco F Duarte, and Jochen Garcke. Explainable machine learning for scientific insights and discoveries. Ieee Access , 8:42200–42216, 2020. 20 International Conference on Learning Representations (ICLR) 2026 Sherwin Rosen. Hedonic prices and implicit markets: product differentiation in pure competition. 

Journal of political economy , 82(1):34–55, 1974. Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature machine intelligence , 1(5):206–215, 2019. Paul Anthony Samuelson. Foundations of economic analysis. Science and Society , 13(1), 1948. Herbert A Simon. A behavioral model of rational choice. The quarterly journal of economics , pp. 99–118, 1955. Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. 

Advances in neural information processing systems , 32, 2019. Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. 

Advances in neural information processing systems , 33:12438–12448, 2020. Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 , 2020. Tijmen Tieleman. Training restricted boltzmann machines using approximations to the likelihood gradient. In Proceedings of the 25th international conference on Machine learning , pp. 1064– 1071, 2008. Berk Ustun and Cynthia Rudin. Supersparse linear integer models for optimized medical scoring systems. Machine Learning , 102(3):349–391, 2016. Aad W Van der Vaart. Asymptotic statistics , volume 3. Cambridge university press, 2000. Pascal Vincent. A connection between score matching and denoising autoencoders. Neural compu-tation , 23(7):1661–1674, 2011. Sewall Wright et al. The roles of mutation, inbreeding, crossbreeding, and selection in evolution. 1932. Markus Wulfmeier, Peter Ondruska, and Ingmar Posner. Maximum entropy deep inverse reinforce-ment learning. arXiv preprint arXiv:1507.04888 , 2015. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms. arXiv preprint arXiv:1708.07747 , 2017. Ge Yang and Samuel Schoenholz. Mean field residual networks: On the edge of chaos. Advances in neural information processing systems , 30, 2017. Seungil You, David Ding, Kevin Canini, Jan Pfeifer, and Maya Gupta. Deep lattice networks and partial monotonic functions. Advances in neural information processing systems , 30, 2017. Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text clas-sification. Advances in neural information processing systems , 28, 2015. 21 International Conference on Learning Representations (ICLR) 2026 

# A ARCHITECTURE DETAILS 

A.1 LEARNING SCHEME DETAILS 

Input and output of the BL function. We formulate BL as a direct mapping from input–output pairs to compositional utility representations: 

BL : X × Y → Rdout , (x, y ) 7 → BL( x, y ) ∈ Rdout ,

where the output dimension dout is chosen according to the modeling choice. This formulation intentionally allows BL to return either a scalar or a vector for each (x, y ); the following cases are most common: • Scalar per candidate (pointwise evaluation). Set dout = 1 . Here BL( x, y ) ∈ R is a scalar compositional utility evaluated for the single candidate y. This view is natural for continuous y

(regression or density estimation) or when one prefers to evaluate candidates individually. • Vectorized over a finite candidate set. If Y = {y1, . . . , y m} is finite, one can choose dout = m

and define the vector-valued output by stacking evaluations over the candidate set: BL (x) := 



BL( x, y 1)

...

BL( x, y m)

 ∈ Rm.

This vectorized form is convenient for classification: it evaluates all class candidates at once and yields a single compositional utility vector per x.• Flexibility and equivalence. The scalar and vector modes are compatible: the vectorized form is simply a batch of pointwise evaluations. Conversely, a scalar pointwise evaluator can be used to assemble a vector by repeated calls over a candidate set. The choice between pointwise (scalar) and vectorized outputs is therefore an engineering choice that trades off computational efficiency and convenience. Given a dataset D = {(xi, y i)}ni=1 , training and inference may use either mode: vectorized compu-tation where feasible (e.g., small finite Y), or pointwise evaluation when Y is large or continuous. 

Conditional Gibbs model. Let (x, y ) ∼ D with x ∈ Rd and y = ( ydisc , y cont ) ∈ Y disc × Rmc

(discrete, continuous, or hybrid). BL induces a conditional Gibbs distribution with temperature 

τ > 0:

pτ (y | x) = exp {BL( x, y )/τ }

Zτ (x) , Zτ (x) = 

Z

> Y

exp {BL( x, y ′)/τ } dy ′.

For discrete Y = {y1, . . . , y m}, if we choose the vector-output formulation, we define 

BL( x) := BL( x, y 1), . . . , BL( x, y m) ∈ Rm,

so that the conditional distribution reduces to a softmax over this compositional utility vector: 

pτ (y = k | x) = softmax k

  1 

> τ

BL( x) .

Behaviorally, τ encodes noisy rationality ; as τ → 0, pτ (· | x) concentrates on arg max y BL( x, y ),corresponding to the deterministic optimal choice implied by the learned model. 

Supervised, unsupervised, and generative uses. BL accommodates multiple regimes. (i) Su-pervised: take x as input and y as label. For discrete y, one may either (a) adopt the vector-output formulation, where BL( x) ∈ Rm yields a compositional utility vector over all classes and the likelihood is given by a softmax, or (b) adopt the scalar-output formulation, where BL( x, y )

is evaluated separately for each candidate and then normalized across classes. For continuous y,BL naturally operates in the scalar-output mode, treating BL( x, y ) ∈ R as a compositional utility field. (ii) Unsupervised / generative: model a marginal p(y) ∝ exp {BL( y)/τ } (empty x) or a joint 

p(x, y ) ∝ exp {BL( x, y )/τ }; sampling the Gibbs distribution yields a generator. 22 International Conference on Learning Representations (ICLR) 2026 

Learning objective. Since the response y may contain both discrete and continuous components, we estimate θ by minimizing a type-specific risk: 

L(θ) = γd E− log pτ (ydisc | x) + γc E ∇˜ycont log pτ (˜ ycont | x) + σ−2(˜ ycont − ycont ) 2

,

where the first term is cross-entropy on the discrete component and the second is denoising score matching (DSM) on the continuous component with ˜ycont = ycont + ε, ε ∼ N (0 , σ 2I). Set 

(γd, γ c) = (1 , 0) for purely discrete outputs, (0 , 1) for purely continuous outputs, and (> 0, > 0) 

for hybrids. A.2 MODEL STRUCTURE DETAILS 

In the main text we adopted a compact notation for BL; here we present an equivalent, more explicit matrix/vector formulation that makes dimensions, linear maps, and the per-head parameterizations explicit, which is useful for formal proofs and for implementation details. 

Fixed bases and head pre-activations. For a block input z (specified below), let 

mu(z) ∈ Rdu , mc(z) ∈ Rdc , mt(z) ∈ Rdt

denote fixed basis (e.g., monomial) vectors. Learnable linear maps produce head pre-activations: 

u(z) := Mu mu(z) + bu ∈ Rru , c(z) := Mc mc(z) + bc ∈ Rrc , t(z) := Mt mt(z) + bt ∈ Rrt ,

with Mu ∈ Rru×du , Mc ∈ Rrc×dc , Mt ∈ Rrt×dt and optional biases b•.

Single BL block. A single modular block is 

B(z) = λ⊤ 

> 0

ϕ u(z) − λ⊤ 

> 1

ρ c(z) − λ⊤ 

> 2

ψ t(z), (12) where λ0 ∈ Rru , λ1 ∈ Rrc , λ2 ∈ Rrt are learnable weights, and ϕ, ρ, ψ act coordinatewise with the roles specified in Theorem 2.1 (increasing ϕ for utility, penalty ρ for inequality violations, symmetric 

ψ for equalities). Identifying 

UθU (x, y ) = u z = ( x, y ), CθC (x, y ) = c z = ( x, y ), TθT (x, y ) = t z = ( x, y ),

substituting into equation 12 recovers the main-text parameterization in equation 4. 

Layer of parallel blocks. A layer Bℓ stacks dℓ parallel copies of equation 12 with (possibly) distinct parameters θℓ,i :

Bℓ(zℓ) := 



Bθℓ, 1 (zℓ)

...

Bθℓ,d ℓ (zℓ)

 ∈ Rdℓ .

We adopt the standard layered (feedforward) form: 

z1 := ( x, y ), zℓ+1 := Bℓ(zℓ) (ℓ = 1 , . . . , L − 1) ,

so that each layer’s input is simply the previous layer’s output. This is the canonical feedforward architecture. Optionally, one may allow each layer to explicitly access the original inputs: 

z1 := ( x, y ), zℓ+1 := Bℓ

 (x, y ), z ℓ

.

To improve trainability one may also use residual connections: 

zℓ+1 := zℓ + Bℓ(zℓ).

Shallow/Deep composition and final affine readout. For depth L ≥ 1, the BL compositional utility is produced by a final learnable affine transformation of the top layer: 

BL( x, y ) = WL BL

 zL

 + bL, (13) with WL ∈ R1×dL for scalar output or WL ∈ Rm×dL for vector output, and bias bL of matching dimension. The cases L = 1 (with d1 = 1 ), L ≤ 2, and L > 2 correspond to BL(Single), BL(Shallow), and BL(Deep), respectively, exactly as described in the main text. 23 International Conference on Learning Representations (ICLR) 2026 A.3 IMPLEMENTATION DETAILS 

A.3.1 FUNCTION INSTANTIATION 

Default instantiation. In practice, we instantiate equation 4 with the specific choice (ϕ, ρ, ψ ) = (tanh , ReLU , | · | ):

B(x, y ; θ) = λ⊤ 

> 0

tanh  UθU (x, y ) − λ⊤ 

> 1

ReLU  CθC (x, y ) − λ⊤ 

> 2

TθT (x, y ) . (14) Here λ0, λ 1, λ 2 are learnable nonnegative weights. The bounded tanh captures saturation effects and diminishing returns in the utility head (Jevons, 2013), while ReLU and | · | impose asymmetric (one-sided) and symmetric (two-sided) penalties for inequality and equality violations. 

Variants and simplifications. Several variants of equation 14 are often useful: • Identity utility head. Set ϕ = id so the utility head uses raw polynomials: 

B = λ⊤ 

> 0

UθU − λ⊤ 

> 1

ReLU( CθC ) − λ⊤ 

> 2

|T θT |.

• Smooth penalty alternatives. Replace ReLU with softplus to yield smooth inequality penalties, or replace | · | with Huber or squared penalties to modulate sensitivity near zero for equality terms. • Dropping heads. The framework is modular, so one may omit heads depending on the task: 

– No T head: ignores symmetric deviations, yielding a constrained maximization with only inequality penalties. 

– No C head: if the T head is retained, the model reduces to a maximization problem with only equality constraints; if T is also removed, it becomes a fully unconstrained maximization. 

– No U head: produces a pure (soft-)constraint model focusing on feasibility. Strikingly, removing both U and T leaves only piecewise-linear ReLU penalties; when fol-lowed by a final affine readout, the resulting architecture becomes highly similar to a standard MLP—suggesting that MLPs may be viewed as a closely related special instance within the broader BL framework. A.3.2 POLYNOMIAL FEATURE MAPS AND LINEAR REDUCTIONS 

We adopt a pragmatic default: use low-degree polynomial maps for single-block models to maxi-mize interpretability, and use affine (degree-1) maps inside blocks for shallow/deep stacks to control parameter growth and compute. Below we state the instantiations and give the final block formulas used in experiments. 

BL(Single) — polynomial instantiation. Let mD (x, y ) denote a fixed basis of monomials up to total degree D (e.g. D ≤ 2): 

mD (x, y ) = x, y, vec( xx ⊤), vec( xy ⊤), vec( yy ⊤), . . . ⊤.

Parameterize each map as a linear map on this basis: 

UθU (x, y ) = MU mD (x, y )+ bU , CθC (x, y ) = MC mD (x, y )+ bC , TθT (x, y ) = MT mD (x, y )+ bT ,

with learnable matrices M• and biases b•. The block becomes 

B(x, y ; θ) = λ⊤ 

> 0

ϕ(MU mD + bU ) − λ⊤ 

> 1

ρ(MC mD + bC ) − λ⊤ 

> 2

ψ(MT mD + bT ).

BL (Shallow/Deep) — linear-by-layer instantiation. For stacked architectures (Shallow/Deep) we use affine maps inside each block to keep per-layer complexity low: 

UθU (x, y ) = AU [x; y] + bU , CθC (x, y ) = AC [x; y] + bC , TθT (x, y ) = AT [x; y] + bT ,

with learnable A• and b•. The corresponding block is 

B(x, y ; θ) = λ⊤ 

> 0

ϕ(AU [x; y] + bU ) − λ⊤ 

> 1

ρ(AC [x; y] + bC ) − λ⊤ 

> 2

ψ(AT [x; y] + bT ).

24 International Conference on Learning Representations (ICLR) 2026 

On-demand higher-order terms. If diagnostics or domain knowledge indicate underfitting, we optionally augment the affine maps with selected higher-order terms or interactions. Concretely, this is done by appending a small set of monomials (e.g. xiyj , x2 

> i

, y2

> k

) to the input vector [x; y]

and re-estimating the same affine maps A•. This targeted augmentation preserves the base affine parameterization, increases expressivity only where required, and keeps both computational and statistical costs modest while retaining interpretability. 

Figure 7: Visualization of polynomial feature maps as computation graphs, where nodes represent variables or outputs and edges represent their effects. The left panel illustrates the linear form 

F = ax + b, in which the single edge x → F directly encodes the marginal effect of x on F. The middle panel shows the quadratic form F = ax 2 + bx + c, where x not only has a direct edge x → F 

but also acts on its own edge (“ x → F ”), thereby modifying the strength of its self-effect through a higher-order contribution. The right panel depicts the interaction form F = ax + by + cxy + d,where y has an edge y → F and, in addition, x acts on this edge (“ y → F ”), thereby modulating the strength of y’s contribution to F. Symmetrically, y may act on the edge (“ x → F ”), so that each variable can reshape the other’s effect through the interaction term. A.3.3 SKIP CONNECTIONS 

Skip connections are optional in our implementation. When beneficial, we often consider two pat-terns tailored to BL: a DenseNet-style (concatenative) variant and a ResNet-style (additive) variant. 

Dense skip connections (DenseNet-style, concatenation). This variant feeds each layer with the concatenation of all preceding representations, mirroring DenseNet (Huang et al., 2017). Let 

z1 := [ x; y ], s1 := B1(z1) ∈ Rd1 .

For ℓ ≥ 2,

zℓ := [ x; y; s1; . . . ; sℓ−1 ], sℓ := Bℓ(zℓ) ∈ Rdℓ .

The final compositional utility is read out as 

BL( x, y ) = WL sL + bL.

Pros. By exposing all earlier block outputs explicitly as inputs to later blocks, dense skips preserve a transparent feature trail: one can trace which intermediate B-block outputs enter downstream computations and the final affine readout. This often improves feature reuse and yields favorable interpretability at the block level. 

Residual skip connections (ResNet-style, addition). This variant adds an identity (or projected) shortcut to each layer, as in ResNet (He et al., 2016). Define 

z1 := [ x; y ], s1 := B1(z1) ∈ Rd1 ,

and for ℓ ≥ 2,

sℓ := Bℓ(sℓ−1) + Π ℓ sℓ−1, Πℓ ∈ Rdℓ×dℓ−1 ,

where Πℓ is the identity if dℓ = dℓ−1, or a bias-free learnable projection otherwise. The readout is again 

BL( x, y ) = WL sL + bL.

25 International Conference on Learning Representations (ICLR) 2026 

Skip Connections and Interpretability. Skip connections introduce explicit cross-layer depen-dency structures, a form widely studied in statistical physics and other scientific domains. Such structures enhance scientific interpretability by making long-range influences transparent. In behav-ioral and organizational sciences, they capture situations in which lower-level agents directly affect higher-level decision makers without routing through intermediate layers. In physics, microscopic parameters can exert direct effects on macroscopic behaviors across multiple scales. Architecturally, ResNet-style skip connections model linear cross-layer dependencies, whereas DenseNet-style con-nections realize concatenative (information-replicating) dependencies. These mechanisms provide flexible yet interpretable pathways for representing hierarchical interactions. 

# B PROOFS OF THEOREMS 

B.1 UTILITY MAXIMIZATION PROBLEM (UMP) 

Theorem 2.1 (Local Exact Penalty Reformulation for UMP). 

Let X ⊂ Rdx and Y ⊂ Rdy be nonempty compact sets, and let U : X × Y → R, C : X × Y → Rm,and T : X × Y → Rp be C1. Consider the Utility Maximization Problem (UMP) 

max  

> y∈Y

U (x, y) s.t. C(x, y) ≤ 0, T (x, y) = 0 . (15) 

Assume there exists a feasible point y⋆ ∈ int( Y) which is a strict local maximizer of equation 15 and the Han–Mangasarian constraint qualification (2.1) holds at y⋆ (in the notation of Han & Mangasarian (1979)). Let ϕ : R → R be strictly increasing and C1, and define ρ(z) := max {z, 0}

and ψ(z) := |z| (componentwise on Rm and Rp). Then there exist λ0 > 0, λ1 ∈ Rm

> ++

, and 

λ2 ∈ Rp 

> ++

such that y⋆ is a local maximizer of 

max  

> y∈Y

λ0 ϕ U (x, y) − λ⊤ 

> 1

ρ C(x, y) − λ⊤ 

> 2

ψ T (x, y). (16) 

Proof. Fix x ∈ X and abbreviate 

g(y) := C(x, y) ∈ Rm, h(y) := T (x, y) ∈ Rp.

Feasibility of y⋆ means g(y⋆) ≤ 0 componentwise and h(y⋆) = 0 .

Step 1: Convert to a constrained local minimization problem in the ambient space. Pick any 

λ0 > 0 and define 

f (y) := −λ0 ϕ U (x, y). (17) Since ϕ is strictly increasing, for any y1, y2 we have U (x, y1) > U (x, y2) if and only if f (y1) <f (y2). Hence y⋆ is a strict local maximizer of equation 15 if and only if y⋆ is a strict local minimizer of 

min  

> y∈Y

f (y) s.t. g(y) ≤ 0, h(y) = 0 . (18) Now use the interior-point assumption y⋆ ∈ int( Y): there exists ε0 > 0 such that Bε0 (y⋆) ⊂ Y .Therefore, the notion of strict local minimizer over Y at y⋆ coincides with the ambient-space notion: for any function F , there exists ε ∈ (0 , ε 0] such that 

F (y⋆) < F (y) ∀ y ∈  Y ∩ Bε(y⋆) \ { y⋆}

if and only if 

F (y⋆) < F (y) ∀ y ∈ Bε(y⋆) \ { y⋆}.

Hence y⋆ is a strict local minimizer of the constrained problem equation 18 in the ambient-space sense. Moreover, by assumption, the triple (f, g, h ) is continuously differentiable on a neighborhood of y⋆.

Step 2: Embed vector weights into a norm and build a Han–Mangasarian penalty. Define the positive part g+(y) ∈ Rm componentwise by (g+(y)) i := max {gi(y), 0}. Let λ1 ∈ Rm 

> ++

and 

λ2 ∈ Rp 

> ++

be arbitrary for the moment, and define a norm on Rm+p by the weighted ℓ1-norm 

∥(u, v )∥λ := λ⊤ 

> 1

|u| + λ⊤ 

> 2

|v|, (u, v ) ∈ Rm × Rp, (19) 26 International Conference on Learning Representations (ICLR) 2026 where | · | is componentwise absolute value. Since λ1, λ 2 have strictly positive entries, ∥ · ∥ λ is indeed a norm. Choose the scalar penalty function Q : [0 , ∞) → [0 , ∞) as Q(t) = t. Then Q satisfies the penalty regularity condition (1.3) in Han & Mangasarian (1979), in particular Q′(0+) = 1 > 0. Define for 

α ≥ 0 the penalty function 

P (y, α ) := f (y) + α Q     g+(y), h (y)

> λ

 . (20) Expanding equation 20 using equation 19 and Q(t) = t yields 

P (y, α ) = −λ0 ϕ U (x, y) + α

h

λ⊤ 

> 1

g+(y) + λ⊤ 

> 2

|h(y)|

i

. (21) Since ρ(g(y)) = g+(y) and ψ(h(y)) = |h(y)| componentwise, equation 21 can be rewritten as 

P (y, α ) = −λ0 ϕ U (x, y) + α

h

λ⊤ 

> 1

ρ g(y) + λ⊤ 

> 2

ψ h(y)i

. (22) 

Step 3: Apply Han–Mangasarian Theorem 4.4. By Steps 1–2, the functions f, g, h are C1 on a neighborhood of y⋆, y⋆ is a strict local minimizer (ambient-space sense) of the constrained problem equation 18, and the Han–Mangasarian constraint qualification (2.1) holds at y⋆. Therefore, by (Han & Mangasarian, 1979, Thm. 4.4), there exists ¯α ≥ 0 such that for every α ≥ ¯α, y⋆ is a local minimizer of P (·, α ).

Step 4: Return to local maximization and ensure strictly positive vector weights. Choose any 

α > max {¯α, 0}, (23) so in particular α > 0. Define the penalized maximization objective 

eF (y) := −P (y, α ) = λ0 ϕ U (x, y) − α λ ⊤ 

> 1

ρ g(y) − α λ ⊤ 

> 2

ψ h(y).

Since y⋆ is a local minimizer of P (·, α ), it is a local maximizer of eF . Finally set 

λ′ 

> 1

:= α λ 1 ∈ Rm

> ++

, λ′ 

> 2

:= α λ 2 ∈ Rp

> ++

.

Then eF (y) equals 

λ0 ϕ U (x, y) − (λ′

> 1

)⊤ρ C(x, y) − (λ′

> 2

)⊤ψ T (x, y),

which is precisely the objective in equation 16. Hence y⋆ is a local maximizer of equation 16 over 

Y. Since y⋆ ∈ int( Y), this is equivalent to local maximality in the ambient space sense. This completes the proof. 

Theorem 2.2 (Universality of UMP). Let X and Y be arbitrary nonempty sets. Let f : X × Y → R

be an objective and let 

{gi}i∈I≤ , {˜gk}k∈I≥ , {hj }j∈J

be (possibly empty, countable, or uncountable) families of real–valued constraint functions on X × Y. For each fixed x ∈ X , consider the optimization problem 

sup 

> y∈Y

f (x, y) s.t. gi(x, y) ≤ 0 ( i ∈ I≤), ˜gk(x, y) ≥ 0 ( k ∈ I≥), hj (x, y) = 0 ( j ∈ J). (24) 

Define (with the convention sup ∅ := −∞ and maxima taken in the extended reals) 

U (x, y) := f (x, y), C(x, y) := max 

n

0, sup 

> i∈I≤

gi(x, y), sup 

> k∈I≥

 −˜gk(x, y)o

,

T (x, y) := max 

n

0, sup 

> j∈J

|hj (x, y)|

o

.

Then for every x ∈ X , problem equation 24 is equivalent to the utility–maximization problem 

sup 

> y∈Y

U (x, y) s.t. C(x, y) ≤ 0, T (x, y) = 0 , (25) 

in the sense that the feasible sets of equation 24 and equation 25 coincide; hence the optimal values coincide, and whenever maximizers exist, the argmax sets coincide. For minimization problems, replace U by −f .

27 International Conference on Learning Representations (ICLR) 2026 

Proof. Fix x ∈ X . Let 

F (x) := 

n

y ∈ Y : gi(x, y) ≤ 0 ∀i ∈ I≤, ˜gk(x, y) ≥ 0 ∀k ∈ I≥, h j (x, y) = 0 ∀j ∈ J

o

denote the feasible set of equation 24, and let 

ˆF (x) := 

n

y ∈ Y : C(x, y) ≤ 0, T (x, y) = 0 

o

denote the feasible set of equation 25. We prove that F (x) = ˆF (x).

(i) F (x) ⊆ ˆF (x). Let y ∈ F (x). Then gi(x, y) ≤ 0 for all i ∈ I≤, hence 

sup 

> i∈I≤

gi(x, y) ≤ 0.

Similarly, ˜gk(x, y) ≥ 0 for all k ∈ I≥ implies −˜gk(x, y) ≤ 0 for all k, hence 

sup 

> k∈I≥

 −˜gk(x, y) ≤ 0.

Moreover, hj (x, y) = 0 for all j ∈ J implies |hj (x, y)| = 0 for all j ∈ J, hence 

sup 

> j∈J

|hj (x, y)| ≤ 0 (with the convention sup ∅ = −∞ ).

By definition, 

C(x, y) = max 

n

0, sup 

> i∈I≤

gi(x, y), sup 

> k∈I≥

 −˜gk(x, y)o

= 0 ,

and 

T (x, y) = max 

n

0, sup 

> j∈J

|hj (x, y)|

o

= 0 .

Thus y ∈ ˆF (x).

(ii) ˆF (x) ⊆ F (x). Let y ∈ ˆF (x). Set 

A := sup 

> i∈I≤

gi(x, y), B := sup 

> k∈I≥

 −˜gk(x, y), S := sup 

> j∈J

|hj (x, y)|.

Then 

C(x, y) = max {0, A, B } ≤ 0.

Since 0 ≤ max {0, A, B } always holds, we have max {0, A, B } = 0 , and in particular A ≤ 0 and 

B ≤ 0. Using the basic property of the supremum, for every i ∈ I≤ we have 

gi(x, y) ≤ sup 

> i∈I≤

gi(x, y) = A ≤ 0,

and for every k ∈ I≥ we have 

−˜gk(x, y) ≤ sup 

> k∈I≥

 −˜gk(x, y) = B ≤ 0,

i.e., ˜gk(x, y) ≥ 0.Next, T (x, y) = 0 means 

0 = T (x, y) = max {0, S },

hence S ≤ 0. Since |hj (x, y)| ≥ 0 for every j ∈ J and |hj (x, y)| ≤ S ≤ 0, it follows that 

|hj (x, y)| = 0 for all j ∈ J, 

equivalently hj (x, y) = 0 for all j ∈ J. Therefore y ∈ F (x).Combining (i) and (ii) yields F (x) = ˆF (x). Since U (x, y) = f (x, y) (and for minimization problems one may equivalently optimize −f ), the two problems optimize the same objective over the same feasible set. Consequently, their optimal values coincide, and whenever maximizers exist, their argmax sets coincide. 28 International Conference on Learning Representations (ICLR) 2026 B.2 BL A RCHITECTURE 

Theorem 2.3 (Universal Approximation of BL). Let X ⊂ Rd and Y ⊂ Rm be compact sets, and let 

p⋆(y | x) be any continuous conditional density such that p⋆(y | x) > 0 for all (x, y) ∈ X × Y .Then for any τ > 0 and ε > 0, there exists a finite BL architecture (with some depth and width depending on ε) and a parameter θ⋆ such that the Gibbs distribution 

pτ (y | x; θ⋆) = exp  BL θ⋆ (x, y)/τ R 

> Y

exp  BL θ⋆ (x, y′)/τ dy′ (26) 

satisfies 

sup 

> x∈X

KL  p⋆(· | x) ∥ pτ (· | x; θ⋆) < ε. (27) 

Proof. Step 0 (bounded log-density). Define f (x, y) := log p⋆(y | x). Since p⋆ is continuous and strictly positive on the compact set X × Y , it attains a positive minimum and finite maximum. Hence f ∈ C(X × Y ) and is bounded. 

Step 1 (the BL block contains a one-hidden-layer tanh network). Recall the elementary block 

B(x, y; θ) := λ⊤ 

> 0

tanh  pu(x, y) − λ⊤ 

> 1

ReLU  pc(x, y) − λ⊤ 

> 2

pt(x, y) . (28) Set λ1 = 0 and λ2 = 0. Choose pu(x, y) to be affine in [x; y], i.e. pu(x, y) = W [x; y] + b ∈ Rk

for some k ∈ N. Then 

B(x, y; θ) = λ⊤ 

> 0

tanh  W [x; y] + b, (29) which is a standard one-hidden-layer tanh network on the compact domain X × Y .If λ0 ∈ Rk is unconstrained, equation 29 is the classical universal approximation class. If instead one imposes λ0 ≥ 0 componentwise, the same expressivity is retained because tanh is odd: for any scalar a ∈ R, write a = a+ − a− with a± ≥ 0, and note a tanh( h) = a+ tanh( h) + a− tanh( −h).

Since −h is affine whenever h is affine, negative coefficients can be realized by duplicating hidden units and keeping the corresponding output weights nonnegative. Thus, up to a constant-factor increase in width, the block class contains signed linear combinations of tanh units. 

Step 2 (uniform approximation of the target energy). By the universal approximation theorem for single-hidden-layer networks with nonpolynomial activation (e.g., tanh ), for any δ > 0 there exist a width k and parameters θ such that 

sup 

> (x,y)∈X ×Y

B(x, y; θ) − τ f (x, y) < δ. (30) Define g(x, y) := B(x, y; θ)/τ and η := δ/τ . Then equation 30 is equivalent to 

sup 

> (x,y)∈X ×Y

g(x, y) − f (x, y) < η. (31) 

Step 3 (uniform KL control). For each x ∈ X , define 

q(y | x) := exp  g(x, y)R 

> Y

exp  g(x, y′) dy′ . (32) The normalizer in equation 32 is finite because g is continuous and Y is compact. Let Zg (x) := R 

> Y

exp  g(x, y′) dy′. Since p⋆(· | x) is a density, without loss of generality we may normalize the energy so that R 

> Y

ef (x,y′)dy′ = 1 . From equation 31, for all (x, y),

e−η ≤ eg(x,y)

ef (x,y) ≤ eη .

Integrating over y ∈ Y yields 

e−η ≤ Zg (x) ≤ eη , hence | log Zg (x)| ≤ η, ∀ x ∈ X . (33) 29 International Conference on Learning Representations (ICLR) 2026 Moreover, 

log p⋆(y | x)

q(y | x) = log ef (x,y)

eg(x,y)/Z g (x) =  f (x, y) − g(x, y) + log Zg (x).

Taking expectation under p⋆(· | x) and using equation 31 and equation 33 gives 

KL  p⋆(· | x) q(· | x) = Ep⋆(·| x)[f (x, Y) − g(x, Y)] + log Zg (x)

≤ η + η = 2 η, ∀ x ∈ X . (34) 

Step 4 (choose δ and embed into BL). Choose δ := ετ / 4, so that η = δ/τ = ε/ 4. Then equation 34 implies 

sup 

> x∈X

KL  p⋆(· | x) q(· | x) ≤ 2η = ε/ 2 < ε. 

Finally, the density q(· | x) equals the Gibbs distribution equation 26 with energy BL θ⋆ (x, y) := 

B(x, y; θ) (a finite BL architecture containing a single block), and temperature τ . This proves the claim. B.3 IDENTIFIABLE BEHAVIOR LEARNING (IBL) B.3.1 SETUP AND ASSUMPTION 

Input–output space and data. Let X ⊂ Rdx and Y ⊂ Rdy be compact sets. Assume the data distribution PX,Y is supported on X × Y , and that there exists a point z0 = ( x0, y 0) in the interior of its support; that is, some open neighborhood of z0 has positive PX,Y -measure. All expectations are taken with respect to PX,Y unless otherwise specified. 

Parameter space and polynomial feature maps. The parameter space factorizes as 

Θ := Θ U × ΘC × ΘT × W ◦.

For θU ∈ ΘU , θC ∈ ΘC , and θT ∈ ΘT , we define polynomial feature maps 

pu : X × Y → Rdu , pc : X × Y → Rdc , pt : X × Y → Rdt ,

each of fixed degree and injective in their coefficients (i.e., distinct coefficients yield distinct func-tions). For a single block, θU , θ C , θ T correspond to the parameters of the U , C, and T terms together with their respective external multipliers (e.g., penalty weights λ). For a deep network composed of multiple blocks, θ = ( θU , θ C , θ T ) denotes the collection of all block-level parameters across the hierarchy, where θU aggregates the parameters of all U -terms, θC those of all C-terms, and θT those of all T -terms (each including their associated multipliers). The output component W◦ corresponds to the affine transformation in the final layer: W◦ = Rd′

for single-output prediction, and W◦ = Rd′×m for m-way classification, where d′ is the output dimension induced by the preceding network, whether shallow or deep. 

Identifiable base block. Let λ0 ∈ Rdu , λ1 ∈ Rdc , and λ2 ∈ Rdt denote nonnegative weight vectors, treated as learnable parameters. We instantiate the identifiable modular block 

Bid (x, y ; θ) = λ⊤ 

> 0

tanh  pu(x, y ) − λ⊤ 

> 1

softplus  pc(x, y ) − λ⊤

> 2

 pt(x, y )⊙2, (35) where (·)⊙2 denotes elementwise squaring. By construction, the tanh and softplus heads are strictly monotone in their arguments, while the quadratic head is even. We assume that each polynomial feature map p•(x, y ) contains no nonzero monomial independent of y; that is, no feature is a pure function of x or a constant. This ensures that Bid (x, y ) is noncon-stant in y unless all weights vanish. 

Architectures. We implement IBL in three architectural forms, each producing a compositional utility function over (x, y ).• IBL(Single): A single block is used as the compositional utility, 

IBL( x, y ) := Bid (x, y ).

30 International Conference on Learning Representations (ICLR) 2026 • IBL(Shallow): Shallow IBL uses one or two stacked layers of parallel blocks. For instance, a first layer 

Bid 1 (x, y ) := [ Bid 1,1(x, y ), . . . , Bid 1,d 1 (x, y ) ] ⊤ ∈ Rd1

feeds into a bias-free affine map 

IBL Shallow (x, y ) := W◦ 

> 1

Bid 1 (x, y ),

where W◦ 

> 1

∈ Rm×d1 for classification and W◦ 

> 1

∈ R1×d1 for scalar output. • IBL(Deep): Deep IBL extends the construction to depth L > 2, recursively defined as 

IBL( x, y ) := W◦ 

> L

· Bid 

> L

  · · · Bid 2 (Bid 1 (x, y )) · · · ,

where each Bid  

> ℓ

stacks parallel blocks Bid 

> ℓ,i

(x, y ), and W◦ 

> L

is a bias-free affine transformation. The cases L = 1 and L = 2 recover the Single and Shallow architectures, respectively. 

Induced conditional model. Let IBL( x, y ) denote the compositional utility function produced by the chosen architecture (Single, Shallow, or Deep). It induces the conditional Gibbs distribution (Discrete y ∈ [m]) p(y | x) = softmax y {IBL( x, y )}, (36) (Continuous y) p(y | x) = exp {IBL( x, y )/τ }

R 

> Y

exp {IBL( x, ˜y)/τ } d˜y , τ > 0 fixed . (37) Here τ is a fixed temperature parameter. Thus, IBL predicts by defining a compositional utility landscape whose Gibbs distribution governs y given x.

Quotient parameter space. Definition B.1 (Symmetry Quotient Space) . Define the equivalence relation ∼ on Θ as the smallest relation satisfying 

θt ∼ θ′ 

> t

⇐⇒ p(i) 

> t

(x, y ; θ(i) 

> t

)⊙2 = p(i) 

> t

(x, y ; θ′(i) 

> t

)⊙2 for all i and (x, y ).

The corresponding quotient space is ¯Θ := Θ / ∼ .

Explanation. The T -component is designed to encode equality constraints, which are symbolically equations. Flipping the overall sign of such a constraint leaves the equation unchanged, so different parameterizations that differ only by sign should be regarded as equivalent. 

Definition B.2 (Scale-Invariant Quotient Space) . Define the equivalence relation ≈ on ¯Θ by 

¯θ ≈ ¯θ′ ⇐⇒ ∃ c > 0 such that s(x, y ; ¯θ) = c s(x, y ; ¯θ′).

The scale-invariant quotient space is then given by 

eΘ := ¯Θ/ ≈ .

Explanation. In classification, predictions depend only on relative compositional utility differences between candidate labels. From a technical perspective, quotienting out global shifts or uniform scalings is necessary: without this identification, the cross-entropy loss admits redundant parame-terizations that differ only by such transformations. At the same time, this quotient is natural and harmless, since it does not eliminate informative ratios between classes but merely discards absolute levels or scales that play no role in the softmax decision rule. 

Loss Functions. We adopt a hybrid loss to simultaneously accommodate discrete and continuous outputs. Specifically, cross-entropy (CE) is applied to discrete targets, while denoising score match-ing (DSM) is applied to continuous targets. Let γc, γ d ≥ 0 with γc + γd > 0. The population risk, defined on the quotient parameter space, is given by 

M(¯θ) = γd E[− log pθ (Y | X)] + γc E[SDSM (θ; X)] , θ ∈ π−1(¯θ), (38) where π denotes the canonical projection from the original parameter space onto its quotient. 31 International Conference on Learning Representations (ICLR) 2026 For continuous outputs Y ∈ Y ⊆ Rdy , DSM is implemented by perturbing the target with additive Gaussian noise ˜Y = Y + ε, ε ∼ N (0 , σ 2I), and penalizing the squared discrepancy between the model score and the corresponding denoising score: 

SDSM (θ; X) = 12σ2 Eε



∇˜y log pθ (˜ y | X) + 1 

> σ2

(Y − ˜Y ) 2

X, Y 



. (39) In classification-only settings we set γc = 0 (pure CE), while in regression-only settings we set 

γd = 0 (pure DSM). For a single observation Z = ( X, Y ), we define the per-sample loss as 

ℓ(θ; Z) := γd

 − log pθ (Y | X) + γc SDSM (θ; X). (40) The empirical criterion then takes the standard M -estimation form 

ˆQn(θ) = 1

n

> n

X

> i=1

ℓ(θ; Zi), Zi = ( Xi, Y i). (41) 

Key Assumptions. Assumption B.1 (Global Atomic Independence and Injectivity) . Let ¯Ψ be the atomic parameter quotient. 1. Injectivity on the quotient. The map ¯Ψ → RX ×Y , ¯ψ 7 → g ¯ψ , is injective. 2. Linear Independence. Atomic linear independence. Any finite collection of pairwise distinct atoms {g ¯ψi }ri=1 with ¯ψi ∈ ¯Ψ is linearly independent in RX ×Y .3. Minimality. In all model instances we only consider minimal representations: no duplicate atoms and its corresponding linear coefficient in the mixture is nonzero. 4. Canonical ordering. For each model instance, a fixed canonical ordering is imposed on the atom list. Explanation. Assumption B.1 treats each identifiable block Bid as an atomic building unit and im-poses four structural requirements on representations built from these atoms. Together, these four conditions define a non-ambiguous, non-redundant, and canonical algebra of atoms: after quotient-ing by the natural symmetries, every model constructed from B-blocks admits a unique minimal representation (up to the prescribed equivalences). This structural regularity is the foundation on which identifiability statements are built: it guarantees that observing the model output (or the ob-jective it optimizes) allows one, in principle, to recover the underlying atomic components and their coefficients in the appropriate quotient sense. 

Practical remark. In practice, these conditions can be encouraged or approximately enforced in two complementary ways. First, the design of atomic classes (choice of polynomial bases, interaction terms, and activation heads) can be chosen so that injectivity and linear independence are more plausible by construction. Second, model selection and post-processing (e.g., pruning atoms with near-zero coefficients, enforcing a deterministic tie-breaking rule for ordering) can be applied after training to realize minimality and canonical ordering. These practical measures make the theoretical assumptions operationally meaningful in empirical applications. B.3.2 PROOF OF THEOREMS 

Lemma B.1 (Identifiability of Linear Combinations) . Let Z be a set. For each j = 1 , . . . , m , let Φj

be a parameter space and define atomic functions 

gψ := f (·; ϕj ), ψ = ( j, ϕ j ) ∈ Ψ,

where Ψ := Fmj=1 Φj is the disjoint union. Let ¯Ψ be the quotient atomic parameter space, and denote its elements by ¯ψ ∈ ¯Ψ.

32 International Conference on Learning Representations (ICLR) 2026 

Define the quotient parameter space of the model as 

¯Ξ := 

> m

Y

> j=1

 (R \ { 0}) × ¯Ψ, ¯ξ = (( a1, ¯ψ1), . . . , (am, ¯ψm)) .

The associated linear combination model is 

S¯ξ := 

> m

X

> j=1

aj g ¯ψj .

By virtue of Assumption B.1, the model is identifiable in the quotient parameter space ¯Ξ: if S¯ξ ≡ S¯ξ′

on Z, then ¯ξ = ¯ξ′.Proof. Suppose S¯ξ ≡ S¯ξ′ on Z, i.e., 

> m

X

> j=1

aj g(j,ϕ j ) −

> m

X

> j=1

a′ 

> j

g(j,ϕ ′  

> j)

≡ 0.

Let U be the set of distinct atoms in the quotient ¯Ψ that appear on either side, and for each ¯ψ ∈ U 

let 

β( ¯ψ) := X 

> j: [ j,ϕ j]= ¯ψ

aj − X 

> j′: [ j′,ϕ ′
> j′]= ¯ψ

a′

> j′

be the net coefficient of g ¯ψ . Then X

> ¯ψ∈U

β( ¯ψ) g ¯ψ ≡ 0.

By the linear independence condition (Assumption B.1:2) of pairwise distinct atoms in ¯Ψ, we must have β( ¯ψ) = 0 for all ¯ψ ∈ U .Furthermore, by the Minimality requirement (Assumption B.1:3), each ¯ψ appears exactly once on each side and with nonzero coefficient. Thus the two sides must contain the exact same list of coef-ficient–atom pairs {(aj , ¯ψj )}mj=1 , and since a canonical ordering is imposed (Assumption B.1:4), it follows that ¯ξ = ¯ξ′.

Theorem B.1 (Identifiability of IBL(Single)) . The IBL(Single) architecture uses the atom set 

 tanh( pu,i ), softplus( pc,i ), (pt,i )2 : i = 1 , . . . , d u; i = 1 , . . . , d c; i = 1 , . . . , d t .

Under Assumption B.1, the model is identifiable in the quotient space ¯Θ: if Bid  

> θ

≡ B id  

> θ′

on X × Y ,then θ = θ′ in ¯Θ.Proof. Write 

Bid  

> θ

=

> m

X

> j=1

aj f (·; ϕj ), m := du + dc + dt,

where each f (·; ϕj ) is one of the atoms tanh( pu,i ), softplus( pc,i ), or (pt,i )2, and aj is the corre-sponding entry in (λ0, λ 1, λ 2), with a fixed ordering over all indices. If Bid  

> θ

≡ B id  

> θ′

on X × Y , then Lemma B.1 and Assumption B.1 imply that all atoms and coefficients must agree in the quotient atomic space ¯Ψ. Since the ordering is fixed, this implies θ = θ′ in ¯Θ.

Theorem B.2 (Identifiability of IBL(Shallow)) . The IBL(Shallow) architecture uses the atom set 

 Bid  

> θ1,j

(x, y ) d1

> j=1

,

where each Bid  

> θ1,j

: X × Y → R is a single-block IBL module parametrized by θ1,j ∈ Θ1. The full parameter is denoted 

θ :=  (θ1,1, . . . , θ 1,d 1 ), W◦

> 1

 ∈ Θ := (Θ 1)d1 × Rm×d1 .

33 International Conference on Learning Representations (ICLR) 2026 

Under Assumption B.1, the mapping θ 7 → IBL Shallow is identifiable in the quotient space ¯Θ: if 

IBL Shallow (x, y ; θ) ≡ IBL Shallow (x, y ; θ′) on X × Y ,

then 

θ = θ′ in ¯Θ.

Proof. Write the k-th output component as a linear combination of atoms: 

s(k) 

> θ

(x, y ) = 

> d1

X

> j=1

w(k) 

> j

Bid  

> θ1,j

(x, y ), k = 1 , . . . , m, 

where w(k) 

> j

denotes the (k, j )-th entry of W◦ 

> 1

.Suppose two parameter tuples (W◦ 

> 1

, {θ1,j }d1

> j=1

) and (W◦ ′  

> 1

, {θ′ 

> 1,j

}d1

> j=1

) yield identical vector scores on X × Y . Then for each k, we have s(k) 

> θ

≡ s(k) 

> θ′

on X × Y .Fix any k. Under Assumption B.1, Lemma B.1 ensures that the coefficient–atom pairs 

{(w(k) 

> j

, Bid  

> θ1,j

)}d1 

> j=1

are uniquely determined (up to equivalence in the quotient ¯Θ). In particular, for each j = 1 , . . . , d 1, we must have 

w(k) 

> j

= w′(k) 

> j

, Bid  

> θ1,j

≡ B id  

> θ′
> 1,j

.

Because this holds for all k = 1 , . . . , m , it follows that W◦ 

> 1

= W◦ ′  

> 1

and θ1,j = θ′ 

> 1,j

in the quotient parameter space for all j.Thus θ = θ′ in ¯Θ, establishing full identifiability under fixed ordering. 

Theorem B.3 (Identifiability of IBL(Deep)) . Fix integers L > 2 and widths d1, . . . , d L−1. The IBL(Deep) architecture uses the final-layer atom set 

 Bid  

> ϑL,j

(x, y ) dL 

> j=1

⊂ RX ×Y ,

where each Bid  

> ϑL,j

: RdL−1 → R is a scalar-valued block applied to the output of layer L−1.Only the first-layer blocks ( ℓ = 1 ) are IBL(Single) modules as in Theorem B.1. For architectures with skip connections, the final-layer atoms can be extended to include skipped features (e.g., from earlier layers), which are treated as elements of  Bid  

> ϑL,j

(x, y ) dL

> j=1

.

The full parameter is 

θ :=  {ϑℓ,j }L,d ℓ

> ℓ=1 ,j =1

, Wout 

 ∈ Θ := 

> L

Y

> ℓ=1

(Θ 1)dℓ × Rm×dL .

Under Assumption B.1, the mapping θ 7 → IBL Deep (x, y ; θ) is identifiable in the quotient space ¯Θ.Proof. Under the given architecture, the IBL(Deep) model ultimately takes the form 

s(k)(x, y ) = 

> dL

X

> j=1

w(k) 

> j

Bid  

> ϑL,j

(x, y ), k = 1 , . . . , m, 

where each Bid  

> ϑL,j

is a scalar-valued function applied to the output of preceding layers. By treating the set {B id  

> ϑL,j

(x, y )}dL 

> j=1

as the atom set, we reduce the model to an IBL(Shallow) form: 

s(x, y ) = Wout BL(x, y ).

Under Assumption B.1, Theorem B.2 applies, implying that the full parameter θ =({ϑℓ,j }ℓ,j , Wout ) is identifiable in the quotient space ¯Θ.

Theorem 2.4 (Identifiability of IBL). Under Assumption B.1, the architectures IBL(Single), IBL (Shallow), and IBL(Deep) are all identifiable in the quotient space ¯Θ.

34 International Conference on Learning Representations (ICLR) 2026 

Proof. Immediate from Theorems B.1, B.2, and B.3. 

Theorem 2.5 (Loss Identifiability of IBL). Let IBL θ (x, y ) denote an IBL model, and consider the conditional Gibbs distribution 

pθ (y | x) = exp  IBL θ (x, y )R 

> Y

exp  IBL θ (x, y ′) dy ′ .

Define the population risk on the symmetry quotient ¯Θ as in equation 38. Assume that the parameter space Θ is compact. Then, under Assumption B.1, the following holds: (i) If γc > 0, the risk functional M admits a unique minimizer in ¯Θ. Moreover, 

M(¯θ1) = M(¯θ2) =⇒ ¯θ1 = ¯θ2.

(ii) If γc = 0 , the risk functional M admits a unique minimizer in the scale-invariant quotient eΘ.Moreover, 

M(eθ1) = M(eθ2) =⇒ eθ1 = eθ2.

Proof. Under Assumption B.1, the IBL architecture is identifiable modulo the symmetry group defined by ¯Θ, as established in Theorem 2.4. Let θ• ∈ arg min θ∈Θ M(θ) and set p⋆(· | x) := 

pθ• (· | x). Since Θ is compact and the loss M is continuous, a global minimizer exists. We show that it is unique in the stated quotient. 

Case γc > 0. At any minimizer we have both pθ (· | x) = p⋆(· | x) and ∇y log pθ (· | x) = 

∇y log p⋆(· | x) a.e. Since 

∇y log pθ (y | x) = ∇y IBL θ (x, y ) − ∇ y log Zθ (x) = ∇y IBL θ (x, y ),

(the partition function Zθ (x) is y-independent), score equality yields ∇y

 IBL θ − IBL θ•

(y; x) = 0 

a.e. IBL contains no y-independent terms. Therefore, 

IBL θ (x, y ) = IBL θ• (x, y ) a.e. By Theorem 2.4 (identifiability in ¯Θ), the minimizer is unique in ¯Θ; in particular, 

M(¯θ1) = M(¯θ2) = ⇒ ¯θ1 = ¯θ2.

Case γc = 0 . Here, M reduces to the cross-entropy risk, which is minimized if and only if 

pθ (· | x) = p⋆(· | x) almost everywhere.The cross-entropy loss depends on IBL θ (x, y ) only through its relative values across y, and is invariant under additive shifts and positive rescalings of the compositional utility. Hence, the loss depends only on the equivalence class eθ ∈ eΘ}. As a result, 

M(eθ1) = M(eθ2) =⇒ eθ1 = eθ2.

i.e., the minimizer is unique in eΘ.Hence, the minimizer is unique in the stated quotient space. This completes the proof. 

Theorem B.4 (Uniform M-estimation consistency (Newey & McFadden, 1994, Theorem 2.1)) . Let 

(A, d ) be a compact metric space, and let bLn : A → R be a sequence of random objective functions, with population objective L : A → R such that: 1. L(α) is uniquely minimized at α⋆ ∈ A ;2. A is compact; 3. L(α) is continuous; 4. bLn(α) p

−→ L(α) uniformly in α ∈ A .Then any sequence ˆαn ∈ arg min α∈A bLn(α) satisfies ˆαnp

−→ α⋆.

Theorem B.5 (Consistency of IBL) . Let M be the population risk defined in equation 38, and let 

Mn denote its empirical analogue. Suppose: 

35 International Conference on Learning Representations (ICLR) 2026 

1. {(Xi, Y i)}ni=1 are i.i.d. samples; 2. Θ is compact; 3. θ 7 → M (θ) is continuous, and the loss class admits an integrable envelope such that 

sup 

> θ∈Θ

Mn(θ) − M (θ) p

−→ 0; 

Let Ξ denote the relevant quotient space ( ¯Θ if γc > 0, eΘ if γc = 0 ), and let ˆθn ∈ arg min θ∈Θ Mn(θ)

and θ• ∈ arg min θ∈Θ M(θ). Then 

ˆθnp

−→ θ• in Ξ, M(ˆθn) p

−→ M (θ•).

If the model is correctly specified (the data law is realized by some θ⋆ ∈ Θ), then θ• = θ⋆ in Ξ, so 

ˆθnp

−→ θ⋆.Proof. Let Ξ denote the relevant quotient space: Ξ = ¯Θ if γc > 0 and Ξ = eΘ if γc = 0 . Let 

π : Θ → Ξ be the canonical quotient map. Since Θ is compact and π is continuous and onto, Ξ is compact. By assumption, M and Mn are invariant under the corresponding symmetry, hence they factor through π:

fM(ξ) := M(θ), fMn(ξ) := Mn(θ) (any θ ∈ π−1(ξ)) .

These are well-defined and continuous on Ξ because M is continuous on Θ. Moreover, 

sup 

> ξ∈Ξ

fMn(ξ) − fM(ξ) ≤ sup 

> θ∈Θ

Mn(θ) − M (θ) p

−→ 0,

so uniform convergence in probability holds on Ξ.By Loss Identifiability of IBL (Theorem 2.5), fM has a unique minimizer ξ• ∈ Ξ. Let ˆξn ∈

arg min ξ∈Ξ fMn(ξ) (equivalently, choose ˆθn ∈ arg min θ∈Θ Mn(θ) and set ˆξn = π(ˆθn)). Then the conditions of Theorem B.4 hold on the compact metric space (Ξ , d ), whence 

ˆξnp

−→ ξ•.

Since fM is continuous on Ξ and fM( ˆξn) = M(ˆθn), fM(ξ•) = M(θ•) for any representative 

θ• ∈ π−1(ξ•), we also obtain 

M(ˆθn) = fM( ˆξn) p

−→ fM(ξ•) = M(θ•).

If the model is correctly specified (there exists θ⋆ ∈ Θ inducing the data law), the strict propriety of the CE/DSM terms implies that the unique minimizer in the quotient is the class of θ⋆; hence ˆθn

converges in probability to θ⋆ in the corresponding quotient space. 

Theorem B.6 (Universal Approximation of IBL) . Let X ⊂ Rd and Y ⊂ Rm be compact sets, and let p⋆(y | x) be any continuous conditional density such that p⋆(y | x) > 0 for all (x, y ) ∈ X × Y .Then for any τ > 0 and ε > 0, there exists a finite IBL architecture (with some depth and width depending on ε) and a parameter θ⋆ such that the Gibbs distribution 

pτ (y | x; θ⋆) = exp  IBL θ⋆ (x, y )/τ R 

> Y

exp  IBL θ⋆ (x, y ′)/τ dy′ (42) 

satisfies 

sup 

> x∈X

KL  p⋆(· | x) ∥ pτ (· | x; θ⋆) < ε. (43) 

Proof. The argument follows the same construction as in the proof of Theorem 2.3, with only nota-tional modifications due to the IBL parameterization. For brevity, the details are omitted. 36 International Conference on Learning Representations (ICLR) 2026 

Lemma B.2 (Sieve Approximation Lemma) . Let C : Θ → [0 , ∞) be a complexity measure on the parameter space, and let (cn)n≥1 be a nondecreasing sequence with cn ↑ ∞ . Define the sieve 

Θn := {θ ∈ Θ : C(θ) ≤ cn},

and for a fixed data-generating distribution p†, set 

δn(p†) := inf 

> θ∈Θn

sup 

> x∈X

KL  p†(· | x) ∥ pθ (· | x).

Then the following are equivalent: 1. Sieve universal approximation: For every ε > 0 there exists a constant Cε < ∞ such that 

inf  

> θ:C(θ)≤Cε

sup 

> x∈X

KL  p†(· | x) ∥ pθ (· | x) < ε. 

2. Vanishing approximation error: δn(p†) ↓ 0 as n → ∞ .Moreover, if each Θn is compact and θ 7 → sup x KL( p†∥pθ ) is continuous on Θn, then the infimum in δn(p†) is attained for every n.Proof. (1) ⇒ (2). Fix ε > 0 and let Cε(p†) be as in (i). Since cn ↑ ∞ , there exists N such that 

cn ≥ Cε(p†) for all n ≥ N . Hence Θn ⊇ { θ : C(θ) ≤ Cε(p†)} for all n ≥ N , and therefore 

δn(p†) = inf 

> θ∈Θn

sup 

> x

KL( p†∥pθ ) ≤ inf  

> θ:C(θ)≤Cε(p†)

sup 

> x

KL( p†∥pθ ) < ε, 

for all n ≥ N . Since (δn) is nonincreasing in n (because Θn ↑), it follows that δn(p†) ↓ 0.

(2) ⇒ (1). Fix ε > 0. By (ii) choose N such that δN (p†) < ε . Set Cε(p†) := cN . Then 

inf  

> θ:C(θ)≤Cε(p†)

sup 

> x

KL( p†∥pθ ) ≤ inf 

> θ∈ΘN

sup 

> x

KL( p†∥pθ ) = δN (p†) < ε, 

which is (i). The attainment statement follows immediately from compactness of Θn and continuity of θ 7 →

sup x KL( p†∥pθ ) on Θn.

Theorem B.7 (Universal Consistency of IBL) . Consider a parameter space Θ for a class of IBL models, and let C : Θ → [0 , ∞) be a lower semi-continuous complexity measure (e.g., network depth, width, or parameter norm). Let (cn)n≥1 be a nondecreasing sequence with cn ↑ ∞ , and define the sieve 

Θn := {θ ∈ Θ : C(θ) ≤ cn}.

Assume: 1. The map θ 7 → sup x KL( p†∥pθ ) is continuous on each compact Θn.2. The sequence of empirical minimizers {ˆθn} is relatively compact in S 

> n

Θn, as ensured by the uniform LLN together with compactness and continuity. Then for any admissible data-generating distribution p† satisfying the regularity assumptions of Theorem B.6, the IBL posterior sequence {pˆθn } satisfies 

sup 

> x∈X

KL  p†(· | x) ∥ pˆθn (· | x) p

−→ 0,

i.e. {pˆθn } converges to p† uniformly in x (in KL). Proof. Fix an admissible data law p† (satisfying the regularity of Theorem B.6). For θ ∈ S 

> n

Θn

define 

F (θ) := sup 

> x∈X

KL  p†(· | x) ∥ pθ (· | x), δn := inf 

> θ∈Θn

F (θ).

Then Theorem B.6 and Lemma B.2 together imply that δn ↓ 0. By assumption 1, F is continuous on each compact Θn.37 International Conference on Learning Representations (ICLR) 2026 Let ˆθn ∈ arg min θ∈Θn Mn(θ) be any sequence of ERM solutions. We show F (ˆθn) p

−→ 0.

Step 1 (subsequence reduction and precompactness). Take an arbitrary subsequence (ˆθnk )k. By assumption 2 there exists a further subsequence, still denoted (ˆθnk )k, and a (possibly k-dependent) index set Nk ≤ nk with a parameter limit θ∞ ∈ ΘN (for some finite N ) such that ˆθnk → θ∞ in probability. Passing to a further subsequence if needed, we may assume Nk ≡ N .

Step 2 (risk domination against ΘN -approximants). For each k pick θk ∈ ΘN with F (θk) ≤

δN + 1 /k (attainment follows from compactness and continuity of F on ΘN ). By the ERM property and uniform LLN on ΘN ,

M(ˆθnk ) ≤ M (θk) + op(1) (k → ∞ ).

Assume (w.l.o.g.) the CE component is present with a positive weight, so that the population risk decomposes as 

M(θ) = const + γd EX

KL  p†(· | X) ∥ pθ (· | X) + γc LDSM (θ),

with γd > 0 (the DSM-only case is handled analogously by replacing KL with Fisher divergence). Using EX [KL( ·∥· )] ≤ F (·), we obtain 

lim sup 

> k→∞

EX

h

KL  p†(· | X) ∥ pˆθnk

(· | X)i

≤ lim sup 

> k→∞

F (θk) ≤ δN .

Hence, along the subsequence, 

EX

h

KL  p†(· | X) ∥ pˆθnk

(· | X)i p

−→ 0.

Step 3 (identification of the subsequential limit). By continuity of the model map θ 7 → pθ (· | x)

(from Theorem B.6 regularity) and bounded convergence, 

EX

KL  p†(· | X) ∥ pθ∞ (· | X) = 0 .

Thus f (x) := KL  p†(· | x) ∥ pθ∞ (· | x) equals 0 for PX -a.e. x. Since f is continuous on compact 

X (by the same regularity) and PX has full support (admissible law), we conclude f (x) ≡ 0 on X ,i.e. 

F (θ∞) = sup 

> x∈X

f (x) = 0 .

Step 4 (conclude F (ˆθnk ) → 0 in probability, hence F (ˆθn) → 0 in probability). By assumption 1 continuity of F on ΘN and ˆθnk → θ∞ in probability, we have F (ˆθnk ) p

−→ F (θ∞) = 0 . Since the original subsequence was arbitrary and every subsequence admits a further subsequence with 

F (ˆθnk ) p

−→ 0, the full sequence satisfies F (ˆθn) p

−→ 0.Therefore, 

sup 

> x∈X

KL  p†(· | x) ∥ pˆθn (· | x) p

−→ 0,

i.e. pˆθn (· | x) → p†(· | x) uniformly in x in KL. 

Theorem B.8 (Asymptotic normality of extremum estimators (Newey & McFadden, 1994, Theorem 3.1)) . Suppose that the estimator ˆθn satisfies ˆθnp

−→ θ0, and: 1. θ0 lies in the interior of the parameter space Θ;2. the criterion function ˆQn(θ) is twice continuously differentiable in a neighborhood N of θ0;3. the score satisfies √n ∇θ ˆQn(θ0) d

−→ N (0 , Σ); 

4. there exists a function H(θ), continuous at θ0, such that 

sup 

> θ∈N

∇2 

> θ

ˆQn(θ) − H(θ) p

−→ 0; 

38 International Conference on Learning Representations (ICLR) 2026 

5. the limiting Hessian H := H(θ0) is nonsingular. Then the estimator is asymptotically normal: 

√n (ˆθn − θ0) d

−→ N  0, H −1ΣH−1.

Theorem B.9 (Asymptotic Normality of IBL) . Consider the IBL family pθ (y | x) ∝

exp(IBL θ (x, y )) with empirical criterion as in equation 41. Assume (Xi, Y i)ni=1 are i.i.d. from an admissible data law, and that the true parameter θ0 is an interior point of a locally identifiable chart. For each observation Z = ( X, Y ), let ℓ(θ; Z) denote the per-sample loss defined in equation 40, so that ˆQn(θ) = 1

> n

Pni=1 ℓ(θ; Zi) and Q(θ) := E[ℓ(θ; Z)] .Suppose, in addition: 1. Score moments. s(Z) := ∇θ ℓ(θ0; Z) satisfies E[s(Z)] = 0 , Σ := V ar (s(Z)) < ∞, and 

> 1√n

Pni=1 s(Zi) ⇒ N (0 , Σ) .2. Derivative envelopes. There exists a neighborhood N of θ0 and envelopes G1, G 2 with 

sup θ∈N ∥∇ θ ℓ(θ; Z)∥ ≤ G1(Z), sup θ∈N ∥∇ 2 

> θ

ℓ(θ; Z)∥ ≤ G2(Z), E[G21] + E[G2] < ∞.3. Nondegenerate curvature. H := ∇2 

> θ

Q(θ0) exists, is continuous at θ0, and is positive definite, where Q(θ) := E[ ˆQn(θ)] .Then, under conditions of Theorem 2.7, 

√n (ˆθn − θ0) ⇒ N  0, H −1ΣH−1.

Proof. We verify the hypotheses of Theorem B.8 with ˆQn as above. 

(i) Interior & consistency. By quotient identifiability, fix a local chart in which the population minimizer admits a unique interior representative θ0. Consistency ˆθnp

−→ θ0 follows from uniform M-estimation consistency for IBL (Theorem B.5). 

(ii) C2 criterion. Since IBL θ is C2 in θ, the loss ℓ(θ; Z) is twice continuously differentiable in a neighborhood N of θ0, and so is ˆQn.

(iii) Score CLT. By Score moments ,

√n ∇θ ˆQn(θ0) = 1

√n

> n

X

> i=1

s(Zi) ⇒ N (0 , Σ) .

(iv) Hessian limit. By Derivative envelopes and dominated convergence, 

sup 

> θ∈N

∇2 

> θ

ˆQn(θ) − ∇ 2 

> θ

Q(θ) p

−→ 0,

so Assumption 4 of Theorem B.8 holds with H(θ) := ∇2 

> θ

Q(θ), continuous at θ0.

(v) Nonsingularity. By Nondegenerate curvature , H := H(θ0) is positive definite. All assumptions of Theorem B.8 are thus verified; consequently, √n(ˆθn −θ0) ⇒ N (0 , H −1ΣH−1).

Theorem B.10 (Efficiency of IBL Estimators) . Under the regularity conditions of Theorem B.9, consider the estimating function associated with the per-sample loss equation 40: 

ψθ (Z) := ∇θ ℓ(θ; Z), Z = ( X, Y ).

At any population minimizer θ⋆, the moment condition E[ψθ⋆ (Z)] = 0 holds. Define the sensitivity and variability matrices 

J := E∇θ ψθ (Z) 

> θ=θ⋆

, K := Var  ψθ⋆ (Z).

Then the asymptotic covariance of ˆθn is given by the Godambe information matrix (sandwich form): 

√n (ˆθn − θ⋆) ⇒ N  0, J −1KJ −1.

In particular: 

39 International Conference on Learning Representations (ICLR) 2026 

1. CE-only. If γc = 0 (pure cross-entropy) and the model is correctly specified and regular, then 

ψθ (Z) coincides (up to sign) with the log-likelihood score sθ (Z). Hence J = −I(θ⋆) and 

K = I(θ⋆), where I(θ⋆) denotes the Fisher information matrix. It follows that 

√n(ˆθn − θ⋆) ⇒ N  0, I (θ⋆)−1,

so the estimator is asymptotically efficient, attaining the Cram´ er–Rao lower bound. 2. CE+DSM or DSM-only. Suppose there exists a nonsingular matrix R (constant in a neighbor-hood of θ⋆) such that 

ψθ⋆ (Z) = R s θ⋆ (Z) a.s. ,

where sθ (Z) = ∇θ log pθ (Z) denotes the parametric score in a local chart. Then J =

RI (θ⋆)R⊤ and K = RI (θ⋆)R⊤, so the sandwich covariance again reduces to I(θ⋆)−1. Hence the estimator remains asymptotically efficient. Proof. The empirical first–order condition is 

0 = 1

n

> n

X

> i=1

ψˆθn (Zi), ψθ (Z) := ∇θ ℓ(θ; Z).

A mean–value expansion around the population minimizer θ⋆ yields 

0 = Sn + Gn(ˆθn − θ⋆),

where 

Sn := 1

n

> n

X

> i=1

ψθ⋆ (Zi), Gn := 1

n

> n

X

> i=1

∇θ ψ˜θ (Zi),

for some intermediate point ˜θ lying on the line segment between ˆθn and θ⋆.Under the regularity conditions of Theorem B.9, we have 

Gnp

−→ J := E[∇θ ψθ⋆ (Z)] , √n S n ⇒ N (0 , K ), K := Var( ψθ⋆ (Z)) .

Since J is nonsingular, Gn is invertible with probability tending to one, and hence 

√n(ˆθn − θ⋆) = − G−1

> n

√n S n ⇒ N  0, J −1K(J−1)⊤.

Because here ψθ = ∇θ ℓ(θ; ·), the matrix J coincides with the expected Hessian of the loss, which is symmetric. Thus the asymptotic covariance may equivalently be written as J−1KJ −1.

(i) CE-only. When γc = 0 , the per-sample loss reduces to ℓ(θ; Z) = − log pθ (Z), so that ψθ (Z) = 

−sθ (Z), with sθ (Z) = ∇θ log pθ (Z) denoting the likelihood score. Under correct specification and standard likelihood regularity conditions, the information identities hold: 

E[sθ⋆ (Z)] = 0 , Var( sθ⋆ (Z)) = I(θ⋆), −E[∇θ sθ⋆ (Z)] = I(θ⋆).

Therefore, 

K = Var( ψθ⋆ (Z)) = I(θ⋆), J = E[∇θ ψθ⋆ (Z)] = I(θ⋆),

and the asymptotic covariance simplifies to I(θ⋆)−1. Thus the estimator is asymptotically efficient, attaining the Cram´ er–Rao lower bound (see also Van der Vaart, 2000, Theorem 5.39). 

(ii) CE+DSM or DSM-only under score-span. Suppose there exists a nonsingular matrix R (constant in a neighborhood of θ⋆) such that 

ψθ⋆ (Z) = R s θ⋆ (Z) a.s. ,

where sθ (Z) is again the parametric score. In this case, 

K = Var( ψθ⋆ (Z)) = R I (θ⋆) R⊤, J = E[∇θ ψθ⋆ (Z)] = −R I (θ⋆).

Consequently, 

J−1K(J−1)⊤ =   − RI (θ⋆)−1 RI (θ⋆)R⊤  − RI (θ⋆)−⊤ = I(θ⋆)−1.

Hence the sandwich covariance reduces to the Fisher information bound, and the estimator is asymp-totically efficient. This corresponds to the general efficiency condition for minimum-distance or GMM estimators (see Newey & McFadden, 1994, Section 5): the condition ψθ⋆ = R s θ⋆ is equiva-lent to their moment–span condition G′W = C G ′Ω−1 (Newey & McFadden, 1994, Equation 5.4), under which the Godambe information collapses to the Fisher bound. The two claims are thereby established. 40 International Conference on Learning Representations (ICLR) 2026 

# C EXPERIMENTAL DETAILS 

C.1 HARDWARE 

Most experiments are conducted on a single NVIDIA L40S GPU. A small number of runs are performed on a laptop equipped with an NVIDIA GeForce RTX 2050 GPU and an Intel Core i7– 12700H CPU. C.2 STANDARD PREDICTION TASKS 

Datasets. In the Standard Prediction Task, we use 10 OpenML datasets across diverse application domains. Details are given in Table 4. Table 4: Standard OpenML datasets used in our task. #Features denotes the number of input vari-ables (excluding the target and ID). 

Name Size #Features Task type Field 

German Credit 1,000 20 Binary cls. Finance Adult Income 48,842 14 Binary cls. Economics COMPAS (two-years) 5,278 13 Binary cls. Law & Society Bank Marketing 45,211 16 Binary cls. Marketing Planning Relax 182 12 Binary cls. Psychology EEG Eye State 14,980 14 Binary cls. Neuroscience MAGIC Gamma Telescope 19,020 10 Binary cls. Physics Electricity 45,312 8 Binary cls. Electrical Engineering Wine Quality (Red) 1,599 11 Multiclass Chemistry Steel Plates Faults 1,941 27 Multiclass Industrial Engineering 

Baseline Models. For comparison, we include the following baselines: MLP, Neural Additive Model (NAM) (Agarwal et al., 2020; Kayid et al., 2020), ElasticNet, Random Forest, Stochastic Variational Gaussian Process (SVGP) (Gardner et al., 2018), Logistic Regression, Decision Tree, TabNet (Arik & Pfister, 2021), Polynomial Logistic Regression, and LightGBM (Ke et al., 2017). Table 5: Overview of baseline models in the standard prediction task 

Methodological Family Model Name 

Neural networks Standard MLP Neural Additive Model (NAM) TabNet Linear regressors ElasticNet Logistic Regression Polynomial Logistic Regression Tree-based models Random Forest Decision Tree Gradient boosting methods LightGBM Bayesian methods Stochastic Variational Gaussian Process (SVGP) 

Data preprocessing. For all ten datasets, we apply a consistent preprocessing strategy. Ordinal categorical variables are mapped to integer levels to preserve their inherent order. Nominal cat-egorical variables without natural ordering are transformed using one-hot encoding. Continuous variables are standardized to zero mean and unit variance. Each dataset is randomly partitioned into train/validation/test splits with a 7:1:2 ratio. 41 International Conference on Learning Representations (ICLR) 2026 

Hyperparameter Tuning Protocol. We perform hyperparameter optimization for most models using the TPE sampler from the Optuna package (Akiba et al., 2019), with 50 trials per dataset. For each model and dataset, the tuned configuration is evaluated under 8 random seeds. 

BL Model Hyperparameter Space. For BL(Single) and BL(Shallow), we optimize cross-entropy loss for classification. Both Adam (Kingma, 2014) and AdamW (Loshchilov & Hutter, 2017) op-timizers are considered, and the better-performing variant is reported for each dataset. No data augmentation is applied. Batch sizes are chosen in a dataset-specific manner. • BL(Single): A unified setting is reported across all experiments: 

degree U = [2] , degree C = [2 , 2, 2] , degree T = [2 , 2] ,σparams = 0 .01 , σλ0 = 0 .01 , σλ1 = 0 .01 , σλ2 = 0 .01 .

Here, degree U , degree C , and degree T denote the polynomial degrees of the blocks that param-eterize U (x, y ), C(x, y ), and T (x, y ), respectively. Lists indicate both the number of blocks and each block’s degree: degree U = [2] means a single quadratic block for U , degree C = [2 , 2, 2] 

means three quadratic constraint blocks, and degree T = [2 , 2] means two quadratic belief blocks. σparams initializes coefficients of all polynomial blocks, while σλ0 , σλ1 , and σλ2 ini-tialize the UMP weights (λ0, λ 1, λ 2). The search grid is reported in Table 6. • BL(Shallow): We use global gradient clipping of 1.0 and an early stopping patience of 20 epochs without validation improvement. Shallow architectures with depth L ≤ 3 are considered. The search grid is reported in Table 7. 

Baseline Model Hyperparameter Spaces. For baseline models, we also consider both Adam and AdamW for the neural network–based variants, and report results with the better-performing optimizer on each dataset. Batch sizes are tuned separately for each dataset. The detailed hyperpa-rameter search spaces are summarized in Table 8. Table 6: Hyperparameter tuning space for BL(Single) 

Model Parameter Search space 

BL(Single) 

learning rate {1e −3, 1e −1}

batch size {64, 128, 256, 512 }

max grad norm {1.0, 2.0, 5.0 }

Table 7: Hyperparameter tuning space for BL(Shallow) 

Model Parameter Search space 

BL(Shallow) 

learning rate LogUniform {5e −5, 5e −3}

batch size {64, 128, 256, 512 }

n layers UniformInt {1, 3 }

n first layer {24, 30, 36, 40 }

n middle layer {8, 6, 4 }

n last layer {2, 4, 6 }

weight decay LogUniform {1e −4, 1e −1}

Table 8: The hyperparameter tuning space for baseline models used in the standard prediction tasks 

Model Parameter Search space 

MLP 

learning rate LogUniform {1e −5, 1e −1}

batch size {32, 64, 128, 256 }

n layers UniformInt {2, 4 }

hidden size UniformInt {32, 256 }

weight decay LogUniform {1e −6, 1e −2}

42 International Conference on Learning Representations (ICLR) 2026 

Model Parameter Search space 

NAM 

learning rate LogUniform {1e −3, 1e −1}

batch size {128, 256, 512, 1024 }

patience UniformInt {10, 30 }

ElasticNet (SGD) 

alpha LogUniform {1e −4, 1e +2 }

l1 ratio Uniform {0.0, 1.0 }

max iter UniformInt {100, 2000 }

tol LogUniform {1e −6, 1e −2}

fit intercept {true, false }

learning rate {optimal, constant, invscaling, adaptive }

eta0 LogUniform {1e −4, 1e −1}

validation fraction Uniform {0.05, 0.30 }

n iter no change UniformInt {3, 20 }

PolyLogistic 

degree {2, 3 }

penalty {ℓ2, ℓ1, ”elasticnet” }

C LogUniform {1e −3, 1e +2 }

l1 ratio Uniform {0.1, 0.9 }

solver {”liblinear”, ”lbfgs”, “newton-cg”, “saga” }

max iter UniformInt {500, 2000 }

tol LogUniform {1e −5, 1e −3}

Logistic (ElasticNet) 

C LogUniform {1e −3, 1e +2 }

l1 ratio Uniform {0.0, 1.0 }

max iter UniformInt {100, 2000 }

tol LogUniform {1e −6, 1e −2}

fit intercept {true, false }

LogisticRegression 

solver {”liblinear”, ”lbfgs”, ”sag” }

C LogUniform {1e −4, 1e +2 }

max iter UniformInt {100, 2000 }

tol LogUniform {1e −6, 1e −2}

fit intercept {True, False }

intercept scaling Uniform {0.1, 10.0 }

TabNet 

learning rate LogUniform {1e −4, 3e −2}

batch size {128, 256, 512, 1024 }

virtual batch size {64, 128 }

n d =n a UniformInt {16, 64 }

n steps UniformInt {3, 7 }

gamma Uniform {1.2, 1.7 }

lambda sparse LogUniform {1e −6, 1e −3}

DecisionTree 

criterion {”gini”, ”entropy”, ”log loss” }

max depth UniformInt {3, 20 }

min samples split UniformInt {2, 20 }

min samples leaf UniformInt {1, 10 }

min weight fraction leaf Uniform {0.0, 0.5 }

max features {”sqrt”, ”log2” }

max leaf nodes UniformInt {10, 1000 }

min impurity decrease Uniform {0.0, 0.1 }

ccp alpha Uniform {0.0, 0.1 }

GP (SVGP) 

kernel {rbf, matern, rational quadratic }

lengthscale LogUniform {0.1, 10.0 }

rq alpha LogUniform {0.1, 5.0 }

num inducing UniformInt {100, 500 }

learning rate LogUniform {1e −2, 5e −1}

training iters UniformInt {50, 200 }

RandomForest 

n estimators UniformInt {100, 500 }

43 International Conference on Learning Representations (ICLR) 2026 

Model Parameter Search space 

max depth UniformInt {3, 30 }

max features {”sqrt”, ”log2” }

min samples leaf UniformInt {1, 10 }

min samples split UniformInt {2, 20 }

C.3 INTERPRETING BL: A C ASE STUDY 

C.3.1 INTERPRETING BL(D EEP ): H IGH -L EVEL OVERVIEW 

Deeper variants of BL are constructed by stacking multiple BL(Single) modules into hierarchical layers, followed by a final affine transformation. This forms a system of interacting UMPs (each of which can be viewed as an agent), where each internal block B represents a single interpretable UMP. As shown in Figure 4, first-layer modules correspond to individual UMPs, while the second-layer module performs optimal coordination by aggregating or allocating their outputs. This layered structure offers a compositional interpretation of deeper BL models as systems of interacting, inter-pretable UMPs. C.3.2 CASE STUDY : A DDITIONAL DETAILS 

Table 9: Boston Housing dataset variables and descriptions. 

Variable Description 

CRIM Per-capita crime rate by town ZN Proportion of residential land zoned for lots over 25,000 sq.ft. INDUS Proportion of non-retail business acres per town CHAS Charles River dummy variable (=1 if tract bounds river) NOX Nitric oxide concentration (parts per 10 million) RM Average number of rooms per dwelling AGE Proportion of owner-occupied units built prior to 1940 DIS Weighted distances to five Boston employment centers RAD Index of accessibility to radial highways TAX Full-value property-tax rate per $10,000 PTRATIO Pupil–teacher ratio by town B 1000( Bk − 0.63) 2 where Bk is the proportion of Black residents by town LSTAT Percentage of lower-status population MEDV Median value of owner-occupied homes in $1000s 

44 International Conference on Learning Representations (ICLR) 2026 Table 10: Semantic roles of blocks in the deep BL architecture. 

Layer Block Representative preference 

Layer 1 Location-Sensitive Buyer Values river access, transport accessibility, and neighbor-hood amenities. Risk-Sensitive Buyer Averse to local disamenities such as pollution and envi-ronmental risk. Economic-Sensitive Buyer Sensitive to school quality and neighborhood socio-economic composition. Zoning-Contrast Buyer Responds to zoning and land-use patterns that shape local housing supply. Affordability-Preferring Buyer Strongly prefers more affordable housing and dislikes high prices. Layer 2 Integrated Location–Economic Buyer Jointly evaluates location and socio-economic attributes in an integrated way. Budget-Conflict Buyer Exhibits strong preferences for desirable locations but faces binding budget constraints. Balanced Trade-off Buyer Jointly considers multiple housing attributes in a balanced manner. Layer 3 Representative Composite Buyer Aggregates all lower-level preference components into a representative household. 

Table 11: Each block in the deep BL architecture is aligned with a classic preference mechanism documented in the economics literature. 

Layer / Block Representative reference 

Layer 1: Location-Sensitive Buyer Gibbons & Machin (2005) Layer 1: Risk-Sensitive Buyer Chay & Greenstone (2005) Layer 1: Economic-Sensitive Buyer Black (1999) Layer 1: Zoning-Contrast Buyer Glaeser & Gyourko (2002) Layer 1: Affordability-Preferring Buyer McFadden (1977) Layer 2: Integrated Location–Economic Buyer Bayer et al. (2007) Layer 2: Budget-Conflict Buyer Balseiro et al. (2019) Layer 2: Balanced Trade-off Buyer Rosen (1974) 

45 International Conference on Learning Representations (ICLR) 2026 C.4 PREDICTION ON HIGH -D IMENSIONAL INPUTS 

Datasets Description and Preprocessing. For image datasets, we use the official train/test splits of MNIST and Fashion-MNIST: Inputs are converted to single-channel images scaled to [0 , 1] and standardized with dataset-specific statistics. No resizing or data augmentation is applied. Training uses shuffled mini-batches of size 64 . For text datasets, we apply the following procedures: 1 Data sources and official splits. We use the official training and test splits for AG News and Yelp Review Polarity without any custom re-partitioning. Both datasets are class-balanced across labels, and we do not perform any resampling. 2 Dataset sizes. AG News: 120,000 training / 7,600 test samples with four balanced classes. Yelp Review Polarity: 560,000 training / 38,000 test samples with two balanced classes. 3 Label mapping. AG News: labels 1–4 are mapped to 0–3. Yelp Review Polarity: labels 1–2 are mapped to 0–1. 4 Text preprocessing and feature representation. All texts are lowercased and tokenized at the word level. The vocabulary is built with unigrams and bigrams, discarding words that appear fewer than two times in the training corpus. The vocabulary size is capped (AG News: 200,000; Yelp: 100,000). We compute TF–IDF weights on the training split and apply the learned weights to the test split. Dimensionality is reduced to 128 latent components using truncated singular value decomposition (SVD). Features are standardized to zero mean and unit variance and finally ℓ2-normalized. We fix the random seed for reproducibility and reuse the learned preprocessing components across runs. 

Additional OOD Detection Results. In addition to accuracy and AUROC, we also report AUPR and FPR@95 for both image and text datasets; the results are shown in Table 12. On image datasets, BL (depth=1) achieves the best overall balance: it ranks first on Fashion-MNIST AUPR and second on Fashion-MNIST FPR@95. On MNIST, it is second in AUPR but underperforms in FPR@95 compared with E-MLP (depth=2). These results suggest that BL yields separable score distributions, particularly on Fashion-MNIST, although its 95% FPR threshold admits more OOD samples than E-MLP at the same recall. On text datasets, OOD detection performance is dataset-dependent: E-MLP performs better on AG News, whereas BL achieves stronger OOD performance on Yelp. Table 12: OOD AUPR and FPR@95 (%) on image and text datasets. BL and E-MLP are evaluated at depths 1–3 with matched parameter counts, both without skip connections. Top-two per column are blue and red. 

Model MNIST Fashion-MNIST 

AUPR FPR@95 AUPR FPR@95 E-MLP (depth=1) 89.37 ± 1.52 35.57 ± 5.87 91.35 ± 1.25 28.24 ± 4.37 

BL (depth=1) 91.57 ± 2.39 47.81 ± 11.29 91.79 ± 0.90 38.86 ± 2.57 

E-MLP (depth=2) 91.52 ± 1.27 28.89 ± 2.85 86.19 ± 2.27 47.72 ± 4.79 

BL (depth=2) 91.20 ± 1.22 52.71 ± 18.66 89.30 ± 2.47 42.65 ± 9.53 

E-MLP (depth=3) 90.04 ± 1.89 31.92 ± 5.76 84.30 ± 1.50 54.49 ± 2.74 

BL (depth=3) 92.36 ± 2.03 32.32 ± 5.76 88.41 ± 4.04 41.19 ± 13.36 

Model AG News Yelp 

AUPR FPR@95 AUPR FPR@95 E-MLP (depth=1) 44.52 ± 15.10 33.82 ± 4.89 3.31 ± 1.60 54.21 ± 2.11 

BL (depth=1) 18.68 ± 16.48 42.03 ± 5.99 12.70 ± 2.29 40.95 ± 1.56 

E-MLP (depth=2) 31.48 ± 23.94 40.20 ± 9.82 1.47 ± 2.31 57.80 ± 4.88 

BL (depth=2) 10.76 ± 15.94 53.71 ± 9.68 6.73 ± 2.61 46.54 ± 1.86 

E-MLP (depth=3) 51.24 ± 9.13 32.96 ± 3.23 3.14 ± 2.22 55.24 ± 5.33 

BL (depth=3) 16.99 ± 17.12 45.24 ± 6.11 10.96 ± 1.10 42.27 ± 1.94 

46 International Conference on Learning Representations (ICLR) 2026 

Number of Parameters. To ensure a fair comparison between E-MLP and BL, we match the number of trainable parameters as closely as possible for models with the same depth (see Table 13). 

Running Time. To evaluate computational cost, we compare the training time of BL and Energy-based MLP across image and text datasets (Table 3). Under comparable parameter budgets, BL generally requires slightly higher training time than E-MLP across datasets. In particular, BL is moderately slower on image datasets and AG News, while exhibiting comparable running time on Yelp. 

Calibration We report ECE and NLL metrics to assess calibration quality, and the results are presented in Table 2. On image datasets, BL provides substantially better calibration, with BL models occupying the top two positions in each column. On text datasets, calibration performance is broadly comparable, with BL showing slightly lower NLL on Yelp. Overall, these results indicate that BL delivers strong predictive performance together with reliable probability estimates. Table 13: Number of trainable parameters for E-MLP and BL models across high-dimension datasets. 

Dataset Model # Parameters 

MNIST & FashionMNIST E-MLP (depth=1) 203,530 BL (depth=1) 208,384 E-MLP (depth=2) 235,146 BL (depth=2) 219,264 E-MLP (depth=3) 238,314 BL (depth=3) 221,684 AGNews E-MLP (depth=1) 136,196 BL (depth=1) 149,720 E-MLP (depth=2) 386,284 BL (depth=2) 397,568 E-MLP (depth=3) 230,788 BL (depth=3) 224,128 Yelp E-MLP (depth=1) 134,146 BL (depth=1) 148,960 E-MLP (depth=2) 385,770 BL (depth=2) 397,312 E-MLP (depth=3) 230,530 BL (depth=3) 224,000 C.5 CASE STUDY : E STIMATION RESULTS OF BL ON THE BOSTON HOUSING DATASET 

47 International Conference on Learning Representations (ICLR) 2026 Table 14: Estimated UMP block parameters learned by the BL model (layer = [2, 1]) on the Boston Housing dataset. For each block, U denotes the Utility component, C the Inequality-Constraint component, and T the Equality-Constraint component. 

Block 11 Block 12 Variable U11 C11 T11 U12 C12 T12 

λ 1.003 0.997 0.999 0.997 1.003 1.000 per capita crime rate (CRIM) 0.21 0.14 0.03 0.12 0.09 0.25 residential land proportion (ZN) 0.23 -0.04 -0.27 0.25 0.00 0.09 non-retail business acreage (INDUS) -0.06 0.21 0.25 0.16 0.22 0.27 Charles River dummy (CHAS) 0.25 0.04 -0.24 -0.12 -0.20 -0.23 nitric oxide concentration (NOX) -0.06 -0.13 0.21 0.16 0.02 -0.28 average rooms per dwelling (RM) 0.06 0.07 0.05 0.05 -0.19 -0.22 proportion of older units (AGE) -0.13 -0.12 -0.09 0.14 0.08 -0.18 distance to employment centres (DIS) 0.16 -0.03 0.17 -0.17 -0.09 0.11 radial highway accessibility (RAD) 0.24 -0.11 0.04 -0.28 0.09 0.10 property tax rate (TAX) -0.20 0.18 0.22 -0.11 -0.06 0.23 low-income population (LSTAT) 0.05 -0.12 -0.09 0.23 -0.16 -0.19 median home value (MEDV) 0.21 -0.08 0.07 0.08 -0.17 0.15 Constant term (C) 0.03 -0.17 -0.07 0.11 -0.16 -0.12 

Block 21 Variable U21 C21 T21 

λ 1.000 1.003 0.999 Block 11 output ( b1,1) 0.428 -0.551 0.147 Block 12 output ( b1,2) -0.168 -0.356 -0.178 Constant term (C) 0.406 0.219 0.421 

48 International Conference on Learning Representations (ICLR) 2026 Table 15: Estimated UMP parameters for the Layer 1 blocks of the BL model (layer = [5, 3, 1]) trained on the Boston Housing dataset. Here, U denotes the Utility component, C the Inequality-Constraint component, and T the Equality-Constraint component. 

Variable U11 U12 U13 U14 U15 

λ 1.000 0.998 1.003 1.002 1.000 per capita crime rate (CRIM) 0.21 0.12 0.17 -0.09 0.06 residential land proportion (ZN) 0.23 0.25 -0.07 -0.22 -0.16 non-retail business acreage (INDUS) -0.06 0.16 0.16 0.23 -0.14 Charles River dummy (CHAS) 0.25 -0.12 -0.22 -0.05 -0.01 nitric oxide concentration (NOX) -0.06 0.16 -0.14 0.24 0.16 average rooms per dwelling (RM) 0.05 0.05 0.08 0.09 -0.07 proportion of older units (AGE) -0.13 0.14 0.06 -0.23 -0.15 distance to employment centres (DIS) 0.16 -0.17 -0.07 0.19 -0.10 radial highway accessibility (RAD) 0.24 -0.27 0.17 -0.08 -0.20 property tax rate (TAX) -0.20 -0.11 0.19 -0.11 0.10 low-income population (LSTAT) 0.05 0.23 -0.15 -0.28 -0.26 median home value (MEDV) 0.21 0.08 0.25 0.08 0.06 Constant term (C) 0.03 0.12 -0.09 -0.06 0.15 

C11 C12 C13 C14 C15 

λ 0.999 1.001 1.000 0.997 1.002 per capita crime rate (CRIM) 0.13 0.09 -0.10 0.11 0.05 residential land proportion (ZN) -0.04 -0.01 -0.27 -0.23 -0.10 non-retail business acreage (INDUS) 0.21 0.22 -0.16 0.20 0.15 Charles River dummy (CHAS) 0.04 -0.19 0.07 -0.20 0.15 nitric oxide concentration (NOX) -0.13 0.02 -0.04 -0.05 0.11 average rooms per dwelling (RM) 0.07 -0.19 -0.20 0.06 -0.05 proportion of older units (AGE) -0.13 0.08 0.01 0.14 -0.07 distance to employment centres (DIS) -0.03 -0.09 -0.19 0.22 0.03 radial highway accessibility (RAD) -0.11 0.08 -0.23 0.25 -0.05 property tax rate (TAX) 0.18 -0.06 -0.15 -0.22 -0.08 low-income population (LSTAT) -0.13 -0.17 -0.18 -0.12 0.24 median home value (MEDV) -0.08 -0.17 0.28 -0.03 -0.03 Constant term (C) -0.17 -0.16 0.05 -0.21 -0.06 

T11 T12 T13 T14 T15 

λ 0.999 1.002 0.999 1.004 1.001 per capita crime rate (CRIM) 0.03 0.25 0.08 0.25 0.00 residential land proportion (ZN) -0.27 0.10 -0.26 -0.20 -0.02 non-retail business acreage (INDUS) 0.25 0.26 -0.18 0.15 0.07 Charles River dummy (CHAS) -0.23 -0.23 -0.09 0.10 0.08 nitric oxide concentration (NOX) 0.21 -0.28 0.04 0.09 -0.25 average rooms per dwelling (RM) 0.05 -0.21 -0.24 -0.15 -0.10 proportion of older units (AGE) -0.09 -0.19 -0.12 0.26 0.24 distance to employment centres (DIS) 0.17 0.12 -0.17 0.06 0.10 radial highway accessibility (RAD) 0.04 0.10 0.00 0.04 -0.01 property tax rate (TAX) 0.22 0.23 -0.10 -0.24 -0.17 low-income population (LSTAT) -0.09 -0.19 -0.19 -0.04 -0.25 median home value (MEDV) 0.08 0.15 -0.19 -0.13 -0.09 Constant term (C) -0.07 -0.11 -0.16 0.24 0.10 

49 International Conference on Learning Representations (ICLR) 2026 Table 16: Layer 2 and Layer 3 UMP parameters ( U , C, T ) for Blocks in the BL model (layer = [5, 3, 1]). 

Block 21 Block 22 Block 23 Variable U21 C21 T21 U22 C22 T22 U23 C23 T23 

λ 1.000 1.000 1.000 0.999 1.003 1.002 1.001 1.002 0.999 Block 11 output ( b1,1) 0.28 0.06 -0.20 -0.31 0.24 0.18 -0.29 -0.08 0.22 Block 12 output ( b1,2) 0.21 -0.11 -0.09 -0.44 0.12 -0.22 0.15 -0.22 0.20 Block 13 output ( b1,3) -0.40 0.18 -0.44 -0.36 -0.01 -0.09 -0.13 -0.14 0.32 Block 14 output ( b1,4) -0.27 -0.17 0.30 0.33 -0.34 -0.26 0.28 -0.42 -0.34 Block 15 output ( b1,5) -0.07 -0.29 0.34 0.22 -0.38 -0.08 -0.14 0.25 0.32 Constant term (C) 0.43 0.33 0.16 0.38 -0.42 -0.32 -0.33 -0.31 -0.21 

Variable U31 C31 T31 

λ 1.002 0.998 1.000 Block 21 output ( b2,1) 0.21 -0.13 0.36 Block 22 output ( b2,2) 0.54 -0.48 0.43 Block 23 output ( b2,3) -0.08 0.28 0.55 Constant term (C) -0.01 -0.58 -0.14 

50