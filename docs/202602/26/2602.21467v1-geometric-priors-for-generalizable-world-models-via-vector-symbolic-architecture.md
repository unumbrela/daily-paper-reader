---
title: Geometric Priors for Generalizable World Models via Vector Symbolic Architecture
title_zh: 基于向量符号架构的可泛化世界模型几何先验
authors: "William Youngwoo Chung, Calvin Yeung, Hansen Jin Lillemark, Zhuowen Zou, Xiangjian Liu, Mohsen Imani"
date: 2026-02-25
pdf: "https://arxiv.org/pdf/2602.21467v1"
tags: ["query:sr"]
score: 6.0
evidence: 用于世界模型和转移函数的向量符号架构
tldr: 针对传统世界模型因缺乏结构化先验而导致泛化性与可解释性差的问题，本文提出一种基于向量符号架构（VSA）几何先验的通用世界模型。该模型利用可学习的傅里叶全息简化表示（FHRR）将状态和动作映射到具有群结构的复向量空间，并通过元素级复数乘法建模状态转移。实验表明，该方法在零样本泛化、长程预测及抗噪性方面显著优于传统MLP模型，为构建高效、可解释的规划与推理模型提供了新路径。
motivation: 传统世界模型通常使用非结构化神经网络，限制了其在未见状态或动作组合下的泛化能力、样本效率及可解释性。
method: 采用傅里叶全息简化表示（FHRR）编码器将状态与动作映射至高维复向量空间，并利用群论基础通过元素级复数乘法实现潜在空间的动力学演化。
result: "在离散网格世界中，该模型实现了87.5%的零样本准确率，在20步长程预测中准确率提升53.6%，且抗噪能力是MLP基准的4倍。"
conclusion: 通过引入潜在群结构几何先验，可以构建出具有强泛化性、高数据效率且具备可解释性的世界模型。
---

## 摘要
人工智能和神经科学领域的一个关键挑战是理解神经系统如何学习能够捕捉世界底层动力学的表示。大多数世界模型使用无结构神经网络来表示转移函数，这限制了可解释性、样本效率以及对未见状态或动作组合的泛化能力。我们通过一种以向量符号架构（VSA）原理作为几何先验的可泛化世界模型来解决这些问题。我们的方法利用可学习的傅里叶全息简化表示（FHRR）编码器，将状态和动作映射到具有学习到的群结构的高维复向量空间中，并使用逐元素复数乘法对转移进行建模。我们形式化了该框架的群论基础，并展示了如何通过训练此类结构化表示使其具有近似不变性，从而直接在潜空间中实现强大的多步组合能力，并在各种实验中表现出优异的泛化性能。在离散网格世界环境中，我们的模型在未见过的状态-动作对上实现了 87.5% 的零样本准确率，在 20 个时间步长的预测中准确率提高了 53.6%，并且相对于 MLP 基准模型，其抗噪鲁棒性提高了 4 倍。这些结果强调了通过训练获得潜群结构如何产生可泛化、数据高效且可解释的世界模型，为构建用于现实世界规划和推理的结构化模型提供了一条有原则的路径。

## Abstract
A key challenge in artificial intelligence and neuroscience is understanding how neural systems learn representations that capture the underlying dynamics of the world. Most world models represent the transition function with unstructured neural networks, limiting interpretability, sample efficiency, and generalization to unseen states or action compositions. We address these issues with a generalizable world model grounded in Vector Symbolic Architecture (VSA) principles as geometric priors. Our approach utilizes learnable Fourier Holographic Reduced Representation (FHRR) encoders to map states and actions into a high dimensional complex vector space with learned group structure and models transitions with element-wise complex multiplication. We formalize the framework's group theoretic foundation and show how training such structured representations to be approximately invariant enables strong multi-step composition directly in latent space and generalization performances over various experiments. On a discrete grid world environment, our model achieves 87.5% zero shot accuracy to unseen state-action pairs, obtains 53.6% higher accuracy on 20-timestep horizon rollouts, and demonstrates 4x higher robustness to noise relative to an MLP baseline. These results highlight how training to have latent group structure yields generalizable, data-efficient, and interpretable world models, providing a principled pathway toward structured models for real-world planning and reasoning.