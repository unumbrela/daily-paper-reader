---
title: Adaptive Collaboration of Arena-Based Argumentative LLMs for Explainable and Contestable Legal Reasoning
title_zh: 基于竞技场辩论式大语言模型的自适应协作，用于可解释且可质疑的法律推理
authors: "Hoang-Loc Cao, Phuc Ho, Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Dinh Thien Loc Nguyen, Hung Cao"
date: 2026-02-21
pdf: "https://arxiv.org/pdf/2602.18916v1"
tags: ["query:sr"]
score: 6.0
evidence: 用于可解释推理的神经符号框架
tldr: 针对法律推理中解释性与可质疑性不足的问题，本文提出ACAL框架。该框架结合了神经符号方法与竞技场量化双极论证框架（A-QBAF），通过多智能体协作构建论证图谱，并引入冲突解决与不确定性升级机制。ACAL支持人类干预，允许用户审计和修改推理逻辑。在LegalBench上的实验证明，该方法在保持高预测性能的同时，显著提升了法律判决的透明度与可质疑性。
motivation: 现有的LLM法律推理方法生成的解释往往缺乏结构化验证机制，且难以让用户进行有效的干预和质疑。
method: 提出ACAL框架，利用多智能体协作构建基于竞技场的量化双极论证框架（A-QBAF），并集成冲突解决与人机协同工作流。
result: 在LegalBench基准测试中，ACAL在Gemini系列模型上均优于强基准模型，有效平衡了预测准确性与结构化透明度。
conclusion: ACAL通过将论证理论与LLM结合，为构建可解释且可质疑的法律人工智能系统提供了一种有效的神经符号化方案。
---

## 摘要
法律推理不仅需要高准确性，还需要能够通过可验证且可质疑的论据来证明决策的合理性。然而，现有的大语言模型（LLM）方法，如思维链（CoT）和检索增强生成（RAG），通常产生非结构化的解释，缺乏正式的验证或用户干预机制。为解决这一局限性，我们提出了辩论式大语言模型的自适应协作（ACAL），这是一种将自适应多智能体协作与基于竞技场的定量双极论证框架（A-QBAF）相结合的神经符号框架。ACAL 动态部署专家智能体团队来构建论据，采用冲突解决机制来裁定相互矛盾的主张，并针对边缘案例利用不确定性感知升级机制。至关重要的是，我们的框架支持人机回环（HITL）可质疑性工作流，使用户能够直接审计和修改底层的推理图，从而影响最终判决。在 LegalBench 基准测试上的实证评估表明，ACAL 在 Gemini-2.5-Flash-Lite 和 Gemini-2.5-Flash 架构上均优于强基准模型，有效地平衡了高效的预测性能与结构化的透明度和可质疑性。我们的实现代码可在以下网址获取：https://github.com/loc110504/ACAL。

## Abstract
Legal reasoning requires not only high accuracy but also the ability to justify decisions through verifiable and contestable arguments. However, existing Large Language Model (LLM) approaches, such as Chain-of-Thought (CoT) and Retrieval-Augmented Generation (RAG), often produce unstructured explanations that lack a formal mechanism for verification or user intervention. To address this limitation, we propose Adaptive Collaboration of Argumentative LLMs (ACAL), a neuro-symbolic framework that integrates adaptive multi-agent collaboration with an Arena-based Quantitative Bipolar Argumentation Framework (A-QBAF). ACAL dynamically deploys expert agent teams to construct arguments, employs a clash resolution mechanism to adjudicate conflicting claims, and utilizes uncertainty-aware escalation for borderline cases. Crucially, our framework supports a Human-in-the-Loop (HITL) contestability workflow, enabling users to directly audit and modify the underlying reasoning graph to influence the final judgment. Empirical evaluations on the LegalBench benchmark demonstrate that ACAL outperforms strong baselines across Gemini-2.5-Flash-Lite and Gemini-2.5-Flash architectures, effectively balancing efficient predictive performance with structured transparency and contestability. Our implementation is available at: https://github.com/loc110504/ACAL.