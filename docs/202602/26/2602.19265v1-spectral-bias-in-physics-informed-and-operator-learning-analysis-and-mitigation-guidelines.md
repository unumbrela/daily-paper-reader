---
title: "Spectral bias in physics-informed and operator learning: Analysis and mitigation guidelines"
title_zh: 物理信息与算子学习中的光谱偏差：分析与缓解指南
authors: "Siavash Khodakarami, Vivek Oommen, Nazanin Ahmadi Daryakenari, Maxim Beekenkamp, George Em Karniadakis"
date: 2026-02-22
pdf: "https://arxiv.org/pdf/2602.19265v1"
tags: ["query:sr"]
score: 6.0
evidence: 用于偏微分方程发现的物理信息神经网络与KAN网络
tldr: 本研究针对物理信息神经网络（PINNs）、PIKANs及神经算子在求解偏微分方程时存在的“谱偏差”现象（即优先学习低频成分）进行了系统性分析。通过频率解析误差指标和Barron范数诊断，探讨了架构、激活函数、损失函数及优化策略对谱偏差的影响。研究发现谱偏差本质上是动态的，并提出利用二阶优化方法和谱感知损失函数来有效缓解该问题，从而加速高频模式的恢复并提升模型精度。
motivation: 旨在深入理解物理信息学习中谱偏差与优化动力学、损失函数设计及网络架构之间的复杂相互作用机制。
method: 采用频率解析误差、Barron范数及高阶统计矩，对多种PDE类型（如KdV、波动方程等）下的不同网络架构和优化策略进行量化评估。
result: 实验证明二阶优化方法能显著改变学习顺序并加速高频模式恢复，且神经算子的谱偏差可通过谱感知损失函数在不增加推理成本的情况下得到缓解。
conclusion: 谱偏差不仅是表示能力的限制，更是动态优化过程的结果，通过合理的优化策略和损失函数设计可有效提升模型对复杂物理场的捕捉能力。
---

## 摘要
已知利用神经网络以及 Kolmogorov-Arnold 网络 (KANs) 求解偏微分方程 (PDEs)，包括物理信息神经网络 (PINNs)、物理信息 KANs (PIKANs) 和神经算子，会表现出光谱偏差（spectral bias），即解的低频分量学习速度显著快于高频模式。虽然光谱偏差通常被视为神经架构固有的表示局限性，但其与优化动力学及基于物理的损失函数公式之间的相互作用仍不为人所知。在这项工作中，我们对物理信息和算子学习框架中的光谱偏差进行了系统研究，重点关注网络架构、激活函数、损失设计和优化策略的耦合作用。我们通过频率分辨误差指标、Barron 范数诊断和高阶统计矩来量化光谱偏差，从而实现了对椭圆型、双曲型和色散型 PDE 的统一分析。通过包括 Korteweg-de Vries 方程、波动方程和稳态扩散-反应方程、湍流重建以及地震动力学在内的多种基准问题，我们证明了光谱偏差不仅是表示性的，而且从根本上是动力学性的。特别是，二阶优化方法显著改变了光谱学习顺序，使所有类型的 PDE 都能更早、更准确地恢复高频模式。对于神经算子，我们进一步表明光谱偏差取决于神经算子架构，并且可以通过光谱感知损失公式有效缓解，而不会增加推理成本。

## Abstract
Solving partial differential equations (PDEs) by neural networks as well as Kolmogorov-Arnold Networks (KANs), including physics-informed neural networks (PINNs), physics-informed KANs (PIKANs), and neural operators, are known to exhibit spectral bias, whereby low-frequency components of the solution are learned significantly faster than high-frequency modes. While spectral bias is often treated as an intrinsic representational limitation of neural architectures, its interaction with optimization dynamics and physics-based loss formulations remains poorly understood. In this work, we provide a systematic investigation of spectral bias in physics-informed and operator learning frameworks, with emphasis on the coupled roles of network architecture, activation functions, loss design, and optimization strategy. We quantify spectral bias through frequency-resolved error metrics, Barron-norm diagnostics, and higher-order statistical moments, enabling a unified analysis across elliptic, hyperbolic, and dispersive PDEs. Through diverse benchmark problems, including the Korteweg-de Vries, wave and steady-state diffusion-reaction equations, turbulent flow reconstruction, and earthquake dynamics, we demonstrate that spectral bias is not simply representational but fundamentally dynamical. In particular, second-order optimization methods substantially alter the spectral learning order, enabling earlier and more accurate recovery of high-frequency modes for all PDE types. For neural operators, we further show that spectral bias is dependent on the neural operator architecture and can also be effectively mitigated through spectral-aware loss formulations without increasing the inference cost.