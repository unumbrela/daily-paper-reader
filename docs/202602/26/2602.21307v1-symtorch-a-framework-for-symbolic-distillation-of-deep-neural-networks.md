---
title: "SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks"
title_zh: SymTorch：深度神经网络符号蒸馏框架
authors: "Elizabeth S. Z. Tan, Adil Soubki, Miles Cranmer"
date: 2026-02-24
pdf: "https://arxiv.org/pdf/2602.21307v1"
tags: ["query:sr"]
score: 10.0
evidence: 使用PySR进行物理定律的符号蒸馏
tldr: SymTorch 是一个旨在简化深度神经网络符号蒸馏的框架。它通过集成 PySR，自动将复杂的神经组件替换为可解释的数学表达式，解决了 GPU-CPU 数据传输和模型序列化等工程障碍。该框架支持 GNN、PINN 和 Transformer 等多种架构，不仅能发现物理规律，还能通过符号替代提升 LLM 的推理效率，为构建可解释且高效的模型提供了有力工具。
motivation: 尽管符号蒸馏在发现物理规律方面具有潜力，但由于将符号回归集成到深度学习工作流中存在巨大的工程障碍，其应用受到限制。
method: SymTorch 通过包装神经网络组件、自动收集输入输出数据并利用 PySR 生成人类可读的等式，实现了神经与符号前馈路径的无缝切换。
result: "实验证明 SymTorch 适用于多种架构，并在 LLM 推理中通过符号化 MLP 层实现了 8.3% 的吞吐量提升。"
conclusion: SymTorch 降低了符号蒸馏的技术门槛，为深度学习模型的可解释性研究和推理加速提供了高效的自动化方案。
---

## 摘要
符号蒸馏通过可解释的、闭式数学表达式来替换神经网络或其组件。这种方法在直接从训练好的深度学习模型中发现物理定律和数学关系方面展现出潜力，但由于将符号回归集成到深度学习工作流中存在工程障碍，其应用仍然受限。我们推出了 SymTorch，这是一个通过封装神经网络组件、收集其输入输出行为并利用 PySR 将其近似为人类可读方程来自动化该蒸馏过程的库。SymTorch 解决了阻碍应用的工程挑战：GPU-CPU 数据传输、输入输出缓存、模型序列化以及神经前向传递与符号前向传递之间的无缝切换。我们在包括图神经网络 (GNN)、物理信息神经网络 (PINN) 和 Transformer 模型在内的多种架构上演示了 SymTorch。最后，我们提出了一个通过用符号代理替换 MLP 层来加速大语言模型 (LLM) 推理的概念验证，在性能适度下降的情况下实现了 8.3% 的吞吐量提升。

## Abstract
Symbolic distillation replaces neural networks, or components thereof, with interpretable, closed-form mathematical expressions. This approach has shown promise in discovering physical laws and mathematical relationships directly from trained deep learning models, yet adoption remains limited due to the engineering barrier of integrating symbolic regression into deep learning workflows. We introduce SymTorch, a library that automates this distillation by wrapping neural network components, collecting their input-output behavior, and approximating them with human-readable equations via PySR. SymTorch handles the engineering challenges that have hindered adoption: GPU-CPU data transfer, input-output caching, model serialization, and seamless switching between neural and symbolic forward passes. We demonstrate SymTorch across diverse architectures including GNNs, PINNs and transformer models. Finally, we present a proof-of-concept for accelerating LLM inference by replacing MLP layers with symbolic surrogates, achieving an 8.3\% throughput improvement with moderate performance degradation.

---

## 论文详细总结（自动生成）

以下是对论文《SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks》的结构化深入总结：

### 1. 核心问题与研究动机
*   **核心问题**：深度学习模型（如大语言模型、物理模拟网络）虽然性能强大，但其内部机制如同“黑盒”，难以解释。符号回归（Symbolic Regression, SR）虽能将模型转化为可读的数学公式，但在实际应用中存在巨大的**工程障碍**，如 GPU-CPU 数据传输复杂、激活值缓存困难、模型序列化不兼容以及神经/符号组件切换不便。
*   **研究动机**：开发一个名为 **SymTorch** 的自动化框架，将符号回归无缝集成到 PyTorch 工作流中，使研究人员能够轻松地对神经网络组件进行“符号蒸馏”，从而发现物理定律、解释模型行为或加速推理。

### 2. 方法论
*   **核心思想**：通过包装（Wrapping）神经网络组件，自动收集其输入输出（I/O）数据，并利用 `PySR` 库（基于遗传算法）搜索最优的闭式数学表达式来近似该组件的功能。
*   **关键技术细节**：
    *   **SymbolicModel 包装器**：继承自 `nn.Module`，可包裹任意 PyTorch 模块或函数。
    *   **自动化流程**：注册前向钩子（Forward Hooks）记录激活值 -> 自动处理 GPU 到 CPU 的数据转移 -> 调用 PySR 进行多群体进化搜索 -> 生成帕累托前沿（Pareto front）方程。
    *   **混合模型切换**：支持 `switch_to_symbolic` 操作，在推理时直接用数学公式替换原有的神经层，并支持 `torch.compile` 优化。
    *   **SLIME 实现**：内置了“超局部可解释模型无关说明”（SLIME），通过在特定点周围采样并拟合符号方程来解释黑盒模型的局部行为。
    *   **降维集成**：针对高维输入（如 LLM 的 MLP 层），集成 PCA 降维技术，使符号回归在计算上可行。

### 3. 实验设计
论文设计了四个具有代表性的案例研究：
*   **LLM 推理加速**：
    *   **场景**：替换 Qwen2.5-1.5B 模型中的部分 MLP 层。
    *   **Benchmark**：Wikitext-2 数据集上的困惑度（Perplexity）与令牌吞吐量（Throughput）。
    *   **对比**：基准模型、PCA+MLP 压缩模型、恒等函数替换（Control）。
*   **物理定律发现**：
    *   **场景**：使用图神经网络（GNN）模拟粒子动力学（引力、弹力等）。
    *   **目标**：从训练好的 GNN 边函数中恢复出 $1/r^2$ 或 $k\Delta x$ 等物理公式。
*   **PDE 解提取**：
    *   **场景**：使用物理信息神经网络（PINN）求解一维热传导方程。
    *   **对比**：标准神经网络 vs. PINN。
*   **LLM 算术行为分析**：
    *   **场景**：分析 Llama-3.2-1B 在加法、乘法、计数和温度转换任务中的内部逻辑。

### 4. 资源与算力
*   **硬件使用**：
    *   **推理基准测试**：使用 **Nvidia A100-SXM4-80GB GPU**。
    *   **符号回归拟合**：在 **Apple M4 Max SoC**（14核 CPU，36GB 统一内存）上运行。
*   **耗时情况**：
    *   拟合 LLM 的 3 个 MLP 块约需 **7-8 小时**。
    *   GNN 边函数蒸馏约需 **10 分钟**。
    *   PINN 蒸馏约需 **3 分钟**以内。
    *   LLM 算术操作分析约需 **5-15 分钟**。

### 5. 实验数量与充分性
*   **实验规模**：涵盖了从基础物理模拟（GNN/PINN）到前沿大模型（Transformer）的多种架构。
*   **消融与敏感性分析**：针对 LLM 实验，进行了详细的 **PCA 敏感性分析**（改变输入/输出的主成分数量），并对比了不同正则化手段（L1、KL 散度、剪枝）对 GNN 符号恢复的影响。
*   **充分性评价**：实验设计较为全面，不仅验证了可解释性（恢复已知公式），还验证了实用性（推理加速）。但在 LLM 加速实验中，仅测试了 1.5B 规模的模型，且仅替换了 3 层（共 28 层），对于更大规模模型和更深层替换的泛化性仍有待验证。

### 6. 主要结论与发现
*   **推理加速**：通过符号代理替换 LLM 的 MLP 层，在困惑度轻微上升（从 10.62 升至 13.76）的情况下，实现了 **8.3% 的吞吐量提升**。
*   **物理发现**：SymTorch 成功从 GNN 中恢复了正确的电荷力、引力和弹力公式，证明了其在科学发现中的潜力。
*   **模型诊断**：发现 LLM 在执行简单算术时，内部实际上拟合了带有系统性误差的复杂非线性函数，而非完美的数学逻辑。
*   **工程价值**：SymTorch 显著降低了符号蒸馏的门槛，使原本需要大量手动编写的代码变为简单的 API 调用。

### 7. 优点
*   **高度自动化**：解决了深度学习与符号回归之间繁琐的数据对接问题。
*   **架构无关性**：适用于 GNN、CNN、Transformer 等多种 PyTorch 模型。
*   **混合建模**：允许模型在保留大部分神经权重的同事，将关键部分替换为公式，兼顾性能与可解释性。
*   **开源贡献**：提供了完整的文档和 Jupyter 笔记本示例，易于复现。

### 8. 不足与局限
*   **计算瓶颈**：符号回归本质上是暴力搜索，运行时间随变量数量呈指数级增长，处理超高维数据仍需依赖 PCA 等可能导致信息丢失的降维手段。
*   **性能权衡**：在 LLM 实验中，符号替换导致的性能下降（困惑度增加）虽然在帕累托前沿上可接受，但对于精度要求极高的任务可能不适用。
*   **可解释性悖论**：生成的数学公式可能非常复杂（如嵌套的 `sin` 函数），虽然是闭式的，但人类依然难以直观理解其物理含义。
*   **泛化风险**：符号代理在训练分布外（OOD）的稳定性尚未在 LLM 任务中得到充分验证。

（完）
