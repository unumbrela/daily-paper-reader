---
title: "GENSR: Symbolic Regression Based in Equation Generative Space"
title_zh: GenSR：基于方程生成空间的符号回归
authors: "Qian Li, Yuxiao Hu, Juncheng Liu, Yuntian Chen"
date: 2026-02-24
pdf: "https://arxiv.org/pdf/2602.20557v1"
tags: ["query:sr"]
score: 10.0
evidence: 用于符号回归和方程搜索的生成潜空间
tldr: 针对符号回归在离散空间搜索时结构变化与数值行为不一致的问题，本文提出GenSR框架。该框架通过预训练双分支条件变分自编码器（CVAE），将方程重参数化为具有连续性和数值平滑性的生成潜空间。通过“地图构建、粗略定位、精细搜索”的范式，结合CMA-ES优化，实现了在潜空间中的高效方程搜索。实验证明GenSR在精度、简洁性、效率和抗噪性方面均表现优异。
motivation: 传统符号回归在离散空间搜索，方程结构的微小改变会导致数值行为剧烈波动，使得误差反馈难以有效指导搜索过程。
method: 构建基于CVAE的生成潜空间将方程映射为连续表示，并采用“定位+精细搜索”的策略，利用CMA-ES在潜空间中优化方程。
result: GenSR在保持高预测精度的同时，显著提升了表达式的简洁性和计算效率，并在噪声环境下表现出极强的鲁棒性。
conclusion: 该研究通过将符号回归重构为潜空间概率分布最大化问题，为符号方程的自动化发现提供了一种理论完备且高效的新方案。
---

## 摘要
符号回归 (SR) 旨在揭示观测数据背后隐藏的方程。然而，大多数方法在离散的方程空间中进行搜索，其中方程的结构修改很少与其数值行为保持一致，导致拟合误差反馈过于嘈杂，难以引导探索。为了应对这一挑战，我们提出了 GenSR，这是一个基于生成潜空间的符号回归框架，遵循“地图构建 -> 粗略定位 -> 精细搜索”的范式。具体而言，GenSR 首先预训练一个双分支条件变分自编码器 (CVAE)，将符号方程重新参数化为具有符号连续性和局部数值平滑性的生成潜空间。该空间可被视为方程空间中结构良好的“地图”，为搜索提供方向性信号。在推理阶段，CVAE 将输入数据粗略定位到潜空间中有潜力的区域。随后，改进的 CMA-ES 利用平滑的潜梯度对候选区域进行精细化搜索。从贝叶斯角度来看，GenSR 将符号回归任务重新定义为最大化条件分布 $p(\mathrm{Equ.} \mid \mathrm{Num.})$，而 CVAE 的训练通过证据下界 (ELBO) 实现了这一目标。这一新视角为 GenSR 的有效性提供了理论保证。大量实验表明，GenSR 在保持对噪声鲁棒性的同时，共同优化了预测准确性、表达式简洁性和计算效率。

## Abstract
Symbolic Regression (SR) tries to reveal the hidden equations behind observed data. However, most methods search within a discrete equation space, where the structural modifications of equations rarely align with their numerical behavior, leaving fitting error feedback too noisy to guide exploration. To address this challenge, we propose GenSR, a generative latent space-based SR framework following the `map construction -> coarse localization -> fine search'' paradigm. Specifically, GenSR first pretrains a dual-branch Conditional Variational Autoencoder (CVAE) to reparameterize symbolic equations into a generative latent space with symbolic continuity and local numerical smoothness. This space can be regarded as a well-structured `map'' of the equation space, providing directional signals for search. At inference, the CVAE coarsely localizes the input data to promising regions in the latent space. Then, a modified CMA-ES refines the candidate region, leveraging smooth latent gradients. From a Bayesian perspective, GenSR reframes the SR task as maximizing the conditional distribution $p(\mathrm{Equ.} \mid \mathrm{Num.})$, with CVAE training achieving this objective through the Evidence Lower Bound (ELBO). This new perspective provides a theoretical guarantee for the effectiveness of GenSR. Extensive experiments show that GenSR jointly optimizes predictive accuracy, expression simplicity, and computational efficiency, while remaining robust under noise.

---

## 论文详细总结（自动生成）

以下是对论文《GENSR: Symbolic Regression Based in Equation Generative Space》的深度结构化总结：

### 1. 核心问题与研究动机
*   **核心问题**：传统的符号回归（SR）方法大多在**离散的方程空间**中进行启发式搜索（如遗传编程、树搜索）。
*   **研究动机**：
    *   **结构与数值脱节**：在离散空间中，方程结构的微小改变（编辑距离）往往导致数值行为的剧烈波动。
    *   **搜索效率低下**：由于缺乏平滑的反馈信号，搜索过程高度依赖随机变异和回溯，导致计算复杂度高且难以收敛到最优解。
    *   **空间破碎**：现有的判别式预训练方法（如对比学习）生成的潜空间不具备生成能力，存在大量无法解码的“空洞”。

### 2. 方法论
GenSR 提出了一个遵循“**地图构建 → 粗略定位 → 精细搜索**”范式的符号回归框架：
*   **核心思想**：利用生成模型将离散的方程空间重参数化为一个**连续、生成式且数值平滑**的潜空间（Latent Space）。
*   **关键技术细节**：
    1.  **双分支 CVAE 预训练**：
        *   **后验分支**：输入方程和数值样本，学习符号结构的连续性，确保潜空间中的点都能解码为合法的方程。
        *   **先验分支**：仅输入数值样本，学习数值行为的特征，并利用 KL 散度将其与后验分布对齐。
    2.  **潜空间特性**：构建了一个具有“全局符号连续性”和“局部数值平滑性”的空间。相似数值行为的方程在空间中邻近，为优化提供方向信号。
    3.  **三阶段搜索流程**：
        *   **地图构建**：在大规模合成数据集上预训练 CVAE。
        *   **粗略定位**：推理时，先验分支将观测数据映射到潜空间的高概率区域。
        *   **精细搜索**：使用改进的 **CMA-ES**（协方差矩阵自适应进化策略）在潜空间内进行分布收缩，寻找拟合度最高的方程。
    4.  **算法优化**：为应对高维优化，采用对角协方差假设和 Top-k 维度更新策略，显著降低了计算开销。
*   **贝叶斯视角**：论文证明了 GenSR 的训练本质上是在最大化证据下界（ELBO），从而优化条件概率 $p(\text{Equation} | \text{Numerical Data})$。

### 3. 实验设计
*   **数据集与场景**：
    *   **Feynman 数据集**：119 个物理方程，用于验证科学发现能力。
    *   **Strogatz 数据集**：14 个动力系统挑战，侧重非线性动力学。
    *   **Black-box 数据集**：57 个来自 PMLB 的现实世界黑盒回归任务。
*   **Benchmark 与对比方法**：
    *   对比了 **18 种基线方法**，涵盖遗传编程（GPlearn, Operon）、强化学习（DSR）、Transformer 规划（TPSR）、对比学习（SNIP）以及传统的机器学习模型（XGBoost, Random Forest）。
*   **评估指标**：拟合优度 ($R^2$)、方程复杂度（Token 数量）、时间复杂度（运行秒数）。

### 4. 资源与算力
*   **硬件环境**：使用了 **2 台 NVIDIA H800 GPU** (80GB 显存)。
*   **训练时长**：预训练阶段共 200 个 epoch，每个 epoch 耗时约 1 小时。
*   **模型规模**：参数量约为 **1.621 亿** (162.1M)。
*   **数据规模**：在约 500 万个合成的“方程-样本对”上进行预训练。

### 5. 实验数量与充分性
*   **实验规模**：在三个主流 Benchmark 上进行了全面测试，涵盖了从简单物理公式到复杂黑盒数据的多种场景。
*   **消融实验**：非常充分。作者探讨了潜空间维度（64 到 768）、CMA-ES 的超参数（种群大小、步长、惩罚权重 $w$）以及 Top-k 更新策略对性能的影响。
*   **鲁棒性测试**：专门设计了针对不同噪声水平（0.0 到 0.1）的对比实验，验证了模型在干扰下的稳定性。
*   **可视化分析**：通过 t-SNE 降维展示了潜空间的聚类特性和数值连续性，客观地证明了方法论的有效性。

### 6. 主要结论与发现
*   **性能领先**：GenSR 在 $R^2$ 精度、方程简洁度和搜索效率之间取得了最佳的 Pareto 平衡，始终处于基准测试的 Rank-1 前沿。
*   **搜索范式有效**：证明了在连续潜空间中进行进化搜索比在离散空间中盲目变异更高效。
*   **抗噪性强**：由于潜空间的平滑性，GenSR 在面对高噪声数据时，其 $R^2$ 的下降幅度远小于传统方法，且生成的方程更简洁。
*   **多任务潜力**：该潜空间不仅能用于回归，还能有效支持方程分类等下游任务。

### 7. 优点与亮点
*   **理论与工程结合**：将严谨的贝叶斯 ELBO 推导与高效的进化策略结合，为 SR 提供了坚实的理论支撑。
*   **解决“空洞”问题**：相比之前的判别式模型，GenSR 确保了潜空间的每一个点都有物理意义（可解码），支持平滑插值。
*   **高效性**：通过“定位+搜索”的策略，避免了从零开始的穷举搜索，极大地缩短了推理时间。

### 8. 不足与局限
*   **预训练偏差风险**：模型的性能高度依赖于预训练合成数据的分布。如果目标方程包含预训练中未见过的特殊算子或极端结构，模型可能难以发现。
*   **高维优化挑战**：尽管使用了 Top-k 优化，但随着潜空间维度的进一步增加，CMA-ES 的采样效率仍可能面临瓶颈。
*   **常数处理**：虽然引入了 BFGS 优化常数，但在潜空间搜索过程中，如何更完美地解耦“结构搜索”与“精确常数微调”仍有优化空间。

（完）
