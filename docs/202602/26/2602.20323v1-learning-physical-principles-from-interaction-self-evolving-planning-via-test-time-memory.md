---
title: "Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory"
title_zh: 从交互中学习物理原理：通过测试时记忆实现的自演化规划
authors: "Haoyang Li, Yang You, Hao Su, Leonidas Guibas"
date: 2026-02-23
pdf: "https://arxiv.org/pdf/2602.20323v1"
tags: ["query:sr"]
score: 7.0
evidence: 通过交互学习物理原理和假设
tldr: 针对视觉语言模型（VLM）在机器人操控中难以准确把握特定物理属性的问题，本文提出了 PhysMem 框架。该框架允许机器人在测试阶段通过交互学习物理原理，无需更新模型参数。它通过记录经验、生成并验证假设，将验证后的知识用于指导未来决策。实验表明，PhysMem 在多项任务中显著提升了成功率，实现了自进化的规划能力。
motivation: 现有的 VLM 规划器虽然具备通用推理能力，但难以在缺乏直接经验的情况下准确预测特定物体或环境的物理特性。
method: 提出一种测试时存储框架，通过记录交互经验、生成候选假设并进行针对性验证，将验证后的物理原理用于指导后续规划。
result: "在砖块插入任务中，该方法将成功率从 23% 提升至 76%，且在真实世界 30 分钟的部署中展现出持续的性能优化。"
conclusion: 通过在应用前对物理假设进行验证，机器人能够更可靠地从交互中学习抽象原理，从而实现更稳健的物理操控规划。
---

## 摘要
可靠的物体操纵需要理解随物体和环境而变化的物理属性。视觉语言模型（VLM）规划器可以对摩擦力和稳定性进行一般性的推理；然而，如果没有直接经验，它们通常无法预测特定的球在特定表面上如何滚动，或者哪块石头能提供稳定的基础。我们提出了 PhysMem，这是一个记忆框架，使 VLM 机器人规划器能够在测试时通过交互学习物理原理，而无需更新模型参数。该系统记录经验，生成候选假设，并通过有针对性的交互对其进行验证，然后将经过验证的知识提升为指导未来决策的准则。一个核心设计选择是“先验证后应用”：系统根据新的观察结果测试假设，而不是直接应用检索到的经验，从而减少了在物理条件发生变化时对先前经验的僵化依赖。我们在三个真实世界的操纵任务和跨四个 VLM 骨干网络的仿真基准上评估了 PhysMem。在受控的积木插入任务中，基于原理的抽象实现了 76% 的成功率，而直接经验检索的成功率为 23%，且真实世界实验显示在 30 分钟的部署过程中性能持续提升。

## Abstract
Reliable object manipulation requires understanding physical properties that vary across objects and environments. Vision-language model (VLM) planners can reason about friction and stability in general terms; however, they often cannot predict how a specific ball will roll on a particular surface or which stone will provide a stable foundation without direct experience. We present PhysMem, a memory framework that enables VLM robot planners to learn physical principles from interaction at test time, without updating model parameters. The system records experiences, generates candidate hypotheses, and verifies them through targeted interaction before promoting validated knowledge to guide future decisions. A central design choice is verification before application: the system tests hypotheses against new observations rather than applying retrieved experience directly, reducing rigid reliance on prior experience when physical conditions change. We evaluate PhysMem on three real-world manipulation tasks and simulation benchmarks across four VLM backbones. On a controlled brick insertion task, principled abstraction achieves 76% success compared to 23% for direct experience retrieval, and real-world experiments show consistent improvement over 30-minute deployment sessions.