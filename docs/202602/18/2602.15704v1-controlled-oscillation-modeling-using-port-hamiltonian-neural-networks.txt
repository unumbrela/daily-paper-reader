Title: Controlled oscillation modeling using port-Hamiltonian neural networks

URL Source: https://arxiv.org/pdf/2602.15704v1

Published Time: Wed, 18 Feb 2026 01:59:04 GMT

Number of Pages: 25

Markdown Content:
# Controlled oscillation modeling using port-Hamiltonian neural networks 

M. Linares a, ∗, G. Doras a, T. Hélie a, A. Roebel a

> aIRCAM, 1, place Igor-Stravinsky, 75004, Paris, France

Abstract 

Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training. 

Keywords: physics-informed machine learning, port-Hamiltonian neural networks, discrete gradient, Jacobian regularization 

1. Introduction 

Purely data-driven methods for dynamical systems pose several challenges: the volume of useful data is gener-ally limited, they produce accurate-but-wrong predictions, they are not capable of dealing with uncertainty and their predictions are not explainable nor interpretable [1]. At the same time, it is natural to leverage the prior knowl-edge obtained through centuries of scientific study in the form of inductive bias [2] when designing predictive mod-els [3]. In this direction, a successful data-driven physical model is one whose inductive bias better captures the true dynamics and is able to predict a correct outcome for data not observed during training. These inductive bias are incorporated through soft and hard constraints [4]. Soft constraints add penalty terms to the training loss func-tion, discouraging violations of physical laws. This ap-proach is widely applicable, but the model must balance adherence to the constraints against fitting the observed data, without providing any formal guarantee. The sem-inal Physics-Informed Neural Networks (PINNs) [5] is an example of soft-constraining the model. In contrast, hard constraints ensure strict compliance with specified physical       

> ∗Corresponding author
> Email addresses: maximino.linares@ircam.fr (M. Linares),
> guillaume.doras@ircam.fr (G. Doras), thomas.helie@ircam.fr
> (T. Hélie), axel.roebel@ircam.fr (A. Roebel)

laws by embedding them directly into the model’s struc-ture, independently of the available data. In this sense, hard constraints can be used to incorporate energy con-servation laws, symmetry, numerical methods for PDEs or Koopman theory [6]. However, imposing hard constraints reduces the space of possible solutions and generally limits the model’s expressiveness. As a result, hard constraints are difficult to apply in practice: incorrect assumptions about the physical system can lead to overly biased mod-els with a poor generalization performance. In this paper, we consider dynamical systems whose state x is governed by the following ODE: 

dx

dt := ˙ x = f (x) (1) and analyze how hard constraints based on energy con-servation and power balance principles are incorporated into neural networks based on physically consistent port-Hamiltonian systems formulations. By physically consis-tent , we refer, in this work, to the combination of power-balanced state-space models with discrete gradient numer-ical methods, which preserve the system’s energy during discretization. The central hypothesis is that enforcing this physical structure as a hard constraint improves in-terpretability and generalization with respect to a vanilla NeuralODE. To substantiate this claim, we conduct a sys-tematic study on three controlled oscillatory systems of 

> arXiv:2602.15704v1 [cs.LG] 17 Feb 2026

increasing modeling complexity: a harmonic oscillator, a Duffing oscillator and a self-sustained oscillator. These systems are deliberately selected to include linear and non-linear Hamiltonian dynamics as well as nonlinear dissipa-tion mechanisms. The harmonic oscillator serves as the simplest baseline example with quadratic energy storage; the Duffing oscillator offers nonlinearities in the Hamil-tonian, capturing amplitude-dependent effects; and the self-sustained oscillator incorporates a nonlinear dissipa-tion which can stabilize the system in a controlled-limit cycle. The main contributions of this paper are 

• a comparison of two theoretically equivalent port-Hamiltonian systems (PHS) formulations: the semi-explicit PH-Differential-Algebraic-Equations (PH-DAE) and the input-state-output PHS with feedthrough; when they are implemented as port-Hamiltonian neu-ral networks (PHNNs). 

• a performance comparison between the Gonzalez dis-crete gradient method, which is a second-order energy-preserving numerical method, and a second-order ex-plicit Runge-Kutta method when used to discretize the PHNN model during learning. 

• an empirical study of the impact of regularizing the Jacobian of PHNN through two methods already ap-plied to NeuralODEs and a new one tackling the stiff-ness of the learned ODE solutions. The rest of this paper is organized as follows. Section 2 introduces the necessary preliminaries on dynamical sys-tems, port-Hamiltonian systems, numerical methods, neu-ral ordinary differential equations, and port-Hamiltonian neural networks. Section 3 presents the port-Hamiltonian formulations considered in this work, the enforced physical constraints, and the oscillatory examples used throughout the paper. Section 4 focuses on port-Hamitonian neural networks, detailing how physical constraints are incorpo-rated into the learning process, the comparison between continuous- and discrete-time models, and the Jacobian regularization in the port-Hamiltonian neural networks. Section 5 formulates the key research questions addressed by the experimental study. Section 6 reports and dis-cusses the results of the experiments. Finally, Section 7 concludes the paper and outlines directions for future work. The code is publicly available: https://github. com/mlinaresv/ControlledOscillationPHNNs [will be re-leased after paper acceptance]. 

2. Preliminaries 

2.1. Dynamical systems 2.1.1. Dynamical system ODE 

Consider a dynamical system governed by the following system of equations: 

(

˙x(t) = f (x(t), u(t)) 

y(t) = h(x(t), u(t)) (2) where x(t) ∈ Rnx , u(t) ∈ Rnu and y(t) ∈ Rny are re-ferred to as the state , input and output of the system, respectively; and where f : D → Rnx , h : D → Rny are 

C1 functions with domain D ⊆ Rnx × Rnu . The system of equations (2) as a whole is referred to as state-space model [7]. In this work, we consider autonomous systems (i.e. where u(t) is constant for all t). Obtaining a solution for a given initial condition is often referred to as solving the initial value problem (IVP) 

˙x(t) = f (x(t)) x(0) = x0. (3) In the following, we omit the explicit time dependence of 

x(t), y(t) and u(t) to simplify the notation, when there is no ambiguity, and we let Jf (x) denote the Jacobian matrix of the function f of (3). 

2.1.2. Well-posed problems 

The term well-posed was introduced to refer to prob-lems where a) the solution exists, b) is unique, and c) depends continuously on the initial conditions and param-eters [8]. A sufficient condition for an IVP to be well-posed is that f is K-Lipschitz [9]. The spectral norm of a matrix A is defined as: 

∥A∥2 = max  

> ∥x∥2=1

∥Ax ∥2 = σmax (A), (4) where σmax (A) is the largest singular value of A [10]. It is a standard result that if the following condition holds: 

∥Jf (x)∥2 ≤ K < ∞ ∀x ∈ D 

then f is K-Lipschitz [9] (see Appendix A). In practice, controlling the well-posedness of the IVP reduces to enforcing an upper bound on the spectral norm of the Jacobian of f .

2.1.3. Well-conditioned problems 

The term well-conditioned refers to problems seen as a function f where a small perturbation of x yields only small changes in f (x) – the meaning of small depending 2on the context [11]. This relationship can be characterized by the relative condition number of f defined as: 

κf (x) = lim  

> δ→0

sup 

> ∥δx∥≤ δ

 ∥f (x + δx) − f (x)∥2

∥f (x)∥2

 ∥δx∥2

∥x∥2



,

(5) where δx and δf are infinitesimal. If f ∈ C 1, this rewrites as: 

κf (x) = ∥Jf (x)∥2

∥f (x)∥2/∥x∥2

. (6) for ∥x∥2̸ = 0 and its limit when ∥x∥2 → 0. If κf (x) is small (resp. large), the problem is said to be well-conditioned 

(resp. ill-conditioned ). For a linear system f (x) = Ax , the Jacobian of f

becomes Jf (x) = A, ∀x. It is a standard result that the condition number can then be bounded s.t.: 

κf (x) ≤ ∥ Jf (x)∥2∥J−1 

> f

(x)∥2 = σmax (Jf (x)) 

σmin (Jf (x)) (7) where σmax (Jf (x)) , σ min (Jf (x)) are the maximum and minimum singular values of Jf (x) [11]. In the following, the upper bound in (7) is denoted as κ(Jf (x)) .In practice, controlling the well-conditioning of a linear problem f reduces to enforcing an upper bound on its condition number. 

2.1.4. Stiff ODE systems 

The term stiff refers to an initial value problem for which certain numerical methods require prohibitively small step sizes to maintain stability. This behavior can be char-acterized by the stiffness ratio defined as: 

ρ(Jf ) = max |R (λ(Jf )) |

min |R (λ(Jf )) | , (8) where λ(Jf ) are the eigenvalues of the Jacobian matrix and R(·) : C → R is the real part operator [12]. Although it is rigorously only true for linear equations, a system with a large stiffness ratio is generally stiff [12]. In practice, controlling the stiffness of an ODE system reduces to enforcing an upper bound on its stiffness ratio. 

2.2. Port-Hamiltonian systems 

In the Hamiltonian formalism [13], the mechanical state of S is represented by a vector x = [ q, p]⊤ ∈ Rnx , where 

q, p ∈ Rnx/2 denote the generalized coordinates and con-jugate momenta. The dynamics is governed through a scalar-valued energy function H(x) known as Hamiltonian ,and the time evolution of the system follows Hamilton’s equations: 

˙x = f (x) = S∇H(x) = 

 0 In

−In 0



∇H(x), (9) where S ∈ Rnx×nx is the canonical symplectic matrix which imposes the energy conservation principle. This formalism is restricted to conservative closed systems and does not readily describes dissipation or external control, which are common to many real-world systems. Port-Hamiltonian formalism [14–16] generalizes Hamil-tonian mechanics to multi-physics open systems by ex-plicitly modeling energy exchange with the environment through ports (inputs/outputs) and dissipation. In this work, the considered class of open systems is represented in this formalism as a network of: 

• energy storing components with state x and energy 

E := H(x), with H positive definite and C1-regular, so the stored power is Pstored := ˙E = ∇H(x)⊤ ˙x,

• dissipative components , described by an effort law 

z(w) for a flow variable w, where Pdiss := z(w)⊤w;by convention, the dissipated power is counted posi-tively, i.e. Pdiss ≥ 0, with Pdiss = 0 for conservative components, 

• external components are represented through ports by system inputs u and outputs y, with the conven-tion that Pext := u⊤y is positive when received by these external components. The coupling of internal flows F and efforts E governs the time evolution of the system, expressed as: 



˙xwy

| {z } 

> := F

= S

∇H(x)

z(w)

u

| {z }

> := E

, (10) where S = −ST is skew-symmetric so that 

0 = Pstored 

| {z }  

> ∇H(x)T˙x

+ Pdiss 

|{z}  

> z(w)Tw

+ Pext 

|{z}  

> uTy

= ⟨E|F⟩ (11) with ⟨E|F⟩ = ET F. Indeed, 

ET F (14) 

= ET SE (S=−ST )

= 0 (12) The passivity of the system stems from the fact that Pdiss ≥

0, which imposes that Pstored = −Pdiss − Pext ≤ − Pext . As a consequence, Pstored ≤ 0 (non-increasing internal energy) when external sources are off. This intrinsically physics-consistent formulation is highly general and can be ap-plied to a wide range of physical domains, including acous-tics, fluid mechanics, quantum physics and others [17–21] (see [16] for formulations more general than (10)). 

2.3. Numerical methods 

For a given IVP (3), a numerical method approximates the solution without the need to analytically solve the ODE. A discrete trajectory T is defined as the set {xn}n∈N

3of consecutive states where xn := x(nh ), h = 1 /sr is the time step and sr the sampling rate. Given the initial state 

x0 = x(0) , the applied control u and the ODE governing 

x, a trajectory T is obtained by such numerical method. If the governing equation is given by (10), the resulting T

is said to be a discretization of a port-Hamiltonian system .In this work, we use numerical methods that belong to two different categories: 

2.3.1. Runge-Kutta (RK) methods 

A well-known family of numerical methods is the Runge-Kutta methods [22]. Let bi, a i,j (i, j = 1 , ..., s ) be real numbers and let ci = Psj=1 aij . An s-stage Runge-Kutta method is given by 

(ki = f



t0 + hc i, xn + h Psj=1 ai,j kj



, i = 1 , ..., s 

xn+1 = xn + h Psi=1 biki

(13) where the weights bi, a i,j are chosen to reach an accuracy order. In particular, the explicit midpoint method (RK2) 

xn+1 = xn + f



tn + h

2 , xn + h

2 f (tn, xn)



(14) is a second-order explicit Runge-Kutta method. 

2.3.2. Discrete gradient (DG) methods 

Physical properties like energy-preservation are not in general respected when discretizing a port-Hamiltonian system using RK methods [23]. However, in Hamiltonian mechanics there is a rich theory of structure preserving integrators [22]. In particular, discrete gradient methods are a family of geometrical integrators that preserve the exact energy by construction [24]. A discrete gradient 

∇H : Rnx × Rnx → Rnx is an approximation of the gra-dient of a function H : Rnx → R, satisfying the following two properties 1:1. ∇H(x, δ x)T δx = H(x + δx) − H(x)

2. ∇H(x, 0) = ∇H(x)

where δx = x′ − x. In this work, we consider the Gonzalez discrete gradient method [25] (DG) 

∇mid H(x, δ x) = ∇H



x + 12 δx



+ H(x + δx) − H(x) − ∇ H(x + 12 δx)T δx

δxT δx δx.

(15) Note that this method is, in general, a second-order inverse-explicit integrator [26] that becomes linearly implicit when the Hamiltonian satisfies H(x) = 12 xT Qx .           

> 1In the literature, these two properties are usually written as 1. ∇H(x,x′)T(x′−x) = H(x′)−H(x)
> 2. ∇H(x,x) = ∇H(x).

2.4. Neural ODEs and Jacobian regularization Neural Differential Ordinary Equations (NODEs) were introduced by Chen et al. [27] to define the evolution of a system’s state using an ODE whose dynamics are modeled by a neural network: 

dx(t)

dt = fθ (t, x(t)) (16) where θ represents the parameters of the neural network. The forward pass of a NODE is defined as 

x(tn+1 ) = x(tn) + 

Z tn+1 

> tn

fθ (t, x(t)) dt (17) where in practice the integration is approximated by any numerical method. A well-documented challenge in the training of NODEs is the fact that the Jacobian of the learned dynamics fθ be-comes poorly conditioned as the training progresses. Sev-eral studies have underlined this phenomenon. For in-stance, Dupont et al. [28] reported that when NODEs are overfitted on the MNIST dataset [29], the resulting flow may become so ill-conditioned that the numerical ODE solver is forced to take time steps smaller than machine precision, leading to numerical underflow and an increase in the number of function evaluations (NFE). Such patho-logical dynamics can also destabilize training and cause the loss to diverge. Motivated by these observations, Finlay et al. [30] emphasized the importance of explicitly con-straining the learned vector field. They noted that, in the absence of such constraints, the learned dynamics may ex-hibit poor conditioning, which in turn degrades numerical integration and degrades training performance. To ad-dress this issue, they proposed regularizing the Jacobian of fθ using its Frobenius norm. In this direction, Josias et al. [31] proposed instead to regularize the Jacobian con-dition number, arguing that it reduced NFE without a significant loss in accuracy and controlling at the same time the Jacobian norm. Focusing on Jacobian regular-ization enables a connection to sensitivity analysis found in neural network literature, where also the spectral norm regularization has been employed [32] [33]. 

2.5. Port-Hamiltonian neural networks 

In the context of learning Hamiltonian ODEs, Grey-danus et al. [34] introduced Hamiltonian Neural Network 

(HNN), modifying the usual NODEs framework by param-eterizing the Hamiltonian function of a given conservative physical system. Once the Hamiltonian is parameterized, (9) is leveraged in the loss function. This work led to many others trying to generalize the framework to learn more general physical systems. For example, Sosanya et al. [35] generalized the approach of HNN to non-conservative sys-tems using Helmholtz’s decomposition theorem to param-eterize the dissipation potential. Several works integrating port-Hamiltonian systems theory into neural networks are 4found in literature. Most of them implement the input-state-output representation 2 [16] 

(

˙x = ( J(x) − R(x)) ∇xH(x) + G(x)uy = GT (x)∇H(x) (18) for designing the computation graph of the dynamics. In this context, Desai et al. [36] introduce the Port-Hamiltonian Neural Network (PHNN) to learn damped and controlled systems. Zhong et al. [37] use this formulation to model conservative systems with external control introducing the 

Symplectic ODE-Net (SymODEN). In another work, the same authors generalize the framework of SymODEN to learn also the dissipation [38]. Cherifi et al. [39] propose a framework based on input-state-output data to learn port-Hamiltonian systems described by (18). Roth et al. [40] introduce Stable Port-Hamiltonian Neural Networks 

(sPHNN) to learn dynamical systems with a single equilib-rium under stability guarantees. A similar work to the one presented in this article, but based on pseudo-Hamiltonian formalism, is found in [4]. These approaches learn the dy-namics through (18) and impose a priori knowledge, ei-ther on the expression of the Hamiltonian [37–41] or on the way dissipation affects the system [4, 36, 39, 40]. As in any other NODE framework, (18) is discretized, during or after the training, using a numerical method so that there is no preservation of the power balance and no guar-antee of stability. Generally, this has been done either by high-order RK methods [34–36, 39, 40], but also via symplectic integrators [41–45], although the impact on the accuracy of one or the other approach has not been thor-oughly studied. To the best of our knowledge, the use of discrete gradients methods has not yet been described in the PHNN literature. 

3. Port Hamiltonian Models 

3.1. Port-Hamiltonian formulations 

Let x ∈ X ⊂ Rnx be the state of S with an associated Hamiltonian H : X → R and u, y ∈ Rnu be the input and output of the system, respectively. We consider three formulations in this work: (i) Semi-explicit PH-Differential-Algebraic-Equations (PH-DAE): 

˙xwy

| {z }  

> flows Fi

= S



∇H(x)

z(w)

u

| {z } 

> efforts Ei

, (19) where S = −ST ∈ R(nx+nw +nu)×(nx+nw +nu) and 

z(w) : Rnw → Rnw is the resistive structure of S.                       

> 2In the literature, this equation adopts the convention that
> uTy=Pext is positive when given to the system by the exter-nal components, so that Pext =−Pext and that (u,y) = ( u,−y)or
> (−u,y), contrary to conventions used in (10) and all this paper

The skew-symmetry of S guarantees energy conser-vation and the resistive property of z(w) is given by 

z(w)T w ≥ 0, which guarantees passivity. (ii) Input-state-output PHS with feedthrough [46]: 

 ˙xy

|{z}  

> flows Fii

=  J − R(x, u) ∇H(x)

u

| {z } 

> efforts Eii

, (20) where J and R(x, u) ∈ R(nx+nu)×(nx+nu) satisfy 

J = −JT and R = RT ⪰ 0. The skew-symmetry of J accounts for conservative connections and the positive semi-definiteness of R(x, u) guarantees pas-sivity. This formulation can be retrieved from (i) in particular when Sww = 0 and Swx , Swu do not de-pend on w. It is also an extension of (18) for systems with direct feed-through. (iii) Skew-symmetric gradient PH-DAE: If the function 

z(w) = ∂wZ(w) is derived from a potential Z (often referred to as the Rayleigh potential), the system (19) rewrites as the skew-gradient system [47] 



˙xwy

| {z }  

> flows Fiii

= S ∇F

xwu

| {z } 

> efforts Eiii

, (21) where S = −ST ∈ R(nx+nw +nu)×(nx+nw +nu) and 

F = H(x) + Z(w) + uT u 

> 2

.Only the formulations (i) and (ii) are considered in the experiments. The skew-symmetric gradient PH-DAE is presented as a generalization of the formulation used by Sosanya et al. [35]. The PHS formulations (i-iii) are passive (see Appendix B). 

3.2. Physical constraints enforcement 

The general class of physical systems considered in this work is such that the Hamiltonian H is C1-regular positive definite. In addition, we consider the subclass of Hamilto-nians of the form 

H(x) = 12 xT Q(x)x, (22) where Q(x) is a C1-regular symmetric positive definite ma-trix function. As already mentioned, The PHS formula-tions (i)-(ii) satisfy two types of constraints by construc-tion: 

(

S (or J) skew-symmetric (energy conservation) 

z(w)T w ≥ 0, ∀w (or R ⪰ 0) (passive laws) (23) In the PH-DAE formulation, we consider the subclass of dissipation function of the form: 

z(w) = Γ(w)w (24) 5where Γ(w) ∈ Rnw ×nw is C0-regular positive semidefinite matrix function that admits a symmetric/skew-symmetric decomposition Γ(w) = Γskew (w)+ Γsym (w) with Γskew = 

> 12

(Γ − ΓT ) and Γsym = 12 (Γ + ΓT ) ⪰ 0. The resistive property is satisfied as 

∀w, z(w)T w = wT Γ( w)T w

= wT Γsym (w)T w Γsym ⪰0

≥ 0

(25) Note that the classes of systems described by equations (22) to (25) cover a large spectrum of physical systems and remain fairly general. 

3.3. Reparameterization of constraints 

We now reparameterize the matrix constraints using the following properties: 

• any symmetric positive semidefinite (resp. definite) matrix M sym can be written in the form M sym =

LT L where L is a lower triangular matrix with pos-itive (resp. strictly positive) diagonal coefficients (Cholesky factorization [48]), 

• any skew-symmetric matrix M skew can be written in the form M skew = K − KT where K is a strictly lower triangular matrix. Then, the physical constraints (23) are naturally satis-fied considering the following reparametrizations: 

Q(x) = LTQ(x)LQ(x) (26) 

Γ(w) = LT 

> Γ

(w)LΓ(w) + KΓ(w) − KT 

> Γ

(w) or (27) 

R(x, u) = LTR(x, u)LR(x, u) (28) where LQ,R, Γ, resp. KΓ, are lower, resp. strictly lower, triangular matrices. 

3.4. Oscillatory physical examples 

Three oscillating systems that satisfy (22)-(24) are con-sidered: 

• the harmonic oscillator, which is quadratic in energy, with a linear dissipation; 

• the Duffing oscillator, which is non-quadratic in en-ergy, with a linear dissipation; 

• a self-sustained oscillator, which is quadratic in en-ergy, with a nonlinear dissipation. This last physical system is of particular dynamical inter-est as it is designed to self-oscillate when combined with an adapted constant input, leading to a stable limit cycle [49]. Table 1 shows the different port-Hamiltonian structural el-ements for each of these systems. 

4. Port-Hamiltonian neural networks 

4.1. Port-Hamiltonian neural network models 

A port-Hamiltonian neural network (PHNN) parame-terizes the right-hand side of (19)-(20), modeling the Hamil-tonian and the dissipative terms with two distinct neural networks. In this work, we assume that the interconnec-tion matrices J and S, are given a priori. The Hamiltonian function is parameterized identically for each formulation by a neural network HθH (x), and its gradient is derived by auto-differentiation as proposed in the seminal HNN [34]. The implementation of the dissipative term depends on the formulation considered (i or ii), which yields two different PHNN architectures: (i) PHNN-S models (19), where the dissipation function 

z(w) : Rnw → Rnw is parameterized by a neural net-work zθz (w), implementing the dynamic function: 

fθ (x, u) = f Sθ (x, u) = S



∇HθH (x)

zθz (w)

u

 (29) (ii) PHNN-JR models (20), where the coefficients of the dissipation matrix R(x, u) are parameterized by the outputs a neural network RθR (x, u), implementing the dynamic function: 

fθ (x, u) = f JR θ (x, u) = ( J−RθR (x, u)) 

∇HθH (x)

u



(30) Figure 1 shows the architecture of the two different PHNN models according to each of the PHS formulations. 

4.2. Physical constraints enforcement in neural networks 

According to Section 3.2, the PHS model is passive if the Hamiltonian and the dissipative terms take the form of (26) and (27) or (28). The non-zero coefficients of a 

n × n lower (resp. strictly lower) triangular matrix can be parameterized by the n(n+1) /2 (resp. n(n−1) /2) outputs of a neural network LθL (resp. KθK ), implementing the functions: 



HθH (x) = 12 xT LTθLH

(x)LθLH (x)xzθz (w) = 



LTθLz (w)LθLz (w) + KθKz (w) − KTθKz (w)



wRθR (x, u) = LTθLR

(x, u)LTθLR

(x, u)

(31) This parametrization is widely used in the literature [37, 39, 40, 50, 51]. Table 2 shows the fixed and learned objects for the port-Hamiltonian networks based on formulations (i) and (ii). 6System Harmonic oscillator Duffing oscillator Self-sustained oscillator (linear) (nonlinear) (nonlinear) 

x =

qp



u

q : centered position (elongation) [m] 

p : momentum [Kg.m.s −1]

u = f : force (applied or exterior) [N] 

H(x) p2

2m + kq 2

2

p2

2m + k1q2

2 + k3q4

4

p2

2m + kq 2

2

J J =



0 1 0

−1 0 −10 1 0

 J =



0 −1 01 0 00 0 0



R R = α



0 0 00 1 00 0 0

 with α > 0 [N /ms −1] R = Γ( w)



1 0 10 0 01 0 1

 with Γ( w) > 0 [m/s N] 

S S =



0 1 0 0

−1 0 −1 −10 1 0 00 1 0 0

 S =



0 −1 1 01 0 0 0

−1 0 0 −10 0 1 0



Γ( w) α aw 2 + bw + cz(w) z(w) = α w z(w) = aw 3 + bw 2 + cw Z(w) Z(w) = αw 2 

> 2

Z(w) = aw 4 

> 4

+ bw 3 

> 3

+ cw 2

> 2

Jf (x)

 0 1

> m

−k − αm

  0 1

> m

−k1 − 3k3q2 − αm

 −Γ′(w)kq − Γ( w)k − 1

> m

k 0



∥Jf (x)∥2

pλmax (( Jf (x)) T Jf (x)) (see the exact details on the Appendix C) 

κ(Jf (x)) σmax (Jf (x))   

> σmin (Jf(x))

=

q λmax (( Jf (x)) T Jf (x))     

> λmin (( Jf(x)) TJf(x))

(see the exact details on the Appendix C) 

ρ(Jf (x)) 1, if the system is underdamped  

> Table 1: Different port-Hamiltonian structural elements, Jacobian matrices and related quantities for the considered oscillators.
> (a) Architecture of PHNN-S (b) Architecture of PHNN-JR Figure 1: Architecture of the two PHNN models considered in this work. White boxes with orange contour denote fixed algebraic operations whereas orange boxes indicate the trainable parameters.

4.3. Continuous- vs. discrete-time models 

A continuous model fθ (xt, ut) represents the field ˙xt.During training, it learns an estimate of ˙xt by minimizing the loss 

Lc = ∥ ˙xt − fθ (xt, ut)∥22 (32) During inference, it is integrated as the right-hand side of the ODE using a numerical method. A discrete model gθ,h (xn, un) represents the next state 

xn+1 . During training, it learns an estimate of xn+1 by minimizing the loss 

Ld = xn+1 − gθ,h (xn, un)

h 1

(33) via backpropagation through a differentiable numerical ODE solver using a discretization step h. We introduce (33) inspired by Zhu et al. [52], as it was shown to have the-oretical guarantees for NeuralODEs using explicit Runge Kutta methods (see [52], Theorem 3.1). During inference, the discrete model is applied autoregressively to predict future states. Examples of discrete PHNN model learning framework can be found in literature [37, 38, 41, 53]. 7Objects Formulation (i) 



˙xy

 = ( J − R(x, u)) 



∇H(x)

u

 (ii) 



˙xwy



= S



∇H(x)

z(w)

u



H(x) HθH (x) = 12 xT LθLH (x)T LθLH (x)x

Dissipation RθR (w) = LθLR (x, u)T LθLR (x, u)

zθz (w) = ΓθΓ (w)w

ΓθΓ (w) = ( LTθLz (w)LθLz (w)) + ( KθKz (w) − KTθKz (w)) 

Interconnection matrix J ∈ R(nx+nu)×(nx+nu) S ∈ R(nx+nw +nu)×(nx+nw +nu)      

> Table 2: Fixed and learned objects for the different port-Hamiltonian networks based on formulations (i) and (ii). Numerical
> Schema
> Train Inference
> Figure 2: Training and inference diagram for the continuous models fθ.Numerical
> Schema
> Train Inference
> Figure 3: Training and inference diagram for the discrete models gθ.

As it can be seen on Figures 2 and 3, the neural net-work parameterizing the continuous- and the discrete-time models is the same. However, the ODE solver is used at different phases: during training and inference for discrete-time model, but only during inference for continuous-time model. In this work, we focus on discrete models, where the two different ODE solver schemes compared are shown in Table 3. This decision is based on the fact that in prac-tice it is generally impossible to have access to state deriva-tives ˙xt. Following (33), training discrete models does not require state derivative measurements and relies only on state measurements. Nevertheless, their performance dur-ing inference is limited to using the same discretization step h as during training. 

4.4. Jacobian regularization on PHNN 

Let Jfθ (x, u) denote the Jacobian of a PHNN, where 

fθ (x, u) corresponds to (29)-(30). Ideally, we would like Accuracy order Name Characteristic Power-balance 2 Explicit midpoint (RK2) Explicit ×    

> 2Discrete gradient (DG) Inverse-explicit ✓
> Table 3: Accuracy order, name, characteristic and whether power-balance is respected for the chosen numerical schema.

fθ (x, u) not only to be physically-consistent, which is al-ready structurally guaranteed in the PHNNs, but also nu-merically smooth . This means that, among the differ-ent physically-consistent solutions learned by our mod-els, those that are ill-posed, ill-conditioned or highly stiff should be penalized through some kind of Jacobian reg-ularization, as proposed in the NeuralODE literature [28, 30, 31]. Following this approach, we soft-constraint the training loss Ld to avoid non-desirable numerical behav-iors in the PHNNs. We experiment with regularizing the spectral norm ∥Jfθ ∥2,8the condition number κ(Jfθ ) or the stiffness ratio ρ(Jfθ )

as defined in Section 2.1. Penalizing higher spectral norm values promotes solutions with a lower Lipschitz constant whereas doing so with condition number rewards well-conditioned solutions. The rationale for introducing ρ(Jfθ )

as a new regularization term stems from the observation that ill-conditioned Jacobians, often associated with a high NFE in adaptive numerical methods, are characteristic of stiff ODE systems. Thus, penalizing large values of ρ(Jfθ )

discourages the training procedure from converging to-ward stiff dynamics, thereby promoting indirectly better-conditioned ODE solutions. During the training, these regularization quantities are obtained after evaluating the Jacobian at the input data from a given batch, making the same assumption as in [31]: that regularizing dynamics at the input data can lead to regularized dynamics across the entire solution space . The following loss functions with Jacobian regularization terms are introduced: 

LCN = Ld + λCN ∥κ(Jfθ (x, u)) ∥22 (34) 

LSN = Ld + λSN ∥Jfθ (x, u)∥2 (35) 

LSR = Ld + λSR ∥ρ(Jfθ (x, u)) − 1∥22 (36) We set λSN = 10 −6, λCN = 10 −6 and λSR = 10 −4 in later experiments, and, as in [31], we add 10 −6 to the denominator of κ(Jfθ ) and ρ(Jfθ ) to avoid underflow in the early stages of training. 

5. Experiments 

5.1. Our questions 

Given a discrete trajectory T and its initial state x0,the objective of this work is to design PHNN models capa-ble of accurately generating a trajectory ˜T = { ˜xn}n∈N+ ,with ˜x0 = x0, that approximates T as closely as possible. Each of the PHNN models presented in this work can be characterized by the: 1. PHS formulation: PHNN-S or PHNN-JR. 2. Type of model: Continuous or discrete. 3. Numerical method: RK2 or DG (see Table 3). 4. Number of trainable parameters: 800, 2k or 10k. 5. Number of training points: 25, 100 or 400. 6. Loss function: Ld, LSN , LCN or LSR .We set a baseline NODE [27] model and conduct several experiments to compare its performance to the proposed familiy of PHNNs models. 

Study I : Impact of the number of training points .The first study focuses on how the different PHNN archi-tectures compare at inference stage with different numer-ical methods for the systems in Table 1. For this study, experiments are carried out for 25, 100 and 400 training points and the smallest number of training parameters is considered ( ≈ 800 ). 

Study II : Impact of the number of trainable pa-rameters . The second study uses the same combination of PHNN architectures and numerical methods but, oppo-site to Study I, the number of training points is fixed to 25 and the number of training parameters varies between 

small (≈ 800 ), medium (≈ 4k) and large (≈ 20 k). Tables E.8-E.10 in Appendix D detail the design choices of the neural network components for each model. In each case, the criteria is to have a similar number of parameters for each formulation, which enables a fair comparison between them. 

Study III : Impact of the Jacobian regularizations .The third study focuses on how the different Jacobian regularizations in (34)-(36) influence the inference perfor-mance of the models. In this case, the same combination of PHNN architectures, numerical methods, training pa-rameters and training points as in Study I is considered. 

5.2. Implementation details 

Table 4 shows the parameters considered for the gen-eration of trajectories for each physical system as well as the training and inference parameters considered for the neural network experiments, whereas Figure 4 shows the distribution of the training and test points as well as two complete test trajectories for each oscillatory system. 

Generation of synthetic data . The dataset T con-sists of Ntraj = 12500 trajectories. Each trajectory is generated synthetically according to the following criteria: i Initial condition : We fix Emin , E max , and we sam-ple an initial condition x0 such that 

H(x0) ∈ I E0 = [ Emin , E max ] (37) with Emin , E max ∈ R+ (see Table 4 for numerical values). ii Control : For the harmonic and Duffing oscillators, external control is applied as a constant force u so that 

H(x∗) ∈ I Eeq = [ Emin eq , E max eq ] (38) where x∗ is the equilibrium point of the system. In control theory, this is usually referred to as potential energy shaping [54]. For the self-sustained oscillator, the external constant control u is applied so that the system stabilizes in a limit cycle around x∗ (see Table 4 for numerical values). Further details about the sampling of the initial condi-tions and the control design can be found in Appendix E. As for the intrinsic parameters of each system, they are chosen to satisfy that the natural frequency f0 is 1Hz .For the harmonic and Duffing oscillator, a linear dissipa-tion function z(w) = cw is considered. In this case, c is chosen so that the damped harmonic oscillator has dissi-pated 99% of its energy in D = 5 T0 = 5 s, where T0 = 1 /f 0

9System Harmonic Oscillator Duffing Oscillator Self-sustained oscillator 

Intrinsic parameters (m, k ) (m, k 1, k 3) (m, k )

f0 [Hz] 1Hz m [kg] 0.16 1/k, 1/k 1 [N/m ] 0.16 

k3 [N/m 3] - 100 k1 -

z(w) 0.9w [N] 1.3w3 − 4w2 + 3 w [m/s ]

Constant control u [N] Such that the equilibrium point energy lies in IE0 Such that system reaches a limit cycle 

IE0 , IEeq [J] [0 .1, 1] 

sr gen [Hz] 400 f0

Generation numerical method Gonzalez discrete gradient (15) 

α 0.31 

β 5

Dtrain [s] αT 0

Dinf er [s] βT 0

sr train , sr inf er [Hz] 100 f0

Ntrain [25 , 100 , 400] 

Batch size 64 

Neval 2500 

Ninf er 100 

Table 4: Implementation hyperparameters for the different experiments. 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00 

p 

> 1.00
> 0.75
> 0.50
> 0.25
> 0.00
> 0.25
> 0.50
> 0.75
> 1.00
> q
> Training points
> Test trajectories
> Test initial points
> Isoenergy lines E0

(a) Harmonic oscillator 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00 

p  

> 1.00
> 0.75
> 0.50
> 0.25
> 0.00
> 0.25
> 0.50
> 0.75
> 1.00
> q
> Training points
> Test trajectories
> Test initial points
> Isoenergy lines E0

(b) Duffing oscillator 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00 

p  

> 1.00
> 0.75
> 0.50
> 0.25
> 0.00
> 0.25
> 0.50
> 0.75
> 1.00
> q
> Training points
> Test trajectories
> Test initial points
> Isoenergy lines E0

(c) Self-sustained oscillator Figure 4: Training points, test initial points and two complete test trajectories for each of the three oscillatory systems. Note that in the case of the harmonic and Duffing oscillator, the applied control shifted the equilibrium point from (p, q ) = (0 , 0) whereas in the case of the self-sustained oscillator, it stabilizes the trajectories in a limit cycle. 

is the natural period. The same value of c is considered for the Duffing oscillator. As for the self-sustained os-cillator, the considered nonlinear dissipation function is 

z(w) = 1 .3w3 − 4w2 + 3 w. In each physical system, the numerical scheme considered for the generation of the tra-jectories is the Gonzalez discrete gradient (15) for a dura-tion D and a sampling rate sr gen = 400 f0.

Training details . Let Dtrain = αT 0 and sr train =

γf 0 < sr gen be the training time and data sampling rate, respectively, where α and γ are hyperparameters. For each system, we consider α such that the harmonic os-cillator has dissipated 25% of its initial energy in the ab-sence of control and γ = 100 . The set of training trajecto-ries Ttrain is built considering Ntrain trajectories from T

up until a duration Ttrain sub-sampled at sr train . Once 

Ttrain is created, one point ξitrain = (( xin, uin), xin+1 ) is uniformly sampled from each trajectory τ itrain ∈ T train 

(see Figure 5 for a graphical description). The set of points ξtrain = {ξitrain }i=1 ,...,N train constitutes the train-ing dataset. Note that training on a set of isolated points sampled at random from complete trajectories is closer to experimental conditions than training on a set of complete trajectories that might be more difficult to measure accu-10 Dtrain                  

> Dinfer Figure 5: Schematic sampling and dataset construction procedure. A trajectory generated at sampling frequency sr gen over a duration
> D=Dinf er =βT 0is shown as white dot markers. From this trajectory, a training point, highlighted with a green star marker, is uniformly sampled from a subset of samples, shown as black dot markers, obtained at frequency sr train and restricted to t≤αT 0. The training horizon
> Dtrain and the inference horizon Dinf er are indicated by arrows, with the vertical dashed line marking the end of the training interval.

rately in practice. It also probably adds complexity for the model, as isolated points are not obviously correlated. Experiments are carried out for Ntrain ∈ [25 , 100 , 400] . Af-ter each training epoch, models are validated on another dataset ξeval , which is constructed as ξtrain but for 2500 trajectories. For each of the datasets, experiments are car-ried out for 10 runs with different model initializations us-ing the Adam optimizer [55] with a batch size 64 for 50 k

optimizer steps with a learning rate of 10 −3.

Inference details . The inference dataset Tinf er is constructed taking a subset of Ninf er = 100 trajectories from T for a duration Dinf er = βT 0 and a sampling rate 

sr inf er = sr train . Note that β ≫ α, i.e. the model has to generate in inference longer sequences that it has been trained for. The performance of the model is then assessed generat-ing autoregressively a trajectory ˜τ from each of the initial conditions of the trajectories in Tinf er and comparing it with the reference trajectory τ . For each model initializa-tion, we compute the Mean Squared Error (MSE) between the reference and predicted trajectories: 

Ltraj = 1

Ninf · Tinf · finf Ninf 

X

> i=1

∥τi − ˜τi∥2 (39) 

6. Results and discussions 

6.1. Impact of the number of training points 

Figure 6 shows the inference error (see Table F.11 in the Appendix F for the detailed numerical values) for the different models across the three values of Ntrain when learning the three controlled oscillatory systems with small model size. As expected, increasing the number of points decreases the error for all systems and architectures, ex-cept for when we train the PHNN-S model on the self-sustained oscillator where the performance seems to be fairly constant. The NODE architecture is consistently outperformed by one of the physically constrained mod-els. Regarding the differences between the two numerical methods, the discrete gradient outperforms the RK2 in the low-data regime for the harmonic oscillator, and for every number of training points in the case of the nonlinear os-cillators. For the Duffing oscillator, all performance errors show a high dispersion (as shown by large IQR) in the low-data regime, reflecting the model sensitivity to weight initialization when very few training points are available. Finally, whereas the PHNN-S model achieves the lowest performance error for the harmonic and Duffing oscillator, it is not the case for the self-sustained oscillator, where it is outperformed by the PHNN-JR and the NODE. Figure 7 compares the NODE with the best PHNN architecture for each oscillator when discretizing a trajectory starting on an initial condition x0 such that H(x0) = 0 .5J.

6.2. Impact of the number of trainable parameters 

Figure 8 shows the inference error (see Table F.12 in the Appendix F for the detailed numerical values) for the different models across the three regimes (small, medium, large) of trainable parameters when learning the three con-trolled oscillatory systems with Ntrain = 25 . In this case, increasing the number of trainable parameters increases the error in general for all the systems and architectures. This can be explained by the fact that there are not enough 11 25                          

> 100
> 400
> n_points
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Harmonic oscillator
> 25
> 100
> 400
> n_points
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Duffing oscillator
> 25
> 100
> 400
> n_points
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Self-sustained oscillator
> NODE-RK2 PHNN-JR-DG PHNN-JR-RK2 PHNN-S-DG PHNN-S-RK2

Figure 6: Boxplot of the inference errors for the three different oscillators and varying numbers of training points (small models). From left to right: harmonic, Duffing and self-sustained oscillators. 0.4 0.2 0.0 0.2 0.4 

p

> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> q
> Ground truth
> NODE-RK2
> PHNN-S-DG
> PHNN-S-RK2

(a) Harmonic oscillator 0.4 0.2 0.0 0.2 0.4 

p 

> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> q
> Ground truth
> NODE-RK2
> PHNN-S-DG
> PHNN-S-RK2

(b) Duffing oscillator 0.4 0.2 0.0 0.2 0.4 

p 

> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> q
> Ground truth
> NODE-RK2
> PHNN-JR-DG
> PHNN-JR-RK2

(c) Self-sustained oscillator Figure 7: Comparison of the learned trajectory discretizations for each oscillatory system starting on x0 such that H(x0) = 0 .5J. (Left )NODE and PHNN-S models trained on Ntrain = 25 from the harmonic oscillator. (Center ) NODE and PHNN-S models trained on 

Ntrain = 100 from the Duffing oscillator. ( Right ) NODE and PHNN-JR models trained on Ntrain = 25 from the self-sustained oscillator. For the harmonic and Duffing oscillator, the trajectory is obtained with u = 0 ; and for the self-sustained, with u such that the system stabilizes in a limit cycle. 

training samples to fit larger models and, thus, medium and large size models directly overfit and are not able to generalize correctly. The NODE is again consistently outperformed by one of the physically constrained mod-els. Regarding the impact of using the different numerical methods, the discrete gradient only outperforms the RK2 when training small models. Interestingly, increasing the number of trainable parameters has a positive effect on the dispersion of the results for the Duffing oscillator, as we observe how the IQR is reduced with respect to the small size setting. Figure 9 shows how the trajectory dis-cretization from the best PHNN architecture for each os-cillator changes with respect to the number of trainable parameters starting on an initial condition x0 such that 

H(x0) = 0 .5J.

6.3. Impact of the Jacobian regularizations 

Regularizing the Jacobian of the PHNN models is mo-tivated by the potential correlation existing between the inference dispersion and a high condition number, spec-tral norm or stiffness ratio mean value at the end of the training. As we observe in Figure 10, the models with the highest mean condition number, spectral norm and stiffness ratio when modeling the Duffing oscillator with 

Ntrain = 25 , i.e. PHNN-S-RK2 and PHNN-S-DG, are precisely the ones with a higher IQR value (see Figure 6 and Table F.11 in Appendix F). Furthermore, their stiff-ness ratio is higher than 1, meaning that these models are 12 small_size                          

> medium_size
> large_size
> model_size
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Harmonic oscillator
> small_size
> medium_size
> large_size
> model_size
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Duffing oscillator
> small_size
> medium_size
> large_size
> model_size
> 10 7
> 10 6
> 10 5
> 10 4
> 10 3
> 10 2
> 10 1
> 10 0
> 10 1
> traj
> Self-sustained oscillator
> NODE-RK2 PHNN-JR-DG PHNN-JR-RK2 PHNN-S-DG PHNN-S-RK2

Figure 8: Boxplot of the inference errors for the three different oscillators and model sizes ( Ntrain = 25 ). From left to right: harmonic, Duffing and self-sustained oscillators. 0.6 0.4 0.2 0.0 0.2 0.4 0.6 

p

> 0.6
> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> 0.6
> q
> Ground truth
> PHNN-S-small
> PHNN-S-medium
> PHNN-S-large

(a) Harmonic oscillator 0.6 0.4 0.2 0.0 0.2 0.4 0.6 

p 

> 0.6
> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> 0.6
> q
> Ground truth
> PHNN-S-small
> PHNN-S-medium
> PHNN-S-large

(b) Duffing oscillator 0.4 0.2 0.0 0.2 0.4 

p 

> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> q
> Ground truth
> PHNN-JR-small
> PHNN-JR-medium
> PHNN-JR-large

(c) Self-sustained oscillator Figure 9: Comparison of the learned trajectory discretizations by the discrete gradient for each oscillatory system starting on x0 such that 

H(x0) = 0 .75 J. (Left ) PHNN-S models trained on Ntrain = 25 from the harmonic oscillator. (Center ) PHNN-S models trained on 

Ntrain = 25 from the Duffing oscillator. (Right ) PHNN-JR models trained on Ntrain = 25 from the self-sustained oscillator. For the harmonic and Duffing oscillator, the trajectory is obtained with u = 0 ; and for the self-sustained, with u such that the system stabilizes in a limit cycle. 

learning a representation that is stiffer than the original system from which we generate the data. Experiments are, thus, carried out to test whether controlling the numerical behavior through any of the proposed Jacobian regulariza-tions lowers the inference error and/or dispersion. Figure 11 shows the inference error (see Table F.13 in the Appendix F for the detailed numerical values) when learning the three oscillatory systems under the differ-ent Jacobian regularizations (34)-(36) with different small models and Ntrain = 25 . BL refers to the baseline (i.e. no Jacobian regularization); CN, to the condition number reg-ularization (34); SN, to the spectral norm regularization (35); and SR, to the stiffness ratio regularization (36). In general, Jacobian regularization does not improve the re-sults for those systems in which the model performances were already good (harmonic and self-sustained oscillator). However, CN-regularization considerably improves the re-sults for the Duffing oscillator, where the dispersion was high. Interestingly, controlling the stiffness ratio towards the ground truth system value is not directly associated with an improvement in the accuracy nor the dispersion: the stiffness ratio values after SR-regularization are closer to 1 (see Figure 12) but the inference error or the disper-sion is not always reduced. 13 0 10000 20000 30000 40000 50000 

Optimizer steps 

> 10 0
> 10 1
> 10 2
> 10 3
> 10 4
> Mean condition number

Baseline 

> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(a) Condition number 0 10000 20000 30000 40000 50000 

Optimizer steps 

> 0
> 50
> 100
> 150
> 200
> 250
> Mean spectral norm

Baseline  

> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(b) Spectral norm 0 10000 20000 30000 40000 50000 

Optimizer steps 

> 10 0
> 10 1
> 10 2
> 10 3
> 10 4
> Mean stiffness ratio

Baseline  

> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(c) Stiffness ratio Figure 10: Mean condition number ( left ), spectral norm ( center ) and stiffness ratio ( right ) per optimizer step during the training for the different architectures when modeling the Duffing oscillator with Ntrain = 25 points and no Jacobian regularization (BL). For each optimizer step, the corresponding mean value (solid line) is obtained computing the average over the 10 model initializations, with the shaded area indicating the range between the minimum and maximum values. BL     

> CN
> SN
> SR
> normalization
> 10 7
> 10 5
> 10 3
> 10 1
> 10 1
> 10 3
> traj

Harmonic oscillator     

> BL
> CN
> SN
> SR
> normalization
> 10 7
> 10 5
> 10 3
> 10 1
> 10 1
> 10 3
> traj

Duffing oscillator     

> BL
> CN
> SN
> SR
> normalization
> 10 7
> 10 5
> 10 3
> 10 1
> 10 1
> 10 3
> traj

Self-sustained oscillator     

> NODE-RK2 PHNN-JR-DG PHNN-JR-RK2 PHNN-S-DG PHNN-S-RK2

Figure 11: Boxplot of the inference errors for the three different oscillators and normalizations ( Ntrain = 25 and small number of parameters). Notation: BL refers to the baseline (i.e. no Jacobian regularization); CN, to the condition number regularization (34); SN, to the spectral norm regularization (35); and SR, to the stiffness ratio regularization (36). From left to right: harmonic, Duffing and self-sustained oscillators. 

6.4. Differences between PHNN-S and PHNN-JR 

It is a recurrent conclusion in all the studies carried out in this work that the architecture that performs the best for the harmonic and Duffing oscillator is the PHNN-S, while for the self-sustained oscillator, is the PHNN-JR, independently of the numerical method used for discretiza-tion. We hypothesize that this could be due to whether the dissipation of the system is nonlinear or not, implying that PHNN-S has difficulty learning the system’s dynam-ics in the presence of nonlinear dissipation, which is the case for the self-sustained oscillator. 

7. Conclusion Contributions . In this work, we have addressed the problem of designing physically consistent neural network models based on PHS formulations and energy-preserving numerical methods. The main contributions of this study include a comparison of two theoretically equivalent PHS formulations: the PH-DAE and the input-state-output PHS with feedthrough, when implemented as PHNNs; a perfor-mance comparison between a second-order energy-preserving numerical method and a Runge-Kutta method of the same order; and a empirical study of the impact of regularizing the Jacobian of PHNN through two methods already ap-14 0 10000 20000 30000 40000 50000 

> Optimizer steps
> 10 0
> 10 1
> 10 2
> 10 3
> 10 4
> Mean condition number
> CN-regularization
> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(a) Condition number 0 10000 20000 30000 40000 50000  

> Optimizer steps
> 0
> 50
> 100
> 150
> 200
> 250
> 300
> 350
> Mean spectral norm
> SN-regularization
> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(b) Spectral norm 0 10000 20000 30000 40000 50000  

> Optimizer steps
> 10 0
> 10 1
> 10 2
> 10 3
> 10 4
> Mean stiffness ratio
> SR-regularization
> NODE-RK2
> PHNN-JR-RK2
> PHNN-JR-DG
> PHNN-S-RK2
> PHNN-S-DG

(c) Stiffness ratio Figure 12: Impact on the mean condition number ( left ), spectral norm ( center ) and stiffness ratio ( right ) per optimizer step during the training for the different architectures when modeling the Duffing oscillator with Ntrain = 25 points and the proposed Jacobian regularizations. For each optimizer step, the corresponding mean value (solid line) is obtained computing the average over the 10 model initializations, with the shaded area indicating the range between the minimum and maximum values. 

plied to NODEs and a new one tackling the stiffness of the learned ODE solutions. Our results demonstrate that the PHNN based on the discrete gradient method outperform those based on RK2, especially when the data comes from nonlinear systems and is learned by models with a small number of trainable parameters. The results also indicate that the best PHS formulation to be implemented as a neural network depends on the modeled system and where the nonlinearity operates. Interestingly, this dependence is also found in the results when Jacobian regularization is applied, where the harmonic and Duffing oscillator clearly benefited from these additional soft constraints while the self-sustained oscillator did not. Overall, the experiments on Jacobian regularization show how this technique could be used in PHNNs to improve the generalization when in-creasing the number of training points is not possible. 

Limitations . While the proposed frameworks have shown promising performance, they are subject to cer-tain limitations, including the fact the interconnection ma-trix ( S or J, depending on the formulation) is always given a priori, and that we are only considering Hamil-tonians of the form (22) and semi-explicit PHS formula-tions, which are not sufficiently general to describe any given physical system [16]. Numerically, our results are also limited by the fact that in our experiments we use second-order numerical methods, as the objective is to compare two classes of schemes (energy preserving versus non-preserving), rather than to achieve the best possible performance. As for the Jacobian regularizations, they are limited by the hypothesis that regularizing dynamics at the input data can lead to regularized dynamics across the entire solution space, which could not necessarily be the case when working with the nonlinear dynamics in-duced by neural network-based models. Furthermore, the real impact of each Jacobian regularization is not fully ex-plored in this study, as the value of λCN , λ SN and λSR in (34)-(36) are chosen equally for each physical system and architecture, without an exhaustive grid search for each case. 

Future works . Future work will focus on designing and testing learning frameworks capable of modelling PHS without knowing the interconnection matrix a priori and from which we only have access to its inputs and outputs. Of particular interest will be understanding the reasons why the performance is dependent on the PHS formulation and the modeled physical system, as well as detecting the factors that hinder the training of these models and how this relates to a well-conditioned and non-stiff learned Ja-cobian matrix. Whether the same conclusions hold when using a fourth-order discrete gradient and Runge-Kutta method remains to be explored. Finally, this framework could be used to model more complex ODE systems or even extended to tackle the learning of Hamiltonian PDEs, where power-preserving spatial discretizations should also be considered [56]. Overall, this paper provides a first comparison between the use of Runge-Kutta and discrete gradient methods in the PHNN framework as well as an extensive empirical study on the impact that different PHS formulations, num-ber of training points, size of the models or Jacobian reg-ularizations have on the modeling of a given physical sys-tem. The authors also hope that this type of work serves as a baseline for future methods and thus contribute to addressing the lack of homogeneity that characterizes sim-ilar work in the literature. 15 Acknowledgements . This project is co-funded by the European Union’s Horizon Europe research and in-novation program Cofund SOUND.AI under the Marie Sklodowska-Curie Grant Agreement No 101081674. This project was also provided with computing HPC and stor-age resources by GENCI at IDRIS thanks to the grant 2024-102911 on the supercomputer Jean Zay’s V100 par-tition. 

References 

[1] A. Cicirello, Physics-enhanced machine learning: aposition paper for dynamical systems investigations, Journal of Physics: Conference Series 2909 (1) (2024) 012034. doi:10.1088/1742-6596/2909/1/012034 .[2] J. Baxter, A model of inductive bias learning, Journal of Artificial Intelligence Research 12 (2000) 149–198. 

doi:10.1613/jair.731 .[3] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, L. Yang, Physics-informed machine learning, Nature Re-views Physics 3 (6) (2021) 422–440. doi: 10.1038/s42254-021-00314-5 .[4] S. Eidnes, A. J. Stasik, C. Sterud, E. Bøhn, S. Riemer-Sørensen, Pseudo-hamiltonian neural networks with state-dependent external forces, Physica D: Nonlin-ear Phenomena 446 (2023) 133673. doi:10.1016/j. physd.2023.133673 .[5] M. Raissi, P. Perdikaris, G. Karniadakis, Physics-informed neural networks: A deep learning frame-work for solving forward and inverse problems in-volving nonlinear partial differential equations, Jour-nal of Computational Physics 378 (2019) 686–707. 

doi:10.1016/j.jcp.2018.10.045 .[6] C. Meng, S. Griesemer, D. Cao, S. Seo, Y. Liu, When physics meets machine learning: A survey of physics-informed machine learning, Machine Learning for Computational Science and Engineering 1 (2025) 20. doi:10.1007/s44379-025-00016-0 .[7] H. K. Khalil, Nonlinear systems, 3rd Edition, Prentice Hall, Upper Saddle River, N.J., 2002. [8] J. Hadamard, Sur les problèmes aux dérivées par-tielles et leur signification physique, Princeton uni-versity bulletin (1902) 49–52. [9] M. W. Hirsch, R. L. Devaney, S. Smale, Differential equations, dynamical systems, and linear algebra, 1st Edition, Vol. 60, Academic press, 1974. [10] G. Golub, C. Van Loan, Matrix Computations, 4th Edition, Johns Hopkins Studies in the Mathematical Sciences, Johns Hopkins University Press, 2013. [11] L. N. Trefethen, D. Bau, III, Numerical Linear Al-gebra, 1st Edition, Society for Industrial and Ap-plied Mathematics, Philadelphia, PA, 1997. doi: 10.1137/1.9780898719574 .[12] A. Iserles, A First Course in the Numerical Analysis of Differential Equations, 2nd Edition, A First Course in the Numerical Analysis of Differential Equations, Cambridge University Press, 2009. [13] J. R. Taylor, Classical mechanics, 1st Edition, Calif.:University Science Books, 2005. [14] B. Maschke, A. Van Der Schaft, P. Breedveld, An intrinsic hamiltonian formulation of network dynam-ics: non-standard poisson structures and gyrators, Journal of the Franklin Institute 329 (1992) 923–966. 

doi:10.1016/S0016-0032(92)90049-M .[15] V. Duindam, A. Macchelli, S. Stramigioli, H. Bruyn-inckx, Modeling and control of complex physical sys-tems: the port-Hamiltonian approach, 1st Edition, Springer Science & Business Media, 2009. [16] A. Van Der Schaft, D. Jeltsema, et al., Port-hamiltonian systems theory: An introductory overview, Foundations and Trends ® in Systems and Control 1 (2-3) (2014) 173–378. [17] A. Chaigne, J. Kergomard, Acoustics of musical in-struments, 1st Edition, Springer, 2016. [18] S. Aoues, F. L. Cardoso-Ribeiro, D. Matignon, D. Alazard, Modeling and control of a rotating flex-ible spacecraft: A port-hamiltonian approach, IEEE Transactions on Control Systems Technology 27 (1) (2017) 355–362. doi:10.1109/TCST.2017.2771244. 

[19] T. Hélie, Elementary tools on Port-Hamiltonian Sys-tems with applications to audio/acoustics, lecture (Mar. 2022). doi:hal-03986168 .[20] F. L. Cardoso-Ribeiro, G. Haine, Y. Le Gorrec, D. Matignon, H. Ramirez, Port-hamiltonian formula-tions for the modeling, simulation and control of flu-ids, Computers & Fluids (2024) 106407 doi:10.1016/ j.compfluid.2024.106407 .[21] D. Roze, T. Hélie, E. Rouhaud, Time-space formula-tion of a conservative string subject to finite transfor-mations, IFAC-PapersOnLine 58 (6) (2024) 232–237. 

doi:10.1016/j.ifacol.2024.08.286 .[22] E. Hairer, C. Lubich, G. Wanner, Geometric numer-ical integration, 2nd Edition, Vol. 31 of Springer Se-ries in Computational Mathematics, Springer-Verlag, Berlin, 2006. [23] E. Celledoni, E. H. Høiseth, Energy-preserving and passivity-consistent numerical discretiza-tion of port-hamiltonian systems, arXiv preprint arXiv:1706.08621 (2017). 16 [24] G. Quispel, G. S. Turner, Discrete gradient methods for solving odes numerically while preserving a first in-tegral, Journal of Physics A: Mathematical and Gen-eral 29 (13) (1996) L341. doi:10.1088/0305-4470/ 29/13/006 .[25] O. Gonzalez, Time integration and discrete hamilto-nian systems, Journal of Nonlinear Science 6 (1996) 449–467. doi:10.1007/BF02440162 .[26] E. Celledoni, S. Eidnes, H. N. Myhr, Learning dynam-ical systems from noisy data with inverse-explicit inte-grators, Physica D: Nonlinear Phenomena 472 (2025) 134471. doi:10.1016/j.physd.2024.134471 .[27] R. T. Q. Chen, Y. Rubanova, J. Bettencourt, D. Du-venaud, Neural ordinary differential equations, in: Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS’18, Curran Associates Inc., Red Hook, NY, USA, 2018, p. 6572–6583. [28] E. Dupont, A. Doucet, Y. W. Teh, Augmented neural odes, in: Proceedings of the 33rd International Con-ference on Neural Information Processing Systems, Curran Associates Inc., Red Hook, NY, USA, 2019, pp. 3140–3150. [29] L. Deng, The mnist database of handwritten digit images for machine learning research, IEEE Signal Processing Magazine 29 (6) (2012) 141–142. doi: 10.1109/MSP.2012.2211477 .[30] C. Finlay, J.-H. Jacobsen, L. Nurbekyan, A. M. Ober-man, How to train your neural ode: the world of jaco-bian and kinetic regularization, in: Proceedings of the 37th International Conference on Machine Learning, ICML’20, JMLR.org, 2020, pp. 3154–3164. [31] S. Josias, W. Brink, Jacobian norm regularisation and conditioning in neural odes, in: Artificial Intelli-gence Research, Springer Nature Switzerland, Cham, 2022, pp. 31–45. [32] Y. Yoshida, T. Miyato, Spectral norm regularization for improving the generalizability of deep learning, arXiv preprint arXiv:1705.10941 (2017). [33] M. Takeru, K. Toshiki, K. Masanori, Y. Yuichi, Spectral normalization for generative adversarial net-works, in: International Conference on Learning Rep-resentations, 2018, pp. 1–26. [34] S. Greydanus, M. Dzamba, J. Yosinski, Hamiltonian neural networks, Advances in neural information pro-cessing systems 32 (2019). [35] A. Sosanya, S. Greydanus, Dissipative hamilto-nian neural networks: Learning dissipative and conservative dynamics separately, arXiv preprint arXiv:2201.10085 (2022). [36] S. A. Desai, M. Mattheakis, D. Sondak, P. Protopa-pas, S. J. Roberts, Port-hamiltonian neural networks for learning explicit time-dependent dynamical sys-tems, Physical Review E 104 (3) (2021) 034312. [37] Y. D. Zhong, B. Dey, A. Chakraborty, Symplectic ode-net: Learning hamiltonian dynamics with con-trol, arXiv preprint arXiv:1909.12077 (2019). [38] Y. D. Zhong, B. Dey, A. Chakraborty, Dissipative symoden: Encoding hamiltonian dynamics with dis-sipation and control into deep learning, arXiv preprint arXiv:2002.08860 (2020). [39] K. Cherifi, A. E. Messaoudi, H. Gernandt, M. Roschkowski, Nonlinear port-hamiltonian system identification from input-state-output data, arXiv preprint arXiv:2501.06118 (2025). [40] F. J. Roth, D. K. Klein, M. Kannapinn, J. Peters, O. Weeger, Stable port-hamiltonian neural networks, arXiv preprint arXiv:2502.02480 (2025). [41] Z. Chen, J. Zhang, M. Arjovsky, L. Bottou, Sym-plectic recurrent neural networks, arXiv preprint arXiv:1909.13334 (2019). [42] A. Zhu, P. Jin, Y. Tang, Deep hamiltonian net-works based on symplectic integrators, arXiv preprint arXiv:2004.13830 (2020). [43] D. DiPietro, S. Xiong, B. Zhu, Sparse symplectically integrated neural networks, Advances in Neural Infor-mation Processing Systems 33 (2020) 6074–6085. [44] S. Xiong, Y. Tong, X. He, S. Yang, C. Yang, B. Zhu, Nonseparable symplectic neural networks, arXiv preprint arXiv:2010.12636 (2020). [45] H. Choudhary, C. Gupta, V. Kungurtsev, M. Leok, G. Korpas, Learning generalized hamiltonians us-ing fully symplectic mappings, arXiv preprint arXiv:2409.11138 (2024). [46] A. Van der Schaft, L2-gain and passivity techniques in nonlinear control, 2nd Edition, Springer, 2000. [47] R. Muller, T. Hélie, Power-balanced modelling of cir-cuits as skew gradient systems, in: 21 st International Conference on Digital Audio Effects (DAFx-18), 2018, pp. 1–8. [48] W. Press, S. Teukolsky, W. Vetterling, B. Flannery, Numerical Recipes: The art of Scientific Computing, Thrid Edition in C++, 3rd Edition, Cambridge Uni-versity Press, 2007. [49] T. Hélie, M. Linares, G. Doras, Modèle passif mini-mal d’instrument musical auto-oscillant à configura-tion variable en temps, in: CFA 2025 - 17e Congrès Français d’Acoustique, Paris, France, 2025, pp. 1–21. 

doi:hal-05228704 .17 [50] P. Schwerdtner, Port-hamiltonian system identifi-cation from noisy frequency response data, arXiv preprint arXiv:2106.11355 (2021). [51] P. Schwerdtner, T. Moser, V. Mehrmann, M. Voigt, Structure-preserving model order reduction for in-dex one port-hamiltonian descriptor systems, arXiv preprint arXiv:2206.01608 (2022). [52] A. Zhu, P. Jin, B. Zhu, Y. Tang, On numerical in-tegration in neural ordinary differential equations, in: International Conference on Machine Learning, PMLR, 2022, pp. 27527–27547. [53] C. Neary, U. Topcu, Compositional learning of dy-namical system models using port-hamiltonian neu-ral networks, in: Learning for Dynamics and Control Conference, PMLR, 2023, pp. 679–691. [54] R. Ortega, A. J. van der Schaft, I. Mareels, B. Maschke, Energy shaping control revisited, in: Ad-vances in the control of nonlinear systems, Springer, 2007, pp. 277–307. [55] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980 (2014). [56] V. Trenchant, H. Ramirez, Y. Le Gorrec, P. Koty-czka, Finite differences on staggered grids preserving the port-hamiltonian structure with application to an acoustic duct, Journal of Computational Physics 373 (2018) 673–697. doi:10.1016/j.jcp.2018.06.051 .[57] S. H. Strogatz, Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engi-neering, 3rd Edition, CRC press, 2024. 

Appendix A. Well-posedness Theorem 1. If ∥Jf (x)∥2 ≤ K < ∞, ∀x ∈ D , then f is K-Lipschitz. 

Proof . Fix x, y ∈ D . Define the segment between them like γ(t) = x + t(y − x) for t ∈ [0 , 1] . Let g(t) = 

f (γ(t)) . By the chain rule, g′(t) = Jf (γ(t))( y − x). Using the fundamental theorem of calculus: 

f (y) − f (x) = 

Z 10

Jf (γ(t))( y − x)dt 

Considering norms, 

∥y − x∥2 ≤

Z 10

∥Jf (γ(t))( y − x)∥2dt 

By operator norm inequality 

∥Jf (γ(t))( y − x)∥2 ≤ ∥ Jf (γ(t)) ∥2∥(y − x)∥2

So 

∥f (y) − f (x)∥2 ≤

Z 10

∥Jf (γ(t)) ∥2∥(y − x)∥2dt 

From which, using ∥Jf (x)∥2 ≤ K,

∥f (y) − f (x)∥2 ≤ K∥y − x∥2

□

Following the proof of Theorem 1, it is easy to see that 

K = sup x∈D ∥Jf (x)∥2 is a Lipschitz constant. 

Appendix B. Passivity 

The concept of passivity is related to the power-balance property and it is a powerful tool for the analysis of nonlin-ear open systems. In the following, we denote ⟨a|b⟩ = aT b.

Definition 1 (Passivity, [7, Def 6.3]) . A system of state 

x(t) ∈ Rn, input u(t) ∈ Rp and output y(t) ∈ Rp is said to be passive if there exists a continuously differentiable pos-itive semidefinite function V (x) (called the storage func-tion 3) such that for all the trajectories and inputs 

⟨u(t)|y(t)⟩ ≥ ⟨∇ V (x(t)) | ˙x(t)⟩, ∀t ∈ R+ (B.1) 

Moreover, it is said to be 

• lossless if 

⟨u(t)|y(t)⟩ = ⟨∇ V (x(t)) | ˙x(t)⟩ (B.2) 

• strictly passive if 

⟨u(t)|y(t)⟩ ≥ ⟨∇ V (x(t)) | ˙x(t)⟩ + ψ(x(t)) (B.3) 

for some positive definite function ψ(x).

Note that if V (x) represents the system’s energy and 

P ext = ⟨u|y⟩ the external power given to the system, the integral of (B.1) over any period of time [0 , t ] reads 

Z t

> 0

⟨u(s)|y(s)⟩ds ≥ V (x(t)) − V (x(0)) (B.4) which interprets as "the system is passive if the energy given to the network through inputs and outputs over that period is greater or equal to the increase in the energy stored in the network over the same period". In the ab-sence of external control u = 0 , the passivity condition (B.1) implies 

V (x(0)) ≥ V (x(t)) ∀t ∈ R (B.5) 

Remark 1. If the system is governed by 

(

˙x = f (x, u)

y = h(x, u) , (B.6) the criterion (B.1) can be written as 

⟨u|h(x, u)⟩ ≥ ∇ V (x)T f (x, u), ∀(x, u) ∈ Rn × Rp.

(B.7) 

> 3The storage function is a Lyapunov function if it is positive def-inite.

18 Appendix B.1. Passivity of PHS formulations (i)-(iii) 

Proposition 1. The semi-explicit port-Hamiltonian DAE (formulation (i)) governed by 



˙xwy

| {z } 

> Fi

= S

∇H(x)

z(w)

u

| {z }

> Ei

, (B.8) 

with S = −ST and ⟨z(w)|w⟩ ≥ 0, is passive in the sense of Definition 1 for storage function V = H and input-output (u, y) = ( u, −y).

Proof . By skew-symmetry of S, ET F = ET SE = 0 ,so that the instantaneous power balance 

⟨∇ H(x)| ˙x⟩

| {z } 

> stored power PS

+ ⟨z(w)|w⟩

| {z } 

> dissipated power PR≥0

+ ⟨u|y⟩

| {z }  

> external power PP

= 0 .

(B.9) After introducing V = H and (u, y) = ( u, −y), (B.9) implies 

⟨∇ V (x)| ˙x⟩ − ⟨ u|y⟩ = −⟨ z(w)|w⟩ ≤ 0 (B.10) from which we obtain the passivity condition ((B.1)). □

Proposition 2. The input-state-output port-Hamiltonian system with feed through: 

 ˙xy

|{z} 

> Fii

=  J − R(x, u) ∇H(x)

u

| {z }

> Eii

, (B.11) 

where J = −JT and R = RT ⪰ 0 is passive in the sense of Definition 1 for storage function V = H and input-output 

(u, y) = ( u, −y). Moreover, it is strictly passive if 

ψ(x) = 

∇H(x)0

T

R

∇H(x)0



> 0, ∀x̸ = 0 (B.12) 

Proof . The instantaneous power balance 

ET F = ⟨∇ H(x)| ˙x⟩

| {z }

> PS

+ ⟨u|y⟩

| {z } 

> PP

= −

 ∇H(x)

u



|R(x)|

∇H(x)

u

 | {z }

> PR⪰0

< 0 (B.13) The passivity condition is obtained from (B.13) introduc-ing V = H and (u, y) = ( u, −y). Note that, because 

R ⪰ 0, −PR < −ψ(x). Introducing this inequality into (B.13) gives 

⟨∇ V (x)|x⟩ − ⟨ u|y⟩ = −PR < −ψ(x), (B.14) from which the strict passivity condition ((B.3)) is ob-tained. □

Proposition 3. The skew-symmetric gradient PH-DAE: 



˙xwy

| {z } 

> Fiii

= S ∇F



xwu

| {z }

> Eiii

, (B.15) 

where S = −ST and F = H(x) + Z(w) + uT u 

> 2

, with 

∇Z(w)w ≥ 0, is passive in the sense of Definition 1 for storage function V = H and input-output (u, y) = (u, −y).

The proof is similar to Proposition 1 with z(w) = 

∇Z(w).

Appendix C. Jacobian quantities for the physical systems 

Tables C.5-C.7 show the Jacobian matrix Jf (x), the spectral norm ∥Jf (x)∥2, the condition number κ(Jf (x)) 

and the stiffness ratio ρ(Jf (x)) for the different physical systems. The spectral norm is computed using the for-mula [10] 

∥Jf (x)∥2 =

q

λmax (( Jf (x)) T Jf (x)) = σmax (Jf (x)) ,

(C.1) where λmax (·), σ max (·) denotes the maximum eigenvalue and singular value of a matrix. The condition number is computed using the formula [10] 

κ(Jf (x)) = ∥Jf (x)∥2∥Jf (x)−1∥2 = σmax (Jf (x)) 

σmin (Jf (x)) (C.2) where σmax (·), σ min (·) denote the maximum and minimum singular value of a matrix. The stiffness ratio is computed using the formula [12] 

ρ(Jf (x)) = λmax (Jf (x)) 

λmin (Jf (x)) (C.3) where λmax (·), λ min (·) denote the maximum and minimum eigenvalue of a matrix. 

Appendix D. Implementation details 

Table E.8-E.10 show the design choices for each sub-network inside the PHNN that models the energy or the dissipation of the system. 

Appendix E. Initial conditions and control design Initial condition sampling : All the Hamiltonians in this work can be written in the form 

H(q, p ) = 12m p2 + 12 k1q2 + β

4 k3q4 (E.1) 19 System Harmonic oscillator (linear) 

Jf (x)

 0 1

m

−k − αm



∥Jf (x)∥2

s

12



k2 + 1+ α2

m2 +

q k2 + 1+ α2

m2

2 − 4k2

m2



κ(Jf (x)) 

vuuuut

k2+ 1+ α2

m2 +

s

k2− 1+ α2

m2

2

+ 4k2α2

m2

k2+ 1+ α2

m2 −

s

k2− 1+ α2

m2

2

+ 4k2α2

m2

ρ(Jf (x)) 1, if α 2 < 4km (underdamped )

Table C.5: Jacobian matrix, spectral norm, condition number and stiffness ratio for the harmonic oscillator. 

System Duffing oscillator (nonlinear) 

Jf (x)

 0 1

m

−k1 − 3k3q2 − αm



∥Jf (x)∥2

s

12



(k1 + 3 k3q2)2 + 1+ α2

m2 +

q (k1 + 3 k3q2)2 + 1+ α2

m2

2 − 4( k1+3 k3q2)2

m2



κ(Jf (x)) 

vuuuut

(k1+3 k3q2)2+ 1+ α2

m2 +

s

(k1+3 k3q2)2− 1+ α2

m2

2

+ 4α2(k1+3 k3q2)2

m2

(k1+3 k3q2)2+ 1+ α2

m2 −

s

(k1+3 k3q2)2− 1+ α2

m2

2

+ 4α2(k1+3 k3q2)2

m2

ρ(Jf (x)) 1, if α2 < 4m(k1 + 3 k3q2) (underdamped) 

Table C.6: Jacobian matrix, spectral norm, condition number and stiffness ratio for the Duffing oscillator. 

System Self-sustained oscillator (nonlinear) 

Jf (x)

−Γ′(w)kq − Γ( w)k − 1

m

k 0



∥Jf (x)∥2

vuut 12 k2 Γ′(w)q + Γ( w)2 + k2 + 1

m2 +

r

k2 Γ′(w)q + Γ( w)2 + k2 + 1

m2

2

− 4k2

m2

!

κ(Jf (x)) 

vuuut k2(Γ ′(w)q+Γ( w)) 2+k2+ 1

m2 +

r

k2(Γ ′(w)q+Γ( w)) 2+k2− 1

m2

2

+ 4k2(Γ ′(w)q+Γ( w)) 2

m2

k2(Γ ′(w)q+Γ( w)) 2+k2+ 1

m2 −

r

k2(Γ ′(w)q+Γ( w)) 2+k2− 1

m2

2

+ 4k2(Γ ′(w)q+Γ( w)) 2

m2

ρ(Jf (x)) 1, if k2(Γ ′(w)q + Γ( w)) 2 < 4km (underdamped) 

Table C.7: Jacobian matrix, spectral norm, condition number and stiffness ratio for the self-sustained oscillator. 

For the harmonic (HO) and the self-sustained oscillator (SSO), the Hamiltonian satisfies β = 0 , so that (E.1) par-ticularizes to 

H(q, p ) = p2

2m + 12 k1q2 (E.2) We now want to sample an initial condition x0 = ( q0, p 0)

so that H(x0) ∈ I E0 = [ Emin , E max ]. This problems is equivalent to sample (q, p ) such that 

E0 = p2

2m + 12 k1q2, E0 ∈ I E0 (E.3) 20 Note that (E.3) is the equation of an ellipse with semiaxes 

a =

q 2E0 

> k1

and b = √2E0m. In parametric equations, this means that (q, p ) can be written as: 

(

q =

q 2E0 

> k1

sin θp = √2mE 0 cos θ E0 ∈ I E0 , θ ∈ [0 , 2π) (E.4) The initial condition sampling method (Algorithm 1) for the harmonic and self-sustained oscillator is based on (E.4). 

Algorithm 1 Initial condition sampling for HO and SSO 

Require: Emin , E max 

Ensure: (q, p ) 

> 1:

Sample θ ∼ U (0 , 2π) 

> 2:

Sample r ∼ U (Emin , E max ) 

> 3:

Compute E0 ← √r 

> 4:

Compute 

q ←

r 2E0

k1

sin θ, p ← p2mE 0 cos θ 

> 5:

return (q, p )

For the Duffing oscillator (DO), the Hamiltonian sat-isfies β > 0 in (E.1). This Hamiltonian is not quadratic, which increases the complexity if we are to design a sim-ilar sampling technique to the one described before. In this case, the initial condition sampling is based on an acceptance-rejection method ((Algorithm 2)). 

Algorithm 2 Initial condition sampling for DO 

Require: Emin , E max , q min , q max , p min , p max 

Ensure: (q, p ) 

> 1:

repeat  

> 2:

Sample q ∼ U (qmin , q max ) 

> 3:

Sample p ∼ U (pmin , p max ) 

> 4:

Compute H0 ← H(q, p ) 

> 5:

until Emin ≤ H0 ≤ Emax ▷ Accept only if Hamiltonian in desired range  

> 6:

return (q, p )

Control design : For the harmonic and Duffing oscil-lator, external control was applied as a constant force u

so that 

H(x∗) ∈ I Eeq = [ Emin eq , E max eq ] (E.5) The equilibrium ph-DAE formulation for these systems is 



˙q = 0 ˙p = 0 

w∗

y∗

 =



0 1 0 0

−1 0 −1 −10 1 0 00 1 0 0



∇q H(q∗, p ∗) = f (q∗)

∇pH(q∗, p ∗) = p∗/m z(w∗)

u∗



(E.6) which simplifies to 



0 = p∗/m 

0 = −f (q∗) − z(w∗) − u∗

w∗ = p∗/m y∗ = p∗/m 

(E.7) From (E.7), p∗ = w∗ = y∗ = 0 , which also implies that 

z(w∗) = cw ∗ = 0 . The equilibrium point of the system 

(q∗, p ∗) satisfies 

(

H(q∗, p ∗) = 12 k1(q∗)2 + β 

> 4

k3(q∗)4 = Eeq ∈ I Eeq 

f (q∗) = k1q∗ + βk 3(q∗)3 = −u∗

(E.8) The following algorithm is designed to find the control u∗

that shifts the equilibrium point to the desired energy. 

Algorithm 3 Control design for the HO and DO 

Require: Emin  

> eq

, E max 

> eq

Ensure: Control input u∗ 

> 1:

Sample Eeq ∼ U (Emin  

> eq

, E max  

> eq

) 

> 2:

Find q∗ such that H(q∗, 0) = Eeq  

> 3:

Compute control input u∗ ← − k1q∗ − βk 3(q∗)3 

> 4:

return u∗

For the case of the self-sustained oscillator, we want to apply a constant control u such that the system stabi-lizes in a limit cycle around x∗. The equilibrium ph-DAE formulation for this system is 



˙q = 0 ˙p = 0 

w∗

y∗

 =



0 −1 1 01 0 0 0

−1 0 0 −10 0 1 0



∇q H(q∗, p ∗) = kq ∗

∇pH(q∗, p ∗) = p∗/m z(w∗)

u∗



(E.9) which simplifies to 



0 = −p∗/m + z(w∗)0 = kq ∗

w∗ = −kq ∗ − u∗

y∗ = z(w∗)

(E.10) We note that the system has en equilibrium point in (q∗, p ∗) = (0 , m · z(w∗)) . In order to determine whether closed orbits arise in this system, we use the Poincaré-Bendixson theo-rem [57]. As there is only one fixed point, and the phase space is of dimension 2, the existence of a close orbit (or, limit cycle) is guaranteed if the fixed point is unstable. The fixed point is unstable if ∆ > 0 and τ < 0 (see [57]), where ∆ and τ are the determinant and the trace of the Jacobian matrix Jf of f = ( ˙ q, ˙p) evaluated at the fixed point. From (E.10) 

Jf (q∗, p ∗) = 

z′(w∗) · k − 1

> m

k 0



(E.11) 21 Model Components Network Input Layers Hidden Output Number of parameters type dimension units dimension (per component) (per model) NODE Black-box MLP 3 3 100 2 21,4k 21,4k PHNN-JR LθLH (x) MLP 2 2 100 3 10,7k 21,8k 

LθLR (x, u) MLP 3 2 100 3 11,1k PHNN-S LθLH (x) MLP 2 2 100 3 10,7k 21,1k LθLz (w) MLP 1 2 100 1 10,4k 

KθLz (w) MLP 1 2 100 0 0

> Table E.8: Specificities of the implemented port-Hamiltonian neural networks with large number of parameters.

Model Components Network Input Layers Hidden Output Number of parameters type dimension units dimension (per component) (per model) NODE Black-box MLP 3 2 60 2 4,3k 4,3k PHNN-JR LθLH (x) MLP 2 2 42 3 2,1k 4,3k 

LθLR (x, u) MLP 3 2 42 3 2,2k PHNN-S 

LθLH (x) MLP 2 2 42 3 2,1k 4,1k LθLz (w) MLP 1 2 42 1 2k 

KθLz (w) MLP 1 2 42 0 0

> Table E.9: Specificities of the implemented port-Hamiltonian neural networks with medium size of parameters.

Model Components Network Input Layers Hidden Output Number of parameters type dimension units dimension (per component) (per model) NODE Black-box MLP 3 2 24 2 848 848 PHNN-JR LθLH (x) MLP 2 2 16 3 371 809 

LθLR (x, u) MLP 3 2 16 3 438 PHNN-S 

LθLH (x) MLP 2 2 16 3 371 852 LθLz (w) MLP 1 2 20 1 481 

KθLz (w) MLP 1 2 20 0 0

> Table E.10: Specificities of the implemented port-Hamiltonian neural networks with low size of parameters.

The Jacobian matrix Jf has determinant ∆ = km > 

0 and trace τ = z′(w∗) · k. In order to generate self-oscillations, the external force u must be chosen so that 

z′(w∗) = z′(−kq ∗ − u) < 0. Taking into account that in the equilibrium q∗ = 0 and w∗ = −u∗, the set of external controls that sets the system in a self-oscillation is 

u∗ = −w∗ where w∗ ∈ { w ∈ R | z′(w) < 0} (E.12) The above information gives the following algorithm 

Algorithm 4 Control design for the SSO 

Require: z(w)

Ensure: Control input u∗ 

> 1:

Find Iw = {w ∈ R | z′(w) < 0}. 

> 2:

Sample w ∼ U (Iw) 

> 3:

Compute control input u∗ = −w 

> 4:

return u∗

Appendix F. Table of results 

Tables F.11-F.13 show the exact inference errors for each of the studies presented in Section 5. In each table cell, the median value and IQR for 10 model initializations are reported. 22 Harmonic 25 100 400 NODE-RK2 2.53e-02 [2.33e-02] 1.69e-04 [1.54e-04] 2.79e-05 [1.84e-05] PHNN-JR-DG 2.58e-04 [3.82e-04] 9.10e-06 [1.22e-05] 7.29e-06 [5.07e-06] PHNN-JR-RK2 1.14e-04 [1.02e-04] 6.88e-06 [3.81e-06] 5.18e-06 [5.50e-06] PHNN-S-DG 4.22e-05 [5.99e-05] 6.24e-06 [4.97e-06] 4.78e-06 [1.21e-05] PHNN-S-RK2 4.89e-05 [2.11e-04] 5.77e-06 [9.55e-06] 3.73e-06 [8.89e-06] Duffing 25 100 400 NODE-RK2 4.09e-01 [1.01e+00] 7.62e-02 [2.62e-01] 3.67e-03 [2.73e-03] PHNN-JR-DG 4.36e-01 [1.19e+00] 1.83e-02 [2.55e-02] 7.89e-03 [4.76e-03] PHNN-JR-RK2 5.82e-01 [2.96e+00] 2.13e-02 [3.15e-02] 6.15e-03 [9.92e-03] PHNN-S-DG 7.06e-02 [4.37e+00] 8.08e-03 [4.93e-02] 9.08e-04 [8.69e-04] 

PHNN-S-RK2 9.35e-02 [4.54e+00] 2.07e-02 [1.85e-02] 9.17e-03 [6.13e-03] 

Self-sustained 25 100 400 NODE-RK2 2.59e-02 [2.21e-02] 2.01e-04 [1.38e-04] 9.56e-05 [9.18e-05] PHNN-JR-DG 1.71e-03 [2.71e-03] 7.93e-05 [5.03e-05] 7.06e-05 [7.01e-05] 

PHNN-JR-RK2 1.38e-02 [2.48e-02] 2.59e-04 [2.63e-04] 1.39e-04 [2.20e-04] PHNN-S-DG 5.40e-03 [3.60e-03] 1.68e-03 [4.83e-04] 2.72e-03 [1.12e-03] PHNN-S-RK2 4.26e-03 [7.81e-03] 2.64e-03 [1.60e-03] 2.22e-03 [7.85e-04] 

> Table F.11: Median inference error and IQR (in brackets) for different numbers of training points when learning the three oscillatory systems with small models. In bold, the best result for each combination of system and number of training points.

Harmonic Small size Medium size Large size NODE-RK2 2.53e-02 [2.33e-02] 2.85e-02 [2.59e-02] 1.45e-01 [4.67e-02] PHNN-JR-DG 2.58e-04 [3.82e-04] 1.47e-04 [2.68e-04] 7.33e-04 [2.52e-03] PHNN-JR-RK2 1.14e-04 [1.02e-04] 5.56e-05 [1.19e-04] 1.51e-04 [3.87e-04] 

PHNN-S-DG 4.22e-05 [5.99e-05] 5.56e-05 [9.58e-05] 2.45e-04 [4.59e-04] PHNN-S-RK2 4.89e-05 [2.11e-04] 4.28e-05 [3.73e-05] 2.01e-04 [2.13e-04] 

Duffing Small size Medium size Large size NODE-RK2 4.09e-01 [1.01e+00] 3.80e-01 [1.77e+00] 2.31e-01 [3.08e+00] PHNN-JR-DG 4.36e-01 [1.19e+00] 1.15e-01 [1.19e-01] 3.08e-01 [4.01e-01] PHNN-JR-RK2 5.82e-01 [2.96e+00] 1.50e-01 [2.60e-01] 3.08e-01 [7.61e-02] PHNN-S-DG 7.06e-02 [4.37e+00] 8.63e-02 [1.10e-01] 1.80e-01 [1.46e-01] 

PHNN-S-RK2 9.35e-02 [4.54e+00] 7.42e-02 [7.00e-02] 2.19e-01 [1.70e-01] 

Self-sustained Small size Medium size Large size NODE-RK2 2.59e-02 [2.21e-02] 3.74e-02 [3.06e-02] 6.53e-02 [5.74e-02] PHNN-JR-DG 1.71e-03 [2.71e-03] 6.56e-03 [2.02e-02] 7.59e-03 [1.54e-02] PHNN-JR-RK2 1.38e-02 [2.48e-02] 1.36e-02 [2.37e-02] 1.75e-02 [1.50e-02] PHNN-S-DG 5.40e-03 [3.60e-03] 6.12e-03 [3.48e-03] 7.74e-03 [5.18e-03] PHNN-S-RK2 4.26e-03 [7.81e-03] 3.98e-03 [2.95e-03] 3.77e-03 [4.27e-03]   

> Table F.12: Median inference error and IQR (in brackets) for different model sizes when learning the three oscillatory systems with Ntrain = 25 .In bold, the best result for each combination of system and model size.

23 Harmonic BL CN SN SR NODE-RK2 2.53e-02 [2.33e-02] 7.82e-02 [1.63e+00] 2.63e-02 [2.53e-02] 2.56e-02 [5.70e-02] PHNN-JR-DG 2.58e-04 [3.82e-04] 2.20e-04 [3.40e-04] 1.94e-04 [3.09e-04] 2.30e-04 [3.19e-04] PHNN-JR-RK2 1.14e-04 [1.02e-04] 1.50e-04 [5.70e-04] 7.18e-05 [9.39e-05] 1.26e-04 [1.46e-04] PHNN-S-DG 4.22e-05 [5.99e-05] 3.84e-05 [4.05e-05] 3.44e-05 [6.62e-05] 1.13e-04 [3.07e-04] PHNN-S-RK2 4.89e-05 [2.11e-04] 1.17e-05 [5.67e-05] 5.66e-05 [2.02e-04] 2.97e-05 [5.35e-04] 

Duffing BL CN SN SR NODE-RK2 4.09e-01 [1.01e+00] 9.93e+00 [4.77e+01] 5.77e-01 [9.72e-01] 7.33e-01 [5.18e+00] PHNN-JR-DG 4.36e-01 [1.19e+00] 6.72e+00 [5.63e+01] 3.55e-01 [1.24e+01] 4.43e-01 [8.66e+01] PHNN-JR-RK2 5.82e-01 [2.96e+00] 2.76e+00 [2.35e+01] 3.26e-01 [2.69e+01] 9.97e-01 [3.91e+02] PHNN-S-DG 7.06e-02 [4.37e+00] 5.15e-02 [8.92e-02] 6.26e-02 [1.07e-01] 6.57e-02 [2.54e+00] 

PHNN-S-RK2 9.35e-02 [4.54e+00] 6.74e-02 [5.83e-02] 8.27e-02 [4.53e+00] 6.97e+00 [2.80e+01] Self-sustained BL CN SN SR NODE-RK2 2.59e-02 [2.21e-02] 4.04e-02 [1.63e-02] 2.39e-02 [3.27e-02] 3.10e-02 [4.33e-02] PHNN-JR-DG 1.71e-03 [2.71e-03] 2.84e-03 [2.74e-03] 1.91e-03 [3.14e-03] 1.43e-02 [2.36e-02] PHNN-JR-RK2 1.38e-02 [2.48e-02] 8.24e-03 [2.58e-02] 1.38e-02 [2.93e-02] 3.62e-02 [3.97e-02] PHNN-S-DG 5.40e-03 [3.60e-03] 4.90e-03 [3.89e-03] 5.23e-03 [3.72e-03] 1.22e-02 [4.37e-03] PHNN-S-RK2 4.26e-03 [7.81e-03] 5.00e-03 [5.67e-03] 4.31e-03 [8.56e-03] 5.11e-03 [6.72e-03]     

> Table F.13: Median inference error and IQR (in brackets) after applying the different Jacobian regularizations when learning the three oscillatory systems with Ntrain = 25 and small models. The best result for each combination of system and Jacobian regularization is shown in bold. Notation: BL refers to the baseline (i.e. no Jacobian regularization); CN, to the condition number regularization (34); SN, to the spectral norm regularization (35); and SR, to the stiffness ratio regularization (36)

24 Figure captions 

Figure 1: Architecture of the two PHNN models con-sidered in this work. White boxes with orange contour denote fixed algebraic operations whereas orange boxes in-dicate the trainable parameters. Figure 2: Training and inference diagram for the con-tinuous models fθ .Figure 3: Training and inference diagram for the dis-crete models gθ .Figure 4: Training points, test initial points and two complete test trajectories for each of the three oscillatory systems. Note that in the case of the harmonic and Duff-ing oscillator, the applied control shifted the equilibrium point from (p, q ) = (0 , 0) whereas in the case of the self-sustained oscillator, it stabilizes the trajectories in a limit cycle. Figure 5: Schematic sampling and dataset construc-tion procedure. A trajectory generated at sampling fre-quency sr gen over a duration D = Dinf er = βT 0 is shown as white dot markers. From this trajectory, a training point, highlighted with a green star marker, is uniformly sampled from a subset of samples, shown as black dot markers, obtained at frequency sr train and restricted to 

t ≤ αT 0. The training horizon Dtrain and the inference horizon Dinf er are indicated by arrows, with the vertical dashed line marking the end of the training interval. Figure 6: Boxplot of the inference errors for the three different oscillators and varying numbers of training points (small models). From left to right: harmonic, Duffing and self-sustained oscillators. Figure 7: Comparison of the learned trajectory dis-cretizations for each oscillatory system starting on x0 such that H(x0) = 0 .5J. (Left ) NODE and PHNN-S mod-els trained on Ntrain = 25 from the harmonic oscilla-tor. (Center ) NODE and PHNN-S models trained on 

Ntrain = 100 from the Duffing oscillator. ( Right ) NODE and PHNN-JR models trained on Ntrain = 25 from the self-sustained oscillator. For the harmonic and Duffing os-cillator, the trajectory is obtained with u = 0 ; and for the self-sustained, with u such that the system stabilizes in a limit cycle. Figure 8: Boxplot of the inference errors for the three different oscillators and model sizes ( Ntrain = 25 ). From left to right: harmonic, Duffing and self-sustained oscilla-tors. Figure 9: Comparison of the learned trajectory dis-cretizations by the discrete gradient for each oscillatory system starting on x0 such that H(x0) = 0 .75 J. (Left )PHNN-S models trained on Ntrain = 25 from the har-monic oscillator. (Center ) PHNN-S models trained on 

Ntrain = 25 from the Duffing oscillator. ( Right ) PHNN-JR models trained on Ntrain = 25 from the self-sustained oscillator. For the harmonic and Duffing oscillator, the tra-jectory is obtained with u = 0 ; and for the self-sustained, with u such that the system stabilizes in a limit cycle. Figure 10: Mean condition number ( left ), spectral norm (center ) and stiffness ratio ( right ) per optimizer step dur-ing the training for the different architectures when mod-eling the Duffing oscillator with Ntrain = 25 points and no Jacobian regularization (BL). For each optimizer step, the corresponding mean value (solid line) is obtained comput-ing the average over the 10 model initializations, with the shaded area indicating the range between the minimum and maximum values. Figure 11: Boxplot of the inference errors for the three different oscillators and normalizations ( Ntrain = 25 and small number of parameters). Notation: BL refers to the baseline (i.e. no Jacobian regularization); CN, to the condition number regularization (34); SN, to the spectral norm regularization (35); and SR, to the stiffness ratio regularization (36). From left to right: harmonic, Duffing and self-sustained oscillators. Figure 12: Impact on the mean condition number ( left ), spectral norm ( center ) and stiffness ratio ( right ) per op-timizer step during the training for the different architec-tures when modeling the Duffing oscillator with Ntrain =25 points and the proposed Jacobian regularizations. For each optimizer step, the corresponding mean value (solid line) is obtained computing the average over the 10 model initializations, with the shaded area indicating the range between the minimum and maximum values. 25