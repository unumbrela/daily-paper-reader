---
title: "QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery"
title_zh: QuPAINT：一种用于量子材料发现的物理感知指令微调方法
authors: "Xuan-Bac Nguyen, Hoang-Quan Nguyen, Sankalp Pandey, Tim Faltermeier, Nicholas Borys, Hugh Churchill, Khoa Luu"
date: 2026-02-19
pdf: "https://arxiv.org/pdf/2602.17478v1"
tags: ["query:sr"]
score: 6.0
evidence: 用于量子材料科学发现的物理感知框架。
tldr: 针对二维量子材料光学表征中对比度微弱、标注数据匮乏及跨实验室泛化难的问题，本文提出QuPAINT框架。该框架包含物理驱动的合成数据生成器Synthia、大规模指令微调数据集QMat-Instruct，以及集成物理先验注意力的多模态模型。通过物理信息与视觉特征的融合，显著提升了模型对材料厚度和外观的理解能力，并建立了标准化基准QF-Bench。
motivation: 现有视觉模型在量子材料表征中缺乏物理先验，难以应对有限的标注数据和多变的实验环境。
method: 提出结合物理合成数据生成、物理信息指令微调及物理感知注意力机制的多模态架构QuPAINT。
result: 成功构建了首个大规模量子材料指令数据集和标准化基准，增强了模型在不同材料和成像条件下的鲁棒性。
conclusion: 物理感知指令微调能有效提升多模态大模型在量子材料发现领域的表征能力和泛化性能。
---

## 摘要
由于细微的层依赖对比度、有限的标注数据以及实验室和成像设置之间的显著差异，从光学显微镜图像中表征二维量子材料具有挑战性。现有的视觉模型在这一领域表现不佳，因为它们缺乏物理先验，且无法泛化到新材料或硬件条件。本研究提出了一种新的物理感知多模态框架，从数据和模型两个角度解决了这些局限性。我们首先介绍了 Synthia，这是一种基于物理的合成数据生成器，能够模拟薄膜干涉下量子材料薄片的真实光学响应。Synthia 生成了多样化且高质量的样本，有助于减少对专家手动标注的依赖。我们推出了 QMat-Instruct，这是首个针对量子材料的大规模指令数据集，包含多模态、物理感知的问答对，旨在教导多模态大语言模型 (MLLM) 理解薄片的外观和厚度。随后，我们提出了物理感知指令微调 (QuPAINT)，这是一种多模态架构，结合了物理感知注意力模块，将视觉嵌入与光学先验融合，从而实现更稳健且更具辨别力的薄片表征。最后，我们建立了 QF-Bench，这是一个涵盖多种材料、基底和成像设置的综合基准，为公平且可重复的评估提供了标准化协议。

## Abstract
Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since they lack physical priors and cannot generalize to new materials or hardware conditions. This work presents a new physics-aware multimodal framework that addresses these limitations from both the data and model perspectives. We first present Synthia, a physics-based synthetic data generator that simulates realistic optical responses of quantum material flakes under thin-film interference. Synthia produces diverse and high-quality samples, helping reduce the dependence on expert manual annotation. We introduce QMat-Instruct, the first large-scale instruction dataset for quantum materials, comprising multimodal, physics-informed question-answer pairs designed to teach Multimodal Large Language Models (MLLMs) to understand the appearance and thickness of flakes. Then, we propose Physics-Aware Instruction Tuning (QuPAINT), a multimodal architecture that incorporates a Physics-Informed Attention module to fuse visual embeddings with optical priors, enabling more robust and discriminative flake representations. Finally, we establish QF-Bench, a comprehensive benchmark spanning multiple materials, substrates, and imaging settings, offering standardized protocols for fair and reproducible evaluation.