Title: NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering

URL Source: https://arxiv.org/pdf/2602.15353v1

Published Time: Wed, 18 Feb 2026 01:29:11 GMT

Number of Pages: 26

Markdown Content:
# NEURO SYM ACTIVE : D IFFERENTIABLE NEURAL -S YMBOLIC 

# REASONING WITH ACTIVE EXPLORATION FOR KNOWLEDGE 

# GRAPH QUESTION ANSWERING 

Rong Fu ∗

University of Macau 

mc46603@um.edu.mo 

Yang Li 

University of Chinese Academy of Sciences 

liyang221@mails.ucas.ac.cn 

Zeyu Zhang 

The Australian National University 

steve.zeyu.zhang@outlook.com 

Jiekai Wu 

Juntendo University 

ketsu0612@gmail.com 

Yaohua Liu 

Guangdong Institute of Intelligence Science and Technology 

liuyaohua@gdiist.cn 

Shuaishuai Cao 

Central South University 

202226204053@jxnu.edu.cn 

Yangchen Zeng 

Southeast University 

220245765@seu.edu.cn 

Yuhang Zhang 

China Agricultural University 

zyh140981@outlook.com 

Xiaojing Du 

Adelaide University 

xiaojing.du@adelaide.edu.au 

Chuang Zhao 

The Hong Kong University of Science and Technology 

czhaobo@connect.ust.hk 

Kangning Cui 

Wake Forest University 

cuij@wfu.edu 

Simon Fong 

University of Macau 

ccfong@um.edu.mo 

February 18, 2026 

## ABSTRACT 

Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive , a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines. 

Keywords Knowledge Graph Question Answering; neural-symbolic reasoning; differentiable logic; active exploration; Monte Carlo search 

> ∗

Corresponding author: mc46603@um.edu.mo 

> arXiv:2602.15353v1 [cs.CL] 17 Feb 2026

NeuroSymActive 

## 1 Introduction 

Large language models have produced striking improvements in many language tasks, but they do not always provide robust solutions for questions that require structured, multi-hop reasoning over world knowledge. Knowledge graphs are a natural vehicle for encoding factual relations and multi-step semantic chains, yet incorporating graphs into neural pipelines raises several practical and methodological issues. One common strategy retrieves relevant subgraphs and injects them into neural models or prompts; this approach grounds model predictions but can be inefficient, since iterative retrieval and repeated model calls are often necessary to assemble multi-hop evidence [ 1, 2, 3]. Another line of work embeds graph structure into differentiable modules or applies soft logical operators to enable gradient-based refinement; these methods improve interpretability and allow end-to-end training, but they can struggle to discover long-range compositional paths without targeted search guidance [ 4, 5, 6]. Symbolic search and beam-style expansion offer exhaustive path coverage but at the cost of many KG lookups and brittle heuristics [ 7, 8 ]. Recent attempts to combine learning and search point to the benefit of guiding exploration with learned value estimates, but existing instantiations have not fully reconciled differentiable symbolic constraints with principled active exploration [9, 10]. Motivated by these gaps, we present NeuroSymActive, a framework that tightly integrates three components. The first is a differentiable neural-symbolic reasoning layer that supports soft pattern matching and differentiable rule scoring, which allows logical preferences to be learned from data while retaining interpretability. The second is a neural path evaluator that assigns value estimates to partial reasoning trajectories. The third is an active exploration controller that uses the evaluator to prioritize expansion and rollout, thereby focusing retrieval effort on promising branches and reducing unnecessary KG queries. This design intentionally separates offline learning of symbolic affinities from online search control, enabling efficient and adaptive multi-hop reasoning under constrained retrieval budgets. Our contributions are as follows. Our first contribution is a compact differentiable neural-symbolic module for KG reasoning that supports soft-unification, differentiable scoring of rule-like patterns, and seamless interfacing with neural path evaluators. Our second contribution is an active exploration mechanism that integrates learned value signals into a Monte Carlo style search procedure; this mechanism concentrates retrieval and expansion on high-payoff paths and reduces the number of costly lookups. Our third contribution is an empirical study demonstrating that the combined system improves the accuracy-efficiency trade-off on standard KGQA benchmarks compared to retrieval-heavy baselines and to purely symbolic pipelines. Together, these elements make multi-hop KGQA more tractable for deployments that must minimize query cost while preserving interpretable reasoning traces. 

## 2 Related Work 

2.1 Neural–Symbolic Integration 

Neural and symbolic methods have been combined to yield systems that leverage the perceptual strength of deep networks alongside the compositionality and interpretability of symbolic rules. Early work on joint neural perception and logic reasoning established the value of end-to-end coupling between perception modules and symbolic inference engines [ 11 , 12 , 13 ]. Differentiable relaxations of logic programs enable gradient-based learning of rule weights and structure, which improves robustness on noisy or structured examples [ 14 , 15 , 4 , 16 ]. More recent studies scale differentiable neuro-symbolic reasoning to large knowledge graphs and propose practical approximations that trade off efficiency and fidelity to logical constraints [ 17 , 18 ]. Surveys and reviews summarize advances and identify central challenges such as scalability, multimodal integration, and preserving interpretability [ 19 , 20 ]. These works provide the foundational techniques that our system adapts to the multi-hop KGQA setting. 

2.2 Differentiable Rule Learning and Logic Networks 

Learning first-order rules through differentiable semantics has seen rapid progress. Approaches construct continuous surrogates for logical operators, enabling rules to be discovered and refined with gradient signals [ 4 , 14 , 16 ]. Archi-tectures that produce interpretable logic networks by softening discrete components have demonstrated competitive performance while improving model transparency [ 16 , 15 ]. Complementary lines of work study probabilistic soft logic and energy-based neuro-symbolic models that meld weighted rules with embedding-based scores [ 13 , 17 ]. These methods inform our differentiable inductive logic layer and the techniques used to update rule confidences from supervised and human-provided signals. 

2.3 Human-in-the-Loop and Active Supervision 

Human involvement during model training and inference can dramatically increase sample efficiency and correctness for uncertain decisions. Active learning and related human-in-the-loop paradigms provide mechanisms to query annotators 2NeuroSymActive selectively, with proven benefits across domains [ 21 , 22 , 23 , 24 ]. The literature distinguishes active selection strategies that reduce label cost from interactive protocols that allow richer human guidance [ 21 , 25 ]. Graph-specific active schemes, including hybrid uncertainty reduction and noisy-crowd models, are particularly relevant when queries concern graph structure or relation validity [ 8, 26 ]. We design our query policy and replay buffer to concentrate human effort where it yields maximal information gain, building on these established techniques. 

2.4 Uncertainty Quantification and Entropy Prediction 

Accurate uncertainty estimates are central to effective query selection and to adaptive exploration strategies. Work on epistemic and heteroscedastic uncertainty for neural networks proposes principled estimators and Bayesian ap-proximations that improve active-selection reliability [ 27 , 28 , 29 , 30 , 31 ]. For graph-structured data and few-shot KG completion, uncertainty-aware GNNs have been proposed to model distributional uncertainty and to guide sampling [ 32 , 33 , 34 ]. These techniques motivate our neural entropy predictor and the calibration methods we apply to the uncertainty module. 

2.5 Retrieval-Augmented Generation and RAG-DDR 

Integrating retrieval components with generative models has become a practical approach to reduce model hallucinations and recover up-to-date facts [ 35 , 36 , 37 , 38 ]. Recent proposals frame end-to-end optimization of retrieval-augmented systems through differentiable reward signals, aligning retrieval and generation modules for global performance gains [ 35 , 39 , 36 ]. Our adapter design and the way we condition LLMs on compact, fused path representations are informed by these retrieval and optimization strategies [35, 39, 37]. 

2.6 Search, Monte Carlo Tree Search and Differentiable Exploration 

Search-based methods that view multi-hop KGQA as sequential decision making have advanced with MCTS- and RL-style explorations. Training-free tree search guided by LLM evaluations yields competitive reasoning traces [ 40 , 41 , 42 ]. Differentiable relaxations for discrete selection, such as Gumbel-Softmax and straight-through estimators, enable backpropagation through exploration and selection decisions [ 43 , 44 ]. Prior work combines structured exploration with neural guidance to improve path discovery over KGs [ 45 , 46 , 47 ]. We adopt progressive widening and a continuously relaxed rollout mechanism so that inner-loop search remains differentiable and compatible with gradient-based updates. 

2.7 Knowledge Graph Question Answering and Multi-hop Reasoning 

Classical and modern KGQA approaches range from end-to-end embedding models to hybrid pipelines that retrieve subgraphs and apply symbolic or neural reasoning [ 48 , 45 , 49 , 47 ]. The multi-hop KGQA literature emphasizes accurate subgraph retrieval, robust path scoring, and methods for mitigating spurious paths [ 50 , 51 , 52 , 45 ]. Recent works explore LLMs as reasoning agents over KGs and study decomposition or conversation-based interactions to refine answers [ 53 , 54 , 55 ]. Our framework addresses the three core KGQA challenges simultaneously: targeted retrieval, symbolic plausibility scoring, and LLM-conditioned answer generation. 

2.8 Prompting, Adapter Strategies and Compact LLMs 

Prompt-based and adapter-based conditioning of frozen LLMs provide parameter-efficient ways to incorporate structured context [ 56 , 57 , 58 , 59 ]. Knowledge adapters map fused graph and symbolic signals into compact soft prompts that preserve task-relevant information while controlling token overhead. These design choices are aligned with findings that compact prompt tuning can make LLMs effectively consume external knowledge without full fine-tuning [ 57 , 56 , 58 ]. 

2.9 Complementary Methods: Rule-Regularized Embeddings and Scalability 

A number of works enhance embedding-based reasoning with logical constraints or rule regularizers to improve interpretability and generalization [ 12 , 13 , 18 ]. Scalability-oriented research studies approximations and filtering mechanisms that reduce the combinatorial cost of rule evaluation on large graphs [ 17 , 18 , 60 ]. These contributions guided our choices for selective triple filtering and for efficient batched evaluation during search. 

2.10 Summary of Positioning 

The contributions described in this paper draw upon and synthesize multiple active research threads: differentiable logic and rule learning [ 14 , 4, 16 , 15 ], neural-symbolic fusion and soft-rule integration [ 11 , 13 , 17 ], human-in-the-loop and 3NeuroSymActive 

Figure 1: Architectural overview of the NeuroSymActive framework for knowledge graph question answering. The framework operates via a coupled dual-loop optimization process across three main stages: Stage 1: Uncertainty-Aware Active Retrieval , which utilizes a Bayesian head to model heteroscedastic uncertainty in hop prediction and a neural entropy predictor ηθ to estimate information gain ( IG ). This stage selectively invokes a Human Oracle via the QUERY _HUMAN action when uncertainty U(st) exceeds the threshold τhop . Stage 2: Differentiable Neural-Symbolic Fusion , where a hybrid Knowledge Adapter merges continuous path embeddings ( zneural  

> f

) with soft symbolic plausibility scores ( zsym  

> f

) derived from a Differentiable Inductive Logic Layer (DILL) . Rule confidences wρ are updated via gradient signals from active supervision stored in the human replay buffer Dhuman . Stage 3: Differentiable MCTS with Active Exploration , which implements a relaxed Monte Carlo Tree Search. It employs Progressive Widening governed by predictive uncertainty and treats human intervention as explicit nodes with value Vhuman (s).The search is fully differentiable via Gumbel-Softmax relaxations, allowing end-to-end joint training of the policy πϕ,value vψ , and symbolic weights through a composite multi-objective loss Ltotal .active supervision strategies [ 21 , 8 , 22 ], uncertainty modeling for selective querying [ 27 , 32 , 29 ], and differentiable exploration mechanisms that allow end-to-end updates through search [ 40 , 43 , 41 ]. The following sections explain how these elements are combined and extended in our NeuroSymActive framework to address multi-hop KGQA with constrained annotation budgets. 

## 3 Methodology 

This section describes the NeuroSymActive methodology for multi-hop question answering over knowledge graphs. The design preserves a retrieve–embed–reason pipeline while introducing active, differentiable retrieval, a hybrid neural-symbolic knowledge adapter, and an iterative neural-guided graph exploration mechanism that interleaves retrieval and reasoning. 

3.1 Problem formalization 

We cast knowledge-graph question answering as a partially observable sequential decision process with an explicit neural-symbolic duality. Let G = {(h, r, t )} denote a knowledge graph and let q be a natural-language query. The agent maintains an internal cognitive state st that decomposes into a continuous neural component sneural  

> t

and a discrete symbolic component ssym  

> t

. The neural component contains differentiable embeddings of currently retrieved subgraphs 4NeuroSymActive 

Algorithm 1 NeuroSymActive 

Require: knowledge graph G, query q, budgets, human buffer Dhuman  

> 1:

extract anchors B and compute Vq = PLM( q) 

> 2:

obtain hop distribution and uncertainty via (4)  

> 3:

initialize Gcur ← ∅ and search root  

> 4:

while not terminated do  

> 5:

if uncertainty U(st) > τ human then invoke QueryHuman and update rules by (16)  

> 6:

for iteration = 1 to Ninner do  

> 7:

enumerate candidate relations {r} and predict cIG( r) via (5)  

> 8:

compute utility u(r) using (6) and obtain soft weights {sr } via (7)  

> 9:

expand Gcur with top/sampled sr , compute zneural  

> f

via (11)  

> 10:

compute symbolic activations and score via (12)–(13) and fuse using (14)  

> 11:

run differentiable rollouts under tree policy πtree in (19), guided by UCB PW in (17); treat human choices with value in (18)  

> 12:

end for  

> 13:

form Ltotal per (20) and update πϕ, v ψ , adapter and DILL weights  

> 14:

end while  

> 15:

return highest-scoring answer from the LLM conditioned on the adapter prompt and related latent variables, whereas the symbolic component encodes discrete logical constraints, type relations and other symbolic checks used for pruning and consistency verification. At each decision step t the agent selects an action at from a set of candidate retrieval/expansion operations At

augmented with an explicit human-query action QUERY _HUMAN , that is at ∈ A t ∪{ QUERY _HUMAN }. Selecting 

QUERY _HUMAN triggers a supervised annotation with incurred cost chuman > 0. An episode terminates when the agent emits a final answer a or exhausts its computational or annotation budget. The agent’s objective trades off answer correctness and human annotation cost: it seeks to maximize expected accuracy while minimizing cumulative annotation expenditure. Formally we optimize a bi-objective that can be collapsed into a single scalar objective by penalizing human queries: 

J = EI[ˆ a = a⋆]

− β X

> t

Iat = QUERY _HUMAN  chuman , (1) where ˆa denotes the emitted answer, a⋆ is the ground-truth answer, I[·] is the indicator function, and β > 0 balances accuracy and annotation cost. In (1), the expectation is taken over the agent’s stochastic policy and any environment randomness. A reasoning path p is represented by an ordered sequence of triples with both neural embeddings and symbolic identifiers: 

p =  (e0, r 1, e 1), . . . , (eL−1, r L, e L), (2) where each entity ei and relation rj is associated with a continuous embedding ei, rj ∈ Rd used by the differentiable modules and with a discrete symbolic identifier used by the symbolic checks, and L denotes the dynamic path length determined by the agent’s value function or budget termination. In (2), the neural embedding vectors live in Rd and the symbolic identifiers index logical constraints and types. 

3.2 Algorithm framework 

The following algorithm summarizes the coupled inner/outer loop of NeuroSymActive in a concise form. Key estimators and relaxations are referenced where used. The overall procedure is summarized in Algorithm 1. 

Implementation guidance. Use minibatched inner-loop rollouts with shared batched GNNs for ηθ to amortize entropy predictions. Maintain separate optimizers for DILL parameters {wρ} and neural encoder weights to allow differential learning rates. For stability, anneal the Gumbel temperature τ in (7) and the search temperature τsearch in (19), and apply gradient normalization when minimizing (20) so that no single objective dominates training. 5NeuroSymActive 

3.3 High-level architecture: coupled dual-loop optimization 

NeuroSymActive operates through two tightly coupled loops that run on distinct time scales and exchange information continuously. The inner loop is a fast, differentiable neural-symbolic exploration driven by a neural policy πϕ and a value estimator vψ . At this time scale the system performs many lightweight expansions: the policy proposes candidate relation expansions, symbolic constraints encoded as a differentiable logical layer prune infeasible expansions, and discrete choices are represented with continuous relaxations (for example Gumbel-Softmax) so that gradients can flow through the exploration decisions. The inner loop thus produces a relaxed reasoning graph whose edge-selection variables are stochastic, differentiable weights. The outer loop runs at a slower time scale and implements active human-in-the-loop supervision. An uncertainty quanti-fier U(st), which monitors entropy and saturation of information gain, decides whether to invoke QUERY _HUMAN .When the uncertainty metric exceeds a pre-specified threshold or when information gain plateaus, the system requests expert feedback for critical decisions such as hop depth, relation relevance, or path validity. Human annotations are stored in a replay buffer Dhuman and used for off-policy updates of πϕ, vψ , and the neural-symbolic adapter. The knowledge adapter forms the bridge between modalities by fusing three signals: continuous path embeddings produced by the neural encoders, soft plausibility scores returned by the differentiable symbolic module, and uncertainty signals used to trigger outer-loop queries. The adapter projects fused representations into the frozen LLM’s token embedding space as compact soft prompts. Gradients from the LLM’s downstream loss are routed back to the differentiable components through the adapter’s continuous interfaces while symbolic constraints remain enforced via soft scores. 

3.4 Stage 1: Uncertainty-aware active retrieval 

We first refine hop prediction using a probabilistic neural head that models heteroscedastic uncertainty. The semantic encoder computes 

Vq = PLM( q), (3) where PLM( ·) is a pretrained language encoder and Vq ∈ Rd is the semantic vector for query q. A Bayesian head yields a distribution over hop budgets: 

P (hq | Vq ) = Softmax  MLP( Vq ) + ϵ,

where ϵ ∼ N  0, σ 2(Vq )I. (4) where MLP( ·) is a small feedforward network and σ2(Vq ) is a learned heteroscedastic variance. In (4), the additive Gaus-sian noise models epistemic/aleatoric uncertainty and the softmax converts logits to a probability distribution over dis-crete hop counts. If max h P (hq = h | Vq ) falls below a threshold τhop , the system issues QueryHuman( hop-depth , q )

to obtain an annotated hop count h⋆q .Estimating the information gain for a candidate relation r is computationally expensive if performed by Monte-Carlo simulation. We therefore learn a neural entropy predictor ηθ that maps subgraph features to predicted answer entropy and use it to approximate information gain: 

cIG( r) = ηθ

 Gcur , r, V q

 − ηθ

 Gcur , ∅, V q

, (5) where ηθ (·) is implemented as a graph neural network that ingests the current subgraph Gcur , the candidate relation r,and the query embedding Vq , and returns a scalar predictive entropy. In (5), the second term denotes predicted entropy without adding relation r.We generalize the acquisition utility to support both autonomous and human-augmented selection. The two-mode utility is 

u(r) = 

( cIG( r) − λ C (r), (auto mode) 

cIG human (r) − λ C (r) − chuman , (human) (6) where C(r) is an estimated retrieval cost, λ > 0 balances information gain and cost, chuman is the explicit annotation cost for invoking human feedback, and cIG human (·) leverages relevance labels from the human replay buffer Dhuman .In (6), the human-augmented mode is considered when the uncertainty quantifier or policy indicates high ambiguity at a decision point. 6NeuroSymActive To allow end-to-end optimization, discrete relation selection is relaxed via a Gumbel-Softmax reparameterization. For a candidate set {r} with base logits log π(r) we compute soft selection weights 

sr = exp  (log π(r) + gr )/τ P 

> r′

exp  (log π(r′) + gr′ )/τ  ,gr ∼ Gumbel(0 , 1) ,

(7) where τ > 0 is a temperature parameter and sr ∈ [0 , 1] approximates a one-hot selection in the low-temperature limit. In (7), sampling the Gumbel noise gr and dividing by τ yields a differentiable approximation to categorical sampling used during inner-loop exploration and training. 

3.5 Stage 2: Differentiable neural-symbolic fusion 

The knowledge adapter places a differentiable inductive logic layer at the core of neural-symbolic integration so that symbolic inference participates in end-to-end gradient-based learning. The adapter receives path-level neural encodings and yields fused representations that carry both distributional semantics and logical validity. For a sampled reasoning path p we first obtain element-wise embeddings from textual and structural encoders. For the 

i-th triple in p denote the relation, head entity and tail entity embeddings by 

eri = Embed( ri), ehi = Embed( ei−1),

eti = Embed( ei), (8) where Embed( ·) denotes a shared textual encoder and each vector lies in Rd. In (8), the symbols eri , ehi and eti denote relation, head and tail continuous embeddings respectively. Local triple structure is summarized by a structural encoder and aggregated across the path to obtain a neural structural summary: 

si = StructEmb  ehi , eri , eti

, zs = Agg  s1, . . . , sL

, (9) where StructEmb( ·) is a small permutation sensitive network that captures local ordering and Agg( ·) denotes a learnable pooling operator producing zs ∈ Rd. In (9), si and zs are the local and global structural summaries respectively. A text fusion operator produces a path-level textual vector: 

zt = Fuse  eh 

> 1

, . . . , ehL, er

> 1

, . . . , etL

, (10) where Fuse( ·) preserves hop order and returns zt ∈ Rd. In (10), zt aggregates textual signals across the path. The neural pathway produces a compact neural path vector: 

zneural  

> f

= KnowledgeEncoder  [zt, zs], (11) where KnowledgeEncoder( ·) denotes a parameterized neural network and [·, ·] denotes concatenation. In (11), 

zneural  

> f

∈ Rd is the neural encoding of path p.Symbolic inference is implemented as a differentiable inductive logic layer (DILL) that grounds learned rules into continuous predicate evaluations. Each rule ρ has a learned confidence weight wρ ∈ [0 , 1] and the rule body is evaluated by a neural predicate grounding πρ(p) that maps path embeddings to truth degrees. The soft activation of rule ρ on path 

p is 

ϕρ(p) = T  wρ, π ρ(p), (12) where T is a differentiable t-norm such as the product operator and πρ(p) ∈ [0 , 1] is the neural predicate grounding for 

ρ on path p. In (12), ϕρ(p) denotes the soft truth value of rule ρ on p.Symbolic plausibility aggregates contributions from applicable rules to produce a path-level symbolic score: 

zsym  

> f

= Agg ρ∈R p ϕρ(p), (13) where Rp is the set of rules relevant to path p and the aggregation operator produces zsym  

> f

∈ Rd. In (13), zsym  

> f

encodes symbolic plausibility derived from the rule base. Neural and symbolic vectors are fused with a learned gating mechanism that admits gradient flow into both pathways: 

zf = γ [zneural  

> f

, zsym  

> f

] ⊙ zneural 

> f

+  1 − γ [zneural  

> f

, zsym  

> f

] ⊙ zsym  

> f

, (14) 7NeuroSymActive where γ(·) is a sigmoid gating network that outputs values in [0 , 1] , ⊙ denotes elementwise multiplication and zf ∈ Rd

is the fused representation used downstream. In (14), the gating function γ mediates gradient distribution between the neural and symbolic components. Rule parameters are updated from active supervision via gradient signals derived from human labels. Given a human-provided binary label yhuman ∈ { 0, 1} for path validity, the differentiable logic loss is the binary cross entropy between the aggregated symbolic activation and the label: 

Llogic = BCE  sigmoid  zsym 

> f

, y human 

, (15) where BCE( ·, ·) denotes binary cross entropy. In (15), gradients with respect to the rule confidences {wρ} are obtained by backpropagating through ϕρ and πρ.A local rule confidence update uses the gradient of the logic loss: 

∆wρ ∝ − η ∂Llogic 

∂w ρ

, (16) where η > 0 is a learning rate. In (16), ∆wρ denotes the change applied to the rule confidence wρ during a supervised update step. 

3.6 Stage 3: Differentiable Monte Carlo Tree Search with active node expansion 

The exploration module implements a differentiable MCTS variant that adapts branching with predictive uncertainty and treats human queries as explicit special nodes. The search balances exploitation and exploration while permitting gradients to propagate from final losses through soft decisions made in the tree. Progressive widening adapts the effective branching factor to node uncertainty. A node selection score extends the classical upper confidence bound by a multiplicative uncertainty factor: 

UCB PW (C) = VC

nC

+ c

r ln nparent 

nC

· InC < k n α

> parent

 1 + U(C) ,

(17) where VC and nC are the cumulative value and visit count for node C, nparent is the parent visit count, c > 0 and 

k > 0 are constants, α ∈ (0 , 1) controls widening, and U(C) ≥ 0 is predictive uncertainty at C. In (17), the indicator function determines whether progressive widening permits adding new children. Human oracle nodes are embedded in the search tree as actions that, if selected, return annotations at cost. The expected value of invoking a human at state s is 

Vhuman (s) = Ey∼H (s)

V (s | y) − chuman , (18) where H(s) is a model of human responses learned from the replay buffer and V (s | y) is the downstream value conditioned on human label y. In (18), the expectation approximates the benefit of human intervention net of annotation cost. To permit end-to-end gradient propagation the discrete visitation counts and argmax selections are relaxed into soft attention weights. The tree policy under the soft relaxation is 

πtree (a | s)= exp  (Q(s, a ) + c · PUCT( s, a )) /τ search 

P 

> a′

exp  (Q(s, a ′) + c · PUCT( s, a ′)) /τ search 

 , (19) where Q(s, a ) is the action value estimator, PUCT( s, a ) injects prior policy and soft visit information, c > 0 is an exploration constant and τsearch > 0 is a temperature parameter controlling softness. In (19), πtree (a | s) is a differentiable distribution over actions at state s, enabling gradients from downstream losses to update policy and value networks. 

3.7 Joint training: multi-objective neuro-symbolic active learning 

We train the full system by optimizing a composite objective that balances answer quality, efficient exploration, symbolic consistency, and active learning efficacy. The total loss is 

Ltotal = Lanswer + λ1Lexplore + λ2Lsymbolic + λ3Lactive , (20) 8NeuroSymActive where {λi}3 

> i=1

are nonnegative weights that are adapted during training to maintain a Pareto balance across objectives. In (20), Ltotal aggregates the four complementary criteria. The answer generation term is the expected negative log-likelihood under the soft tree distribution: 

Lanswer = Eπtree 

Lgen (s), (21) where Lgen (s) denotes the negative log-probability assigned by the frozen language model to the ground-truth answer when conditioned on the soft prompt generated under selection s. In (21), the expectation is taken under the differentiable search policy πtree .Exploration regularization encourages breadth and prevents premature collapse: 

Lexplore = −H πtree 

, (22) where H(·) denotes Shannon entropy. In (22), maximizing entropy fosters diverse exploration. Symbolic consistency enforces agreement between symbolic plausibility and learned neural judgments: 

Lsymbolic = Ep

∥zsym  

> f

− bylogic (p)∥22

, (23) where bylogic (p) is a neural estimate of path validity and the expectation runs over sampled paths p. In (23), the mean squared error penalizes disagreement between symbolic scores and neural judgments. Active learning efficacy explicitly trains the query policy to maximize information gain per unit annotation cost: 

Lactive = −Eq∼D uncertain 

" IG  q | Human( q)

chuman (q)

#

, (24) where Duncertain is a buffer of high-uncertainty queries, IG( q | Human( q)) denotes the estimated information gain after receiving human annotation and chuman (q) is the annotation cost. In (24), maximizing the ratio trains the system to ask efficient questions. The multi-objective weights {λi} are adjusted using gradient normalization so that none of the objectives dominates training. Gradients flow through the soft tree, the differentiable logic layer and the adapter projection so that rule confidences, neural encoder parameters, and policy/value networks are updated jointly. 

## 4 Experiments 

This section presents an empirical assessment of NeuroSymActive on established multi-hop knowledge graph question-answering benchmarks. Our investigation is organized along three dimensions: performance gains relative to existing LLM-augmented KGQA systems, generalization across diverse backbone architectures, and operational characteristics regarding computational footprint and response consistency when deploying parameter-efficient language models. Match accuracy, quantified via Hits@1, serves as the principal evaluation criterion in accordance with established conventions in the literature. 

4.1 Datasets 

We use two widely adopted Freebase-based datasets. WebQuestionsSP (WebQSP)[ 61 ] contains 4,737 questions, each providing a topic entity and a SPARQL query; answers generally require up to two hops. ComplexWebQuestions (CWQ)[ 62 ] contains 34,689 question–answer pairs derived from WebQSP and augmented to demand more compo-sitional multi-hop reasoning, with some queries requiring up to four hops. All experiments use the public splits and standard evaluation scripts for Hits@1. Table 7: Efficiency comparison on WebQSP: NeuroSymActive vs. StructGPT. NPR = average tokens per request. 

Method Time (H:M) Tokens used NPR 

NeuroSymActive (LLaMa3-8B) 1:05:30 338,200 207 StructGPT (ChatGPT) 1:42:12 24,750,610 6400 9NeuroSymActive Table 1: Performance comparison between NeuroSymActive, LightPROF and representative baselines on WebQSP and CWQ. Bold indicates the best reported result. 

Method WebQSP (Hits@1) CWQ (Hits@1) 

KV-Mem[63] 46.7 18.4 EmbedKGQA[64] 66.6 45.9 NSM[65] 68.7 47.6 KGT5[66] 56.1 36.5 GraftNet[51] 66.4 –PullNet[50] 68.1 –TransferNet[52] 71.4 48.6 UniKGQA[67] 75.1 50.7 LLaMa2-7B-Chat 61.4 31.5 LLaMa2-70B-Chat 57.4 39.1 ToG (LLaMa2-70B)[68] 68.9 57.6 StructGPT (ChatGPT)[69] 72.6 54.3 AgentBench[70] 47.8 24.8 KnowledgeNavigator (LLaMa2-70B)[71] 71.8 –LightPROF (LLaMa2-7B)[72] 71.2 48.5 LightPROF (LLaMa3-8B)[72] 83.8 59.3 

NeuroSymActive (LLaMa3-8B) 87.1 62.5 

Table 2: Extended ablation: disentangling architectural choices. 

# Variant WebQSP CWQ (Hits@1) (Hits@1) 

# Full NeuroSymActive 87.1 62.5 

# Core mechanisms 

# w/o Knowledge Adapter 79.5 54.2 w/o Uncertainty-aware triggering 83.4 59.8 w/o Progressive Widening (fixed k=3) 84.6 60.3 

# Neural-symbolic integration 

# w/o DILL rule learning (fixed rules) 83.9 59.1 w/o Neural predicates (pure symbolic) 78.2 52.4 

# Differentiability 

# w/ Hard selection (STE) 85.3 61.2 w/ REINFORCE (no relaxation) 84.8 60.5 Table 9: Sensitivity to human-cost penalty β on WebQSP. “Query rate” denotes average human invocations per question. 

# β Hits@1 (%) Query Rate ∆ Accuracy 0.1 87.1 2.8 baseline 0.5 86.9 1.6 −0.2

# 1.0 86.4 1.0 −0.7

# 2.0 84.2 0.6 −2.9

# 5.0 81.5 0.4 −5.6

# 10.0 78.3 0.3 −8.8

10 NeuroSymActive Table 3: Effect of structure-encoder design on NeuroSymActive. 

# Encoder Type WebQSP CWQ 

# Triplet-Only (H, R, T) 84.3 59.0 Context-Aware (order-sensitive) 87.1 62.5 Relation-Path (path-centric) 84.7 60.8 Table 4: Error mode distribution across datasets. Percentages denote proportions of incorrect predictions. Dataset Retrieval (%) Reasoning (%) Generation (%) WebQSP 31.2 42.8 26.0 CWQ 48.5 32.4 19.1 Table 10: Influence of Gumbel temperature τ on WebQSP performance and training stability. Temperature τ Hits@1 (%) Training iterations to convergence 2.0 82.4 18,500 1.0 84.7 12,200 0.5 86.2 9,800 0.1 87.1 8,400 STE (hard) 85.3 11,600 

4.2 Baselines and evaluation protocol 

We compare NeuroSymActive to three classes of baselines. The first class comprises full fine-tuning methods that learn task parameters end-to-end (e.g., KV-Mem, EmbedKGQA, NSM, KGT5, GraftNet, PullNet, TransferNet, UniKGQA). The second class contains vanilla LLMs evaluated with plain prompting (representative LLaMa variants). The third class covers hybrid LLM+KG systems that augment frozen LLMs with KG processing but do not fine-tune the LLMs (for example, ToG, StructGPT, KnowledgeNavigator, AgentBench). For fair comparison we adopt the same metric (Hits@1) and standard test sets used in prior literature. 

4.3 Implementation details 

To demonstrate plug-and-play use and parameter efficiency, we integrate NeuroSymActive with compact LLMs (default backbone: LLaMa3-8B). The knowledge encoder uses a BERT-style encoder; the adapter projector is a two-layer MLP that maps fused path representations into the LLM token embedding space. Training runs for a small number of epochs with modest batch sizes. Learning rate schedules employ cosine annealing; experiments are run on NVIDIA A800-class GPUs. When reporting wall-clock efficiency we measure end-to-end inference time on the WebQSP evaluation set. 

4.4 Performance comparison 

Table 1 summarizes Hits@1 on WebQSP and CWQ for NeuroSymActive and representative baselines. NeuroSymActive achieves state-of-the-art results among the reported methods, showing clear gains on both benchmarks. NeuroSymActive consistently improves answer accuracy relative to LightPROF and other baselines, indicating that combining active retrieval, a differentiable neural-symbolic adapter, and differentiable exploration benefits multi-hop KGQA. 

4.5 Ablation study 

To isolate the contributions of individual components, we perform ablations that remove active querying, the symbolic module, or the differentiable MCTS. Results are in Table 2. The ablation shows that each component contributes non-negligibly; the symbolic layer and differentiable search bring notable improvements on multi-hop queries. 11 NeuroSymActive 

Figure 2: Reduction in error rates for each failure mode as annotation budget increases. Confidence intervals obtained by bootstrapping. 

Figure 3: Composition of residual errors under strong active supervision. Components include KG incompleteness, question ambiguity, and entropy-predictor bias. 

4.6 Structure-encoder comparison 

We compare several structure-encoding strategies to assess sensitivity to how path structure is represented. Table 3 reports Hits@1 for three encoder variants. Order-sensitive context encoders achieve the best balanced performance, indicating the value of preserving hop order and local structural cues. 

4.7 Case study 

A representative reasoning trace is shown in Table 5. The trace illustrates hop prediction, an active human query triggered by uncertainty, neural-symbolic pruning, and the final answer generated by the frozen LLM conditioned on the adapter prompt. 

4.8 Compatibility with different LLM backbones 

To verify plug-and-play capability, we integrate NeuroSymActive with several LLM backbones and report base vs. integrated scores in Table 6. NeuroSymActive consistently enhances performance across model families and sizes, confirming its general applicability. 12 NeuroSymActive Table 5: Illustrative case: NeuroSymActive reasoning trace for a complex WebQSP query. 

Component Observed trace / output 

Question Which films starring Bruce Willis were directed by a filmmaker born in Germany? Ground truth [“Die Hard”, “The Fifth Element”] Reasoning (selected steps) Anchor extraction found “Bruce Willis”. Hop prediction indicated three hops. During exploration, uncertainty rose for a candidate relation (director nationality) and the system invoked Q UERY HUMAN ; human feedback confirmed relevance. The differentiable logic layer pruned implausible paths and prioritized validated relation links. The adapter produced a compact soft prompt; the LLM generated the final answer based on the pruned subgraph. Final answer [“Die Hard”, “The Fifth Element”] (correct) Table 6: Performance comparison of different LLM backbones integrated with the LightPROF and NeuroSymActive frameworks. 

## Backbone (Framework) WebQSP CWQ Gain (Hits@1) (Hits@1) (avg) 

## LLaMa2-7B 61.4 31.5 +19.1 LLaMa2-7B (LightPROF) 71.2 48.5 

## LLaMa2-7B (NeuroSymActive) 76.3 54.8 

## LLaMa3-8B 66.8 48.9 +17.0 LLaMa3-8B (LightPROF) 83.8 59.3 

## LLaMa3-8B (NeuroSymActive) 87.1 62.5 

## GPT-4 73.2 55.8 +10.9 

## GPT-4 (NeuroSymActive) 87.6 63.2 

4.9 Efficiency and stability 

We compare NeuroSymActive to StructGPT on wall-clock inference time and token consumption for the WebQSP evaluation set. Table 7 summarizes runtime, total tokens sent to the LLM, and average tokens per request (NPR). NeuroSymActive uses substantially fewer tokens and runs faster in our setup, reflecting compact soft prompts and focused retrieval. 

4.10 Active Supervision Efficiency and Query Economy 

NeuroSymActive converts human annotations into a focused, uncertainty-driven resource. The following text is deliberately concise; detailed metrics and visualizations are provided in Table 12, Table 13, Figure 4, Figure 5, and Figure 6. The query policy concentrates oracle calls on a small set of decision types. The allocation pattern and per-query efficiency are summarized in Table 12. The uncertainty threshold that triggers human queries defines an accuracy versus annotation-cost frontier. The curve in Figure 4 shows trade-offs for static thresholds and the position of the adaptive strategy. Marginal information gain varies across query positions. Figure 5 plots the entropy reduction sequence for successive human queries within episodes. Early-stage queries deliver the largest reductions; later queries show reduced marginal utility. Table 13 compares active and passive supervision regimes and reports accuracy, total queries, and efficiency metrics. Under tight annotation budgets, prioritizing high-yield decisions preserves most of the achievable accuracy. Figure 6 contrasts NeuroSymActive with uncertainty-agnostic baselines across budget levels and illustrates the robustness of uncertainty-aware prioritization. 13 NeuroSymActive Table 8: Representative failure cases by error mode. Suggested human-query opportunities are noted where applicable.           

> Error mode Question System output Analysis
> Retrieval What language is spoken in the country where the film “Inception” was produced? English (incorrect) Hop-depth underestimated; adepth-query before retrieval would prevent this omission. Reasoning Which actor starred in both “Ti-tanic” and “The Revenant”? Johnny Depp (incorrect) Correct path present but misranked by the value estimator; relation rel-evance verification does not fully resolve path-ranking ambiguity. Generation Who directed the sequel to “The Matrix”? The Wachowskis, James Cameron (incorrect) Correct supporting path was pro-vided; generation introduced a spu-rious director due to prompt ambi-guity and entity-linking noise.

Table 11: Ablation over multi-objective weights λ1:3 . Default is (0 .3, 0.5, 0.2) .

# (λ1, λ 2, λ 3) WebQSP CWQ 

# (0 .3, 0.5, 0.2) 87.1 62.5 

# (0 .0, 0.5, 0.2) 84.5 58.9 

# (0 .3, 0.0, 0.2) 83.2 57.4 

# (0 .3, 0.5, 0.0) 85.8 60.1 

# (0 .5, 0.3, 0.2) 86.3 61.2 

# (0 .2, 0.6, 0.2) 86.7 61.8 

4.11 Training Dynamics and Convergence Behavior 

We monitor the optimization progress of the multi-objective training to understand how individual loss terms evolve and how symbolic structure emerges within the differentiable inductive logic layer. The normalized trajectories of the loss components are shown in Figure 7. Early training is dominated by the answer-generation term, while the symbolic-consistency term grows in importance after the replay buffer accumulates useful rule candidates. The exploration term exhibits a rise-and-fall pattern consistent with temperature annealing. The active-learning objective converges comparatively fast. Rule confidences in DILL differentiate during training. Figure 8 tracks mean trajectories for rule categories; broadly applicable rules (for example, transitivity or type constraints) quickly reach high confidence, while relation-specific rules converge more selectively. This separation results from the gradient signal and replayed human annotations. Convergence stability is summarized in Table 14, which reports final values, coefficients of variation, and gradient norms for each loss component. Gradient normalization is necessary to avoid instability where the symbolic term would otherwise dominate and impede policy learning. 

4.12 Search Topology and Progressive Widening Analysis 

We analyze how progressive widening parameters shape the differentiable MCTS search and the resulting computational trade-offs. Table 15 reports performance and average tree statistics for representative (k, α ) settings in Equation (17). Conservative widening yields compact trees with lower runtime, while aggressive widening increases depth and branching at higher computational cost. The intermediate configuration provides a practical accuracy versus cost compromise. Search expansion patterns are visualized in Figure 9. Single-hop queries typically terminate quickly, whereas multi-hop queries produce asymmetric trees that focus resources on branches with high estimated information gain. Human-query nodes tend to appear at intermediate depths where epistemic uncertainty concentrates. 14 NeuroSymActive Table 12: Annotation economy on WebQSP. See text for interpretation. Query strategy Avg. queries per question Hits@1 (%) Efficiency (% ↑ / query) Random sampling 3.0 82.4 2.8 Fixed-interval 2.0 84.1 3.2 Uncertainty-only ( τhuman = 0 .9) 0.8 83.6 6.5 Uncertainty-only ( τhuman = 0 .7) 1.2 86.4 5.2 Uncertainty-only ( τhuman = 0 .5) 2.1 87.0 3.1 Adaptive (NeuroSymActive) 1.2 87.1 5.8 

Figure 4: Accuracy versus annotation cost as controlled by uncertainty threshold τhuman . The adaptive strategy is marked. Figure 10 quantifies the uncertainty-adaptive widening effect. The multiplicative uncertainty factor (1 + U(C)) raises effective branching in high-uncertainty states, allocating more search capacity where decisions are most ambiguous. Progressive widening improves quality but increases per-rollout cost due to GNN-based entropy prediction and soft policy evaluation. Batched evaluation of sibling nodes mitigates this overhead and reduces per-rollout latency substantially compared to strictly sequential expansion; see Table 15 for timing metrics. 

Figure 9: Distribution of node expansions by tree depth and query hop count. Human query nodes marked separately. 15 NeuroSymActive 

Figure 5: Marginal information gain across successive human queries within episodes. Shaded area denotes variance across queries. Table 13: Comparison of supervision paradigms on WebQSP. Efficiency is accuracy gain per query normalized by annotation count. Supervision mode Hits@1 (%) Total queries (K) Efficiency ( ×10 −3)Unsupervised (no human) 80.9 0 —Passive (fixed schedule) 84.1 9.5 3.4 Active (random selection) 85.3 7.1 6.2 Active (uncertainty-only) 86.4 5.7 9.6 Active (information-gain) 87.1 5.2 11.9 Fully supervised 88.3 23.8 3.1 

Figure 10: Effective branching factor versus visit count, stratified by uncertainty quartiles; dashed line shows the non-adaptive baseline. 

4.13 Error Analysis and Failure Mode Characterization 

We analyze where NeuroSymActive fails, how active supervision mitigates specific error types, and which failures remain under oracle intervention. Summary statistics and representative examples are provided in Table 4 and Table 8. The dynamics of error reduction and residual-error composition are shown in Figure 2 and Figure 3. Errors are grouped by the pipeline stage at which they first arise. Retrieval errors originate when required entities or relations are omitted during subgraph expansion. Reasoning errors occur when a correct subgraph exists but the search policy favors an incorrect path. Generation errors reflect failures of the language model to produce correct output despite valid supporting paths. The dataset-level distribution of these modes is summarized in Table 4. 16 NeuroSymActive 

Figure 6: Accuracy under varying annotation budgets. NeuroSymActive outperforms uncertainty-agnostic baselines across budgets. 

Figure 7: Normalized loss-term magnitudes across training iterations. Shaded bands show seed-wise variation. Active queries reduce different error types unevenly. Figure 2 quantifies how adding oracle annotations affects each mode; retrieval errors are the most responsive because early-stage queries (for example, hop-depth clarification) directly prevent omission. Reasoning errors decline more moderately, since human checks commonly validate relation relevance rather than exhaustively disambiguate competing paths. Generation errors show limited sensitivity to extra annotations, suggesting limits that stem from LLM capacity or prompt representation. Representative failure instances are listed in Table 8. These qualitative cases illustrate three common failure modes. An underestimation of hop depth can remove the correct path before the reasoning process begins. In other cases the correct path is present but is deprioritized by the value estimator, preventing it from being expanded. The language model can also introduce spurious entities in its output even when the prompt contains correct supporting evidence. We decompose the residual error mass remaining under strong active supervision in Figure 3. A substantial portion arises from knowledge-graph incompleteness and from intrinsically ambiguous questions; the remainder traces to systematic biases in the entropy predictor that lead to missed oracle invocations at crucial decision points. These findings suggest focused improvements: extend active queries to include explicit entity verification in addition to hop-depth and relation checks; incorporate prompt-focused remedies or targeted LLM adaptation to address generation errors; and calibrate the entropy predictor (for instance via temperature scaling or epistemic/aleatoric decomposition) to reduce missed high-value queries. 

4.14 Hyperparameter Sensitivity Analysis 

We evaluate how key hyperparameters affect NeuroSymActive’s trade-offs among reasoning accuracy, computation, and human annotation cost. The analysis focuses on three knobs: the human-cost penalty β in Eq. (1), the Gumbel 17 NeuroSymActive 

Figure 8: Evolution of rule confidences in DILL, grouped by rule category. Solid lines denote means; shading indicates distribution density. Table 14: Convergence statistics for loss components. CV denotes coefficient of variation over the final 1,000 iterations. Loss component Final value CV Gradient norm 

# Lanswer 0.847 0.08 2.34 

# Lexplore 0.623 0.12 1.89 

# Lsymbolic 0.291 0.09 3.12 

# Lactive 0.445 0.11 1.56 temperature τ in Eq. (7), and the multi-objective weights λ1:3 in Eq. (20). Results are summarized in Tables 9–11 and the text below highlights practical implications without reproducing the table numbers. 

Effect of the human-cost penalty β. Adjusting β directly changes the system’s propensity to solicit oracle input. Higher values penalize queries more heavily and therefore reduce human invocations, whereas lower values encourage more frequent supervision. A mid-range setting provides a practical compromise between annotation budget and answer quality; detailed statistics are given in Table 9. 

Gumbel temperature τ and search dynamics. The temperature τ controls how sharply the continuous relaxation approximates categorical choices during training. Annealing toward smaller temperatures sharpens selection distribu-tions and tends to improve exploration efficiency and final accuracy, while overly large temperatures produce diffuse selections that impede learning. A straight-through hard-selection alternative yields competitive but generally inferior stability compared to a well-annealed soft relaxation; see Table 10 for training-convergence comparisons. 

Balancing multi-objective weights λ1:3 . The multi-term loss requires tuning to prevent any single objective from dominating. Suppressing the exploration or symbolic-consistency terms harms policy diversity and rule learning respectively. Configurations that prioritize symbolic consistency while retaining non-negligible exploration and active-learning weights produce stable, high-performing solutions; comparative results appear in Table 11. 

Deployment recommendations. Based on the sensitivity study, we recommend initializing β conservatively (around 1.0) and adapting to annotation-budget constraints, linearly annealing τ from ∼ 1.0 to ∼ 0.1 across training, and assigning higher priority to the symbolic-consistency weight than to exploration and active-learning weights. These heuristics offer practical starting points that avoid exhaustive grid searches in most operational settings. 

4.15 Summary 

The experimental results demonstrate that NeuroSymActive improves answer accuracy on multi-hop KGQA tasks, integrates effectively with diverse LLMs, and reduces token overhead while providing stable outputs when paired 18 NeuroSymActive Table 15: Progressive widening sensitivity on WebQSP. Tree statistics averaged over 500 evaluation queries.                            

> (k, α )Hits@1 (%) Avg. nodes Avg. depth Branching factor Rollout time (ms) (1.5, 0.4) 85.2 24.3 2.8 4.2 12.4 (2.5, 0.5) 87.1 38.7 3.4 5.9 18.6 (4.0, 0.6) 87.4 67.2 4.2 7.8 31.2 Fixed k= 3 84.6 45.1 3.1 6.2 22.3

with compact language models. The ablation analysis highlights the importance of active querying, the differentiable symbolic layer, and differentiable graph exploration in achieving these gains. 

## 5 Conclusion 

We presented NeuroSymActive, a modular framework that integrates differentiable neural-symbolic reasoning with an active, value-guided exploration controller for knowledge graph question answering. By combining soft-unification style symbolic modules, a neural path evaluator, and guided Monte Carlo expansion, the system uncovers multi-hop reasoning chains efficiently while preserving interpretable path-level traces. Empirical evaluation and ablation experiments demonstrate that the active exploration mechanism markedly reduces costly graph retrievals and model invocations needed to reach high-quality answers, and that the differentiable symbolic layer increases robustness when facts are noisy or incomplete. Overall, NeuroSymActive attains a favorable trade-off between answer accuracy and query cost while providing explicit, human-readable reasoning traces. Future work will investigate uncertainty-aware stopping criteria for exploration and extend the symbolic layer to capture richer predicate and temporal constraints for dynamic knowledge graphs. 

## References 

[1] Zhengbao Jiang, Luyu Gao, Zhiruo Wang, Jun Araki, Haibo Ding, Jamie Callan, and Graham Neubig. Retrieval as attention: End-to-end learning of retrieval and reading within a single transformer. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing , pages 2336–2349, 2022. [2] Qiaoyu Tang, Jiawei Chen, Zhuoqun Li, Bowen Yu, Yaojie Lu, Haiyang Yu, Hongyu Lin, Fei Huang, Ben He, Xianpei Han, et al. Self-retrieval: End-to-end information retrieval with one large language model. Advances in Neural Information Processing Systems , 37:63510–63533, 2024. [3] Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, and Chao Huang. Lightrag: Simple and fast retrieval-augmented generation. arXiv preprint arXiv:2410.05779 , 2024. [4] Kun Gao, Hanpin Wang, Yongzhi Cao, and Katsumi Inoue. Learning from interpretation transition using differentiable logic programming semantics. Machine Learning , 111(1):123–145, 2022. [5] Jaron Maene and Luc De Raedt. Soft-unification in deep probabilistic logic. Advances in Neural Information Processing Systems , 36:60804–60820, 2023. [6] Jiaxin Bai, Xin Liu, Weiqi Wang, Chen Luo, and Yangqiu Song. Complex query answering on eventuality knowledge graph with implicit logical constraints. Advances in Neural Information Processing Systems , 36: 30534–30553, 2023. [7] Farah Atif, Ola El Khatib, and Djellel Difallah. Beamqa: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 781–790, 2023. [8] Xiaoting Li, Yuhang Wu, Vineeth Rakesh, Yusan Lin, Hao Yang, and Fei Wang. Smartquery: An active learning framework for graph neural networks through hybrid uncertainty reduction. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management , pages 4199–4203, 2022. [9] Zhiyang Chen, Tsung-Yi Ho, Ulf Schlichtmann, Datao Chen, Mingyu Liu, Hailong Yao, and Xia Yin. Neuroescape: Ordered escape routing via monte-carlo tree search and neural network. In 2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD) , pages 01–09. IEEE, 2023. [10] Zheng Zhang, Levent Yilmaz, and Bo Liu. A critical review of inductive logic programming techniques for explainable ai. IEEE transactions on neural networks and learning systems , 35(8):10220–10236, 2023. 19 NeuroSymActive [11] Xuguang Duan, Xin Wang, Peilin Zhao, Guangyao Shen, and Wenwu Zhu. Deeplogic: Joint learning of neural perception and logical reasoning. IEEE Transactions on Pattern Analysis and Machine Intelligence , 45(4): 4321–4334, 2022. [12] Mojtaba Nayyeri, Chengjin Xu, Mirza Mohtashim Alam, Jens Lehmann, and Hamed Shariat Yazdi. Logicenn: A neural based knowledge graphs embedding model with logical rules. IEEE Transactions on Pattern Analysis and Machine Intelligence , 45(6):7050–7062, 2021. [13] Connor Pryor, Charles Dickens, Eriq Augustine, Alon Albalak, William Wang, and Lise Getoor. Neupsl: Neural probabilistic soft logic. arXiv preprint arXiv:2205.14268 , 2022. [14] Hikaru Shindo, Masaaki Nishino, and Akihiro Yamamoto. Differentiable inductive logic programming for structured examples. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 35, pages 5034–5041, 2021. [15] Hikaru Shindo, Viktor Pfanschilling, Devendra Singh Dhami, and Kristian Kersting. α ilp: thinking visual scenes as differentiable logic programs. Machine Learning , 112(5):1465–1497, 2023. [16] Chang Yue and Niraj K Jha. Learning interpretable differentiable logic networks. IEEE Transactions on Circuits and Systems for Artificial Intelligence , 2024. [17] Chen Shengyuan, Yunfeng Cai, Huang Fang, Xiao Huang, and Mingming Sun. Differentiable neuro-symbolic reasoning on large-scale knowledge graphs. Advances in Neural Information Processing Systems , 36:28139–28154, 2023. [18] Yuming Zhang, Jun Hsieh, Xin Li, Ming-Ching Chang, Chun-Chieh Lee, and Kuo-Chin Fan. Mote-nas: Multi-objective training-based estimate for efficient neural architecture search. Advances in Neural Information Processing Systems , 37:100845–100869, 2024. [19] Bikram Pratim Bhuyan, Amar Ramdane-Cherif, Ravi Tomar, and TP Singh. Neuro-symbolic artificial intelligence: a survey. Neural Computing and Applications , 36(21):12809–12844, 2024. [20] Uzma Nawaz, Mufti Anees-ur Rahaman, and Zubair Saeed. A review of neuro-symbolic ai integrating reasoning and learning for advanced cognitive systems. Intelligent Systems with Applications , page 200541, 2025. [21] Eduardo Mosqueira-Rey, Elena Hernández-Pereira, David Alonso-Ríos, José Bobes-Bascarán, and Ángel Fernández-Leal. Human-in-the-loop machine learning: a state of the art. Artificial Intelligence Review , 56 (4):3005–3054, 2023. [22] Yiran Huang, Jian-Feng Yang, and Haoda Fu. Efficient human-in-the-loop active learning: A novel framework for data labeling in ai systems. arXiv preprint arXiv:2501.00277 , 2024. [23] Donghyun Kim, Hyeongjun Yang, Seokju Hwang, Kyuhwan Yeom, Midan Shim, and Kyong-Ho Lee. Active learning framework for improving knowledge graph accuracy. IEEE Access , 2025. [24] Chaeeun Kim and Seungone Kim. Freeson: Retriever-free retrieval-augmented reasoning via corpus-traversing mcts. arXiv preprint arXiv:2505.16409 , 2025. [25] Donald Joseph Hejna III and Dorsa Sadigh. Few-shot preference learning for human-in-the-loop rl. In Conference on Robot Learning , pages 2014–2025. PMLR, 2023. [26] Wentao Zhang, Yexin Wang, Zhenbang You, Yang Li, Gang Cao, Zhi Yang, and Bin Cui. Nc-alg: Graph-based active learning under noisy crowd. In 2024 IEEE 40th International Conference on Data Engineering (ICDE) ,pages 2681–2694. IEEE, 2024. [27] Alice Hein, Stefan Röhrl, Thea Grobel, Manuel Lengl, Nawal Hafez, Martin Knopp, Christian Klenk, Dominik Heim, Oliver Hayden, and Klaus Diepold. A comparison of uncertainty quantification methods for active learning in image classification. In 2022 International Joint Conference on Neural Networks (IJCNN) , pages 1–8. IEEE, 2022. [28] Hanjing Wang and Qiang Ji. Epistemic uncertainty quantification for pre-trained neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 11052–11061, 2024. 20 NeuroSymActive [29] Alexander Immer, Emanuele Palumbo, Alexander Marx, and Julia Vogt. Effective bayesian heteroscedastic regression with deep neural networks. Advances in Neural Information Processing Systems , 36:53996–54019, 2023. [30] Maximilian Seitzer, Arash Tavakoli, Dimitrije Antic, and Georg Martius. On the pitfalls of heteroscedastic uncertainty estimation with probabilistic neural networks. arXiv preprint arXiv:2203.09168 , 2022. [31] Rahul Rathnakumar, Jiayu Huang, Hao Yan, and Yongming Liu. Bayesian entropy neural networks for physics-aware prediction. arXiv preprint arXiv:2407.01015 , 2024. [32] Qian Li, Shu Guo, Yinjia Chen, Cheng Ji, Jiawei Sheng, and Jianxin Li. Uncertainty-aware relational graph neural network for few-shot knowledge graph completion. arXiv preprint arXiv:2403.04521 , 2024. [33] Maxim Ziatdinov. Active learning with fully bayesian neural networks for discontinuous and nonstationary data. 

arXiv preprint arXiv:2405.09817 , 2024. [34] Mariliza Tzes, Nikolaos Bousias, Evangelos Chatzipantazis, and George J Pappas. Graph neural networks for multi-robot active information acquisition. arXiv preprint arXiv:2209.12091 , 2022. [35] Xinze Li, Sen Mei, Zhenghao Liu, Yukun Yan, Shuo Wang, Shi Yu, Zheni Zeng, Hao Chen, Ge Yu, Zhiyuan Liu, et al. Rag-ddr: Optimizing retrieval-augmented generation using differentiable data rewards. arXiv preprint arXiv:2410.13509 , 2024. [36] Yu Wang, Nedim Lipka, Ryan A Rossi, Alexa Siu, Ruiyi Zhang, and Tyler Derr. Knowledge graph prompting for multi-document question answering. In Proceedings of the AAAI conference on artificial intelligence , volume 38, pages 19206–19214, 2024. [37] Yixin Ji, Kaixin Wu, Juntao Li, Wei Chen, Mingjie Zhong, Xu Jia, and Min Zhang. Retrieval and reasoning on kgs: Integrate knowledge graphs into large language models for complex question answering. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 7598–7610, 2024. [38] Mufei Li, Siqi Miao, and Pan Li. Simple is effective: The roles of graphs and large language models in knowledge-graph-based retrieval-augmented generation. arXiv preprint arXiv:2410.20724 , 2024. [39] Guangze Gao, Zixuan Li, Chunfeng Yuan, Jiawei Li, Wu Jianzhuo, Yuehao Zhang, Xiaolong Jin, Bing Li, and Weiming Hu. D-rag: Differentiable retrieval-augmented generation for knowledge graph question answering. In 

Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing , pages 35386–35405, 2025. [40] Xiaozhuang Song, Shufei Zhang, and Tianshu Yu. Rekg-mcts: Reinforcing llm reasoning on knowledge graphs via training-free monte carlo tree search. In Findings of the Association for Computational Linguistics: ACL 2025 ,pages 9288–9306, 2025. [41] Zitian Gao, Boye Niu, Xuzheng He, Haotian Xu, Hongzhang Liu, Aiwei Liu, Xuming Hu, and Lijie Wen. Interpretable contrastive monte carlo tree search reasoning. arXiv preprint arXiv:2410.01707 , 2024. [42] Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, and Zhou Yu. Exact: Teaching ai agents to explore with reflective-mcts and exploratory learning. arXiv preprint arXiv:2410.02052 , 2024. [43] Rushi Shah, Mingyuan Yan, Michael Curtis Mozer, and Dianbo Liu. Improving discrete optimisation via decoupled straight-through gumbel-softmax. arXiv preprint arXiv:2410.13331 , 2024. [44] Laxmi Chaudhary and Buddha Singh. Gumbel-softmax based graph convolution network approach for community detection. International Journal of Information Technology , 15(6):3063–3070, 2023. [45] Chunyang Jiang, Tianchen Zhu, Haoyi Zhou, Chang Liu, Ting Deng, Chunming Hu, and Jianxin Li. Path spuriousness-aware reinforcement learning for multi-hop knowledge graph reasoning. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics , pages 3181–3192, 2023. [46] Long Zhao, Yin Xu, Yanyan Wang, Zhengyi Chen, Youzhi Huang, and Qiangzhong Feng. Rpr-kgqa: Relational path reasoning for multi-hop question answering with knowledge graph. In Proceedings of the 2024 International Conference on Computer and Multimedia Technology , pages 596–600, 2024. 21 NeuroSymActive [47] Junnan Dong, Qinggang Zhang, Xiao Huang, Keyu Duan, Qiaoyu Tan, and Zhimeng Jiang. Hierarchy-aware multi-hop question answering over knowledge graphs. In Proceedings of the ACM web conference 2023 , pages 2519–2527, 2023. [48] Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, and Hong Chen. Subgraph retrieval enhanced model for multi-hop knowledge base question answering. arXiv preprint arXiv:2202.13296 , 2022. [49] Shangfei Zheng, Wei Chen, Weiqing Wang, Pengpeng Zhao, Hongzhi Yin, and Lei Zhao. Multi-hop knowledge graph reasoning in few-shot scenarios. IEEE Transactions on Knowledge and Data Engineering , 36(4):1713–1727, 2023. [50] Haitian Sun, Tania Bedrax-Weiss, and William Cohen. Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP) ,pages 2380–2390, 2019. [51] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and William Cohen. Open domain question answering using early fusion of knowledge bases and text. In Proceedings of the 2018 conference on empirical methods in natural language processing , pages 4231–4242, 2018. [52] Jiaxin Shi, Shulin Cao, Lei Hou, Juanzi Li, and Hanwang Zhang. Transfernet: An effective and transparent framework for multi-hop question answering over relation graph. arXiv preprint arXiv:2104.07302 , 2021. [53] Guanming Xiong, Junwei Bao, and Wen Zhao. Interactive-kbqa: Multi-turn interactions for knowledge base question answering with large language models. arXiv preprint arXiv:2402.15131 , 2024. [54] Peng Yixing, Quan Wang, Licheng Zhang, Yi Liu, and Zhendong Mao. Chain-of-question: A progressive question decomposition approach for complex knowledge base question answering. In Findings of the Association for Computational Linguistics ACL 2024 , pages 4763–4776, 2024. [55] Reham Omar, Omij Mangukiya, Panos Kalnis, and Essam Mansour. Chatgpt versus traditional question answering for knowledge graphs: Current status and future directions towards knowledge graph chatbots. arXiv preprint arXiv:2302.06466 , 2023. [56] Jiaqi Bai, Zhao Yan, Ze Yang, Jian Yang, Xinnian Liang, Hongcheng Guo, and Zhoujun Li. Knowprefix-tuning: A two-stage prefix-tuning framework for knowledge-grounded dialogue generation. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases , pages 525–542. Springer, 2023. [57] Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao, Chaochao Lu, Shuai Li, and Ricardo Henao. Infoprompt: Information-theoretic soft prompt tuning for natural language understanding. Advances in neural information processing systems , 36:61060–61084, 2023. [58] Qizhou Chen, Taolin Zhang, Xiaofeng He, Dongyang Li, Chengyu Wang, Longtao Huang, et al. Lifelong knowledge editing for llms with retrieval-augmented continuous prompt learning. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 13565–13580, 2024. [59] Daixuan Cheng, Shaohan Huang, Junyu Bi, Yuefeng Zhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu Wei, Weiwei Deng, and Qi Zhang. Uprise: Universal prompt retrieval for improving zero-shot evaluation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 12318–12337, 2023. [60] Shanyue Wan. Automatic optimization method for database indexing by integrating monte carlo tree search and graph neural network. Procedia Computer Science , 262:831–839, 2025. [61] Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. The value of semantic parse labeling for knowledge base question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 201–206, 2016. [62] Alon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex questions. arXiv preprint arXiv:1803.06643 , 2018. [63] Alexander H Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston. Key-value memory networks for directly reading documents (emnlp16). arXiv , 2016. 22 NeuroSymActive [64] Apoorv Saxena, Aditay Tripathi, and Partha Talukdar. Improving multi-hop question answering over knowledge graphs using knowledge base embeddings. In Proceedings of the 58th annual meeting of the association for computational linguistics , pages 4498–4507, 2020. [65] Gaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. Improving multi-hop knowledge base question answering by learning intermediate supervision signals. In Proceedings of the 14th ACM international conference on web search and data mining , pages 553–561, 2021. [66] Apoorv Saxena, Adrian Kochsiek, and Rainer Gemulla. Sequence-to-sequence knowledge graph completion and question answering. arXiv preprint arXiv:2203.10321 , 2022. [67] Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, and Ji-Rong Wen. Unikgqa: Unified retrieval and reasoning for solving multi-hop question answering over knowledge graph. arXiv preprint arXiv:2212.00959 , 2022. [68] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Lionel M Ni, Heung-Yeung Shum, and Jian Guo. Think-on-graph: Deep and responsible reasoning of large language model on knowledge graph. arXiv preprint arXiv:2307.07697 , 2023. [69] Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong Wen. Structgpt: A general framework for large language model to reason over structured data. arXiv preprint arXiv:2305.09645 , 2023. [70] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. Agentbench: Evaluating llms as agents. arXiv preprint arXiv:2308.03688 , 2023. [71] Tiezheng Guo, Qingwen Yang, Chen Wang, Yanyi Liu, Pan Li, Jiawei Tang, Dapeng Li, and Yingyou Wen. Knowledgenavigator: Leveraging large language models for enhanced reasoning over knowledge graph. Complex & Intelligent Systems , 10(5):7063–7076, 2024. [72] Tu Ao, Yanhua Yu, Yuling Wang, Yang Deng, Zirui Guo, Liang Pang, Pinghui Wang, Tat-Seng Chua, Xiao Zhang, and Zhen Cai. Lightprof: A lightweight reasoning framework for large language model on knowledge graph. In 

Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, pages 23424–23432, 2025. 

## A Theoretical Analysis 

This section collects formal guarantees that underpin NeuroSymActive. We state assumptions explicitly and present convergence and approximation results for the inner-loop differentiable search, calibration bounds for the Bayesian hop head and the entropy predictor, a simple budget-aware query-complexity bound for active human queries, an approximation lemma for the soft (relaxed) tree policy, and a representational consistency bound for the neural-symbolic fusion. Each result is followed by a proof. 

A.1 Preliminaries and assumptions 

We adopt the following standing assumptions. Assumption A1 (Smoothness). All parameterized neural modules in the inner loop define differentiable objectives whose gradients are L-Lipschitz continuous with respect to the parameters. Concretely, for any module parameter vector θ and any loss ℓ(θ),

∥∇ ℓ(θ) − ∇ ℓ(θ′)∥ ≤ L∥θ − θ′∥. (25) where ∥ · ∥ denotes the Euclidean norm and L > 0 is a constant. Assumption A2 (Bounded variance and sub-Gaussian noise). Stochastic gradient estimators used in the inner loop have uniformly bounded second moment and the observation noise in the Bayesian head is sub-Gaussian with parameter σ2.Assumption A3 (Finite action set). At each tree node the candidate action set A is finite with size at most Amax .Assumption A4 (Nontrivial information gain). There exists ∆min > 0 such that any informative human query reduces the expected predictive entropy by at least ∆min .We will refer to these assumptions throughout the proofs. 23 NeuroSymActive 

A.2 Convergence of the inner loop: differentiable MCTS 

We first treat the inner loop as stochastic gradient descent over a differentiable surrogate objective obtained by the soft tree relaxation and the composite loss defined in Equation (20). 

Theorem A.1 (Inner-loop convergence to stationary points) . Let Ltotal (θ) denote the differentiable surrogate objective of the inner loop, parameterized by θ. Under Assumptions A1 and A2, if the inner-loop updates use stochastic gradient descent with step sizes {ηt}t≥0 satisfying 

> ∞

X

> t=0

ηt = ∞,

> ∞

X

> t=0

η2 

> t

< ∞, (26) 

then the sequence {θt} satisfies 

lim  

> T→∞

1

T 

> T−1

X

> t=0

E∥∇L total (θt)∥2 = 0 . (27) 

Consequently every limit point of {θt} is almost surely a stationary point of Ltotal .

Proof. The proof follows the standard Robbins-Monro stochastic approximation argument for nonconvex smooth objectives. By Assumption A1 the objective Ltotal has L-Lipschitz gradients. Let gt denote the unbiased stochastic gradient estimate at iteration t with bounded variance E∥gt − ∇L total (θt)∥2 ≤ σ2 

> g

by Assumption A2. Using the smoothness inequality and the SGD update θt+1 = θt − ηtgt, one obtains the descent relation 

ELtotal (θt+1 ) ≤ ELtotal (θt) (28) 

− ηtE⟨∇L total (θt), E[gt | θt]⟩

+ Lη 2

> t

2 E∥gt∥2. (29) Replacing E[gt | θt] = ∇L total (θt) and rearranging yields 

ηtE∥∇L total (θt)∥2 ≤ ELtotal (θt) − ELtotal (θt+1 )

+ Lη 2

> t

2 E∥gt∥2. (30) Summing over t = 0 , . . . , T − 1 and dividing by PT −1 

> t=0

ηt gives 

1

PT −1 

> t=0

ηtT −1X

> t=0

ηtE∥∇L total (θt)∥2

≤ Ltotal (θ0) − L ∞

PT −1 

> t=0

ηt

+ L PT −1 

> t=0

η2 

> t

E∥gt∥2

2 PT −1 

> t=0

ηt

, (31) where Linf is the infimum of the objective. Under the step-size conditions P 

> t

ηt = ∞ and P 

> t

η2 

> t

< ∞ the right-hand side vanishes as T → ∞ , which proves the claim that the averaged squared gradient norm tends to zero. Standard subsequence arguments then yield that limit points are stationary. where Ltotal is the differentiable surrogate of the composed objectives, θt denotes inner-loop parameters at iteration t,and other symbols are as introduced above. 

A.3 Uncertainty calibration guarantees 

We now quantify coverage properties of the Bayesian hop head and a concentration bound for the learned entropy predictor. 

Lemma A.2 (Bayesian head coverage under sub-Gaussian noise) . Assume the additive noise in the hop logits is sub-Gaussian with parameter σ2 and the variance estimator ˆσ2(Vq ) is consistent. For any confidence level δ ∈ (0 , 1) 

and appropriate calibration constant cδ , the predictive interval produced by the Bayesian head covers the true hop count with probability at least 1 − δ, that is 

Pr  h⋆q ∈ I δ (Vq ) ≥ 1 − δ, (32) 

where Iδ (Vq ) denotes the interval centered at the posterior mode with half-width cδ ˆσ(Vq ).

24 NeuroSymActive 

Proof. Sub-Gaussianity implies Hoeffding-type concentration for the logit residual. Let Z denote the logit residual for the true hop. Then 

Pr  |Z| ≥ t ≤ 2 exp  −t2/(2 σ2). (33) Selecting t = σp2 log(2 /δ ) yields Pr( |Z| ≥ t) ≤ δ. If the variance estimator ˆσ2(Vq ) is consistent and the posterior mode estimator is consistent, then using the plug-in half-width cδ ˆσ(Vq ) with cδ = p2 log(2 /δ ) ensures asymptotic coverage 1 − δ. Finite-sample calibration depends on the estimator bias; under the consistency assumption the coverage bound holds up to vanishing estimation error terms. □

where ˆσ(Vq ) is the estimated heteroscedastic standard deviation for query q, and h⋆q is the true hop count. 

Proposition A.3 (Entropy predictor concentration) . Let ηθ be trained to predict the Shannon entropy of the answer distribution conditional on a subgraph. Under sub-Gaussian training noise and assuming the predictor class has finite Rademacher complexity Rn, the expected absolute prediction error obeys 

E|ηθ (G, r, V q ) − H(·)| ≤ 2Rn + O q log(1 /δ )

> n

 (34) 

with probability at least 1 − δ, where n is the number of training samples. 

Proof. This is a standard generalization bound for regression under bounded loss. The expected loss deviation from empirical loss is controlled by Rademacher complexity; applying symmetrization and concentration yields the displayed bound. See standard learning theory references for the detailed derivation. □

where H(·) denotes the true conditional Shannon entropy and other symbols are as above. 

A.4 Budget-aware query complexity for active human queries 

We present a simple deterministic bound that relates the number of required human queries to achieve a target entropy reduction to the per-query minimum information gain. 

Theorem A.4 (Query complexity under minimum per-query gain) . Assume each human query reduces the expected predictive entropy by at least ∆min > 0 (Assumption A4). Let the initial expected entropy for a query be H0 and target entropy be Htarget < H 0. Then the number of human queries Q required to reduce entropy below Htarget satisfies 

Q ≤

l H0 − Htarget 

∆min 

m

. (35) 

Proof. Each human query reduces expected entropy by at least ∆min so after Q queries the entropy is at most 

H0 − Q∆min . Requiring this quantity to be less than or equal to Htarget yields the bound. □

where H0 is the initial expected entropy and ∆min is the guaranteed per-query reduction. 

A.5 Soft MCTS approximation and low-temperature limit 

We now formalize the relationship between the softened tree policy and the hard argmax policy as the search temperature 

τsearch tends to zero. 

Lemma A.5 (Softmax concentration and action-probability gap) . Let {ui}ni=1 denote action utilities with unique maximum ui⋆ = max i ui and utility gap ∆ = min i̸=i⋆ (ui⋆ − ui) > 0. Under the soft tree policy πtree (ai | s) defined in Equation (19) the probability mass on the maximal action satisfies 

πtree (ai⋆ | s) ≥ 11 + ( n − 1) exp( −∆/τ search ) . (36) 

Hence lim τsearch →0 πtree (ai⋆ | s) = 1 .

Proof. By definition of softmax, 

πtree (ai⋆ | s) = 11 + P 

> i̸=i⋆

exp  (ui − ui⋆ )/τ search 

 . (37) Since ui − ui⋆ ≤ − ∆ for every i̸ = i⋆ the denominator is bounded by 1 + ( n − 1) exp( −∆/τ search ). This yields the displayed inequality and the limit statement. □

where n ≤ Amax is the local action count and ∆ denotes the utility gap. 25 NeuroSymActive 

A.6 Neural-symbolic fusion consistency 

Finally we bound the representational error of the fused vector when symbolic plausibility vectors approximate ground-truth validity up to a known tolerance and the gating network is Lipschitz. 

Theorem A.6 (Fusion error bound) . Let zneural  

> f

and zsym  

> f

be neural and symbolic path vectors respectively. Suppose the symbolic module approximates a true plausibility vector y with uniform error ∥zsym  

> f

− y∥ ≤ εsym . Let the gating network γ(·) be Lγ -Lipschitz and bounded in [0 , 1] . Then the fused representation zf obtained from Equation (14) 

satisfies 

∥zf − zideal ∥ ≤ εsym + Lγ ∥zneural  

> f

, zsym 

> f



− zneural  

> f

, y∥ · ∥ zneural  

> f

− y∥, (38) 

where zideal denotes the ideal fused vector computed with the true plausibility y.

Proof. Write the fusion as 

zf = γ u ⊙ zneural  

> f

+  1 − γ u ⊙ zsym  

> f

, (39) where u = [ zneural  

> f

, zsym  

> f

]. The ideal fused vector is obtained by replacing zsym  

> f

with y. Subtracting the two expressions and applying the triangle inequality yields 

∥zf − zideal ∥ ≤ ∥ γ(u) ⊙ (zneural  

> f

− zneural  

> f

)∥

+ ∥(1 − γ(u)) ⊙ (zsym  

> f

− y)∥

+ ∥(γ(u) − γ(u′)) ⊙ (zneural  

> f

− y)∥, (40) where u′ = [ zneural  

> f

, y]. The first term vanishes. For the second term use ∥1 − γ(u)∥ ≤ 1 and ∥zsym  

> f

− y∥ ≤ εsym . For the third term use the Lipschitz property of γ to obtain a multiplicative factor Lγ ∥u − u′∥. Combining terms yields the stated bound. □

where zideal is the fused representation had the symbolic module been exact. 

A.7 Discussion and priorities for formal refinement 

The provided theorems form a rigorous baseline for the theoretical behavior of NeuroSymActive under established smoothness and noise assumptions. The most critical formal gaps to address in future revisions are non-asymptotic regret bounds for the full two-loop scheme and PAC-style label complexity bounds under realistic human response models. The current results establish stationary convergence of the inner differentiable optimization, finite-sample concentration for the Bayesian head and entropy predictor under standard statistical assumptions, a deterministic budget-aware query bound, a precise soft-to-hard MCTS approximation statement, and a fusion error bound linking symbolic approximation error to fused representation accuracy. 26