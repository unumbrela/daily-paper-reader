Title: Multi-Objective Coverage via Constraint Active Search

URL Source: https://arxiv.org/pdf/2602.15595v1

Published Time: Wed, 18 Feb 2026 01:47:49 GMT

Number of Pages: 11

Markdown Content:
# Multi-Objective Coverage via Constraint Active Search 

# Zakaria Shams Siam 

University at Albany, State University of New York Albany, United States zsiam@albany.edu 

# Xuefeng Liu 

University of Chicago Chicago, United States xuefeng@uchicago.edu 

# Chong Liu 

University at Albany, State University of New York Albany, United States cliu24@albany.edu 

## ABSTRACT 

In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse sam-ples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predic-tions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features. 

## KEYWORDS 

Multi-objective coverage; Constraint active search; Upper confi-dence bound; Gaussian processes; Drug discovery 

ACM Reference Format: 

Zakaria Shams Siam, Xuefeng Liu, and Chong Liu. 2026. Multi-Objective Coverage via Constraint Active Search. In Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 â€“ 29, 2026 , IFAAMAS, 11 pages. https://doi.org/10. 65109/XTVI9400 

## 1 INTRODUCTION 

Many critical real-world applications, such as drug discovery and materials design, increasingly rely on data-driven screening to identify a small set of promising designs for expensive downstream analysis. Often, the acceptance of candidate designs is governed by a feasible region defined by per-objective lower bounds or accep-tance thresholds (e.g., for docking, solubility, or synthetic accessibil-ity). Under limited experimental budgets, procedures are therefore sought that yield a compact yet diverse set of designs satisfying   

> This work is licensed under a Creative Commons Attribution Inter-national 4.0 License.
> Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), C. Amato, L. Dennis, V. Mascardi, J. Thangarajah (eds.), May 25 â€“ 29, 2026, Paphos, Cyprus .Â©2026 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). https://doi.org/10.65109/XTVI9400

Figure 1: An example of the MOC problem where ğ‘“ 1, ğ‘“ 2 are two objective functions and ğœ 1, ğœ 2 are two thresholds defining the feasible region shown in light green. 15 samples are selected as representative feasible samples, each with a coverage ball whose radius is ğ‘Ÿ .

these acceptability criteria while requiring as few costly experi-ments as possible [ 16 ]. This motivates active and sample-efficient search algorithms that reason directly about the specific outcomes which will be most informative and cost-effective for the decision makers [6, 26]. Classical multi-objective optimization methods typically empha-size approximating the Pareto frontier and improving hypervolume [ 5, 12 , 17 , 32 ]. These objectives are well suited for managing trade-offs among competing objectives, but they do not directly target the discovery of threshold-compliant candidates. Contemporary works on constraint active search (CAS) contribute toward discovery under acceptance/rejection criteria, however, the state-of-the-art [ 20 ] frames coverage in the sample space and applies expected im-provement (EI)-like utilities. However, sample-space coverage can be misaligned with many decision criteria (e.g., in molecular de-sign), where chemically diverse inputs may map to similar objective profiles. In such settings, input-space novelty can waste evaluations on designs that look different yet yield nearly identical outcomes, while failing to cover the feasible region where decisions are made: the objective space. In contrast, coverage in the output (objective) space aligns di-rectly with downstream selection, as acceptability is inherently defined there. Optimizing output-space coverage therefore priori-tizes the discovery of a few representative outcome patterns that satisfy all imposed constraints, enabling faster and more reliable down-selection than strategies that only spread samples in the in-put space or trace the Pareto front. Our goal is to select a compact set of samples whose outcomes are well distributed across the feasi-ble region, rather than merely spreading inputs in sample space or tracing the Pareto frontier. This supports reliable down-selection 

> arXiv:2602.15595v1 [cs.LG] 17 Feb 2026

and risk-aware decision making under uncertainty. See Figure 1 for an example with two objective functions. To solve this new and highly motivated problem, we formu-late the new multi-objective coverage (MOC) problem, where per-objective thresholds define a feasible region in objective space. The goal is to identify a small set of diverse, representative samples whose outcomes satisfy the thresholds and collectively cover the feasible region under uncertaintyâ€”without attempting to enumer-ate all feasible points [ 8], which can be prohibitively expensive. This new problem yields a compact and diverse panel that supports decision-making under uncertainty while minimizing the number of costly evaluations. To solve the MOC problem, We model each objective with an independent Gaussian process (GP) [ 31 ] and de-sign an optimistic acquisition function that trades off feasibility and incremental objective-space coverage gain, using upper confidence bounds (UCB) [27]. 

Contributions. Our contributions are summarized as follows. 

â€¢ We formulate the new MOC problem, which explicitly targets fast coverage and diversity of the feasible objective region under per-objective thresholds. This is distinct from the CAS framed in the sample space [ 20 ] and also different from other frontier-centric objectives [5, 12, 32]. 

â€¢ To solve the problem, we propose the multi-objective cover-age via constraint active search (MOC-CAS) algorithm, which is a novel constrained active search algorithm that evaluates each candidate based on the optimistic estimate of the new feasible volume it is expected to cover within the feasible region. It further employs a tie-breaking mechanism that pro-motes diversity by encouraging dispersion in the predicted objective values. 

â€¢ To enable efficient optimization, we replace the hard feasi-bility indicators with smooth surrogates and thus derive an approximate optimizer for the proposed acquisition function. 

â€¢ On large-scale protein-target datasets of 1 million compounds spanning cancer and SARS-CoV-2 [ 19 ], our MOC-CAS algo-rithm achieves better performance than competitive base-lines under similar evaluation budgets. 

Technical Novelties. Our technical novelties are: 

â€¢ Our moc-cas selects samples by maximizing newly uncov-ered neighborhood volume in the objective space at a fixed coverage resolution, utilizing a UCB prediction to estimate feasibility before any coverage value is assigned. To maintain diversity in the objective space, we break ties by selecting the candidate with the greatest objective-space distance to prior feasible outcomes. 

â€¢ We derive a mass-preserving relaxation of the geometric objective with hard indicators. We replace the ball indicator by a unit-mass Gaussian kernel. Additionally, we substitute a smooth per-objective probit gate for the orthant indica-tor, and further replace the union of covered balls by a soft kernel sum. The resulting local average therefore yields a closed-form novelty term and a fully differentiable acquisi-tion function along with explicit gradients via the chain rule, thus enabling fast optimization in practice. 

## 2 RELATED WORK 

We briefly discuss related work from three different perspectives. 

## 2.1 Constraint Active Search 

Constraint active search (CAS) reexamines multiobjective design from Pareto-frontier tracing for finding a diverse set of threshold-satisfying samples. Past work in [ 20 ] presented CAS with the ex-pected coverage improvement (ECI) acquisition function that scores samples by their expected increase in the covered feasible volume in the sample space, where where coverage is measured in the sample space, using fill distance [ 20 ] as a proxy for diversity. CAS has also been utilized for optimizing performance during machine learning model deployment by connecting offline and online experimen-tations [ 13 ]. A related but distinct line of work [ 22 ] learns active constraint sets in order to speed up repeated deterministic opti-mization by estimating which constraints bind at optimality where the objective is to find faster solution for parametric programs with theoretical guarantees, instead of applying probabilistic search for finding diverse satisfactory samples. In contrast, our proposed ap-proach explicitly defines and directly optimizes coverage in the objective space under multi-threshold feasibility. It introduces an optimism-based feasibility gate linked to incremental objective-space coverage, thereby reshaping the acquisition geometry and the mechanism by which diversity is enforced, while preserving the core intuition of CAS methods - that a few well-chosen samples can effectively cover the feasible set. 

## 2.2 Level Set Estimation 

The level set estimation (LSE) problem was first approached in [ 2]through the straddle heuristic algorithm by utilizing a GP-based active learning technique. Subsequent work in [ 8 ] presented the LSE algorithm for active level-set estimation along with Gaussian-process confidence bounds, derived sample-complexity guarantees, and further extended the method to implicit thresholds and also batched sampling. Also, TRUVAR, a unified Bayesian framework for Bayesian optimization (BO) and LSE was proposed in [ 1] which greedily diminishes the truncated posterior variance over sample sets, controls pointwise costs and heteroscedastic noise, and also comes with theoretical guarantees. Zanette et al. [ 33 ] maximized the expected raise in the volume of the estimated level set. Wang et al. [ 30 ] developed a localâ€“minimax framework for noisy zeroth-order optimization and proposed that instance-dependent rates could be substantially faster when the reference functionâ€™s level sets satisfy fast volume-growth conditions and regularity, explicitly showing that the problemâ€™s difficulty is directly related to and also determined by the properties of the level-set geometry. Iwazaki et al. [ 11 ] focused on the LSE problem with input uncer-tainty where the input parameters are vulnerable to perturbation from a known Normal distribution. This study is closely related to safe BO research [ 28 , 29 ], where they sample only the configura-tions that surpass the threshold with high probability. Subsequent study in [ 21 ] proposed nearly-optimal (instance-dependent and non-asymptotic) sample-complexity bounds for explicit and im-plicit level-set estimation by connecting the problem to adaptive experimental design in reproducing kernel Hilbert space (RKHS), with methods which match known lower bounds in linear (kernel) settings. 

## 2.3 Multi-Objective Optimization 

Multi-objective optimization (MOO) aims to effectively approxi-mate the Pareto front under several competing objectives. Early probabilistic techniques utilized estimation-of-distribution ideas to design Bayesian model-based evolutionary algorithms which maintain diverse approximations to the Pareto front [ 15 ]. The work in [ 15 ] combines a BO algorithm into a multi-objective evolutionary algorithm and investigate its behavior on combinatorial problems, highlighting the role of probabilistic modeling for convergence and diversity. Information-theoretic acquisition functions in Bayesian optimization, such as, PESMO select evaluations in order to maxi-mally reduce the entropy of the posterior over the Pareto set and allow a decomposition across all objectives, thus enabling decou-pled evaluation with computational cost which scales linearly in the number of objectives [10]. Another line of work utilizes random scalarizations where the authors proposed a flexible framework which samples scalariza-tion weights to the target specified regions of the Pareto front and derive sublinear regret guarantees along with favorable computa-tional cost [ 23 ]. Complementarily, it was also shown that dominated hypervolume could be written as an expectation over hypervol-ume scalarizations, producing algorithms with hypervolume re-gret bounds when paired with standard BO (UCB or Thompson sampling) methods and a simple predictor for hypervolume [ 34 ]. Recent scalable MOO-BO approaches develop parallel expected hypervolume improvement (EHVI) and trust-region techniques for higher dimensions and large batches (e.g., qEHVI/qNEHVI and MORBO) [ 3, 4, 17 ]. Park et al. [ 24 ] proposed BOtied which is based on a cumulative distribution function indicator. Unlike these Pareto front-centric approaches (e.g., hypervolume, entropy, or scalariza-tion driven), our proposed work seeks coverage in objective space under explicit multi-threshold feasibility by optimizing a coverage-gain objective which rewards discovering diverse feasible outcomes instead of solely tracing the Pareto front. 

## 3 PRELIMINARIES 3.1 Problem Statement 

Let X âŠ† Rğ‘‘ be a compact sample space and ğ‘“ = (ğ‘“ 1, . . . , ğ‘“ ğ‘š ) :

X â†’ Rğ‘š a black-box, unknown, vector-valued function with ğ‘š 

objectives. A noisy query at ğ‘¥ âˆˆ X gives ğ‘¦ ğ‘– = ğ‘“ ğ‘– (ğ‘¥ ) + ğœ€ ğ‘– , where 

ğœ€ ğ‘– âˆ¼ N ( 0, ğœ 2) are i.i.d. Gaussian noise terms, for ğ‘– = 1, . . . , ğ‘š . Given per-objective thresholds ğœ = (ğœ 1, . . . , ğœ ğ‘š ) âˆˆ Rğ‘š , an outcome is called feasible provided that all objectives meet their thresholds. This defines the feasible region in the objective space: 

S = ğ’› âˆˆ Rğ‘š : ğ‘§ ğ‘– â‰¥ ğœ ğ‘– âˆ€ğ‘– .

In many critical real-world applications, e.g., drug discovery and materials design, the decision criterion is defined on the objective values, not molecular inputs. Therefore, covering representative out-comes inside S is more consistent and aligned with down-selection than finding the Pareto frontier. We select designs ğ‘¥ 1, ğ‘¥ 2, Â· Â· Â· âˆˆ X sequentially and observe ğ‘¦ ğ‘¡ =

ğ‘“ (ğ‘¥ ğ‘¡ ) + ğœ€ ğ‘¡ . At the end of ğ‘¡ steps, Dğ‘¡ = {( ğ‘¥ ğ‘  , ğ‘¦ ğ‘  )} ğ‘¡ ğ‘  =1 and the observed outcomes are ğ‘ ğ‘¡ = {ğ‘¦ ğ‘  }ğ‘¡ ğ‘  =1 âŠ‚ Rğ‘š . We fix a resolution parameter 

ğ‘Ÿ > 0. In real-world problem settings, we can define ğ‘Ÿ with respect to the robustness of the design to perturbations. Many experimental design problems typically have a sense of known resolution (e.g., manufacturing precision/tolerance or simulation accuracy). We interpret ğ‘Ÿ as a coverage resolution: outcomes within distance ğ‘Ÿ are treated as effectively redundant for representing S. For ğ‘Ÿ > 0 and center ğ’› âˆˆ Rğ‘š ,

ğµ ğ‘Ÿ (ğ’› ) = {ğ’› â€² âˆˆ Rğ‘š : âˆ¥ğ’› â€² âˆ’ ğ’› âˆ¥2 < ğ‘Ÿ }

represents the coverage neighborhood of ğ’› which is an ğ‘Ÿ -ball in the output space. We thus define the covered volume for a set of points 

ğ‘ ğ‘¡ as 

ğ‘¢ ğ‘¡ = Vol 



ğµ ğ‘Ÿ (ğ‘ ğ‘¡ ) âˆ© S 



, ğµ ğ‘Ÿ (ğ‘ ğ‘¡ ) =

Ã˜ 

> ğ’› âˆˆğ‘ ğ‘¡

ğµ ğ‘Ÿ (ğ’› ) .

Our objective is to maximize ğ‘¢ ğ‘¡ with as few evaluations as possible ,thus generating a small and diverse set of threshold-compliant or feasible outcomes that broadly covers S at resolution ğ‘Ÿ .

Evaluations. No single metric fully captures performance in multi-objective coverage. We therefore report three complementary met-rics. 

Fill Distance. Fill distance quantifies how evenly the sampled objective vectors cover the feasible region in objective space. The fill distance is formally defined as follows where ğ‘‘ (Â· , Â·) denotes the Euclidean distance in the objective space. 

FILL (ğ‘ ğ‘¡ , S) = sup 

> zâˆˆ S

min  

> zğ‘— âˆˆğ‘ ğ‘¡

ğ‘‘  zğ‘— , z .

FILL (ğ‘ ğ‘¡ , S) represents the radius of the largest empty ball that one can fit in S in Euclidean space [ 20 ]. It measures the spacing of ğ‘ ğ‘¡ 

in S. If a setâ€™s fill distance is smaller with respect to S, then that set is better distributed within S.

Positive Samples. This represents the number of feasible points in the objective space (inside the feasible set, S) for the samples selected by the algorithm. 

Area Under the Positives Curve (AUP). We further sum-marize sample efficiency utilizing the area under the cumulative discoveries curve. For cumulative positives ğ‘ƒ (ğ‘¡ ) up to round ğ‘¡ , we calculate 

AUP =

> ğ‘‡

âˆ‘ï¸ 

> ğ‘¡ =1

ğ‘ƒ (ğ‘¡ ),

or its trapezoidal variant. AUP rewards those methods which find good samples both early and consistently across the budget. Higher AUP indicates better performance by the method (since earlier and steadier discoveries score higher in this case). This metric is analogous to the area under the learning curve metric which is widely utilized in active learning research [9]. 

Additional Notations. We denote the scalars as italics (e.g., ğ‘¡, ğ‘Ÿ ), vectors as bold (e.g., ğ’› ), and sets as calligraphic (e.g., X, S). The Euclidean norm is denoted as âˆ¥Â·âˆ¥ . Vol (Â·) represents the Lebesgue volume in Rğ‘š . We use 1{Â·} to represent an indicator where 1{ğ‘¥ } = 1

if the condition ğ‘¥ holds and 0 otherwise. Similarly, 1Â· (Â·) represents a setâ€“membership indicator where 1ğ´ (ğ‘§ ) = 1 if ğ‘§ âˆˆ ğ´ and 0 if ğ‘§ âˆ‰ ğ´ .We use GP for Gaussian processes. 3.2 Background 

Constraint Active Search. Say X is a discrete or finite sample set having unknown, black-box multi-objective response Ëœğ‘¦ : X â†’ Rğ‘š .For the given collections of per-objective minimum thresholds, 

ğœ âˆˆ Rğ‘š , constraint active search (CAS) targets the feasible subset of the samples 

SX = { ğ‘¥ âˆˆ X : Ëœ ğ‘¦ ğ‘– (ğ‘¥ ) â‰¥ ğœ ğ‘– âˆ€ğ‘– âˆˆ [ ğ‘š ] } ,

and searches adaptively to identify a diverse set of feasible samples. 

Level Set Estimation. The objective of level set estimation (LSE) is to determine the region {ğ‘¥ âˆˆ X : ğ‘“ (ğ‘¥ ) â‰¥ ğœ } by sequentially querying ğ‘¥ and then observing ğ‘¦ = ğ‘“ (ğ‘¥ ) + ğœ€ given a (noisy) black-box objective ğ‘“ : X â†’ R and a threshold ğœ âˆˆ R. With a GP posterior at round ğ‘¡ âˆ’ 1, let ğœ‡ ğ‘¡ âˆ’1 (ğ‘¥ ) and ğœ ğ‘¡ âˆ’1 (ğ‘¥ ) represent the mean and standard deviation, a typical substitute for â€œbeing above the levelâ€ is 

ğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) = Pr  ğ‘“ (ğ‘¥ ) â‰¥ ğœ | D ğ‘¡ âˆ’1

 = Î¦

 ğœ‡ ğ‘¡ âˆ’1 (ğ‘¥ ) âˆ’ ğœ ğœ ğ‘¡ âˆ’1 (ğ‘¥ )



,

and the classic STRADDLE score selects points having high uncer-tainty near the level, 

ğ‘  straddle (ğ‘¥ ) = ğœ… ğœ ğ‘¡ âˆ’1 (ğ‘¥ ) âˆ’ ğœ‡ ğ‘¡ âˆ’1 (ğ‘¥ ) âˆ’ ğœ ,

mostly with ğœ… â‰ˆ 1.96 . LSE methods are inclined to concentrate queries close to the decision boundary that separates {ğ‘“ (ğ‘¥ ) â‰¥

ğœ } from its complement, instead of sampling the interior of the superlevel set. 

Multi-Objective Optimization. Let ğ‘“ (ğ‘¥ ) = (ğ‘“ 1 (ğ‘¥ ), . . . , ğ‘“ ğ‘š (ğ‘¥ )) :

X â†’ Rğ‘š be a function that needs to be maximized over a sample space X. For ğ‘¥ 1, ğ‘¥ 2 âˆˆ X , we say ğ‘¥ 1 Pareto-dominates ğ‘¥ 2 if ğ‘“ ğ‘– (ğ‘¥ 1) â‰¥ 

ğ‘“ ğ‘– (ğ‘¥ 2) for all ğ‘– and ğ‘“ ğ‘— (ğ‘¥ 1) > ğ‘“ ğ‘— (ğ‘¥ 2) for some ğ‘— . The Pareto set ğ‘‹ â˜… âŠ†X accommodates all non-dominated samples and its image ğ‘ƒ =

{ğ‘“ (ğ‘¥ ) : ğ‘¥ âˆˆ ğ‘‹ â˜…} is the Pareto front . A typical scalar summary is the (reference-point) hypervolume indicator 

HV ğ‘§ (ğ‘Œ )

= vol 

  ğ‘¦ âˆˆ Rğ‘š : ğ‘¦ â‰¥ ğ‘§, and âˆƒ ğ‘¦ â€² âˆˆ ğ‘Œ with ğ‘¦ â€² dominates ğ‘¦ 



,

for a finite set ğ‘Œ âŠ‚ Rğ‘š of achieved outcomes and a reference point 

ğ‘§ âˆˆ Rğ‘š . Hypervolume enlarges as ğ‘Œ inflates the dominated portion of objective space beyond ğ‘§ . It is widely utilized to compare methods which trade off multiple objectives. 

## 4 THE MOC-CAS ALGORITHM 

In this section, we show full details of our moc-cas algorithm, summarized in Algorithm 1. Overall, moc-cas performs sequential experimental design in order to identify a diverse set of outcomes which satisfy all perâ€“objective thresholds. At each round, we fit independent GPs for all the ğ‘š objectives, then form optimistic predictions, score each sample by an objective space coverage gain acquisition function which rewards new feasible coverage, and finally select the maximizer, while breaking ties in order to preserve objectiveâ€“space diversity. 

Gaussian Process Modeling. We develop independent GP priors 

ğ‘“ ğ‘– âˆ¼ GP ( 0, ğ‘˜ ğ‘– ), ğ‘– = 1, . . . , ğ‘š , to model all the objectives. Here, we refer to ğ‘˜ ğ‘– (Â· , Â·) as the GP covariance function. Given Dğ‘¡ âˆ’1, the pos-terior mean and variance at ğ‘¥ are denoted as ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) and ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ )2,

Algorithm 1 MOC-CAS Algorithm 

Require: GP prior kernels {ğ‘˜ ğ‘– }ğ‘š ğ‘– =1, thresholds ğœ , radius ğ‘Ÿ , confi-dence schedule (ğ›½ ğ‘¡ )ğ‘¡ â‰¥1, initial data D0 

> 1:

for ğ‘¡ = 1, 2, . . . ,ğ‘‡ do  

> 2:

Update independent GP posteriors using Dğ‘¡ âˆ’1 

> 3:

ğ‘¥ ğ‘¡ â† arg max ğ‘¥ âˆˆ X ğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ) 

> 4:

âŠ² break ties by farthest ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) from ğ‘ ğ‘¡ âˆ’1 

> 5:

Query ğ‘¦ ğ‘¡ = ğ‘“ (ğ‘¥ ğ‘¡ ) + ğœ€ ğ‘¡  

> 6:

Update Dğ‘¡ = Dğ‘¡ âˆ’1 âˆª {( ğ‘¥ ğ‘¡ , ğ‘¦ ğ‘¡ )}  

> 7:

end for  

> 8:

return {ğ‘¥ ğ‘¡ }ğ‘‡ ğ‘¡ =1

shown as 

ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) =  ğ‘˜ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ )âŠ¤  ğ¾ (ğ‘– )  

> ğ‘¡ âˆ’1

+ ğœ 2ğ¼  âˆ’1y(ğ‘– ) 

> 1: ğ‘¡ âˆ’1

,ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ )2 = ğ‘˜ ğ‘– (ğ‘¥, ğ‘¥ ) âˆ’  ğ‘˜ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ )âŠ¤  ğ¾ (ğ‘– )  

> ğ‘¡ âˆ’1

+ ğœ 2ğ¼  âˆ’1ğ‘˜ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ),

where ğ‘‹ ğ‘¡ âˆ’1 = {ğ‘¥ 1, . . . , ğ‘¥ ğ‘¡ âˆ’1 } are the sample points queried so far and y(ğ‘– )  

> 1: ğ‘¡ âˆ’1

= [ ğ‘¦ (ğ‘– ) 

> 1

, . . . , ğ‘¦ (ğ‘– )  

> ğ‘¡ âˆ’1

]âŠ¤ are the observations for ob-jective ğ‘– with independent and identically distributed Gaussian noise variance ğœ 2, and ğ¾ (ğ‘– )  

> ğ‘¡ âˆ’1

= ğ‘˜ ğ‘– (ğ‘¥ ğ‘ , ğ‘¥ ğ‘ )ğ‘¡ âˆ’1

> ğ‘,ğ‘ =1

, ğ‘˜ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) =

ğ‘˜ ğ‘– (ğ‘¥ 1, ğ‘¥ ), . . . , ğ‘˜ ğ‘– (ğ‘¥ ğ‘¡ âˆ’1, ğ‘¥ )âŠ¤.Using a confidence schedule ğ›½ ğ‘¡ > 0, we now define the optimistic UCB prediction 

ğ‘ˆ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) = ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) + âˆšï¸ ğ›½ ğ‘¡ ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ), ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) :=  ğ‘ˆ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ )ğ‘š ğ‘– =1.

Outputâ€“Coverage Acquisition. We define the optimistic feasibil-ity indicator in the objective space 

Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) =

(1, if ğ‘ˆ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) â‰¥ ğœ ğ‘– âˆ€ğ‘–, 

0, otherwise. Next, we define the incremental coverage gain at resolution ğ‘Ÿ which is our acquisition function used in step 3 in Algorithm 1: 

ğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ) := Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) Â· Vol 

 ğµ ğ‘Ÿ (ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ )) âˆ© S  \ ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1)



, (1) where ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1) := Ãğ‘¡ âˆ’1 

> ğ‘  =1

ğµ ğ‘Ÿ (ğ‘¦ ğ‘  ). Value is gained only if ğ‘¥ is opti-mistically feasible, and then only by the new ğ‘Ÿ -ball volume supplied within S. We prefer the sample whose predicted outcome ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ )

is farthest (in â„“2) from the existing set ğ‘ ğ‘¡ âˆ’1 in order to diversify among ties. 

Smoothing for efficient optimization. We substitute smooth surrogates (e.g., soft margins with respect to differentiable ğ‘Ÿ -ball ker-nels and thresholds ğœ ) for the hard feasibility test and set-difference to enable fast and gradient-based maximization of the acquisition function. This provides a smooth surrogate approximation of the discrete gain and could be optimized much more efficiently with the help of known gradient-based optimization methods like L-BFGS. The formal construction of smoothing is presented in Section 5. 

## 5 EFFICIENT OPTIMIZATION FOR PRACTICE 

In this section, we analyze and efficiently optimize Algorithm 1. Here, we delineate both the exact (hard) acquisition with an op-timistic feasibility guard and a fully smooth surrogate function utilized for inner optimization. More analyses of acquisition ap-proximation error and time complexity of MOC-CAS are deferred to the Appendix. Beginning from the hard geometric definition (eq. (1) ), Step A in Subsection 5.1 converts the set difference into a local Gaussian average. Then, Step B in Subsection 5.1 replaces the hard feasibility by a smooth multi-threshold gate evaluated at the local center. Finally, Step C in Subsection 5.1 replaces the union by a soft sum whose local average yields a closed-form expression. The resulting smooth acquisition function (eq. (7) ) is cheap to evaluate and also easy to differentiate, thus yielding an efficient inner maximization routine for moc-cas .

## 5.1 From Hard to Soft Indicators: Deriving the MOC-CAS Acquisition 

The hard new-coverage objective in output space at iteration ğ‘¡ is given in eq. (1) , that is, the S-constrained volume newly covered by the ğ‘Ÿ -ball around the optimistic prediction ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) while discarding the region already covered by the previous outputs {ğ‘¦ ğ‘  }ğ‘¡ âˆ’1 

> ğ‘  =1

.

Step A: Replace the Ball by a Mass-preserved Normalized Gaussian Kernel. We write the set-volume in eq. (1) as an integral over three hard indicators: 

ğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ) = Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ )

âˆ«

> Rğ‘š

1ğµ ğ‘Ÿ (ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) ) (ğ‘§ ) 1S (ğ‘§ )Â·



1 âˆ’ 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘§ )



ğ‘‘ğ‘§. (2) The three factors inside the integral in (2) correspond to the new ğ‘Ÿ -ball, the satisfactory set, and the not-yet-covered region, respectively. We introduce two unitâ€“mass radial kernels in output space. One is the uniform kernel on the open ball 

ğ‘¢ ğ‘Ÿ (ğ‘§ âˆ’ ğ‘ˆ ) := 1

ğ‘‰ ğ‘š (ğ‘Ÿ ) 1{âˆ¥ ğ‘§ âˆ’ ğ‘ˆ âˆ¥ < ğ‘Ÿ }, ğ‘‰ ğ‘š (ğ‘Ÿ ) := ğœ‹ ğ‘š /2

Î“   ğ‘š  

> 2

+ 1 ğ‘Ÿ ğ‘š ,

where Î“ is the Gamma function, and another one is the Gaussian kernel 

ğœ… ğ‘Ÿ (ğ‘§ âˆ’ ğ‘ˆ ) := N  ğ‘§ ; ğ‘ˆ , ğ‘Ÿ 2ğ¼ ,

âˆ«

ğœ… ğ‘Ÿ (ğ‘§ âˆ’ ğ‘ˆ ) ğ‘‘ğ‘§ = 1.

We then make the standard mass-preserving substitution 

1ğµ ğ‘Ÿ (ğ‘ˆ ) (ğ‘§ ) â‰ˆ ğ‘‰ ğ‘š (ğ‘Ÿ ) ğœ… ğ‘Ÿ (ğ‘§ âˆ’ ğ‘ˆ ),

which yields 

ğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ )â‰ˆ Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) ğ‘‰ ğ‘š (ğ‘Ÿ )

âˆ«

> Rğ‘š

ğœ… ğ‘Ÿ (ğ‘§ âˆ’ ğ‘ˆ ) 1S (ğ‘§ )  1 âˆ’ 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘§ ) ğ‘‘ğ‘§ 

= Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) ğ‘‰ ğ‘š (ğ‘Ÿ ) Eğ‘ âˆ¼N ( ğ‘ˆ ,ğ‘Ÿ 2ğ¼ )

h

1S (ğ‘ )  1 âˆ’ 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘ )i

,

(3) where ğ‘ˆ := ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ). Therefore, Step A converts the hard geometry into a local Gaussian average around ğ‘ˆ .

Step B: Soften the Satisfactory Gate. We replace the hard indicator of the thresholded orthant 1S (ğ‘§ ) = Ãğ‘š ğ‘– =1 1{ğ‘§ ğ‘– â‰¥ ğœ ğ‘– } by a smooth 

probit gate with softness ğœ† > 0:

ğ‘ sat (ğ‘§ ) :=

> ğ‘š

Ã–

> ğ‘– =1

Î¦

 ğ‘§ ğ‘– âˆ’ ğœ ğ‘– 

ğœ† 



, (4) where Î¦ is the standard normal cumulative distribution function (CDF). Using the narrow and centered Gaussian kernel from eq. (3) , we approximate the local average of the satisfactory gate by its value at the center: 

Eğ‘ âˆ¼N ( ğ‘ˆ ,ğ‘Ÿ 2ğ¼ )

ğ‘ sat (ğ‘ ) â‰ˆ ğ‘ sat (ğ‘ˆ ). (5) Substituting eq. (4) and (5) into eq. (3) gives 

ğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ )â‰ˆ Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) ğ‘‰ ğ‘š (ğ‘Ÿ ) ğ‘ sat (ğ‘ˆ ) Eğ‘ âˆ¼N ( ğ‘ˆ ,ğ‘Ÿ 2ğ¼ ) [1 âˆ’ 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘ )] .

Step C: Soften the Set Difference (Union) and Derive a Closed-Form Expectation. 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘§ ) = 1{ğ‘§ âˆˆ âˆª ğ‘¡ âˆ’1 

> ğ‘  =1

ğµ ğ‘Ÿ (ğ‘¦ ğ‘  )} is the exact membership of the already-covered region. We utilize a bounded soft union by summing the normalized Gaussian kernels centered at the previous outputs, which yields the â€œsoft-ORâ€ of the covered neighborhoods: 

1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘§ ) â‰ˆ  

> ğ‘¡ âˆ’1

âˆ‘ï¸ 

> ğ‘  =1

ğœ… ğ‘Ÿ (ğ‘§ âˆ’ ğ‘¦ ğ‘  ).

Under the local Gaussian in eq. (3) , the expectation of each term is reduced to a productâ€“integral of two Gaussian distributions: 

Eğ‘ âˆ¼N ( ğ‘ˆ ,ğ‘Ÿ 2ğ¼ )

ğœ… ğ‘Ÿ (ğ‘ âˆ’ ğ‘¦ ğ‘  ) =

âˆ«

N ( ğ‘§ ; ğ‘ˆ , ğ‘Ÿ 2ğ¼ ) N ( ğ‘§ ; ğ‘¦ ğ‘  , ğ‘Ÿ 2ğ¼ ) ğ‘‘ğ‘§ 

= N  ğ‘ˆ ; ğ‘¦ ğ‘  , 2ğ‘Ÿ 2ğ¼ 

= ğ‘ ğ‘š (ğ‘Ÿ ) exp 



âˆ’ âˆ¥ğ‘ˆ âˆ’ğ‘¦ ğ‘  âˆ¥2 

> 4ğ‘Ÿ 2



.

where ğ‘ ğ‘š (ğ‘Ÿ ) := (4ğœ‹ğ‘Ÿ 2)âˆ’ğ‘š /2. Therefore, 

Eğ‘ âˆ¼N ( ğ‘ˆ ,ğ‘Ÿ 2ğ¼ )

h

1 âˆ’ 1ğµ ğ‘Ÿ (ğ‘ ğ‘¡ âˆ’1 ) (ğ‘ )

i

â‰ˆ 1 âˆ’ 

> ğ‘¡ âˆ’1

âˆ‘ï¸ 

> ğ‘  =1

ğ‘ ğ‘š (ğ‘Ÿ ) exp 



âˆ’ âˆ¥ğ‘ˆ âˆ’ğ‘¦ ğ‘  âˆ¥2 

> 4ğ‘Ÿ 2



=: ğ‘› (ğ‘ˆ ).

(6) 

## 5.2 Soft MOC-CAS Acquisition and Efficient Maximization 

Once we combine eq. (3) , (4) , and (6) , it produces the fully softened acquisition function: 

eğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ) := ğ‘‰ ğ‘š (ğ‘Ÿ ) ğ‘ sat 

 ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ )| {z }

> soft feasibility

ğ‘›  ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ )| {z }

> soft new-coverage

. (7) This expression is not expensive to evaluate. This is because 

ğ‘‰ ğ‘š (ğ‘Ÿ ) is a constant given ğ‘Ÿ and ğ‘š . Also, ğ‘ sat (ğ‘ˆ ) is a product of 1-dimensional CDFs at ğ‘ˆ . Furthermore, ğ‘› (ğ‘ˆ ) is a short sum of ex-ponentials in squared distances to the previous outputs. The hard gate Ëœğ‘ ğ‘¡ âˆ’1 (ğ‘¥ ) appears in the exact (hard) acquisition function de-fined in eq. (1) to enforce optimistic feasibility. For efficient and fully differentiable optimization, we drop this binary factor in eq. (7) and utilize the smooth feasibility term ğ‘ sat (ğ‘ˆ ). Empirically, both variants behave identically. By default, we utilize (7) for inner opti-mization. Gradients for inner optimization. Let ğ‘ˆ = ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) and we write 

ğ‘‰ ğ‘š (ğ‘Ÿ ) once as a constant factor. 

âˆ‡ğ‘ˆ ğ‘ sat (ğ‘ˆ ) = ğ‘ sat (ğ‘ˆ )

h ğœ™   ğ‘ˆ 1 âˆ’ğœ 1

> ğœ†



ğœ† Î¦  ğ‘ˆ 1 âˆ’ğœ 1

> ğœ†

 , . . . , ğœ™   ğ‘ˆ ğ‘š âˆ’ğœ ğ‘š 

> ğœ†



ğœ† Î¦  ğ‘ˆ ğ‘š âˆ’ğœ ğ‘š 

> ğœ†

iâŠ¤

,

Here, we use the standard normal CDF Î¦(ğ‘¢ ) and PDF ğœ™ (ğ‘¢ )

Î¦(ğ‘¢ ) =

âˆ« ğ‘¢ 

> âˆ’âˆ

1

âˆš2ğœ‹ ğ‘’ âˆ’ğ‘¡ 2/2 ğ‘‘ğ‘¡, ğœ™ (ğ‘¢ ) = 1

âˆš2ğœ‹ ğ‘’ âˆ’ğ‘¢ 2/2,

and in the gradient, the argument is ğ‘¢ ğ‘– = ğ‘ˆ ğ‘– âˆ’ğœ ğ‘–  

> ğœ†

.

âˆ‡ğ‘ˆ ğ‘› (ğ‘ˆ ) = 

> ğ‘¡ âˆ’1

âˆ‘ï¸ 

> ğ‘  =1

ğ‘ ğ‘š (ğ‘Ÿ ) exp 



âˆ’ âˆ¥ğ‘ˆ âˆ’ğ‘¦ ğ‘  âˆ¥2 

> 4ğ‘Ÿ 2

 ğ‘ˆ âˆ’ ğ‘¦ ğ‘  

2ğ‘Ÿ 2 .

By the chain rule, with ğ‘ˆ ğ‘– (ğ‘¥ ) = ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) + âˆšï¸ ğ›½ ğ‘¡ ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ),

âˆ‡ğ‘¥ eğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ) = ğ‘‰ ğ‘š (ğ‘Ÿ )



âˆ‡ğ‘ˆ ğ‘ sat (ğ‘ˆ ) ğ‘› (ğ‘ˆ ) + ğ‘ sat (ğ‘ˆ ) âˆ‡ ğ‘ˆ ğ‘› (ğ‘ˆ )

âŠ¤

Â· âˆ‡ ğ‘¥ ğ‘ˆ (ğ‘¥ ).

(8) where, for each ğ‘– ,

âˆ‡ğ‘¥ ğ‘ˆ ğ‘– (ğ‘¥ ) = âˆ‡ğ‘¥ ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) + âˆšï¸ ğ›½ ğ‘¡ âˆ‡ğ‘¥ ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ).

These derivatives are already available in standard GP toolkits. Eq. (7) together with eq. (8) yields a smooth objective and explicit gradients for multi-start L-BFGS (or similar methods) over ğ‘¥ âˆˆ X .The best ğ‘¥ ğ‘¡ is then chosen by ğ‘¥ ğ‘¡ = arg max ğ‘¥ âˆˆ X eğ›¼ moc-cas   

> ğ‘¡ âˆ’1

(ğ‘¥ ).

## 6 EXPERIMENTS 6.1 Experimental Settings 

Datasets. We use the DrugImprover dataset [ 18 , 19 ] that comprises curated, orderable subsets of the ZINC15 compound library, where 1 million in-stock or quickly shippable molecules were selected per target for structure-based drug discovery. Protein pockets were defined using crystallographic ligand data or FPocket, and a sin-gle binding site was used for docking per protein. The dataset includes docking scores (via OpenEye FRED) and trained surro-gate models (with validation ğ‘… 2 of 0.842 for 3CLPro and 0.73 for RTCB) for 24 SARS-CoV-2 protein (e.g., 3CLPro , PLPro , RDRP , NSPs )and 5 human cancer-related targets (e.g., 6T2W , RTCB , WRN ). Pro-vided files include Simplified Molecular Input Line Entry System (SMILES)-docking score pairs, receptor structures, model weights, and inference code, supporting applications in high-throughput virtual screening and predictive modeling. From the available tar-gets, we use three cancer proteins 6T2W , RTCB , and WRN , and one SARS-CoV-2 protease target 3CLPro .

Baselines. We benchmark moc-cas against the following four baseline methods on all the four drugâ€“discovery tasks to delineate the comparison. 

Random. We utilize the uniform random selection method from the remaining pool each round. 

One-Step. We apply the oneâ€“step active search method that selects the sample maximizing the predicted feasibility probability 

ğ‘ (ğ‘ =1 | D ğ‘¡ âˆ’1), calculated as the product of perâ€“objective Gaussian tail probabilities under independent GPs [7]. 

Straddle. We implement a multiobjective extension of STRAD-DLE [ 2] for levelâ€“set estimation that alternates the targeted ob-jective ğ‘– âˆˆ [ ğ‘š ] each iteration and scores candidates by ğ‘  ğ‘– (ğ‘¥ ) =

ğœ…ğœ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) âˆ’ | ğœ‡ (ğ‘– )  

> ğ‘¡ âˆ’1

(ğ‘¥ ) âˆ’ ğœ ğ‘– |, ğœ… = 1.96 , then selects the maximizer using the shared shortlist. 

MOO+Cluster. We implement the multiobjective BO with clus-tering that develops optimistic outcome predictions ğ‘ˆ ğ‘¡ âˆ’1 (ğ‘¥ ) using UCB, keeps optimistically feasible candidates, clusters their esti-mated outcomes with ğ‘˜ -means, scores each cluster by its uncovered feasible mass within radius ğ‘Ÿ (via neighbor counts in objective space), then selects within the best cluster the point farthest (in objective space) from the previously observed outcomes. All baseline methods share the same GP modeling pipeline, bud-get, initializations, and shortlist settings as moc-cas for ensuring controlled and fair comparisons. 

Evaluation. As discussed in Section 3.1, we report the number of positives (samples with all objectives â‰¥ ğœ ), AUP, and fill distance inside the feasible outcome region, over 220 iterations. We finally aggregate the results as mean Â±adjusted standard error over four different trials for each experiment (i.e., mean Â± std /âˆš4). 

## 6.2 Results on SARS-CoV-2 Dataset 

We test all five methods on the SARS-CoV-2 3CLPro target dataset. 

moc-cas achieves the best results, as evidenced in Figure 2, where it consistently achieves the lowest fill distance and highest AUP and number of positives across multiple trials, outperforming all other algorithms. One-step active search method is competitive but un-derperforms compared to our moc-cas method. Overall, straddle ,

random search , and MOO+Cluster did not perform well in terms of the three evaluation criteria where straddle performs worst among all methods in terms of number of positives and AUP. 

One-step selects points that maximize the estimated feasibility probability, therefore it tends to exploit the high-feasibility region (where feasibility probability is highest) early. This makes it com-petitive on number of positives, however, it can concentrate evalu-ations in a smaller portion of the feasible objective space, which is consistent with its slightly worse fill-distance trajectory than 

moc-cas . In contrast, moc-cas explicitly rewards coverage gain in the feasible objective space, so once it finds a feasible neighborhood, it is driven to expand into new feasible neighborhoods rather than repeatedly sampling near already-covered outcomes. This is ex-actly the behavior we want in molecular screening: beyond finding many feasible candidates, we want them to be diverse in objective space to support down-selection and follow-up synthesis. Finally, the weaker baselines align with their design intent: straddle is primarily a level-set (boundary) learner, therefore it focuses on un-certain points near thresholds and consequently sacrifices feasible yield and AUP. MOO+Cluster relies on clustering of optimistic predictions and is less effective when posterior uncertainty is high, whereas random search provides a lower-bound reference. 

## 6.3 Results on Cancer Dataset 

We test all five methods on three cancer proteins 6T2W , RTCB ,and WRN target datasets. Again, our moc-cas turns out to be the best method in terms of all the evaluation criteria, as evidenced 50 100 150 200           

> Iterations
> 0.60
> 0.65
> 0.70
> 0.75
> 0.80
> Fill distance
> 50 100 150 200
> Iterations
> 0
> 50
> 100
> 150
> 200
> # Positives
> 50 100 150 200
> Iterations
> 0
> 5000
> 10000
> 15000
> 20000
> AUP
> Random Straddle MOO+Cluster One-Step MOC-CAS (ours)

Figure 2: Quantitative comparison on the SARS-CoV-2 3CLPro target dataset. 50 100 150 200                    

> Iterations
> 0.5
> 0.6
> 0.7
> Fill distance
> 50 100 150 200
> Iterations
> 0
> 50
> 100
> 150
> # Positives
> 50 100 150 200
> Iterations
> 0
> 5000
> 10000
> 15000
> AUP 50 100 150 200
> Iterations
> 0.65
> 0.70
> 0.75
> 0.80
> 0.85
> Fill distance
> 50 100 150 200
> Iterations
> 0
> 50
> 100
> 150
> # Positives
> 50 100 150 200
> Iterations
> 0
> 5000
> 10000
> 15000
> AUP
> Random Straddle MOO+Cluster One-Step MOC-CAS (ours)

Figure 3: Quantitative comparison on the Cancer RTCB (top row) and Cancer 6T2W (bottom row) target datasets. 

in Figure 3. The performance gap between moc-cas and the base-lines turns out to be statistically significant on the 6T2W dataset in Figure 3 in terms of AUP and number of positives - indicating that feasibility-only exploitation is not sufficient. The most plau-sible explanation is geometric: this target behaves like a harder coverage problem where feasible outcomes are either sparser or more fragmented in objective space, so repeatedly sampling the most confident feasible area leaves other feasible neighborhoods undiscovered. moc-cas is explicitly designed to exploit information from the posterior GPs and the history of discovered feasible out-comes, so its advantage grows as the posteriors sharpen and the soft feasibility/coverage terms become more accurate. In the initial iterations, all methods operate in a highly uncertain regime with very sparse data, so even sophisticated acquisitions behave close to exploratory baselines, which explains the small performance gaps. Results on WRN dataset are deferred to the Appendix which show a similar pattern. Among the baseline methods, One-step 

active search performed better than the other baselines across all the Cancer datasets. 

## 6.4 Ablation Studies 

moc-cas has two important hyperparameters carrying clear geo-metric meaning which govern its empirical efficiency and behavior. The coverage resolution, ğ‘Ÿ assigns the granularity at which objec-tiveâ€“space diversity is rewarded. Therefore, changes in the values of chosen ğ‘Ÿ will have influence on the quality of dispersion, covered volume and cumulative positive samples found. Also, the optimism schedule, ğ›½ ğ‘¡ governs how strongly the UCB gate considers feasibil-ity, trading exploration close to the thresholds against conservative consolidation and so its time profile forms early vs. late discovery and therefore AUP. Since objective scales, threshold calibrations, and noise levels vary across the targets (e.g., cancer vs. viral pro-teins), a fixed setting is not always universally optimal. Therefore, we ablate ğ‘Ÿ and ğ›½ ğ‘¡ for characterizing sensitivity by reporting influ-ences on all the evaluation criteria. 50 100 150 200            

> Iterations
> 0.60
> 0.65
> 0.70
> 0.75
> 0.80
> Fill distance
> 50 100 150 200
> Iterations
> 0
> 50
> 100
> 150
> 200
> # Positives
> 50 100 150 200
> Iterations
> 0
> 5000
> 10000
> 15000
> 20000
> AUP
> MOC-CAS ( r= 0.035) MOC-CAS ( r= 0.05) MOC-CAS ( r= 0.10)

Figure 4: Ablation of coverage resolution ğ‘Ÿ on the SARS-CoV-2 3CLpro dataset. 50 100 150 200            

> Iterations
> 0.60
> 0.65
> 0.70
> 0.75
> 0.80
> Fill distance
> 50 100 150 200
> Iterations
> 0
> 50
> 100
> 150
> 200
> # Positives
> 50 100 150 200
> Iterations
> 0
> 5000
> 10000
> 15000
> 20000
> AUP
> MOC-CAS ( Î²0= 2.0) MOC-CAS ( Î²0= 3.0) MOC-CAS ( Î²0= 4.0)

Figure 5: Ablation of optimism schedule ğ›½ ğ‘¡ on the SARS-CoV-2 3CLpro dataset. Coverage resolution ( ğ‘Ÿ ). We study the effect of the coverage reso-lution ğ‘Ÿ by fixing all hyperparameters (including the UCB schedule) and reusing the same seeds and initial indices across different trials, then sweeping ğ‘Ÿ âˆˆ { 0.035 , 0.05 , 0.10 } on the SARS-CoV-2 3CLpro 

dataset. We show the results in Figure 4. Across our runs, the high-est resolution ( ğ‘Ÿ = 0.10) delivered the most favorable tradeâ€“off yielding slightly lower fill distance and higher number of posi-tives than others while maintaining competitive AUP, whereas the intermediate resolution ( ğ‘Ÿ = 0.05) delivered slightly higher AUP. Figure 4 also shows that the smaller radius ( ğ‘Ÿ = 0.035) comparatively underâ€“covers the feasible region. 

Optimism schedule ( ğ›½ ğ‘¡ ). In our implementation, the time-varying confidence is ğ›½ ğ‘¡ = ğ›½ 0 Â· ğ‘ ğ‘¡ , where the annealing multiplier ğ‘ ğ‘¡ âˆˆ ( 0, 1]

is held fixed across runs. The ablation changes only ğ›½ 0 while keep-ing ğ‘ ğ‘¡ constant. To investigate explorationâ€“exploitation, we fix the coverage radius and all other settings and then sweep the initial optimism level ğ›½ 0 âˆˆ { 2.0, 3.0, 4.0} with the same annealing sched-ule (with constant seeds and initial indices across four different trials). Figure 5 investigates the optimism schedule: a larger ğ›½ 0

early encourages broader exploration that can escape low-quality pockets, whereas smaller values promote later consolidation within the feasible region. Empirically, Figure 5 shows that increasing ğ›½ 0

modestly improves AUP and cumulative positives, while smaller 

ğ›½ 0 tends to slightly reduce fill distance. 

## 7 CONCLUSION 

We address a practically important setting common in drug dis-covery and materials design: when success depends on meeting multiple performance thresholds, the objective is not to trace a Pareto front or spread samples in input space, but to rapidly iden-tify a small, representative set whose outcomes broadly cover the feasible region. Such sets enable faster downstream evaluation and decision-making, accelerating scientific iteration under tight exper-imental budgets. We formulate this as a multi-objective coverage problem and propose moc-cas , an acquisition strategy that integrates Gaussian process UCB predictions with an incremental coverage objective. To enable efficient inner optimization, we introduce a smoothed relax-ation of the hard geometric objective, yielding a differentiable sur-rogate with closed-form components and simple gradients. Across large-scale proteinâ€“target benchmarks for cancer and SARSâ€“CoVâ€“2, 

moc-cas consistently achieves better coverageâ€“quality tradeoffs than strong baselines, improving early discovery (higher cumu-lative positives and AUP) while maintaining diversity (lower fill distance). Our study employs independent Gaussian processes for each objective, though richer outcome models, such as deep kernels or correlated multi-output priors, represent promising directions for future work. 

## ACKNOWLEDGMENTS 

This work was partially supported by the IBM-UAlbany CEAIS Seed Grant 1201104-1-102522. The authors would like to thank anonymous reviewers and the area chair for helpful comments that improve this paper. REFERENCES 

[1] Ilija Bogunovic, Jonathan Scarlett, Andreas Krause, and Volkan Cevher. 2016. Truncated variance reduction: A unified approach to bayesian optimization and level-set estimation. Advances in neural information processing systems 29 (2016). [2] Brent Bryan, Robert C Nichol, Christopher R Genovese, Jeff Schneider, Christo-pher J Miller, and Larry Wasserman. 2005. Active learning for identifying func-tion threshold boundaries. Advances in neural information processing systems 18 (2005). [3] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. 2021. Parallel bayesian optimization of multiple noisy objectives with expected hypervolume improve-ment. Advances in neural information processing systems 34 (2021), 2187â€“2200. [4] Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy. 2022. Multi-objective bayesian optimization over high-dimensional search spaces. In 

Uncertainty in Artificial Intelligence . PMLR, 507â€“517. [5] Michael TM Emmerich, AndrÃ© H Deutz, and Jan Willem Klinkenberg. 2011. Hypervolume-based expected improvement: Monotonicity properties and exact computation. In 2011 IEEE congress of evolutionary computation (CEC) . IEEE, 2147â€“2154. [6] Peter I Frazier. 2018. A tutorial on Bayesian optimization. arXiv preprint arXiv:1807.02811 (2018). [7] Roman Garnett, Yamuna Krishnamurthy, Xuehan Xiong, Jeff Schneider, and Richard Mann. 2012. Bayesian optimal active search and surveying. arXiv preprint arXiv:1206.6406 (2012). [8] Alkis Gotovos, Nathalie Casati, Gregory Hitz, and Andreas Krause. 2013. Active learning for level set estimation. In International Joint Conference on Artificial Intelligence . 1344â€“1350. [9] Isabelle Guyon, Gavin C Cawley, Gideon Dror, and Vincent Lemaire. 2011. Results of the active learning challenge. In Active Learning and Experimental Design workshop In conjunction with AISTATS 2010 . JMLR Workshop and Conference Proceedings, 19â€“45. [10] Daniel HernÃ¡ndez-Lobato, Jose Hernandez-Lobato, Amar Shah, and Ryan Adams. 2016. Predictive entropy search for multi-objective bayesian optimization. In 

International conference on machine learning . PMLR, 1492â€“1501. [11] Shogo Iwazaki, Yu Inatsu, and Ichiro Takeuchi. 2020. Bayesian experimental design for finding reliable level set under input uncertainty. IEEE Access 8 (2020), 203982â€“203993. [12] Joshua Knowles. 2006. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE trans-actions on evolutionary computation 10, 1 (2006), 50â€“66. [13] Junpei Komiyama, Gustavo Malkomes, Bolong Cheng, and Michael McCourt. 2022. Bridging offline and online experimentation: Constraint active search for deployed performance optimization. Transactions on Machine Learning Research 

(2022). [14] Greg Landrum and contributors. [n.d.]. RDKit: Open-source cheminformatics. https://www.rdkit.org. Accessed: 2025-10-08. [15] Marco Laumanns and Jiri Ocenasek. 2002. Bayesian optimization algorithms for multi-objective optimization. In International Conference on Parallel Problem Solving from Nature . Springer, 298â€“307. [16] Diantong Li, Kyunghyun Cho, and Chong Liu. 2025. None To Optima in Few Shots: Bayesian Optimization with MDP Priors. arXiv preprint arXiv:2511.01006 

(2025). [17] Diantong Li, Fengxue Zhang, Chong Liu, and Yuxin Chen. 2025. Constrained Multi-objective Bayesian Optimization through Optimistic Constraints Estima-tion. In International Conference on Artificial Intelligence and Statistics . PMLR, 370â€“378. [18] Xuefeng Liu, Songhao Jiang, Siyu Chen, Zhuoran Yang, Yuxin Chen, Ian Foster, and Rick Stevens. 2025. DrugImproverGPT: A Large Language Model for Drug Optimization with Fine-Tuning via Structured Policy Optimization. arXiv preprint arXiv:2502.07237 (2025). [19] Xuefeng Liu, Songhao Jiang, Archit Vasan, Alexander Brace, Ozan Gokdemir, Thomas Brettin, Fangfang Xia, Ian Foster, and Rick Stevens. 2023. DRUGIM-PROVER: Utilizing reinforcement learning for multi-objective alignment in drug optimization. In NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development , Vol. 1. 8. [20] Gustavo Malkomes, Bolong Cheng, Eric H Lee, and Mike Mccourt. 2021. Be-yond the pareto efficient frontier: Constraint active search for multiobjective experimental design. In International Conference on Machine Learning . PMLR, 7423â€“7434. [21] Blake Mason, Lalit Jain, Subhojyoti Mukherjee, Romain Camilleri, Kevin Jamieson, and Robert Nowak. 2022. Nearly Optimal Algorithms for Level Set Estimation. In 

International Conference on Artificial Intelligence and Statistics . PMLR, 7625â€“7658. [22] Sidhant Misra, Line Roald, and Yeesian Ng. 2022. Learning for constrained optimization: Identifying optimal active constraint sets. INFORMS Journal on Computing 34, 1 (2022), 463â€“480. [23] Biswajit Paria, Kirthevasan Kandasamy, and BarnabÃ¡s PÃ³czos. 2020. A flexible framework for multi-objective bayesian optimization using random scalarizations. In Uncertainty in Artificial Intelligence . PMLR, 766â€“776. [24] Ji Won Park, NataÅ¡a Tagasovska, Michael Maser, Stephen Ra, and Kyunghyun Cho. 2023. BOtied: Multi-objective Bayesian optimization with tied multivariate ranks. arXiv preprint arXiv:2306.00344 (2023). [25] Sereina Riniker and Gregory A. Landrum. 2013. Open-source platform to bench-mark fingerprints for ligand-based virtual screening. Journal of Cheminformatics 

5, 26 (2013). https://doi.org/10.1186/1758-2946-5-26 [26] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. 2012. Practical bayesian optimization of machine learning algorithms. Advances in neural information processing systems 25 (2012). [27] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. 2010. Gaussian process optimization in the bandit setting: no regret and experimen-tal design. In International Conference on International Conference on Machine Learning . 1015â€“1022. [28] Yanan Sui, Alkis Gotovos, Joel Burdick, and Andreas Krause. 2015. Safe explo-ration for optimization with Gaussian processes. In International conference on machine learning . PMLR, 997â€“1005. [29] Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue. 2018. Stagewise safe Bayesian optimization with Gaussian processes. In International conference on machine learning . PMLR, 4781â€“4789. [30] Yining Wang, Sivaraman Balakrishnan, and Aarti Singh. 2019. Optimization of smooth functions with noisy observations: Local minimax rates. IEEE Transactions on Information Theory 65, 11 (2019), 7350â€“7366. [31] Christopher KI Williams and Carl Edward Rasmussen. 2006. Gaussian processes for machine learning . Vol. 2. MIT Press. [32] Kaifeng Yang, Michael Emmerich, AndrÃ© Deutz, and Thomas BÃ¤ck. 2019. Efficient computation of expected hypervolume improvement using box decomposition algorithms. Journal of Global Optimization 75, 1 (2019), 3â€“34. [33] Andrea Zanette, Junzi Zhang, and Mykel J Kochenderfer. 2018. Robust super-level set estimation using gaussian processes. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases . Springer, 276â€“291. [34] Richard Zhang and Daniel Golovin. 2020. Random hypervolume scalarizations for provable multi-objective black box optimization. In International conference on machine learning . PMLR, 11096â€“11105. A ADDITIONAL ANALYSES A.1 Acquisition Approximation Error 

Let ğ›¼ denote the true acquisition function and Ëœğ›¼ denote our approx-imated acquisition function. Our analysis shows that âˆ€ğ‘¥ âˆˆ X , ğ‘¡ âˆˆ[ğ‘‡ ], |ğ›¼ ğ‘¡ âˆ’1 (ğ‘¥ ) âˆ’ Ëœğ›¼ ğ‘¡ âˆ’1 (ğ‘¥ )| â‰¤ ğ‘‰ ğ‘š (ğ‘Ÿ )( ğœ– 1 + ğœ– 2), where ğ‘‰ ğ‘š (ğ‘Ÿ ) denotes the volume of an ğ‘š -dimensional ball of radius ğ‘Ÿ , ğœ– 1 is the soft feasibility gate error, and ğœ– 2 is the soft union error. Here, ğœ– 1 depends only on the feasibility margin, not ğ‘¡ . As the GP posterior sharpens and MOC-CAS prefers points that lie deeper inside the feasible orthant, this term decays exponentially with the distance from the thresholds. In contrast, ğœ– 2 arises from summing the Gaussian overlap with all past outcomes, which introduces a lin-ear factor in ğ‘¡ , but each summand is exponentially small whenever the candidate outcome is well separated from previously observed ones. Since MOC-CAS explicitly favors such outcome-space new points, the exponential decay in these overlaps dominates the linear factor, keeping ğœ– 2 small even as ğ‘¡ grows. 

## A.2 Time Complexity of MOC-CAS 

We provide our time complexity in this section. Let ğ‘š denote the number of objectives, ğ‘‡ denote total iterations, ğ‘ = |X| denote candidate set size, and ğ‘‘ denote input dimension. 

Overall complexity. With incremental GP updates and a finite candidate set, the overall time complexity of MOC-CAS is ğ‘‚ (ğ‘šğ‘‡ 3)+ 

ğ‘‚ (ğ‘ğ‘šğ‘‘ğ‘‡ 2), with the ğ‘‚ (ğ‘ğ‘šğ‘‘ğ‘‡ 2) term typically dominating for large ğ‘ .

GP updates. At round ğ‘¡ , each of the ğ‘š GPs has ğ‘¡ âˆ’ 1 data points. Using incremental Cholesky updates, one GP update costs ğ‘‚ (ğ‘¡ 2),so per round this is ğ‘‚ (ğ‘šğ‘¡ 2), and over ğ‘‡ rounds: 

> ğ‘‡

âˆ‘ï¸ 

> ğ‘¡ =1

ğ‘‚ (ğ‘šğ‘¡ 2) = ğ‘‚ (ğ‘šğ‘‡ 3).

Acquisition maximization (finite X). At round ğ‘¡ , evaluating Ëœğ›¼ ğ‘¡ âˆ’1 (ğ‘¥ )

for one candidate ğ‘¥ requires: (i) GP prediction for all ğ‘š objectives: 

ğ‘‚ (ğ‘šğ‘¡ğ‘‘ ) with precomputed Cholesky factors, (ii) the soft feasibility gate and novelty term: ğ‘‚ (ğ‘š ) and ğ‘‚ (ğ‘šğ‘¡ ), respectively. The dominant cost is therefore ğ‘‚ (ğ‘šğ‘¡ğ‘‘ ) per candidate. For exhaustive maximiza-tion over ğ‘ candidates: 

> ğ‘‡

âˆ‘ï¸ 

> ğ‘¡ =1

ğ‘‚ (ğ‘ğ‘šğ‘¡ğ‘‘ ) = ğ‘‚ (ğ‘ğ‘šğ‘‘ğ‘‡ 2).

## B ADDITIONAL EXPERIMENTAL DETAILS B.1 Settings of Datasets 

From DrugImprover, we then construct five per-molecule objectives from the given raw docking outputs using RDKit chemistry: 

â€¢ a docking objective derived from the raw OEDOCK scores (converted to â€œhigher-is-betterâ€ and normalized per target), 

â€¢ predicted solubility (ESOL from RDKit), 

â€¢ synthetic accessibility (SA), 

â€¢ RDKit QED which indicates drug-likeness, and 

â€¢ a structural similarity_to_topK objective given by the maxi-mum Tanimoto similarity to 1024 top-scoring ligands. 

Table 1: ğ‘‡ @50 on Cancer 6T2W dataset (smaller is better). 

Method ğ‘‡ @50 (mean Â± std over 4 trials) 

RANDOM 171 .2 Â± 14 .6

ONE-STEP 100 .0 Â± 26 .7

STRADDLE > 220 (not converge) 

MOO+CLUSTER 152 .5 Â± 42 .4

MOC-CAS (ours) 75 .0 Â± 5.4

All five objectives are scaled to [0, 1]. For molecular representa-tions, we develop SMILESâ€“derived numeric features (RDKit descrip-tors) using RDKit [ 14 , 25 ]. After the data preprocessing steps, the 

6T2W , RTCB , WRN , and 3CLPro datasets have 119, 197, 193, and 194 SMILESâ€“derived numeric features, respectively, that we use to con-duct the experiments. We split all the 10 6 molecules into 20 shards and featurize each independently. Thus, all the experiments are con-ducted on four different drugâ€“discovery tasks with five objectives per molecule (dock, solubility, SA, QED, and similarity-to-top ğ¾ ), where the perâ€“dataset thresholds ğœ âˆˆ Rğ‘š define feasibility in the ob-jective space. In our experiments, we set the perâ€“dataset thresholds such that, for each dataset, the feasible set contains approximately 30% of the full pool of 1 million molecules. We model each objective using an independent GP and prefit kernel hyperparameters on a random subset of 200 samples. We then update the GP posteriors at each iteration with the cumulative data available up to that iteration. We run a budget of ğ‘‡ =200 iterations with a common warm start of ğ‘› init =20 uniformly drawn designs (220 iterations in total). Across 4 randomized trials, we reuse the same seeds and initial indices for all five methods in order to enable paired comparisons. In order to ensure scalability, all methods evaluate their acquisition function on a shared and lightâ€“weight shortlist developed each iteration by integrating optimistic perâ€“objective prefiltering with random exploration under fixed caps. We break the ties by farthest distance in objective space from the previously observed outcomes. 

## B.2 Additional Results on Cancer Dataset 

In Figure 6 we show additional results on Cancer WRN dataset, which shows similar performances of MOC-CAS algorithm as in the main paper. 

## B.3 Additional Sample-Efficiency Metric: T@50 

Apart from the evaluation metrics used in the main paper, in order to quantify sample efficiency, we define a new evaluation metric, 

ğ‘‡ @ğ‘‹ = min ğ‘¡ : ğ‘ƒ (ğ‘¡ ) â‰¥ ğ‘‹ , which is the number of iterations ğ‘‡ 

needed to obtain ğ‘‹ satisfactory samples. Following the same ex-perimental setups in the main paper, we observe that MOC-CAS reaches 50 feasible samples significantly faster than all baselines. Table 1 shows T@50 on Cancer 6T2W dataset. Similar performances have been observed on other datasets too. 50 100 150 200 

Iterations    

> 0.60
> 0.65
> 0.70
> 0.75
> 0.80
> Fill distance
> 50 100 150 200

Iterations    

> 0
> 50
> 100
> 150
> # Positives
> 50 100 150 200

Iterations 

> 0
> 5000
> 10000
> 15000
> AUP

Random Straddle MOO+Cluster One-Step MOC-CAS (ours) Figure 6: Quantitative comparison on the Cancer WRN target dataset.