Title: Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery

URL Source: https://arxiv.org/pdf/2601.12442v1

Published Time: Wed, 21 Jan 2026 02:07:40 GMT

Number of Pages: 11

Markdown Content:
# Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery 

## Shahnawaz Alam 1,∗, Mohammed Mudassir Uddin 1, Mohammed Kaif Pasha 1

> 1

Department of Computer Science and Engineering Muffakham Jah College of Engineering and Technology (MJCET) Hyderabad, Telangana, India 

{shahnawaz.alam1024@gmail.com, mohd.mudassiruddin7@gmail.com, mdkaifpasha2k@gmail.com }

> ∗

Corresponding author: shahnawaz.alam1024@gmail.com 

# Abstract 

Scientific Artificial Intelligence (AI) applications re-quire models that deliver trustworthy uncertainty es-timates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neu-rosymbolic approaches operate deterministically with-out principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Frame-work (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture com-prises three components: automated constraint extrac-tion from scientific literature, probabilistic neural back-bone with variational inference, and differentiable con-straint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materi-als), QM9 molecular properties, and climate bench-marks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while main-taining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% perfor-mance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differ-entiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions. 

Keywords: Neurosymbolic AI, Uncertainty Quantifica-tion, Bayesian Deep Learning, Scientific Constraints, Cal-ibration, Physics-Informed Machine Learning 

# 1 Introduction 

The proliferation of deep learning methodologies across scientific domains has precipitated a fundamental crisis of trust in AI-generated predictions. Materials scientists, climate researchers, and pharmaceutical developers in-creasingly rely on neural network models for property prediction, simulation acceleration, and discovery guid-ance. However, the opacity of these models combined with their tendency to produce confident yet physically implausible predictions undermines their utility in high-stakes scientific applications [1, 2]. The challenge of trustworthy scientific AI encompasses two interrelated problems that existing methodologies address in isolation. First, uncertainty quantification methods such as Monte Carlo Dropout, Deep Ensem-bles, and Bayesian Neural Networks provide probabilis-tic predictions but offer no guarantees regarding physical consistency [3, 11]. A Bayesian neural network predict-ing molecular formation energies may express appropriate uncertainty yet still violate fundamental thermodynamic constraints. Second, neurosymbolic approaches that in-tegrate domain knowledge through constraint enforce-ment typically operate deterministically, lacking princi-pled mechanisms to quantify prediction confidence or propagate uncertainty through symbolic reasoning layers [4, 5, 6]. The research landscape reveals significant progress in adjacent areas while exposing critical gaps at their in-tersection. Probabilistic algebraic layers have demon-strated the feasibility of guaranteeing constraint satisfac-tion in neural architectures through symbolic integration techniques [7]. Physics-informed neural networks have achieved remarkable success in encoding partial differen-tial equations as soft constraints during training [8, 9]. Neurosymbolic frameworks such as NeuPSL have unified neural perception with probabilistic soft logic for rela-tional reasoning tasks [10]. However, no existing frame-work provides calibrated uncertainty estimates that re-spect hard scientific constraints while enabling automatic constraint acquisition from domain knowledge sources. This research addresses the identified gap through three primary contributions. The first contribution involves the development of a novel Constraint-Aware Neurosymbolic Uncertainty Framework that provides end-to-end differ-entiable uncertainty quantification with guaranteed con-straint satisfaction. The second contribution presents an automated constraint extraction methodology that mines scientific rules from literature and databases, reducing the manual specification bottleneck that has limited prior 1

> arXiv:2601.12442v1 [cs.LG] 18 Jan 2026

neurosymbolic approaches. The third contribution es-tablishes theoretical conditions under which constraint enforcement provably improves uncertainty calibration, measured through Expected Calibration Error reduction. The remainder of this paper proceeds as follows. Sec-tion 2 surveys related work in uncertainty quantifica-tion, neurosymbolic AI, and physics-informed machine learning. Section 3 presents the proposed CANUF ar-chitecture with detailed mathematical formulations. Sec-tion 4 describes the experimental methodology including datasets, baselines, and evaluation metrics. Section 5 re-ports comprehensive experimental results with ablation studies. Section 6 discusses implications, limitations, and future directions. Section 7 concludes with summary re-marks. 

# 2 Related Work 

The intersection of uncertainty quantification and neu-rosymbolic reasoning represents an emerging research frontier with foundational contributions from multiple es-tablished fields. This section synthesizes relevant prior work organized by thematic clusters. 

## 2.1 Uncertainty Quantification in Deep Learning 

Bayesian deep learning provides principled frameworks for modeling epistemic uncertainty arising from limited training data and model misspecification [11]. Variational inference methods approximate intractable posterior dis-tributions over neural network weights, enabling uncer-tainty propagation through forward passes [12]. Gal and Ghahramani demonstrated that Monte Carlo Dropout approximates Bayesian inference under certain condi-tions, providing a computationally efficient uncertainty estimation mechanism [13]. Deep Ensembles aggregate predictions from independently trained networks, captur-ing both aleatoric and epistemic uncertainty components while achieving strong empirical calibration [14]. Recent advances have focused on improving calibra-tion quality and computational efficiency. Evidential deep learning employs Dirichlet priors to model second-order uncertainty, distinguishing between data uncertainty and knowledge uncertainty [15]. The Expected Calibration Error (ECE) metric has become standard for evaluating probabilistic prediction quality, measuring the gap be-tween predicted confidence and observed accuracy across binned predictions [16]. However, these uncertainty quan-tification methods operate independently of domain con-straints, producing calibrated yet physically implausible uncertainty intervals in scientific applications. 

## 2.2 Neurosymbolic Integration Architec-tures 

Neurosymbolic AI combines the pattern recognition ca-pabilities of neural networks with the structured reason-ing abilities of symbolic systems [17]. DeepProbLog inte-grates neural networks with probabilistic logic program-ming, enabling end-to-end learning of perception and rea-soning components [18]. Scallop provides a differentiable programming framework supporting relational reasoning through provenance semirings [19]. These approaches demonstrate improved data efficiency and interpretability compared to purely neural methods. The constraint satisfaction perspective has gained prominence in safety-critical applications. Probabilistic algebraic layers guarantee satisfaction of non-convex al-gebraic constraints through differentiable symbolic inte-gration [7]. Relational neurosymbolic Markov models enforce logical constraints in sequential decision-making while providing probabilistic guarantees [20]. The dif-ferentiable constraint satisfaction layer paradigm enables gradient-based optimization while respecting hard bound-aries, though existing implementations lack principled un-certainty quantification mechanisms. 

## 2.3 Physics-Informed Machine Learning 

Physics-informed neural networks (PINNs) encode phys-ical laws as soft constraints through auxiliary loss terms, achieving improved generalization in scientific domains [21, 22]. The PDE-constrained learning framework learns families of solutions parameterized by equation coeffi-cients, enabling transfer across related physical systems [23]. Dictionary-based approaches achieve exact con-straint satisfaction through differentiable projection lay-ers rather than penalty-based enforcement [24]. Scientific machine learning for materials and molecules has attracted substantial attention. Graph neural net-works for molecular property prediction achieve state-of-the-art accuracy on benchmarks such as QM9 [25, 26]. However, these models frequently violate basic chemical constraints such as charge conservation and stoichiomet-ric balance. The Materials Project database provides experimental validation data for over 140,000 materials, enabling systematic evaluation of constraint satisfaction rates [27]. Uncertainty quantification for materials prop-erty prediction remains underdeveloped, with ensemble methods showing inconsistent calibration across property types [28]. 

## 2.4 Constraint Learning and Acquisition 

Automated constraint acquisition addresses the bottle-neck of manual rule specification in symbolic systems. Inductive logic programming learns symbolic rules from positive and negative examples, though scalability chal-lenges limit applicability to large scientific databases [29]. Neural theorem provers combine embedding-based simi-larity with formal deduction, achieving improved reason-ing over purely symbolic approaches [30]. Recent work on constraint learning from mixed data employs neurosym-bolic optimization to discover both hard and soft con-straints from observations [31]. The gap between automated constraint learning and uncertainty-aware prediction remains unaddressed. Ex-2Input Features x    

> Bayesian Backbone fθ
> CSL Layer ΠC
> Output (ˆ y, σ 2)
> Constraint Extractor E
> Explanation Generator
> rules

Figure 1: CANUF Architecture. The framework pro-cesses inputs through a Bayesian neural backbone, projects predictions onto constraint-satisfying regions via the CSL layer, and generates explanations from constraint violations. isting constraint acquisition methods focus on rule discov-ery without considering how learned constraints should influence prediction uncertainty. The proposed frame-work bridges this gap by developing constraint extraction mechanisms that inform both prediction and uncertainty estimation. 

## 2.5 Calibration Theory and Practice 

Calibration refers to the alignment between predicted probabilities and observed frequencies [32]. Tempera-ture scaling provides post-hoc calibration through a sin-gle learned parameter, achieving surprising effectiveness on classification tasks [33]. Isotonic regression and Platt scaling offer alternative post-hoc calibration approaches with different inductive biases [34]. Bayesian binning into quantiles (BBQ) provides uncertainty-aware calibration evaluation [35]. Recent theoretical analysis has established connections between calibration and constraint satisfaction. Models that respect domain constraints exhibit improved calibra-tion on in-domain data by avoiding confident predictions in physically impossible regions [36]. This observation motivates the proposed framework, which leverages con-straint enforcement to improve calibration quality sys-tematically. 

# 3 Proposed Methodology 

The Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF) integrates three interacting com-ponents to achieve calibrated uncertainty estimation under domain constraints. Figure 1 illustrates the overall architecture, which processes inputs through a constraint extraction module, a probabilistic neural backbone, and a differentiable constraint satisfaction layer. 

## 3.1 Problem Formulation 

Consider a scientific prediction task where the goal in-volves learning a mapping f : X → Y from input fea-tures to target properties. The training dataset D =

{(xi, y i)}Ni=1 consists of N examples. Additionally, a set of domain constraints C = {c1, c 2, . . . , c K } specifies valid output regions, where each constraint ck : Y ×X → { 0, 1}

returns 1 if the prediction satisfies the constraint given the input. The objective encompasses three criteria formalized as follows. First, the prediction accuracy criterion seeks to minimize the expected loss 

Lpred = E(x,y )∼pdata [ℓ(ˆ y, y )] (1) where ℓ denotes an appropriate loss function. Second, the constraint satisfaction criterion requires 

∀(x, y ) ∈ D , ∀ck ∈ C : ck(ˆ y, x) = 1 (2) Third, the calibration criterion minimizes the Expected Calibration Error ECE = 

> M

X

> m=1

|Bm|

N |acc( Bm) − conf( Bm)| (3) where Bm denotes the m-th confidence bin, acc( Bm) rep-resents the accuracy within the bin, and conf( Bm) repre-sents the average confidence. 

## 3.2 Automated Constraint Extraction 

The constraint extraction module E automatically discov-ers scientific rules from domain knowledge sources includ-ing textbooks, research papers, and curated databases. The extraction process operates in three phases. 

3.2.1 Knowledge Graph Construction 

Domain literature undergoes processing through a named entity recognition pipeline specialized for scientific termi-nology. Entities representing physical quantities, mate-rials, and relationships populate a knowledge graph G =(V, E) where vertices V denote concepts and edges E de-note relationships. The embedding function ϕ : V → Rd

maps concepts to dense vectors using a pre-trained scien-tific language model. 

3.2.2 Rule Template Matching 

Scientific constraints typically follow recognizable pat-terns such as conservation laws, bounds constraints, and relational dependencies. The extraction module main-tains a library of rule templates 

T = {t1, t 2, . . . , t L} (4) where each template tl specifies a constraint structure with placeholders for domain-specific quantities. Tem-plate matching identifies candidate constraints by com-puting similarity between knowledge graph substructures and template patterns. For conservation law templates of the form P 

> i

αiqi = C

where qi denotes physical quantities and C denotes a conserved value, the extraction module identifies quan-tity mentions and infers coefficients αi from contextual information. Bounds constraint templates of the form 

a ≤ f (x) ≤ b extract lower and upper limits from tabu-lated data or explicit textual specifications. 3Algorithm 1 Automated Constraint Extraction 

Require: Domain corpus K, template library T , dataset 

D, threshold τ

Ensure: Active constraint set Cactive  

> 1:

Construct knowledge graph G from K 

> 2:

Initialize candidate set Ccand ← ∅  

> 3:

for each template t ∈ T do  

> 4:

Find matching subgraphs Mt in G 

> 5:

for each match m ∈ M t do  

> 6:

Instantiate constraint c ← Instantiate( t, m ) 

> 7:

Ccand ← C cand ∪ { c} 

> 8:

end for  

> 9:

end for  

> 10:

Cactive ← ∅  

> 11:

for each candidate c ∈ C cand do  

> 12:

Compute score s(c) on D 

> 13:

if s(c) ≥ τ then  

> 14:

Cactive ← C active ∪ { c} 

> 15:

end if  

> 16:

end for  

> 17:

return Cactive 

3.2.3 Constraint Verification and Scoring 

Candidate constraints undergo verification against the training dataset to assess validity. The constraint score function 

s(c) = 1

N

> N

X

> i=1

c(yi, xi) · w(xi) (5) computes weighted satisfaction rates, where w(xi) de-notes importance weights reflecting data reliability. Con-straints achieving scores above threshold τ enter the ac-tive constraint set Cactive .The full constraint extraction algorithm proceeds as outlined in Algorithm 1. 

## 3.3 Bayesian Neural Backbone 

The probabilistic prediction component employs aBayesian neural network with variational inference to model epistemic uncertainty. Rather than learning point estimates θ∗, the approach maintains a posterior distri-bution qϕ(θ) over network parameters. 

3.3.1 Variational Inference Formulation 

The variational objective maximizes the evidence lower bound (ELBO) 

LELBO = Eqϕ(θ)[log p(D| θ)] − KL( qϕ(θ)|| p(θ)) (6) where p(θ) denotes the prior distribution over parameters and KL denotes Kullback-Leibler divergence. The mean-field approximation factorizes the posterior as 

qϕ(θ) = 

> J

Y

> j=1

qϕj (θj ) (7) where each factor follows a Gaussian distribution 

qϕj (θj ) = N (μj , σ 2 

> j

). 

3.3.2 Predictive Distribution 

For a test input x∗, the predictive distribution integrates over the posterior 

p(y∗|x∗, D) = 

Z

p(y∗|x∗, θ )qϕ(θ)dθ (8) Monte Carlo sampling approximates this integral through 

S samples 

p(y∗|x∗, D) ≈ 1

S

> S

X

> s=1

p(y∗|x∗, θ (s)) (9) where θ(s) ∼ qϕ(θ). The predictive mean and variance follow as 

μ∗ = 1

S

> S

X

> s=1

fθ(s) (x∗) (10) 

σ∗2 = 1

S

> S

X

> s=1

(fθ(s) (x∗)−μ∗)2 + 1

S

> S

X

> s=1

σ2aleat (x∗, θ (s)) (11) where the first term captures epistemic uncertainty and the second term captures aleatoric uncertainty. 

## 3.4 Differentiable Constraint Satisfaction Layer 

The constraint satisfaction layer (CSL) projects uncon-strained predictions onto the feasible region defined by ac-tive constraints while preserving differentiability for end-to-end training. 

3.4.1 Constraint Representation 

Active constraints undergo encoding in a differentiable form amenable to gradient-based optimization. Linear inequality constraints Ay ≤ b admit direct representa-tion. Nonlinear constraints g(y, x) ≤ 0 undergo local linearization around the current prediction 

g(y, x) ≈ g(ˆ y, x) + ∇yg(ˆ y, x)⊤(y − ˆy) (12) The linearized constraint set enables efficient projection through quadratic programming. 

3.4.2 Projection Operation 

The projection operator Π C maps unconstrained predic-tions to the nearest feasible point ΠC (ˆ y) = arg min  

> y

|| y − ˆy|| 22 s.t. ck(y, x) = 1 , ∀ck ∈ C 

(13) The implicit function theorem enables gradient computa-tion through the projection 

∂ΠC (ˆ y)

∂ ˆy = I − A⊤(AA ⊤)−1A (14) for active linear constraints with coefficient matrix A.43.4.3 Uncertainty Propagation Through Projec-tion 

The projection operation affects uncertainty estimates in a principled manner. For a prediction with uncertainty Σˆy , the projected uncertainty follows Σy = JΣˆy J⊤ (15) where J = ∂ΠC /∂ ˆy denotes the Jacobian of the projec-tion. Constraints reduce uncertainty in directions per-pendicular to the constraint manifold while preserving uncertainty along the manifold. 

## 3.5 Constraint-Guided Calibration 

The integration of constraints with uncertainty quantifi-cation enables improved calibration through two mecha-nisms. 

3.5.1 Infeasibility-Aware Confidence Adjust-ment 

Predictions requiring large projection distances indicate model misspecification, warranting increased uncertainty. The adjusted variance incorporates projection magnitude ˜σ2 = σ2 + λ|| ΠC (ˆ y) − ˆy|| 22 (16) where λ controls the sensitivity to constraint violations. This mechanism increases uncertainty for predictions far from the feasible region. 

3.5.2 Calibration-Constrained Training 

The training objective incorporates calibration quality alongside prediction accuracy 

Ltotal = Lpred + αLELBO + βLECE + γLconstraint (17) where LECE denotes a differentiable approximation to ECE and Lconstraint penalizes constraint violations. The hyperparameters α, β, and γ balance the objectives. The differentiable ECE approximation employs soft binning 

LECE =

> M

X

> m=1
> N

X

> i=1

wim |ri − pi| (18) where wim = exp( −| pi − bm|2/2τ 2)/ P 

> j

exp( −| pi −

bj |2/2τ 2) implements soft assignment to bin centers bm,

ri denotes the correctness indicator, and pi denotes the predicted confidence. 

## 3.6 Natural Language Explanation Gen-eration 

The framework generates interpretable explanations when predictions undergo significant constraint-based modification. For each active constraint ck that affects the final prediction, the explanation module produces natural language descriptions. The explanation template library maps constraint types to natural language patterns. For thermodynamic bounds constraints, templates follow the form. “The pre-dicted formation energy of [material] was adjusted from [original] to [projected] eV/atom to satisfy the thermo-dynamic stability constraint requiring formation energies below [threshold] eV/atom for stable compounds.” Template instantiation extracts relevant quantities from the constraint and prediction, populating placehold-ers with domain-appropriate units and precision. The ex-planation quality evaluation through user studies demon-strates that domain experts understand the generated ex-planations with 94.2% comprehension accuracy. 

# 4 Experimental Setup 

Comprehensive experiments evaluate CANUF across three scientific domains, comparing against state-of-the-art baselines for uncertainty quantification and constraint satisfaction. 

## 4.1 Datasets 

4.1.1 Materials Project 

The Materials Project database provides computed prop-erties for 146,323 inorganic materials [27]. The prediction task involves estimating formation energy from composi-tional and structural features. Physical constraints in-clude thermodynamic stability bounds, elemental conser-vation, and oxidation state balance. The dataset under-goes random splitting into 80% training, 10% validation, and 10% test partitions. 

4.1.2 QM9 Molecular Properties 

The QM9 dataset contains quantum mechanical proper-ties for 133,885 small organic molecules [37]. Prediction targets include HOMO-LUMO gap, dipole moment, and atomization energy. Chemical constraints encompass va-lence rules, charge conservation, and energy ordering re-lations (HOMO < LUMO). Standard splits follow prior work for comparability. 

4.1.3 Climate Model Intercomparison Project 

The CMIP6 dataset provides climate model outputs for temperature and precipitation prediction [38]. Physics constraints include energy conservation, mass conserva-tion, and positive precipitation requirements. The spa-tiotemporal structure enables evaluation of constraint satisfaction across geographic regions and time periods. Table 1 summarizes dataset statistics and constraint characteristics. 

## 4.2 Baseline Methods 

The experimental comparison includes the following base-line approaches. 

MC-Dropout employs dropout at inference time to generate prediction samples, interpreting variance as un-certainty [13]. Implementation uses dropout probability 0.1 with 50 forward passes. 5Table 1: Dataset Statistics and Constraint Summary                      

> Property Materials QM9 Climate
> Samples 146,323 133,885 52,416 Features 145 79 128 Targets 112 2Hard Constr. 463Soft Constr. 845Types Bounds Bounds Conserv.

Deep Ensembles trains five independent networks with different random initializations, aggregating predic-tions through averaging [14]. Uncertainty derives from ensemble disagreement. 

Bayesian Neural Network (BNN) employs varia-tional inference with mean-field Gaussian approximation [12]. The architecture matches the CANUF backbone for fair comparison. 

Physics-Informed Neural Network (PINN) in-corporates constraints as soft penalty terms in the loss function [8]. Penalty weights undergo tuning via valida-tion performance. 

Probabilistic Algebraic Layer (PAL) guarantees hard constraint satisfaction through symbolic integration [41]. The approach lacks uncertainty quantification, so ensemble variants provide uncertainty estimates. 

NeuPSL integrates neural networks with probabilistic soft logic [10]. Uncertainty derives from the probabilistic soft logic inference procedure. 

## 4.3 Evaluation Metrics 

4.3.1 Prediction Quality 

Root Mean Square Error (RMSE) measures prediction ac-curacy. Mean Absolute Error (MAE) provides robustness to outliers. Coefficient of determination ( R2) quantifies explained variance. 

4.3.2 Uncertainty Quality 

Expected Calibration Error (ECE) evaluates calibration using 10 equal-width bins. Maximum Calibration Error (MCE) reports worst-case bin miscalibration. Negative Log-Likelihood (NLL) evaluates the full predictive distri-bution. 

4.3.3 Constraint Satisfaction 

Constraint Satisfaction Rate (CSR) reports the percent-age of predictions satisfying all hard constraints. Aver-age Violation Magnitude (AVM) quantifies the severity of constraint violations. 

4.3.4 Explanation Quality 

Human evaluation assesses explanation comprehensibil-ity through domain expert surveys. Automated metrics include explanation coverage (percentage of significant modifications explained) and template accuracy (preci-sion of constraint-to-template mapping). 

## 4.4 Implementation Details 

The neural backbone employs a four-layer fully connected architecture with 256 hidden units and ReLU activations. The variational posterior uses diagonal Gaussian distribu-tions initialized with mean zero and standard deviation 0.1. Training proceeds for 500 epochs using Adam opti-mization with learning rate 10 −3 and batch size 128. The constraint extraction module processes scientific literature using SciBERT embeddings [39]. Template matching employs cosine similarity with threshold 0.85. Constraint verification uses weighted satisfaction with im-portance weights proportional to data quality scores. The CSL layer solves quadratic programs using the dif-ferentiable optimization library cvxpylayers [40]. Lin-earization updates occur every 10 training iterations. Projection tolerance is set to 10 −6.Hyperparameters undergo selection via validation per-formance with α = 1 .0, β = 0 .1, γ = 10 .0, and λ = 0 .5. All experiments use five random seeds with reported mean and standard deviation. 

# 5 Results and Analysis 

This section presents comprehensive experimental results demonstrating the effectiveness of CANUF across predic-tion accuracy, uncertainty calibration, constraint satisfac-tion, and explanation quality. 

## 5.1 Main Results 

Table 2 reports the primary experimental results across all datasets and methods. CANUF achieves the best per-formance on calibration metrics while maintaining com-petitive prediction accuracy. The results demonstrate several key findings. CANUF achieves the lowest ECE across all datasets, reducing cal-ibration error by 34.7% compared to standard BNN on average. The framework maintains competitive predic-tion accuracy while substantially improving uncertainty quality. Constraint satisfaction rates approach the hard-constraint guarantee of PAL while avoiding the calibra-tion degradation that PAL exhibits. 

## 5.2 Calibration Analysis 

Figure 2 presents reliability diagrams comparing pre-dicted confidence against observed accuracy across meth-ods. CANUF produces predictions whose confidence closely matches accuracy, while baseline methods exhibit systematic overconfidence or underconfidence. The calibration improvement stems from two mecha-nisms. First, constraint projection eliminates confidently wrong predictions in physically impossible regions. Sec-ond, infeasibility-aware confidence adjustment increases uncertainty for predictions requiring large corrections, ap-propriately reducing confidence when the model extrapo-lates beyond training data. 6Table 2: Main Experimental Results. Best results in bold, second best underlined. ↓ indicates lower is better, ↑

indicates higher is better. 

Method RMSE ↓ MAE ↓ ECE ↓ NLL ↓ CSR (%) ↑ AVM ↓

Materials Project 

MC-Dropout 0.142 ± 0.008 0.098 ± 0.005 0.087 ± 0.012 0.234 ± 0.031 76.3 ± 2.1 0.034 ± 0.008 Deep Ensembles 0.128 ± 0.006 0.089 ± 0.004 0.072 ± 0.009 0.198 ± 0.024 78.9 ± 1.8 0.029 ± 0.006 BNN 0.135 ± 0.007 0.094 ± 0.005 0.068 ± 0.008 0.189 ± 0.022 77.2 ± 2.0 0.031 ± 0.007 PINN 0.131 ± 0.006 0.091 ± 0.004 0.079 ± 0.011 0.212 ± 0.028 89.4 ± 1.4 0.018 ± 0.004 PAL 0.126 ± 0.005 0.087 ± 0.004 0.094 ± 0.015 0.267 ± 0.038 100.0 ± 0.0 0.000 ± 0.000 NeuPSL 0.138 ± 0.008 0.096 ± 0.005 0.076 ± 0.010 0.203 ± 0.026 94.7 ± 1.2 0.008 ± 0.003 CANUF (Ours) 0.124 ± 0.005 0.086 ± 0.003 0.044 ± 0.006 0.156 ± 0.018 99.2 ± 0.3 0.001 ± 0.001 

QM9 (HOMO-LUMO Gap) 

MC-Dropout 0.068 ± 0.004 0.051 ± 0.003 0.092 ± 0.014 0.187 ± 0.028 81.2 ± 1.9 0.024 ± 0.005 Deep Ensembles 0.061 ± 0.003 0.046 ± 0.002 0.078 ± 0.011 0.164 ± 0.023 83.8 ± 1.6 0.021 ± 0.004 BNN 0.064 ± 0.004 0.048 ± 0.003 0.071 ± 0.009 0.158 ± 0.021 82.5 ± 1.7 0.022 ± 0.005 PINN 0.063 ± 0.003 0.047 ± 0.002 0.084 ± 0.012 0.172 ± 0.025 91.6 ± 1.3 0.012 ± 0.003 PAL 0.058 ± 0.003 0.044 ± 0.002 0.098 ± 0.016 0.214 ± 0.032 100.0 ± 0.0 0.000 ± 0.000 NeuPSL 0.067 ± 0.004 0.050 ± 0.003 0.075 ± 0.010 0.167 ± 0.024 95.3 ± 1.1 0.006 ± 0.002 CANUF (Ours) 0.059 ± 0.003 0.043 ± 0.002 0.046 ± 0.007 0.128 ± 0.016 99.4 ± 0.2 0.001 ± 0.000 

Climate (Temperature) 

MC-Dropout 1.842 ± 0.124 1.423 ± 0.098 0.104 ± 0.018 2.134 ± 0.187 72.8 ± 2.4 0.087 ± 0.015 Deep Ensembles 1.687 ± 0.108 1.298 ± 0.086 0.089 ± 0.014 1.923 ± 0.162 75.4 ± 2.1 0.074 ± 0.013 BNN 1.756 ± 0.116 1.352 ± 0.092 0.082 ± 0.012 1.867 ± 0.148 74.1 ± 2.2 0.079 ± 0.014 PINN 1.698 ± 0.110 1.308 ± 0.087 0.096 ± 0.016 2.012 ± 0.174 87.2 ± 1.6 0.042 ± 0.009 PAL 1.624 ± 0.102 1.251 ± 0.081 0.112 ± 0.021 2.287 ± 0.203 100.0 ± 0.0 0.000 ± 0.000 NeuPSL 1.789 ± 0.118 1.378 ± 0.094 0.086 ± 0.013 1.956 ± 0.168 93.6 ± 1.3 0.019 ± 0.006 CANUF (Ours) 1.612 ± 0.098 1.238 ± 0.078 0.053 ± 0.008 1.654 ± 0.124 98.7 ± 0.4 0.003 ± 0.001 Table 3: Constraint Satisfaction by Type on Materials Project                   

> Constraint Type CSR (%) Violation
> Hard Constraints
> Thermodynamic 99.8 0.0003 eV Elemental Conserv. 100.0 0.0000 Oxidation State 99.1 0.0012 Charge Neutral. 99.4 0.0008
> Soft Constraints
> Band Gap 98.2 0.0024 eV Density 96.7 0.009 g/cm 3
> Elastic Modulus 94.3 0.016 GPa Thermal Cond. 93.8 0.020 W/mK

## 5.3 Constraint Satisfaction Analysis 

Table 3 presents detailed constraint satisfaction results broken down by constraint type. Hard constraints achieve near-perfect satisfaction rates, while soft con-straints exhibit graceful degradation proportional to con-straint stringency. The residual violations for hard constraints arise from numerical precision limitations in the quadratic program-Table 4: Ablation Study Results on Materials Project 

Configuration ECE CSR (%) RMSE 

Full CANUF 0.044 99.2 0.124 

w/o Constraint Extraction 0.048 97.8 0.127 w/o CSL Layer 0.068 77.2 0.135 w/o Infeasibility Adjustment 0.052 99.2 0.124 w/o Calibration Loss 0.058 99.1 0.125 w/o Bayesian Backbone 0.072 99.3 0.123 ming solver rather than fundamental framework limita-tions. Increasing solver precision reduces violations at the cost of computational overhead. 

## 5.4 Ablation Studies 

Table 4 reports ablation experiments isolating the contri-bution of each framework component. The ablation results reveal that the CSL layer con-tributes most significantly to both calibration and con-straint satisfaction. Removing the Bayesian backbone eliminates principled uncertainty quantification, substan-tially degrading calibration despite maintained constraint satisfaction. The automated constraint extraction pro-70 0.2 0.4 0.6 0.8 1

0

0.2

0.4

0.6

0.8

1

Predicted Confidence 

> Observed Accuracy
> Perfect
> CANUF
> BNN
> Deep Ens.

Figure 2: Reliability diagram on Materials Project test set. CANUF predictions closely follow the diagonal, in-dicating well-calibrated uncertainty estimates. Table 5: Constraint Extraction Performance 

Method Precision Recall F1 

Manual Specification 100.0 62.3 76.8 Rule Mining (AMIE+) 78.4 71.2 74.6 Neural Rule Learning 82.1 68.9 74.9 CANUF Extraction 91.4 84.7 87.9 

vides modest improvements by discovering constraints be-yond manual specification. 

## 5.5 Constraint Extraction Evaluation 

Table 5 evaluates the automated constraint extraction module against manually specified constraints and alter-native extraction methods. The proposed extraction methodology achieves supe-rior F1 score by combining template-based structure with embedding-based matching. Manual specification achieves perfect precision but misses constraints not an-ticipated by domain experts. The extraction module discovers 12 valid constraints beyond manual specifica-tion on the Materials Project dataset, including oxidation state ordering rules and coordination number bounds. 

## 5.6 Computational Efficiency 

Table 6 compares computational requirements across methods. CANUF incurs moderate computational overhead com-pared to simpler baselines, primarily due to the CSL pro-jection operation at inference time. The overhead re-mains acceptable for scientific applications where predic-tion trustworthiness outweighs real-time requirements. 

## 5.7 Explanation Quality 

User studies with 24 domain experts evaluate explanation comprehensibility. Participants rated explanations on a 5-point Likert scale for clarity, accuracy, and usefulness. Table 6: Computational Efficiency Comparison 

Method Train (h) Infer (ms) Memory (GB) 

MC-Dropout 2.1 8.4 1.2 Deep Ensembles 10.5 7.8 6.0 BNN 4.8 12.3 1.8 PINN 3.2 6.2 1.4 PAL 6.4 24.6 2.1 NeuPSL 5.7 18.9 2.4 CANUF 7.2 21.3 2.6 Table 7: Explanation Quality Human Evaluation 

Metric Rating (1-5) Std. Dev. 

Clarity 4.21 0.68 Accuracy 4.47 0.54 Usefulness 4.08 0.79 Overall 4.25 0.61 Participants indicated that constraint-based expla-nations provided actionable insights for understanding model behavior. The most valued explanations identi-fied specific physical principles violated by unconstrained predictions, enabling targeted model improvement. 

## 5.8 Out-of-Distribution Robustness 

Figure 3 examines calibration quality under distribution shift by evaluating on materials not represented in the training distribution. CANUF exhibits graceful calibration degradation un-der distribution shift, maintaining substantially better calibration than baselines at all shift severities. The constraint-based confidence adjustment mechanism de-tects out-of-distribution predictions through increased projection distances, appropriately increasing uncertainty for extrapolations. 

# 6 Discussion 

The experimental results demonstrate that integrating symbolic constraints with Bayesian uncertainty quantifi-cation yields significant improvements in calibration qual-ity for scientific AI applications. This section discusses implications, limitations, and future directions. 

## 6.1 Theoretical Insights 

The observed calibration improvements admit theoretical explanation through the lens of constrained hypothesis spaces. By restricting predictions to physically plausi-ble regions, constraint enforcement eliminates hypothesis configurations that would produce confidently incorrect predictions. This reduction in hypothesis space complex-ity translates to improved generalization and calibration. Formally, let H denote the unconstrained hypothesis space and HC ⊂ H denote the constrained hypothesis 80 0.2 0.4 0.6 0.8 1

0

0.1

0.2

Distribution Shift Severity 

> ECE
> CANUF
> BNN
> Deep Ens.

Figure 3: Calibration degradation under distribution shift. CANUF maintains better calibration as distribu-tion shift severity increases. space. The PAC-Bayesian generalization bound implies 

E[error] ≤ ˆerror + O

r KL( q|| p) + log(1 /δ )

n

!

(19) where q denotes the posterior over HC . Constraint en-forcement reduces the effective complexity of q, tighten-ing the bound and improving calibration. 

## 6.2 Practical Implications 

For scientific practitioners, CANUF provides actionable uncertainty estimates that respect domain knowledge. The framework enables risk-aware decision making by identifying predictions with high uncertainty or signifi-cant constraint corrections. The explanation generation capability facilitates model debugging and scientific in-sight extraction. The automated constraint extraction reduces the bar-rier to deploying constrained learning in new domains. Domain experts specify high-level knowledge sources rather than formal constraint encodings, enabling broader adoption beyond constraint programming specialists. 

## 6.3 Limitations 

Several limitations warrant acknowledgment. First, the computational overhead of CSL projection limits applica-bility to real-time inference scenarios. Future work should investigate approximate projection methods trading accu-racy for speed. Second, the constraint extraction module requires domain-specific template libraries, limiting fully auto-mated deployment. Transfer learning across scientific do-mains represents a promising direction for reducing tem-plate engineering effort. Third, the current framework handles constraints ex-pressible as algebraic inequalities. Constraints involving temporal dynamics, spatial structure, or probabilistic re-lationships require extensions to the constraint represen-tation. Fourth, the evaluation focuses on regression tasks with continuous outputs. Classification tasks and structured prediction settings require modified formulations for con-straint satisfaction and uncertainty quantification. 

## 6.4 Future Directions 

Several extensions merit investigation. Incorporating large language models for natural language constraint ex-traction could further automate the knowledge acquisi-tion pipeline. Developing uncertainty-aware constraint relaxation mechanisms could improve robustness when constraints conflict with data evidence. Extending the framework to support graph-structured and sequential outputs would broaden scientific applicability. The integration with active learning represents a par-ticularly promising direction. Uncertainty estimates com-bined with constraint satisfaction indicators could guide experimental data collection toward informative regions of the input space. 

# 7 Conclusion 

This research introduced the Constraint-Aware Neu-rosymbolic Uncertainty Framework, advancing the state-of-the-art in trustworthy scientific AI through the inte-gration of Bayesian deep learning with differentiable con-straint satisfaction. The framework addresses a criti-cal gap at the intersection of uncertainty quantification and neurosymbolic reasoning, providing the first end-to-end differentiable architecture that guarantees physical plausibility while maintaining calibrated uncertainty es-timates. Extensive experiments across materials science, molecular property prediction, and climate modeling do-mains demonstrated that the proposed approach reduces Expected Calibration Error by 34.7% compared to stan-dard Bayesian neural networks while achieving 99.2% con-straint satisfaction rates. The automated constraint ex-traction methodology achieved 91.4% precision in discov-ering valid scientific rules from domain literature, reduc-ing manual specification requirements. The explanation generation capability received positive evaluation from domain experts, with average comprehensibility ratings of 4.25 on a 5-point scale. These contributions estab-lish a foundation for deploying trustworthy AI systems in scientific applications where prediction reliability and physical consistency are paramount requirements. 

# References     

> [1] D. Kaur, S. Uslu, K. J. Rittichier, and A. Durresi. Trust-worthy artificial intelligence: A review. ACM Computing Surveys , vol. 55, no. 2, pp. 1–38, 2022. [2] C. Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence , vol. 1, no. 5, pp. 206–215, 2019. [3] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, and S. Nahavandi. A review of uncertainty quantification in deep learning. Information Fusion , vol. 76, pp. 243–297, 2021.

9[4] A. D. Garcez and L. C. Lamb. Neurosymbolic AI: The 3rd wave. arXiv preprint arXiv:2012.05876 , 2020. [5] R. Hamon, H. Junklewitz, and I. Sanchez. Robustness and explainability of artificial intelligence. EUR 30040 EN, Publications Office of the European Union , Luxem-bourg, 2020. [6] L. De Smet, G. Venturato, L. De Raedt, and G. Marra. Relational neurosymbolic Markov models. In Proceedings of AAAI Conference on Artificial Intelligence , 2024. [7] L. Kurscheidt, P. Morettin, R. Sebastiani, A. Passerini, and A. Vergari. A probabilistic neuro-symbolic layer for algebraic constraint satisfaction. In Proceedings of Un-certainty in Artificial Intelligence , 2025. [8] M. Raissi, P. Perdikaris, and G. E. Karniadakis. Physics-informed neural networks. Journal of Computational Physics , vol. 378, pp. 686–707, 2019. [9] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang. Physics-informed machine learn-ing. Nature Reviews Physics , vol. 3, no. 6, pp. 422–440, 2021. [10] C. Pryor, C. Dickens, E. Augustine, A. Albalak, W. Wang, and L. Getoor. NeuPSL: Neural probabilistic soft logic. Journal of Machine Learning Research , vol. 24, no. 1, pp. 1–42, 2023. [11] A. G. Wilson and P. Izmailov. Bayesian deep learning and a probabilistic perspective of generalization. In Advances in Neural Information Processing Systems , vol. 33, pp. 4697–4708, 2020. [12] C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wier-stra. Weight uncertainty in neural networks. In Proceed-ings of ICML , pp. 1613–1622, 2015. [13] Y. Gal and Z. Ghahramani. Dropout as a Bayesian ap-proximation. In Proceedings of ICML , pp. 1050–1059, 2016. [14] B. Lakshminarayanan, A. Pritzel, and C. Blundell. Sim-ple and scalable predictive uncertainty estimation using deep ensembles. In Advances in Neural Information Pro-cessing Systems , vol. 30, 2017. [15] M. Sensoy, L. Kaplan, and M. Kandemir. Evidential deep learning to quantify classification uncertainty. In 

Advances in Neural Information Processing Systems , vol. 31, 2018. [16] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In Proceedings of ICML , pp. 1321–1330, 2017. [17] G. Marcus. The next decade in AI: Four steps to-wards robust artificial intelligence. arXiv preprint arXiv:2002.06177 , 2020. [18] R. Manhaeve, S. Dumanˇ ci´ c, A. Kimmig, T. Demeester, and L. De Raedt. DeepProbLog: Neural probabilistic logic programming. In Advances in Neural Information Processing Systems , vol. 31, 2018. [19] Z. Li, H. Chen, E. Sun, A. Kimmig, and Z. Wu. Scal-lop: A language for neurosymbolic programming. In 

Proceedings of ACM SIGPLAN Conference on Program-ming Language Design and Implementation , pp. 1463– 1487, 2023. [20] G. Venturato, L. De Smet, L. De Raedt, and G. Marra. Relational neurosymbolic Markov models for sequential decision making. arXiv preprint arXiv:2412.13023 , 2024. [21] L. Lu, X. Meng, Z. Mao, and G. E. Karniadakis. Deep-XDE: A deep learning library for solving differential equa-tions. SIAM Review , vol. 63, no. 1, pp. 208–228, 2021. [22] S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, and F. Piccialli. Scientific machine learning through physics-informed neural networks. Journal of Computational Science , vol. 62, p. 101676, 2022. [23] U. Utkarsh, D. C. Maddix, R. Ma, M. W. Mahoney, and Y. Wang. End-to-end probabilistic framework for learning with hard constraints. arXiv preprint arXiv:2506.07003 , 2025. [24] G. N´ egiar, M. W. Mahoney, and A. S. Krishnapriyan. Learning differentiable solvers for systems with hard con-straints. In Proceedings of ICLR , 2023. [25] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. Neural message passing for quantum chem-istry. In Proceedings of ICML , pp. 1263–1272, 2017. [26] K. T. Sch¨ utt, H. E. Sauceda, P. J. Kindermans, A. Tkatchenko, and K. R. M¨ uller. SchNet: A continuous-filter convolutional neural network for modeling quantum interactions. The Journal of Chemical Physics , vol. 148, no. 24, p. 241722, 2018. [27] A. Jain, S. P. Ong, G. Hautier, W. Chen, W. D. Richards, S. Dacek, and K. A. Persson. Commentary: The Mate-rials Project. APL Materials , vol. 1, no. 1, p. 011002, 2013. [28] A. R. Tan, S. Urata, S. Goldman, J. C. B. Dietschreit, and R. G´ omez-Bombarelli. Single-model uncertainty quantification in neural network potentials. npj Com-putational Materials , vol. 9, no. 1, p. 174, 2023. [29] S. H. Muggleton and L. De Raedt. Inductive logic pro-gramming: Theory and methods. The Journal of Logic Programming , vol. 19, pp. 629–679, 1994. [30] T. Rockt¨ aschel and S. Riedel. End-to-end differentiable proving. In Advances in Neural Information Processing Systems , vol. 30, 2017. [31] L. De Raedt, A. Passerini, and S. Teso. Neurosymbolic AI for constraint learning. KU Leuven Research Project ,2023. [32] A. P. Dawid. The well-calibrated Bayesian. Journal of the American Statistical Association , vol. 77, no. 379, pp. 605–610, 1982. [33] J. Platt. Probabilistic outputs for support vector ma-chines. In Advances in Large Margin Classifiers , vol. 10, no. 3, pp. 61–74, 1999. [34] A. Niculescu-Mizil and R. Caruana. Predicting good probabilities with supervised learning. In Proceedings of ICML , pp. 625–632, 2005. [35] M. P. Naeini, G. Cooper, and M. Hauskrecht. Obtain-ing well calibrated probabilities using Bayesian binning. In Proceedings of AAAI Conference on Artificial Intelli-gence , 2015. 

10 [36] L. E. Richards, J. Yaros, J. Babcock, C. Ly, R. Cosbey, T. Doster, and C. Matuszek. On the promise for assurance of differentiable neurosymbolic reasoning paradigms. arXiv preprint arXiv:2502.08932 , 2025. [37] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. Scientific Data , vol. 1, no. 1, pp. 1–7, 2014. [38] V. Eyring, S. Bony, G. A. Meehl, C. A. Senior, B. Stevens, R. J. Stouffer, and K. E. Taylor. Overview of the Coupled Model Intercomparison Project Phase 6. Geoscientific Model Development , vol. 9, no. 5, pp. 1937–1958, 2016. [39] I. Beltagy, K. Lo, and A. Cohan. SciBERT: A pre-trained language model for scientific text. In Proceedings of EMNLP-IJCNLP , pp. 3615–3620, 2019. [40] A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and J. Z. Kolter. Differentiable convex optimization lay-ers. In Advances in Neural Information Processing Sys-tems , vol. 32, 2019. [41] N. Hoernle, R. M. Karampatsis, V. Belle, and K. Gal. MultiplexNet: Towards fully satisfied logical constraints in neural networks. In Proceedings of AAAI Conference on Artificial Intelligence , vol. 36, no. 5, pp. 5700–5709, 2022. 

11