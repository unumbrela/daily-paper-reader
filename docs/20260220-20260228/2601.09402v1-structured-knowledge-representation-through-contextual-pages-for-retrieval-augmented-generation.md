---
title: Structured Knowledge Representation through Contextual Pages for Retrieval-Augmented Generation
title_zh: 通过上下文页面实现检索增强生成的结构化知识表示
authors: "Xinze Li, Zhenghao Liu, Haidong Xin, Yukun Yan, Shuo Wang, Zheni Zeng, Sen Mei, Ge Yu, Maosong Sun"
date: 2026-01-14
pdf: "https://arxiv.org/pdf/2601.09402v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 检索增强生成的结构化知识表示
tldr: 针对现有迭代式检索增强生成（RAG）方法在知识积累过程中缺乏组织结构的问题，本文提出了PAGER框架。该框架通过大模型生成结构化的认知大纲，将复杂问题拆解为多个知识槽位，并迭代地检索和精炼相关文档来填充这些槽位，最终构建出连贯的“上下文页面”。实验证明，PAGER在多个基准测试中表现优异，能提供更高质量、高密度的知识表示，并有效缓解知识冲突，显著提升了模型对外部知识的利用效率。
motivation: 现有的迭代式RAG方法在知识积累时缺乏连贯的组织结构，导致生成的知识表示不够全面且缺乏凝聚力。
method: 提出PAGER框架，利用大模型构建结构化认知大纲并迭代检索填充各知识槽位，生成连贯的上下文页面作为输入。
result: 在多个知识密集型基准测试中，PAGER一致优于现有RAG基准，并展现出更高质量的知识表示和更强的冲突缓解能力。
conclusion: 通过结构化页面组织外部知识，可以显著增强大语言模型对复杂信息的理解与利用，提升RAG系统的整体性能。
---

## 摘要
检索增强生成（RAG）通过引入外部知识来增强大语言模型（LLMs）。最近，一些研究将迭代知识积累过程引入 RAG 模型，以逐步积累和完善与查询相关的知识，从而构建更全面的知识表示。然而，这些迭代过程通常缺乏连贯的组织结构，限制了更全面且内聚的知识表示的构建。为了解决这一问题，我们提出了 PAGER，一个用于 RAG 的页面驱动自主知识表示框架。PAGER 首先提示 LLM 为给定问题构建一个结构化的认知大纲，该大纲由代表不同知识维度的多个插槽（slots）组成。随后，PAGER 迭代地检索并完善相关文档以填充每个插槽，最终构建一个连贯的页面，作为引导答案生成的上下文输入。在多个知识密集型基准测试和骨干模型上的实验表明，PAGER 的表现始终优于所有 RAG 基线模型。进一步的分析表明，PAGER 构建了更高质量且信息密集的知识表示，能更好地缓解知识冲突，并使 LLM 能够更有效地利用外部知识。所有代码均可在 https://github.com/OpenBMB/PAGER 获取。

## Abstract
Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by incorporating external knowledge. Recently, some works have incorporated iterative knowledge accumulation processes into RAG models to progressively accumulate and refine query-related knowledge, thereby constructing more comprehensive knowledge representations. However, these iterative processes often lack a coherent organizational structure, which limits the construction of more comprehensive and cohesive knowledge representations. To address this, we propose PAGER, a page-driven autonomous knowledge representation framework for RAG. PAGER first prompts an LLM to construct a structured cognitive outline for a given question, which consists of multiple slots representing a distinct knowledge aspect. Then, PAGER iteratively retrieves and refines relevant documents to populate each slot, ultimately constructing a coherent page that serves as contextual input for guiding answer generation. Experiments on multiple knowledge-intensive benchmarks and backbone models show that PAGER consistently outperforms all RAG baselines. Further analyses demonstrate that PAGER constructs higher-quality and information-dense knowledge representations, better mitigates knowledge conflicts, and enables LLMs to leverage external knowledge more effectively. All code is available at https://github.com/OpenBMB/PAGER.