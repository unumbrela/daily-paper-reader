---
title: "Predict the Retrieval! Test time adaptation for Retrieval Augmented Generation"
title_zh: 预测检索！检索增强生成的测试时自适应
authors: "Xin Sun, Zhongqi Chen, Qiang Liu, Shu Wu, Bowen Song, Weiqiang Wang, Zilei Wang, Liang Wang"
date: 2026-01-16
pdf: "https://arxiv.org/pdf/2601.11443v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 检索增强生成的测试时自适应
tldr: 针对检索增强生成（RAG）在特定领域因分布偏移导致性能下降的问题，本文提出了一种名为TTARAG的测试时自适应方法。该方法在推理阶段动态更新语言模型参数，通过引入预测检索内容的辅助任务，使模型能够自动调整以适应目标领域。在六个专业领域的实验证明，TTARAG显著优于基准RAG系统，为提升大模型在专业领域的知识整合能力提供了新思路。
motivation: 解决RAG系统在面对特定领域数据时，由于分布偏移导致的泛化能力不足问题。
method: 提出TTARAG方法，在推理阶段通过让模型学习预测检索到的内容来动态更新语言模型参数。
result: 在六个不同专业领域的广泛实验中，TTARAG均取得了较基准系统显著的性能提升。
conclusion: TTARAG证明了通过测试时自适应技术可以有效增强RAG系统在专业领域的表现。
---

## 摘要
检索增强生成（RAG）已成为一种通过整合外部知识来增强大语言模型问答能力的强大方法。然而，在将 RAG 系统应用于特定领域时，分布偏移带来了挑战，导致泛化性能不佳。在这项工作中，我们提出了 TTARAG，这是一种测试时自适应方法，在推理过程中动态更新语言模型的参数，以提高 RAG 系统在特定领域的性能。我们的方法引入了一种简单而有效的方法，即模型学习预测检索到的内容，从而实现对目标领域的自动参数调整。通过在六个特定领域进行的广泛实验，我们证明了 TTARAG 相比基准 RAG 系统实现了显著的性能提升。代码可在 https://github.com/sunxin000/TTARAG 获取。

## Abstract
Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for enhancing large language models' question-answering capabilities through the integration of external knowledge. However, when adapting RAG systems to specialized domains, challenges arise from distribution shifts, resulting in suboptimal generalization performance. In this work, we propose TTARAG, a test-time adaptation method that dynamically updates the language model's parameters during inference to improve RAG system performance in specialized domains. Our method introduces a simple yet effective approach where the model learns to predict retrieved content, enabling automatic parameter adjustment to the target domain. Through extensive experiments across six specialized domains, we demonstrate that TTARAG achieves substantial performance improvements over baseline RAG systems. Code available at https://github.com/sunxin000/TTARAG.