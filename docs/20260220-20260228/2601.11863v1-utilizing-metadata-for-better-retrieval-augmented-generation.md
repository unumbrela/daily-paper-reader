---
title: Utilizing Metadata for Better Retrieval-Augmented Generation
title_zh: 利用元数据提升检索增强生成
authors: "Raquib Bin Yousuf, Shengzhe Xu, Mandar Sharma, Andrew Neeser, Chris Latimer, Naren Ramakrishnan"
date: 2026-01-17
pdf: "https://arxiv.org/pdf/2601.11863v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 检索增强生成系统与元数据感知检索策略
tldr: 针对结构化文档中语义检索难以区分重叠内容的问题，本文系统研究了元数据增强的检索策略。通过对比元数据作为文本（前缀/后缀）、统一嵌入、后期融合及查询重构等方法，发现将元数据融入嵌入能显著提升检索准确性。研究发布了RAGMATE-10K数据集，证明了元数据在增强文档内聚性和减少歧义方面的关键作用。
motivation: 在处理结构化或重复性语料时，仅靠文本块的语义相似度难以实现精准检索，需要利用元数据进行消歧。
method: 系统对比了元数据前缀/后缀、统一嵌入、双编码器后期融合及元数据感知查询重构等多种检索策略。
result: 实验表明，元数据前缀和统一嵌入方法在多项指标上均优于纯文本基准，且统一嵌入在保持高性能的同时更易于维护。
conclusion: 元数据通过增强文档内部凝聚力并扩大相关与无关块之间的区分度，是提升RAG系统检索性能的有效手段。
---

## 摘要
检索增强生成（RAG）系统依赖于检索语义相关的文档块，以支持大语言模型生成准确且有据可依的输出。在监管文件等结构化且重复性高的语料库中，仅凭文本块相似度往往难以区分语言重叠的文档。从业者通常采用启发式方法将元数据展平并并入输入文本，但这种做法的影响和权衡仍缺乏深入理解。我们对元数据感知检索策略进行了系统研究，将纯文本基线与直接嵌入元数据的方法进行了对比。我们的评估涵盖了元数据即文本（前缀和后缀）、在单一索引中融合元数据与内容的双编码器统一嵌入、双编码器后期融合检索以及元数据感知查询重构。在多种检索指标和问题类型下，我们发现前缀法和统一嵌入法始终优于纯文本基线，且统一嵌入法在更易于维护的同时，有时甚至优于前缀法。除了实证对比，我们还分析了嵌入空间，结果表明元数据集成通过增强文档内凝聚力、减少文档间混淆以及扩大相关与不相关文本块之间的区分度，提升了检索效果。字段级消融实验表明，结构化线索提供了强大的消歧信号。我们的代码、评估框架以及 RAGMATE-10K 数据集已公开。

## Abstract
Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.