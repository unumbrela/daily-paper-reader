---
title: Agentic Reasoning for Large Language Models
title_zh: 大语言模型的智能体推理
authors: "Tianxin Wei, Ting-Wei Li, Zhining Liu, Xuying Ning, Ze Yang, Jiaru Zou, Zhichen Zeng, Ruizhong Qiu, Xiao Lin, Dongqi Fu, Zihao Li, Mengting Ai, Duo Zhou, Wenxuan Bao, Yunzhe Li, Gaotang Li, Cheng Qian, Yu Wang, Xiangru Tang, Yin Xiao, Liri Fang, Hui Liu, Xianfeng Tang, Yuji Zhang, Chi Wang, Jiaxuan You, Heng Ji, Hanghang Tong, Jingrui He"
date: 2026-01-18
pdf: "https://arxiv.org/pdf/2601.12538v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 关于大语言模型智能体推理与规划的综述
tldr: 本文系统综述了大语言模型（LLM）的智能体推理（Agentic Reasoning），旨在解决LLM在开放动态环境下的局限。文章将智能体推理划分为基础推理、自我演化推理和集体多智能体推理三个互补维度，并区分了上下文推理与训练后优化两种实现路径。通过总结在科学、机器人等领域的应用，本文为构建具备自主规划、行动和学习能力的智能体提供了统一的路线图与未来挑战分析。
motivation: 传统LLM在封闭环境表现良好，但在需要持续交互、自主规划和动态适应的开放式复杂任务中仍存在不足。
method: 通过基础能力、自我演化和集体协作三个层面组织推理框架，并对比了结构化编排与强化学习等优化手段。
result: 全面梳理了智能体推理在科学、机器人、医疗及数学等现实场景中的代表性框架、基准测试及应用成果。
conclusion: 智能体推理实现了从思维到行动的跨越，未来研究应聚焦于长程交互、世界建模、可扩展训练及安全治理。
---

## 摘要
推理是推断、问题解决和决策背后的基本认知过程。虽然大语言模型（LLMs）在封闭世界设置中展现出强大的推理能力，但它们在开放式和动态环境中仍面临挑战。智能体推理（Agentic reasoning）标志着一种范式转变，它将 LLMs 重新定义为通过持续交互进行规划、行动和学习的自主智能体。在本综述中，我们从三个互补的维度组织智能体推理。首先，我们通过三个层面来刻画环境动态：基础智能体推理，旨在稳定环境中建立包括规划、工具使用和搜索在内的核心单智能体能力；自我进化智能体推理，研究智能体如何通过反馈、记忆和适应来完善这些能力；以及集体多智能体推理，将智能扩展到涉及协调、知识共享和共同目标的协作场景。在这些层面中，我们区分了上下文推理（in-context reasoning）与训练后推理（post-training reasoning），前者通过结构化编排扩展测试时交互，后者则通过强化学习和监督微调优化行为。我们进一步回顾了涵盖科学、机器人、医疗保健、自主研究和数学等现实应用及基准测试的代表性智能体推理框架。本综述将智能体推理方法整合为一个连接思维与行动的统一路线图，并概述了公开挑战和未来方向，包括个性化、长时程交互、世界建模、可扩展的多智能体训练以及现实部署的治理。

## Abstract
Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.