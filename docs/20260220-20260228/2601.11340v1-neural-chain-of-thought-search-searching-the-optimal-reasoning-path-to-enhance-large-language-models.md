---
title: "Neural Chain-of-Thought Search: Searching the Optimal Reasoning Path to Enhance Large Language Models"
title_zh: 神经思维链搜索：搜索最优推理路径以增强大语言模型
authors: "Guoming Ling, Zhongzhan Huang, Yupei Lin, Junxin Li, Shanshan Zhong, Hefeng Wu, Liang Lin"
date: 2026-01-16
pdf: "https://arxiv.org/pdf/2601.11340v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 搜索最优推理路径以增强大模型的思维链
tldr: "针对大语言模型在思维链（CoT）推理中缺乏前瞻性、易陷入冗余路径的问题，本文提出神经思维链搜索（NCoTS）框架。该框架将推理过程重构为寻找最优思维策略的动态搜索，通过双因子启发式评估推理算子，在保证准确性的同时优化计算成本。实验表明，NCoTS在多个基准测试中实现了帕累托改进，准确率提升超过3.5%，生成长度缩短超过22%，为高效推理提供了新思路。"
motivation: 现有的思维链推理采用顺序生成模式，缺乏对全局路径的预见性，容易产生冗余且低效的推理步骤。
method: 提出NCoTS框架，通过双因子启发式算法动态搜索兼具高准确度和低计算成本的最优推理路径。
result: "在多个推理基准测试中，该方法在提升准确率超过3.5%的同时，将生成长度缩短了22%以上。"
conclusion: 将推理重构为动态搜索过程能有效引导模型发现更简洁、更准确的思维路径，实现性能与效率的帕累托改进。
---

## 摘要
思维链（Chain-of-Thought）推理显著增强了大语言模型的问题解决能力。遗憾的是，当前模型在缺乏前瞻性的情况下顺序生成推理步骤，往往会陷入包含冗余步骤的次优推理路径中。与此相对，我们引入了神经思维链搜索（NCoTS），这是一个将推理重新表述为寻找最优思维策略的动态搜索框架。通过对解空间进行定量表征，我们揭示了稀疏的优选推理路径的存在，这些路径比标准输出更准确且更简洁。我们的方法通过使用双因子启发式评估候选推理算子，主动导航至这些路径，该启发式同时优化正确性和计算成本。因此，NCoTS 在多种推理基准测试中实现了帕累托改进，在将准确率提高 3.5% 以上的同时，将生成长度缩短了 22% 以上。我们的代码和数据可在 https://github.com/MilkThink-Lab/Neural-CoT-Search 获取。

## Abstract
Chain-of-Thought reasoning has significantly enhanced the problem-solving capabilities of Large Language Models. Unfortunately, current models generate reasoning steps sequentially without foresight, often becoming trapped in suboptimal reasoning paths with redundant steps. In contrast, we introduce Neural Chain-of-Thought Search (NCoTS), a framework that reformulates reasoning as a dynamic search for the optimal thinking strategy. By quantitatively characterizing the solution space, we reveal the existence of sparse superior reasoning paths that are simultaneously more accurate and concise than standard outputs. Our method actively navigates towards these paths by evaluating candidate reasoning operators using a dual-factor heuristic that optimizes for both correctness and computational cost. Consequently, NCoTS achieves a Pareto improvement across diverse reasoning benchmarks, boosting accuracy by over 3.5% while reducing generation length by over 22%. Our code and data are available at https://github.com/MilkThink-Lab/Neural-CoT-Search.