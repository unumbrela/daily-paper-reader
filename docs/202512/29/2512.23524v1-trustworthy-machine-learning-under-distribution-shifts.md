
# Trustworthy Machine Learning under Distribution Shifts

**Authors**: Zhuo Huang
**Date**: 2025-12-29

**Tags**: <span class="tag-label tag-green">keywords: symbolic regression</span> <span class="tag-label tag-green">keywords: transformer</span>

---

## Abstract
...


---

## 论文详细总结（自动生成）

以下是基于提供的博士论文摘要、目录及作者贡献声明内容的结构化总结：

### 1. 论文的核心问题与整体含义

*   **核心问题**：尽管人工智能（特别是大语言模型和深度学习）在能力上取得了巨大进步，但**分布偏移**仍是限制 ML 系统可靠性和实际应用的关键瓶颈。当模型在训练数据分布之外的复杂、不可预测的环境中部署时，其性能会严重下降，从而引发信任危机。
*   **研究动机与背景**：随着 AI 深入融入社会基础设施（如医疗 AI 的跨区域应用），仅仅追求准确率已不足够，必须关注 AI 的**责任与可靠性**。论文旨在解决在分布偏移下的**可信机器学习**问题，不仅提升模型的鲁棒性，还关注其多功能性和安全性。

### 2. 论文提出的方法论

论文将分布偏移分为三类，并针对每一类提出了相应的解决方案，涵盖了鲁棒性、可解释性和适应性三个维度：

*   **扰动偏移**：
    *   **核心思想**：通过最小化“最坏情况锐度”来提高对光子限制型 Corruption 的鲁棒性。
    *   **关键技术**：提出了基于锐度的分布鲁棒优化方法，涉及分布感知和分布不可知的鲁棒泛化策略。
*   **域偏移**：
    *   **核心思想 (Ch 2)**：利用 OOD 数据。通过内容与风格的解耦，利用变分推断进行数据增强，从而利用良性或恶性的 OOD 数据。
    *   **核心思想 (Ch 4)**：探索“变种参数”以改善不变学习。提出了 **EVIL 框架**，通过分析稀疏训练与 OOD 数据的关系，利用非变体参数来寻找更鲁棒的“中奖彩票”。
*   **模态偏移**：
    *   **核心思想 (Ch 5 - MVT)**：利用多模态大语言模型（MLLM）增强视觉鲁棒性。提出了“机器视觉治疗”概念，通过**去噪上下文学习**和过渡矩阵估计，利用 MLLM 的知识指导视觉模型微调。
    *   **核心思想 (Ch 6)**：处理无实例级模态对应的跨模态泛化（Out-of-Modal, OOM）。提出了 **Connect&Explore (COX)** 框架，支持半监督和无监督的 OOM 泛化，连接不同模态的特征空间并进行探索。

### 3. 实验设计

根据目录和作者发表列表，论文涵盖了广泛的实验场景和基准测试：

*   **数据集与场景**：
    *   **开放集识别**：涉及 Open-Set SSL（半监督学习）和 Open-Set DA（域适应）场景（Ch 2）。
    *   **鲁棒性测试**：针对 Photon-Limited Corruptions（光子限制型 corruption）、常见的视觉 Corruption 以及 Spurious Correlation（虚假相关性）进行测试（Ch 3, Ch 5）。
    *   **不变学习**：在标准的不变学习基准上进行 OOD 泛化测试（Ch 4）。
    *   **细粒度识别**：测试模型对细粒度属性的识别能力（Ch 5）。
    *   **跨模态泛化**：在没有实例级别对应关系的情况下进行跨模态数据测试（Ch 6）。
*   **基准模型与对比**：
    *   对比了多种不变学习方法（Ch 4）和稀疏不变学习方法（Ch 4）。
    *   使用了不同的视觉架构，如 **ResNet** 系列（Ch 4, 5, 6），以及大规模架构（Ch 4）。
    *   对比了不同的多模态大模型（如 **Otter**）在视觉鲁棒性上的表现（Ch 5）。
    *   包含了与 **SAM**（Sharpness-Aware Minimization）优化器的结合对比（Ch 4）。

### 4. 资源与算力

*   **说明**：提供的文本（摘要、目录、致谢等）中**未明确提及**具体的 GPU 型号、GPU 数量、训练时长或具体的云服务资源消耗情况。
*   **推断**：鉴于论文涉及 ResNet、大尺度架构及多模态大语言模型（MLLM）的训练与微调，预计计算资源需求较高，但具体数值需查阅正文实验部分。

### 5. 实验数量与充分性

*   **实验组数与类型**：从目录结构看，实验设计非常详尽且充分。
    *   **消融实验**：各章节均包含详细的消融研究（如 Ch 5.4.8 Ablation Study），用于验证各组件的有效性。
    *   **定量与定性分析**：包含了定量的对比实验以及定性的性能分析。
    *   **扩展性测试**：在额外的架构（Additional ResNet Architectures）、大规模数据集、额外的 Corruption 类型上进行了验证，证明方法的泛化性。
*   **客观性与公平性**：实验设置涵盖了分布感知和分布不可知的情况，并在多种主流 Baseline 上进行了对比，整体设计看起来客观严谨，旨在全面评估方法的鲁棒性和适应性。

### 6. 论文的主要结论与发现

*   **主要结论**：通过针对扰动偏移、域偏移和模态偏移提出专门的方法（如 SharpDRO, EVIL, MVT, COX），可以显著提升机器学习模型在分布外泛化能力、鲁棒性和可靠性。
*   **具体发现**：
    *   利用 OOD 数据的内容和风格解耦可以辅助训练（Ch 2）。
    *   最小化最坏情况锐度能有效对抗特定类型的 Corruption（Ch 3）。
    *   在不变学习中，非关键的“变种参数”可能包含提升鲁棒性的关键信息（Ch 4）。
    *   多模态大语言模型可以通过去噪上下文学习作为“治疗师”来增强纯视觉模型的鲁棒性（Ch 5）。
    *   即使没有实例级对应，也可以通过 COX 框架实现跨模态的泛化（Ch 6）。

### 7. 优点

*   **结构化与系统性**：论文框架清晰，将分布偏移明确划分为扰动、域和模态三类，并将可信度映射到鲁棒性、可解释性和适应性，逻辑严密。
*   **方法创新**：引入了新颖的视角，如利用 MLLM 进行“视觉治疗”、探索“失败彩票（Losing Tickets）”中的变种参数等，具有很高的创新性。
*   **覆盖面广**：从传统的计算机视觉（ResNet）到前沿的多模态大模型，从数据增强到优化算法，覆盖了 ML 的多个关键领域。

### 8. 不足与局限

*   **文本局限性**：由于提供的内容仅为论文的前言部分，无法从正文中提取具体的理论局限性、失败案例分析或计算成本的详细讨论。
*   **潜在应用限制**：
    *   方法涉及复杂的解（如变分推断、大模型微调），可能在计算资源受限的边缘设备上部署存在挑战。
    *   针对模态偏移的解决（如 OOM）可能依赖于特定的大语言模型能力，其效果可能受限于基础模型本身的性能。
*   **偏差风险**：尽管设计了多种 Corruption，但现实世界的分布偏移可能更为极端和不可预测，实验中的合成 Corruption 可能无法完全覆盖真实场景。