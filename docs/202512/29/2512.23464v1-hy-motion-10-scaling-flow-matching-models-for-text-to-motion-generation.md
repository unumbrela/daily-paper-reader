
# HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation

**Authors**: Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao
**Date**: 2025-12-29

**Tags**: <span class="tag-label tag-green">keywords: symbolic regression</span> <span class="tag-label tag-green">keywords: transformer</span>

---

## Abstract
...


---

## 论文详细总结（自动生成）

# HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation 论文总结

## 1. 论文的核心问题与整体含义

*   **研究背景**：传统的 3D 人体动画制作耗时且昂贵，现有的文本生成动作模型虽然有所进展，但仍面临显著挑战。
*   **核心问题**：
    *   **质量限制**：现有模型（如 MoMask, DART）规模较小，生成能力受限，难以处理复杂指令，且常出现滑步、物理不自然等伪影。
    *   **语义与质量权衡**：利用大语言模型（LLM）的方法（如 LoM, GoToZero）通过离散化 Motion Token 增强了语义多样性，但量化过程导致动作质量下降（缺乏平滑性）。
    *   **扩展性不足**：与图像和视频领域相比，文本生成动作领域的扩散模型扩展研究相对匮乏。
    *   **数据瓶颈**：缺乏大规模、多样化且经过精细清洗标注的数据集。
*   **整体含义**：论文旨在通过将 DiT（Diffusion Transformer）架构扩展至十亿级参数规模，并配合全阶段的训练范式和严谨的数据处理流程，解决上述问题，推动文本生成动作技术向商业成熟度迈进。

## 2. 论文提出的方法论

*   **核心思想**：提出 HY-Motion 1.0，这是首个成功扩展到十亿级参数规模的基于 DiT 的流匹配模型，用于文本生成 3D 人体动作。
*   **关键技术细节**：
    *   **全阶段训练范式**：
        1.  **大规模预训练**：使用超过 3000 小时的多样化运动数据，学习运动结构和文本-动作语义关联。
        2.  **高质量微调**：在 400 小时经过严格筛选的文本-动作对上进行微调，提升质量和指令遵循能力。
        3.  **强化学习对齐**：引入基于人类反馈（RLHF）和奖励模型的强化学习，确保生成动作符合人类偏好且物理合理。
    *   **数据处理流水线**：
        *   **来源**：野生视频（通过 HunyuanVideo 和 GVHMR 提取）、动作捕捉数据、3D 动画资产。
        *   **处理**：统一重定向至 SMPL-H 骨骼；通过去除重复、异常值检测、滑步检测等进行清洗；进行归一化（30fps，坐标系标准化）。
        *   **标注**：利用视觉语言模型（VLM，如 Gemini-2.5-Pro）自动生成初步标注，结合人工验证修正，最后利用 LLM 进行多样化和增强。
    *   **模型架构（HY-Motion DiT）**：
        *   **混合 Transformer 结构**：采用双流和单流结合。双流阶段独立处理动作和文本，通过联合注意力交互；单流阶段将二者融合，使用并行空间和通道注意力。
        *   **动作表示**：基于 SMPL-H（22 个关节，不含手部），使用 6D 连续旋转表示，移除显式速度和足部接触标签（观察到收敛更快）。
        *   **文本条件控制**：结合 Qwen3-8B（细粒度语义）和 CLIP-L（全局语义）。引入双向 Token 细化器解决 LLM 因果注意力的局限。
        *   **注意力机制**：采用非对称注意力掩码（Motion 看 Text，Text 不看 Motion 以防噪声污染）和窄带掩码（仅关注局部 121 帧窗口）。
    *   **辅助模块**：训练一个独立的 LLM 用于预测动作时长并优化用户提示词。

## 3. 实验设计

*   **数据集与场景**：
    *   构建了覆盖范围极广的自定义数据集，包含超过 3000 小时的动作数据（400 小时高质量）。
    *   涵盖 6 大类场景：位移、运动与竞技、健身与户外活动、日常活动、社交互动与休闲、游戏角色动作，共 200+ 细粒度类别。
*   **Benchmark**：
    *   在生成的运动质量和指令遵循能力两个维度上与现有方法进行比较。
*   **对比方法**：
    *   **DART**：基于掩码生成的方法。
    *   **LoM**：利用 LLM 扩展词汇的方法。
    *   **GoToZero**：基于 LLM 的动作生成方法。
    *   **MoMask**：基于掩码的生成模型。

## 4. 资源与算力

*   **说明**：提供的文本内容主要涵盖了摘要、引言、数据部分和模型设计部分，**截断了具体的实验和实现细节章节**。
*   **结论**：因此，文中**未明确提及**具体的 GPU 型号、GPU 数量、总训练时长或具体的 FLOPs 消耗等算力资源细节。

## 5. 实验数量与充分性

*   **说明**：同样由于文本截断，缺少具体的“实验”章节，无法得知具体的消融实验组数或详细的定量指标数值（如 FID, R-precision 等）。
*   **客观性评价**：
    *   论文展示了与多个当前 SOTA 方法（DART, LoM, GoToZero, MoMask）的对比（图 1），声称在运动质量和指令遵循能力上均有显著优势。
    *   数据集覆盖了 200+ 类别，具有很好的多样性。
    *   尽管无法看到具体数值，但从模型设计（如引入双向注意力、窄带掩码）和训练范式（三阶段训练）来看，研究设计较为全面。

## 6. 论文的主要结论与发现

*   **扩展定律的有效性**：证明了将 DiT 架构扩展至十亿级参数并结合流匹配目标，能显著提升文本生成动作模型的指令遵循能力和生成质量。
*   **全阶段训练的重要性**：大规模预训练、高质量微调和强化学习对齐的结合是构建高性能动作生成模型的关键路径。
*   **数据质量决定上限**：通过自动清洗与人工精细化标注结合构建的高质量数据集，是支撑大模型训练的基础。

## 7. 优点

*   **规模突破**：首个在文本生成动作领域成功将 DiT 架构扩展至十亿参数级别的工作。
*   **数据工程严谨**：提出了从多源采集、统一表示、严格过滤到 VLM+LLM 辅助标注的完整数据流水线，保证了数据的规模和质量。
*   **架构设计精巧**：
    *   引入双向 Token 细化器优化了 LLM 特征用于非自回归生成的效果。
    *   非对称注意力掩码有效防止了噪声倒灌。
    *   窄带掩码引入了局部连续性归纳偏置，降低了计算复杂度。
*   **训练范式全面**：创新性地引入了包含预训练、微调和 RLHF 的三阶段训练流程，不仅关注质量，还关注人类对齐。

## 8. 不足与局限

*   **手部细节缺失**：模型采用 22 个关节的 SMPL-H 模型（不含手部关节），这限制了生成精细手部动作（如弹钢琴、手势交流）的能力。
*   **信息缺失**：由于文本截断，无法评估模型在推理速度、显存占用等实际部署层面的性能，也无法了解具体的定量实验结果和潜在的错误案例分析。
*   **数据依赖风险**：虽然数据量大，但依赖视频动作提取算法（如 GVHMR）从视频中重建 3D 动作，可能会引入原始视频中不存在的噪声或伪影，尽管有清洗流程，但仍可能影响模型上限。
*   **计算成本隐忧**：十亿级参数的模型虽然提升了质量，但通常意味着较高的推理成本，可能在实时性要求高的应用场景中受限。