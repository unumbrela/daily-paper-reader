---
title: "How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs"
title_zh: 语境如何塑造真理：大语言模型中陈述级真值表示的几何变换
authors: "Shivam Adarsh, Maria Maistro, Christina Lioma"
date: 2026-01-10
pdf: "https://arxiv.org/pdf/2601.06599v1"
tags: ["query:sr-llm"]
score: 7.0
evidence: LLM激活中真值表示的分析
tldr: 本研究探讨了上下文如何影响大语言模型（LLM）内部对陈述真实性的几何表示。通过分析四个模型在不同数据集下的残差流激活，研究发现上下文会显著改变“真实向量”的方向和模长。研究揭示了模型层深、模型规模以及上下文相关性对真实性表征的影响，首次为上下文如何转换LLM激活空间中的真实性向量提供了几何特征描述。
motivation: 尽管已知LLM内部存在真实性向量，但上下文如何动态影响这些向量的几何特性尚不清楚。
method: 通过测量有无上下文情况下真实向量之间的夹角变化和相对模长，对比分析了不同规模模型在处理相关、无关及冲突上下文时的表现。
result: 真实向量在中间层趋于一致，添加上下文通常会放大真假表征之间的空间距离，且大模型主要通过方向变化而非模长来区分上下文相关性。
conclusion: 上下文对LLM真实性表征具有显著的几何塑造作用，且与模型参数知识冲突的上下文会引发更剧烈的几何变换。
---

## 摘要
大语言模型（LLMs）通常将陈述的真伪编码为其残差流激活中的向量。这些向量也被称为真值向量，在先前的研究中已得到探讨，但当引入语境时它们如何变化仍未被研究。我们通过测量以下指标来研究这一问题：（1）有无语境下真值向量之间的方向变化（$θ$）；（2）添加语境后真值向量的相对模长。通过对四种大语言模型和四个数据集的研究，我们发现：（1）真值向量在早期层大致正交，在中期层趋于一致，在后期层可能趋于稳定或继续增加；（2）添加语境通常会增加真值向量的模长，即激活空间中真假表示之间的分离度被放大；（3）较大的模型主要通过方向变化（$θ$）来区分相关语境与无关语境，而较小的模型则通过模长差异表现出这种区别。我们还发现，与参数化知识相冲突的语境比与参数化一致的语境产生更大的几何变化。据我们所知，这是首个对语境如何在大语言模型激活空间中转换真值向量进行几何表征的研究。

## Abstract
Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.