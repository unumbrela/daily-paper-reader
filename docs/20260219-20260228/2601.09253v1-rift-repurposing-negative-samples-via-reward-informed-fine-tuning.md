---
title: "RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning"
title_zh: RIFT：通过奖励告知微调重用负样本
authors: "Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan"
date: 2026-01-14
pdf: "https://arxiv.org/pdf/2601.09253v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 大语言模型对齐与奖励信息微调
tldr: 针对大语言模型对齐中监督微调（SFT）依赖昂贵专家数据以及拒绝采样微调（RFT）丢弃负样本导致的数据低效问题，本文提出 RIFT 框架。该方法通过奖励分数对模型自生成的正负样本进行加权损失计算，并引入稳定化损失函数防止训练崩溃。实验证明，RIFT 在数学推理任务上显著优于 RFT，实现了更高效的混合质量数据利用。
motivation: 现有的拒绝采样微调方法直接丢弃负样本，导致模型无法从错误尝试中学习且数据利用率低下。
method: 提出一种奖励告知微调框架，利用标量奖励对所有自生成样本的损失进行加权，并采用稳定化损失公式确保数值鲁棒性。
result: 在多个数学基准测试和基础模型上的实验显示，RIFT 的性能持续优于传统的 RFT 方法。
conclusion: RIFT 为利用混合质量自生成数据进行模型对齐提供了一种稳健且高效的替代方案。
---

## 摘要
虽然监督微调（SFT）和拒绝采样微调（RFT）是大型语言模型（LLM）对齐的标准方法，但它们要么依赖昂贵的专家数据，要么丢弃了有价值的负样本，导致数据效率低下。为了解决这一问题，我们提出了奖励告知微调（RIFT），这是一个简单且有效的框架，旨在利用所有自生成样本。与 RFT 的硬阈值筛选不同，RIFT 重新利用了负向轨迹，通过标量奖励对损失函数进行加权，从而同时从模型输出的正向和负向轨迹中学习。为了克服由朴素奖励集成引起的训练崩溃（即直接相乘会导致无界损失），我们引入了一种稳定的损失公式，确保了数值鲁棒性和优化效率。在多个基础模型和数学基准测试上的广泛实验表明，RIFT 的性能始终优于 RFT。我们的结果证明，对于使用质量参差不齐的自生成数据进行对齐，RIFT 是一种鲁棒且高效的数据利用替代方案。

## Abstract
While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.