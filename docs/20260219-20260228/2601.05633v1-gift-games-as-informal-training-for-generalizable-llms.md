---
title: "GIFT: Games as Informal Training for Generalizable LLMs"
title_zh: GIFT：将游戏作为通用大语言模型的非正式训练手段
authors: "Nuoyan Lyu, Bingbing Xu, Weihao Meng, Yige Yuan, Yang Zhang, Zhiyong Huang, Tat-Seng Chua, Huawei Shen"
date: 2026-01-09
pdf: "https://arxiv.org/pdf/2601.05633v1"
tags: ["query:sr-llm"]
score: 7.0
evidence: 利用游戏对通用LLM进行非正式训练
tldr: 本文提出将游戏作为大语言模型的非正式训练环境（GIFT），旨在弥补模型在策略创意和社会推理等“实践智慧”方面的不足。针对多任务学习中的性能退化问题，研究引入了嵌套训练框架，通过顺序任务组合强制模型同时掌握多种能力。实验表明，基于GRPO的强化学习在多种博弈游戏中不仅避免了任务干扰，还显著提升了模型在通用能力基准上的泛化表现。
motivation: 大语言模型在形式化学习上表现优异，但在缺乏目标导向指令、依赖交互反馈的非正式学习（如社会推理和策略灵活性）方面仍存在短板。
method: 提出一种嵌套训练框架，将多种游戏任务进行顺序组合，利用GRPO强化学习算法强制模型在单一训练流中同时优化多个目标。
result: 在矩阵博弈、井字棋和“谁是卧底”等游戏上的实验证明，该方法有效解决了多任务干扰问题，并增强了模型在广泛能力基准上的泛化能力。
conclusion: 将游戏作为非正式训练环境并结合嵌套训练框架，是提升大语言模型通用智能和实践智慧的有效路径。
---

## 摘要
尽管大语言模型（LLMs）在数学和代码生成等正式学习任务中取得了显著成功，但在体现人类认知特征的“实践智慧”和泛化智能（如策略创意和社会推理）方面仍面临挑战。这种差距源于缺乏非正式学习，而这种学习依赖于交互式反馈而非目标导向的指令。在本文中，我们提出将游戏作为大语言模型非正式学习的主要环境，利用其内在的奖励信号和抽象的复杂性来培养多样化的能力。为了解决多任务学习中观察到的性能退化问题，我们引入了一种嵌套训练框架。与优化隐式“或”目标的朴素任务混合不同，我们的框架采用顺序任务组合来强制执行显式的“与”目标，迫使模型同时掌握多种能力以获得最大奖励。通过在矩阵游戏、井字棋和“谁是卧底”游戏中应用基于 GRPO 的强化学习，我们证明了整合基于游戏的非正式学习不仅能防止任务干扰，还能显著增强模型在广泛的能力导向基准测试中的泛化能力。该框架和实现已公开。

## Abstract
While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the "practical wisdom" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit "OR" objective, our framework employs sequential task composition to enforce an explicit "AND" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.