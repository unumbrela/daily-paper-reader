---
title: "ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios"
title_zh: ViDoRe V3：复杂真实场景下检索增强生成（RAG）的全面评估
authors: "António Loison, Quentin Macé, Antoine Edy, Victor Xing, Tom Balough, Gabriel Moreira, Bo Liu, Manuel Faysse, Céline Hudelot, Gautier Viaud"
date: 2026-01-13
pdf: "https://arxiv.org/pdf/2601.08620v1"
tags: ["query:sr-llm"]
score: 10.0
evidence: 复杂场景下检索增强生成（RAG）的全面评估
tldr: 针对现有RAG基准测试在处理复杂视觉元素（如图表、表格）及多文档合成方面的不足，本文推出了ViDoRe v3。这是一个包含10个领域、2.6万页文档及3099个多语言人工验证查询的大规模多模态RAG基准。通过1.2万小时的人工标注，该基准提供了检索相关性、边界框定位及参考答案，旨在全面评估模型在真实视觉丰富场景下的检索与生成能力。
motivation: 现有的RAG基准多侧重于纯文本或单文档检索，无法有效评估模型在处理包含复杂视觉元素的真实世界文档时的综合表现。
method: 构建了一个涵盖10个专业领域的多模态基准，提供高质量的检索相关性、视觉定位标注及多语言参考答案，用于端到端评估RAG流程。
result: 实验显示视觉检索器优于文本检索器，后期交互模型和重排序能显著提升性能，但模型在非文本元素处理和细粒度视觉定位上仍存在挑战。
conclusion: ViDoRe v3为多模态RAG研究提供了重要工具，揭示了当前模型在视觉文档理解方面的局限性，并指出了未来混合检索与视觉上下文增强的研究方向。
---

## 摘要
检索增强生成（RAG）流水线必须应对超越简单单文档检索的挑战，例如解析视觉元素（表格、图表、图像）、跨文档综合信息以及提供准确的源定位。现有的基准测试未能捕捉到这种复杂性，通常侧重于文本数据、单文档理解，或将检索与生成孤立地进行评估。我们推出了 ViDoRe v3，这是一个全面的多模态 RAG 基准测试，其特点是针对视觉丰富的文档语料库进行多类型查询。它涵盖了 10 个不同专业领域的数据库，包含约 26,000 个文档页面，并配有 3,099 个经过人工验证的查询，每个查询均提供 6 种语言版本。通过 12,000 小时的人工标注工作，我们为检索相关性、边界框定位和验证参考答案提供了高质量的标注。我们对最先进的 RAG 流水线的评估表明，视觉检索器的表现优于文本检索器，延迟交互模型和文本重排序显著提升了性能，且混合或纯视觉上下文增强了答案生成的质量。然而，目前的模型在处理非文本元素、开放式查询和细粒度视觉定位方面仍面临困难。为了推动解决这些挑战，该基准测试以商业许可协议在 https://hf.co/vidore 发布。

## Abstract
Retrieval-Augmented Generation (RAG) pipelines must address challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks fail to capture this complexity, often focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. We introduce ViDoRe v3, a comprehensive multimodal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising ~26,000 document pages paired with 3,099 human-verified queries, each available in 6 languages. Through 12,000 hours of human annotation effort, we provide high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers. Our evaluation of state-of-the-art RAG pipelines reveals that visual retrievers outperform textual ones, late-interaction models and textual reranking substantially improve performance, and hybrid or purely visual contexts enhance answer generation quality. However, current models still struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. To encourage progress in addressing these challenges, the benchmark is released under a commercially permissive license at https://hf.co/vidore.

---

## 论文详细总结（自动生成）

### ViDoRe V3：复杂真实场景下多模态 RAG 的全面评估总结

#### 1. 核心问题与整体含义（研究动机和背景）
传统的检索增强生成（RAG）基准测试主要集中在纯文本、单文档检索或简单的 extractive（抽取式）问答上。然而，在真实的工业和专业场景中，文档通常包含大量的图表、表格和复杂的视觉布局。现有的基准测试往往将检索与生成孤立评估，且缺乏对多文档综合推理及精确视觉溯源（如边界框定位）的支持。论文提出了 **ViDoRe V3**，旨在填补这一空白，提供一个能够模拟真实世界复杂性、涵盖视觉丰富文档、支持多语言且具备细粒度人工标注的端到端 RAG 评估框架。

#### 2. 方法论：核心思想与技术细节
ViDoRe V3 的核心思想是通过“人机协作”的大规模标注，构建一个高质量的视觉文档 RAG 基准。
*   **三阶段标注流程**：
    1.  **文档收集**：涵盖金融、计算机、能源、制药等 10 个行业领域，共 2.6 万页 PDF。
    2.  **查询生成（Query Generation）**：采用混合模式，包括人工基于页面编写、人工基于摘要编写（避免抽取式偏见）以及基于 Qwen3-235B 的合成查询。查询被分类为 7 种类型（如多跳、比较、数值等）和 3 种格式（问题、关键词、指令）。
    3.  **答案检测与视觉定位**：利用 VLM（Qwen2.5-VL-32B）进行初步筛选，随后由 76 名专家进行人工复核，标注页面相关性、绘制支持证据的边界框（Bounding Box），并标注内容模态（文本、表格、图表等）。
*   **多语言扩展**：将查询翻译为 6 种语言（英、法、西、德、意、葡），挑战模型的跨语言检索能力。
*   **响应聚合**：使用 VLM 结合多个人工标注答案，生成最终的标准参考答案（Golden Answer）。

#### 3. 实验设计与对比方法
*   **数据集/场景**：涵盖 10 个专业领域语料库，其中 8 个公开，2 个作为私有测试集以防过拟合。
*   **评估维度**：
    1.  **检索（Retrieval）**：对比了文本检索器（如 BGE-M3, Qwen3-8B）和视觉检索器（如 ColPali, ColEmbed, Jina-v4）。
    2.  **重排序（Reranking）**：评估了文本重排序器（zerank-2）与视觉重排序器（jina-reranker-m0）的效果。
    3.  **生成（Generation）**：对比了 Gemini 3 Pro/Flash、GPT-5.2、Qwen3-VL 等模型在不同检索上下文（纯文本、纯图像、混合）下的表现。
    4.  **视觉定位（Grounding）**：评估模型生成边界框的准确性。

#### 4. 资源与算力
*   **人力投入**：投入了约 **12,000 小时** 的人工标注工作。
*   **计算资源**：使用了 NVIDIA H100 GPU，总计约 **3,000 小时** 的计算量。
*   **环境影响**：估计产生约 200 kg CO2e 的碳排放。

#### 5. 实验数量与充分性
实验设计非常充分且具有高度的客观性：
*   **多维度分析**：不仅对比了模型排名，还深入分析了查询类型、文档模态、相关页面数量对性能的影响。
*   **难度分级**：将查询分为“简单”和“困难”（基于模型是否能脱离上下文回答），有效排除了模型参数化知识的干扰。
*   **一致性检验**：对人工标注进行了 Gwet’s AC2 和 IoU/F1 评分，确保了基准数据的可靠性。
*   **端到端评估**：涵盖了从检索到重排再到生成的全链路，实验组数极多（涉及数十种模型组合）。

#### 6. 主要结论与发现
*   **视觉检索占优**：在相同参数规模下，视觉检索器（尤其是延迟交互模型）普遍优于文本检索器。
*   **重排序红利**：文本重排序能带来巨大提升（+13.2 NDCG@10），而当前的视觉重排序器效果有限。
*   **视觉上下文更佳**：在生成阶段，提供页面图像作为上下文比提供 OCR 文本更能提升答案准确率，尤其是在处理复杂查询时。
*   **混合模式最强**：结合文本和图像检索结果的“混合 RAG”在困难查询上表现最好。
*   **定位能力薄弱**：当前最先进的 VLM 在视觉定位（生成边界框）方面远逊于人类（F1 分数仅为人类的 1/6 左右）。

#### 7. 优点与亮点
*   **真实性极高**：采用真实行业文档而非合成数据，查询类型丰富，贴近实际业务需求。
*   **细粒度标注**：提供了边界框和模态标签，这在现有的 RAG 基准中非常罕见，支持对“可解释性”的评估。
*   **严谨的发布策略**：保留私有测试集，并集成到 MTEB 排行榜，有效防止了数据污染。
*   **商业友好**：采用商业许可协议发布，有利于工业界应用。

#### 8. 不足与局限
*   **语言覆盖有限**：虽然支持 6 种语言，但主要集中在西欧语系，缺乏对非拉丁语系（如中文、阿拉伯语）的支持。
*   **文档类型偏差**：主要关注长篇专业文档，未涵盖邮件、工单或手写扫描件等短篇/嘈杂文档。
*   **标注主观性**：尽管有复核机制，但对于“开放式推理”和“边界框范围”的定义仍存在一定的人工主观偏差。
*   **算力门槛**：视觉检索和多模态生成对计算资源要求极高，可能限制了小型研究团队的复现。

（完）
