---
title: "PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs"
title_zh: PlaM：无需训练的平台引导模型合并，旨在提升多模态大语言模型的视觉定位能力
authors: "Zijing Wang, Yongkang Liu, Mingyang Wang, Ercong Nie, Deyuan Chen, Zhengjie Zhao, Shi Feng, Daling Wang, Xiaocui Yang, Yifei Zhang, Hinrich Schütze"
date: 2026-01-12
pdf: "https://arxiv.org/pdf/2601.07645v1"
tags: ["query:sr-llm"]
score: 7.0
evidence: 多模态指令微调与模型合并
tldr: 针对多模态大模型（MLLM）在微调过程中出现的文本推理能力退化问题，本文提出了一种无需训练的合并框架PlaM。研究发现MLLM在处理视觉信息时存在三阶段模式，通过在特定阶段选择性地注入基础语言模型参数，PlaM能有效恢复推理能力并增强视觉定位。在5个模型和9个基准测试上的实验证明，该方法显著提升了模型在视觉任务中的表现，使注意力更聚焦于任务相关区域。
motivation: 多模态指令微调虽然提升了视觉理解，但往往会损害模型原有的语言推理能力，从而限制了整体性能。
method: 提出一种基于高原引导（Plateau-Guided）的模型合并方法，通过层级视觉掩码分析确定关键阶段，并将基础语言模型参数选择性注入MLLM。
result: 在5个主流MLLM和9个基准测试上的实验表明，该方法在无需额外训练的情况下显著提升了视觉定位和推理性能。
conclusion: 通过在特定层级恢复语言模型特性，可以有效缓解多模态退化现象，使模型注意力从分散转向聚焦，提升任务相关性。
---

## 摘要
多模态大语言模型（MLLMs）依赖于从其基础语言模型中继承的强大语言推理能力。然而，多模态指令微调却矛盾地降低了这种文本推理能力，从而损害了多模态性能。为了解决这一问题，我们提出了一个无需训练的框架来缓解这种退化。通过逐层视觉 Token 掩码，我们揭示了多模态大语言模型中普遍存在的三个阶段模式：早期模态分离、中期模态对齐和后期模态退化。通过分析 MLLMs 在不同阶段的行为，我们提出了一种平台引导的模型合并方法，选择性地将基础语言模型参数注入到 MLLMs 中。基于 5 个 MLLMs 在 9 个基准测试上的实验结果证明了我们方法的有效性。基于注意力的分析进一步揭示，合并操作将注意力从弥散、分散的模式转向了对任务相关视觉区域的聚焦定位。我们的代码库位于 https://github.com/wzj1718/PlaM。

## Abstract
Multimodal Large Language Models (MLLMs) rely on strong linguistic reasoning inherited from their base language models. However, multimodal instruction fine-tuning paradoxically degrades this text's reasoning capability, undermining multimodal performance. To address this issue, we propose a training-free framework to mitigate this degradation. Through layer-wise vision token masking, we reveal a common three-stage pattern in multimodal large language models: early-modal separation, mid-modal alignment, and late-modal degradation. By analyzing the behavior of MLLMs at different stages, we propose a plateau-guided model merging method that selectively injects base language model parameters into MLLMs. Experimental results based on five MLLMs on nine benchmarks demonstrate the effectiveness of our method. Attention-based analysis further reveals that merging shifts attention from diffuse, scattered patterns to focused localization on task-relevant visual regions. Our repository is on https://github.com/wzj1718/PlaM.