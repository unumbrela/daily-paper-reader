* [首页](/)
* Daily Papers
  * 2026-02-19 ~ 2026-02-28 <!--dpr-date:20260219-20260228-->
    * 精读区
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.06799v1-cirag-construction-integration-retrieval-and-adaptive-generation-for-multi-hop-question-answering"><div class="dpr-sidebar-title">CIRAG: Construction-Integration Retrieval and Adaptive Generation for Multi-hop Question Answering</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.06842v1-seeing-through-the-conflict-transparent-knowledge-conflict-handling-in-retrieval-augmented-generation"><div class="dpr-sidebar-title">Seeing through the Conflict: Transparent Knowledge Conflict Handling in Retrieval-Augmented Generation</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.07199v1-forward-versus-backward-comparing-reasoning-objectives-in-direct-preference-optimization"><div class="dpr-sidebar-title">Forward versus Backward: Comparing Reasoning Objectives in Direct Preference Optimization</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.08620v1-vidore-v3-a-comprehensive-evaluation-of-retrieval-augmented-generation-in-complex-real-world-scenarios"><div class="dpr-sidebar-title">ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.08670v1-parallel-context-of-experts-decoding-for-retrieval-augmented-generation"><div class="dpr-sidebar-title">Parallel Context-of-Experts Decoding for Retrieval Augmented Generation</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.08747v2-to-retrieve-or-to-think-an-agentic-approach-for-context-evolution"><div class="dpr-sidebar-title">To Retrieve or To Think? An Agentic Approach for Context Evolution</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
    * 速读区
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.09253v1-rift-repurposing-negative-samples-via-reward-informed-fine-tuning"><div class="dpr-sidebar-title">RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.09527v1-private-llm-inference-on-consumer-blackwell-gpus-a-practical-guide-for-cost-effective-local-deployment-in-smes"><div class="dpr-sidebar-title">Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.09865v1-advancing-model-refinement-muon-optimized-distillation-and-quantization-for-llm-deployment"><div class="dpr-sidebar-title">Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.10064v1-long-chain-reasoning-distillation-via-adaptive-prefix-alignment"><div class="dpr-sidebar-title">Long-Chain Reasoning Distillation via Adaptive Prefix Alignment</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.10825v1-reasoning-models-generate-societies-of-thought"><div class="dpr-sidebar-title">Reasoning Models Generate Societies of Thought</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.11024v1-prunerag-confidence-guided-query-decomposition-trees-for-efficient-retrieval-augmented-generation"><div class="dpr-sidebar-title">PruneRAG: Confidence-Guided Query Decomposition Trees for Efficient Retrieval-Augmented Generation</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.05633v1-gift-games-as-informal-training-for-generalizable-llms"><div class="dpr-sidebar-title">GIFT: Games as Informal Training for Generalizable LLMs</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：7.0/10（3.5/5）" aria-label="3.5 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:70%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.06599v1-how-context-shapes-truth-geometric-transformations-of-statement-level-truth-representations-in-llms"><div class="dpr-sidebar-title">How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：7.0/10（3.5/5）" aria-label="3.5 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:70%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.07645v1-plam-training-free-plateau-guided-model-merging-for-better-visual-grounding-in-mllms"><div class="dpr-sidebar-title">PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：7.0/10（3.5/5）" aria-label="3.5 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:70%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2601.08113v1-coordinated-cooling-and-compute-management-for-ai-datacenters"><div class="dpr-sidebar-title">Coordinated Cooling and Compute Management for AI Datacenters</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：7.0/10（3.5/5）" aria-label="3.5 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:70%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
      * <a class="dpr-sidebar-item-link" href="#/20260219-20260228/2602.01574v1-sgha-attack-semantic-guided-hierarchical-alignment-for-transferable-targeted-attacks-on-vision-language-models"><div class="dpr-sidebar-title">SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：6.0/10（3.0/5）" aria-label="3.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:60%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">sr-llm</span></div></a>
  * 2017-06-12
    * <a class="dpr-sidebar-item-link" href="#/201706/12/1706.03762v1-attention-is-all-you-need"><div class="dpr-sidebar-title">Attention Is All You Need</div><div class="dpr-sidebar-tags"><span class="dpr-sidebar-tag dpr-sidebar-tag-score"><span class="dpr-stars" title="评分：10.0/10（5.0/5）" aria-label="5.0 out of 5"><span class="dpr-stars-bg">☆☆☆☆☆</span><span class="dpr-stars-fill" style="width:100%">★★★★★</span></span></span> <span class="dpr-sidebar-tag dpr-sidebar-tag-keyword">SR</span> <span class="dpr-sidebar-tag dpr-sidebar-tag-query">SR</span></div></a>
